{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rbM2tC3zmPAn",
    "outputId": "18ecf2b8-2e4f-40ad-8c0a-1df22a427a87"
   },
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2UtEHybluza"
   },
   "outputs": [],
   "source": [
    "EARLY_STOPPING_PATIENCE = 15\n",
    "\n",
    "\n",
    "TARGET_PHONEMES_MAX = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "kLiXtbnFvA7U",
    "outputId": "17e110ca-d1a8-4a2b-bd00-f9012215c995",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check if GPU support\n",
    "#from tensorflow.python.client import device_lib\n",
    "#device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DsM1dJyXluzN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import difflib\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as K # beware of .python. here\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (BatchNormalization, Conv1D, Conv2D, Dense, Flatten, Input, \n",
    "                                     TimeDistributed, Activation, Bidirectional, SimpleRNN, GRU, LSTM, Reshape)\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "#from tensorflow.keras.backend import ctc_batch_cost, ctc_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn          0.22.1\n",
      "seaborn          0.9.0\n",
      "pandas           0.25.1\n",
      "watermark        1.8.1\n",
      "numpy            1.17.4\n",
      "tensorflow       2.2.0-dev20200331\n",
      "tensorflow.keras 2.2.4-tf\n",
      "matplotlib       3.0.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip -q install watermark\n",
    "import watermark\n",
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Remove an index from a dictionary.\n",
    "'''\n",
    "\n",
    "\n",
    "def copy_and_remove_symbols(symbol_dict, symbols):\n",
    "    symbol_dict2 = symbol_dict.copy()\n",
    "    for key in symbols:\n",
    "        if key in symbol_dict2:\n",
    "            del symbol_dict2[key]\n",
    "    return symbol_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audio</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-abilité</td>\n",
       "      <td>a.bi.li.te</td>\n",
       "      <td>False</td>\n",
       "      <td>suffixe</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-able</td>\n",
       "      <td>abl</td>\n",
       "      <td>False</td>\n",
       "      <td>suffixe</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-ac</td>\n",
       "      <td>ak</td>\n",
       "      <td>False</td>\n",
       "      <td>suffixe</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-acanthe</td>\n",
       "      <td>a.kɑ̃t</td>\n",
       "      <td>False</td>\n",
       "      <td>suffixe</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-ace</td>\n",
       "      <td>as</td>\n",
       "      <td>False</td>\n",
       "      <td>suffixe</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mot Prononciation  H_aspiré     Type Audio  Pré_valide Warn_code  \\\n",
       "0  -abilité    a.bi.li.te     False  suffixe    []        True         -   \n",
       "1     -able           abl     False  suffixe    []        True         -   \n",
       "2       -ac            ak     False  suffixe    []        True         -   \n",
       "3  -acanthe        a.kɑ̃t     False  suffixe    []        True         -   \n",
       "4      -ace            as     False  suffixe    []        True         -   \n",
       "\n",
       "  Warn_label  \n",
       "0          -  \n",
       "1          -  \n",
       "2          -  \n",
       "3          -  \n",
       "4          -  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fr_wiktionary_full.csv', sep='\\t')\n",
    "df = df[df.Audio != '-']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1206333, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHONEMES = [\n",
    "        # Voyelles\n",
    "        'i','e','ɛ','a','ɑ','ɔ','o','u','y','ø','œ','ə','ɛ̃','ɑ̃','ɔ̃','œ̃',\n",
    "        # Semi-consonnes\n",
    "        'j','w','ɥ', \n",
    "        # Consonnes\n",
    "        'p','t','k','b','d','ɡ','f','s','ʃ','v','z','ʒ','l','ʁ','m','n','ɲ','ŋ',\n",
    "    ]\n",
    "    \n",
    "def print_phonemes():\n",
    "    i = 0 \n",
    "    for i in range(len(PHONEMES) + 2):\n",
    "        if i == 0:\n",
    "            print(\"' 0\")\n",
    "        elif i == 1:\n",
    "            print('<SPACE> 1')\n",
    "        else:\n",
    "            print('%s %d' % (PHONEMES[i-2], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip samples whose pronunciation contains unknown phonemes\n",
    "df = df[~df['Prononciation'].isin(PHONEMES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1206153, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Prononciation.str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Prononciation</th>\n",
       "      <th>H_aspiré</th>\n",
       "      <th>Type</th>\n",
       "      <th>Audio</th>\n",
       "      <th>Pré_valide</th>\n",
       "      <th>Warn_code</th>\n",
       "      <th>Warn_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1113969</td>\n",
       "      <td>tonton</td>\n",
       "      <td>tɔ̃.tɔ̃</td>\n",
       "      <td>False</td>\n",
       "      <td>nom</td>\n",
       "      <td>['LL-Q150 (fra)-WikiLucas00-tonton.wav']</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Mot Prononciation  H_aspiré Type  \\\n",
       "1113969  tonton       tɔ̃.tɔ̃     False  nom   \n",
       "\n",
       "                                            Audio  Pré_valide Warn_code  \\\n",
       "1113969  ['LL-Q150 (fra)-WikiLucas00-tonton.wav']        True         -   \n",
       "\n",
       "        Warn_label  \n",
       "1113969          -  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Mot=='tonton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_map_str = \"\"\"\n",
    "' 0\n",
    "<SPACE> 1\n",
    "i 2\n",
    "e 3\n",
    "ɛ 4\n",
    "a 5\n",
    "ɑ 6\n",
    "ɔ 7\n",
    "o 8\n",
    "u 9\n",
    "y 10\n",
    "ø 11\n",
    "œ 12\n",
    "ə 13\n",
    "ɛ̃ 14\n",
    "ɑ̃ 15\n",
    "ɔ̃ 16\n",
    "œ̃ 17\n",
    "j 18\n",
    "w 19\n",
    "ɥ 20\n",
    "p 21\n",
    "t 22\n",
    "k 23\n",
    "b 24\n",
    "d 25\n",
    "ɡ 26\n",
    "f 27\n",
    "s 28\n",
    "ʃ 29\n",
    "v 30\n",
    "z 31\n",
    "ʒ 32\n",
    "l 33\n",
    "ʁ 34\n",
    "m 35\n",
    "n 36\n",
    "ɲ 37\n",
    "ŋ 38\n",
    "\"\"\"\n",
    "\n",
    "char_map = {}\n",
    "index_map = {}\n",
    "for line in char_map_str.strip().split('\\n'):\n",
    "    ch, index = line.split()\n",
    "    char_map[ch] = int(index)\n",
    "    index_map[int(index)+1] = ch\n",
    "index_map[2] = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phonemes(pronuncation):\n",
    "    \n",
    "    phonemes = []\n",
    "    for i in range(len(pronuncation)):\n",
    "        if i < len(pronuncation) - 1:\n",
    "            if pronuncation[i]=='̃':\n",
    "                continue\n",
    "            if pronuncation[i+1]=='̃':\n",
    "                if pronuncation[i] == 'ɑ':\n",
    "                    phoneme = 'ɑ̃'\n",
    "                elif pronuncation[i] == 'ɔ':\n",
    "                    phoneme = 'ɔ̃'\n",
    "                elif pronuncation[i] == 'œ':\n",
    "                    phoneme = 'œ̃'\n",
    "                elif pronuncation[i] == 'ɛ':\n",
    "                    phoneme = 'ɛ̃'\n",
    "                else:\n",
    "                    print('can not happen c=%s' % c)\n",
    "            else:\n",
    "                phoneme = pronuncation[i]\n",
    "        else:\n",
    "            if pronuncation[i]=='̃':\n",
    "                continue\n",
    "            else: \n",
    "                phoneme = pronuncation[i]\n",
    "        phonemes.append(phoneme)\n",
    "    return phonemes\n",
    "\n",
    "def get_padded_phonemes(pronunciation, str_len_max):\n",
    "    \n",
    "    padded_phonemes = get_phonemes(pronunciation)    \n",
    "    # pad list of phonemes\n",
    "    for i in range(len(padded_phonemes), str_len_max):\n",
    "        padded_phonemes.append(\"'\")\n",
    "    return padded_phonemes\n",
    "\n",
    "def get_tk_padded_phonemes(pronunciation, str_len_max):\n",
    "    \n",
    "    padded_phonemes = get_padded_phonemes(pronunciation, str_len_max)\n",
    "    tk_padded_phonemes = []\n",
    "    # tokenize each phoneme\n",
    "    for phoneme in padded_phonemes:\n",
    "        tk_padded_phonemes.append(char_map[phoneme])\n",
    "    \n",
    "    nb = len(padded_phonemes)\n",
    "    np_array = np.array(tk_padded_phonemes).reshape(1, nb)\n",
    "    \n",
    "    return np_array\n",
    "    \n",
    "assert get_phonemes('tɛ̃bʁ') == ['t', 'ɛ̃', 'b', 'ʁ']\n",
    "assert get_phonemes('tɔ̃tɔ̃') == ['t', 'ɔ̃', 't', 'ɔ̃']\n",
    "assert get_padded_phonemes('tɛ̃bʁ', 6) == ['t', 'ɛ̃', 'b', 'ʁ', \"'\", \"'\"]\n",
    "assert np.array_equal(get_tk_padded_phonemes('tɛ̃bʁ', 6), np.array([[22, 14, 24, 34,  0,  0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_files_names(audio_files_str, verbose=False):\n",
    "    if verbose:\n",
    "        print('audio_files=*%s*' % audio_files_str)\n",
    "    if audio_files_str == '[]':\n",
    "        if verbose:\n",
    "            print('empty list')\n",
    "        audio_file_names = []\n",
    "    else:\n",
    "        files_string = audio_files_str[2:-2] + '\\', \\''\n",
    "        audio_file_names = files_string.split('\\', \\'')\n",
    "        audio_file_names = audio_file_names[:-1]\n",
    "        if verbose:\n",
    "            for f in audio_file_names:\n",
    "                print('file=%s' % f)\n",
    "    return audio_file_names\n",
    "\n",
    "assert get_audio_files_names(\"[]\") == []\n",
    "assert get_audio_files_names(\"['a.wav']\") == ['a.wav']\n",
    "assert get_audio_files_names(\"['a.wav', 'b.wav', 'c.wav']\") == ['a.wav', 'b.wav', 'c.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPHJLbfPnD2m"
   },
   "outputs": [],
   "source": [
    "AUDIO_DIR = 'audio/'\n",
    "TIME_MAX = 2.0\n",
    "MFCC_DIR = 'mfcc_' + str(TIME_MAX) + '/'\n",
    "\n",
    "allowed_IPA_letters = [\n",
    "            'a', 'b', 'd', 'e', 'f', 'i', 'j', 'k', 'l', \n",
    "            'm', 'n', 'o','p', 's', 't', 'u', 'v', 'w', 'y', \n",
    "            'z', 'ø', 'ŋ', 'œ', 'ɑ', 'ɔ', 'ə', 'ɛ', 'ɡ', 'ɥ',\n",
    "            'ɲ', 'ʁ', 'ʃ', 'ʒ', '̃'   \n",
    "]\n",
    "\n",
    "''' Retrieve the dataset \n",
    "'''\n",
    "def get_data(df, n_max=1000000, verbose=False):\n",
    "\n",
    "    global TARGET_PHONEMES_MAX\n",
    "    bad_letters = {}\n",
    "    \n",
    "    mfcc_max=sys.float_info.min\n",
    "    mfcc_min=sys.float_info.max     \n",
    "    \n",
    "    #df = pd.read_csv('fr_wiktionary_waves.csv', sep='\\t')\n",
    "    df = df[df.Audio != '-']\n",
    "    indexes_to_drop = []\n",
    "    \n",
    "    # reindex the dataframe by the Pronunciation column lenght\n",
    "    #s = df.Prononciation.str.len().sort_values(ascending=True).index\n",
    "    #df = df.reindex(s)\n",
    "    #df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    df = df[df.Prononciation.str.len() <= TARGET_PHONEMES_MAX]\n",
    "    print('df.shape:%d (with len(prononciation)<%d)' % (df.shape[0], TARGET_PHONEMES_MAX))\n",
    "    # clean pronunciation\n",
    "    # rows having a pronnuciation with \"bad\" caracter will be dropped from the df\n",
    "    for index, row in df.iterrows():\n",
    "        prononciation = row['Prononciation']\n",
    "        prononciation = prononciation.replace('(','').replace(')','').replace('‿','').\\\n",
    "        replace('.','').replace(' ','').replace('͡','').replace('-','').replace('ˈ','')\n",
    "        #prononciation = merge_nasals(prononciation)\n",
    "        for phoneme in prononciation:            \n",
    "            if phoneme not in allowed_IPA_letters:\n",
    "                if phoneme not in bad_letters.keys():\n",
    "                    bad_letters[phoneme] = 0\n",
    "                bad_letters[phoneme] += 1\n",
    "                indexes_to_drop.append(index)\n",
    "                break\n",
    "        df.at[index, 'Prononciation'] = prononciation\n",
    "            \n",
    "    print('bad_letters=', bad_letters)\n",
    "    df = df.drop(indexes_to_drop)\n",
    "    \n",
    "    # read all mfcc file to learn the maximum shape of the samples\n",
    "    mfcc_shape_t = 0\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        #wav_files = get_audio_files_names(row['Audio'])\n",
    "        #for wav_file in wav_files:\n",
    "        #    if 'WikiLucas' in wav_file:\n",
    "                \n",
    "        mfcc_file = ''\n",
    "        wav_files = get_audio_files_names(row['Audio'])\n",
    "        for wav_file in wav_files:\n",
    "            if 'WikiLucas' in wav_file:\n",
    "                mfcc_file = wav_file.replace('.wav','.npy').replace(' ','_')                \n",
    "                mfcc_filename = MFCC_DIR + mfcc_file\n",
    "                if os.path.exists(mfcc_filename):\n",
    "                    mfcc = np.load(mfcc_filename)\n",
    "                    mfcc_shape_t = max(mfcc_shape_t, mfcc.shape[1])\n",
    "                    mfcc_shape_d = mfcc.shape[0]\n",
    "                    break\n",
    "    n=0\n",
    "    n_ko=0\n",
    "    print('mfcc_shape_t:%d', mfcc_shape_t)\n",
    "    # numpy shapes to be ready to be used as inputs and targets\n",
    "    mfccs = np.zeros((n_max, mfcc_shape_t, mfcc_shape_d))\n",
    "    phonemess = np.zeros((n_max, TARGET_PHONEMES_MAX))\n",
    "    mots = []\n",
    "    prononciations = []\n",
    "    \n",
    "    for index, row in df.sample(df.shape[0]).iterrows():                \n",
    "        \n",
    "        mfcc_file = ''\n",
    "        wav_files = get_audio_files_names(row['Audio'])\n",
    "        for wav_file in wav_files:\n",
    "            if not 'WikiLucas' in wav_file:\n",
    "                continue\n",
    "            else:\n",
    "                mfcc_file = wav_file.replace('.wav','.npy').replace(' ','_')\n",
    "                break\n",
    "        \n",
    "        if mfcc_file == '':\n",
    "            continue\n",
    "        \n",
    "        mfcc_filename = MFCC_DIR + mfcc_file\n",
    "        if os.path.exists(mfcc_filename):\n",
    "            mfcc = np.load(mfcc_filename)\n",
    "            if verbose:            \n",
    "                print('mfcc.shape:', mfcc.shape)\n",
    "            \n",
    "            if mfcc[-1][-1] != 0.0:\n",
    "                try:\n",
    "                    print('pb for %s' % row['Wav_file'])\n",
    "                except:\n",
    "                    print('#')\n",
    "                continue\n",
    "            \n",
    "            # add the mfcc in the mfccs table\n",
    "            mfccs[n,:,:] = mfcc.transpose()[:,:]\n",
    "        \n",
    "            # fetch the prononciation\n",
    "            mot = row['Mot']\n",
    "            prononciation = row['Prononciation']\n",
    "            phonemes = get_tk_padded_phonemes(prononciation, TARGET_PHONEMES_MAX)\n",
    "            # add the mfcc in the mfccs table\n",
    "            phonemess[n,:] = phonemes\n",
    "            mots.append(mot)\n",
    "            prononciations.append(prononciation)\n",
    "            n += 1\n",
    "            if n>n_max-1:\n",
    "                break\n",
    "        else:\n",
    "            n_ko+=1\n",
    "            \n",
    "    print('n:',n)\n",
    "    print('n_ko:',n_ko)\n",
    "    #mfccs = (mfccs - mfccs.min()) / (mfccs.max() - mfccs.min())\n",
    "    #mfccs = mfccs - mfccs.mean()\n",
    "    #mfccs = mfccs.astype(int)\n",
    "    print('mfccs.shape:', mfccs.shape)\n",
    "        \n",
    "    return n, mfccs, phonemess, prononciations, mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape:488700 (with len(prononciation)<10)\n",
      "bad_letters= {}\n",
      "mfcc_shape_t:%d 87\n",
      "n: 9989\n",
      "n_ko: 131\n",
      "mfccs.shape: (9989, 87, 40)\n",
      "CPU times: user 1min 51s, sys: 452 ms, total: 1min 52s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "#%time mfccs, phonemes, prononciations, mots = get_data(df, NB_TRAINING_SAMPLES+NB_TEST_SAMPLES, verbose=False)    \n",
    "#%time n, mfccs, phonemes, prononciations, mots = get_data(df, n_max=238685)    \n",
    "%time n, mfccs, phonemes, prononciations, mots = get_data(df, n_max=9989) \n",
    "#%time n, mfccs, phonemes, prononciations, mots = get_data(df, n)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB_TRAINING_SAMPLES:9889\n",
      "NB_TEST_SAMPLES:100\n"
     ]
    }
   ],
   "source": [
    "NB_TEST_SAMPLES = 100\n",
    "NB_TRAINING_SAMPLES = n - NB_TEST_SAMPLES\n",
    "print('NB_TRAINING_SAMPLES:%d' % NB_TRAINING_SAMPLES)\n",
    "print('NB_TEST_SAMPLES:%d' % NB_TEST_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9989, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9989, 87, 40)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9989"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mfccs[0:NB_TRAINING_SAMPLES,]\n",
    "Y_train = phonemes[0:NB_TRAINING_SAMPLES]\n",
    "X_test = mfccs[NB_TRAINING_SAMPLES:,]\n",
    "Y_test = phonemes[NB_TRAINING_SAMPLES:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mean = X_train.mean()\n",
    "x_train_std = X_train.std()\n",
    "X_train -= x_train_mean\n",
    "X_train /= x_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test -= x_train_mean\n",
    "X_test /= x_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual loss calculation\n",
    "def ctc_lambda_func(args):\n",
    "  y_pred, labels, input_length, label_length = args\n",
    "  # From Keras example image_ocr.py:\n",
    "  # the 2 is critical here since the first couple outputs of the RNN\n",
    "  # tend to be garbage:\n",
    "  #y_pred = y_pred[:, 2:, :]\n",
    "  y_pred = y_pred[:, :, :]\n",
    "  return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input tensor for sequences of 46 timesteps,\n",
    "# each containing a 40-dimensional vector\n",
    "\n",
    "class MyModel(object):\n",
    "\n",
    "    # CTC Layer implementation using Lambda layer\n",
    "    # (because Keras doesn't support extra prams on loss function)\n",
    "    def CTC(self, name, args):\n",
    "        return Lambda(ctc_lambda_func, output_shape=(1,), name=name)(args)\n",
    " \n",
    "    def __init__(self, D, max_string_len, C, T, conv = '1D'):\n",
    "        print('D=%d, max_string_len=%d, C=%d' % (D, max_string_len, C))\n",
    "        \n",
    "        \n",
    "        filters = 512\n",
    "        units = filters\n",
    "        kernel_size_1d = 3\n",
    "        kernel_size_2d = (3,3)\n",
    "        conv_stride = 1 #3\n",
    "        conv_border_mode = 'same'#'valid'\n",
    "                  \n",
    "        if conv == '1D':\n",
    "            self.input_data = Input(name='the_input', shape=(None, D), dtype='float32') #D=40\n",
    "            \n",
    "            self.conv_1d_01 = Conv1D(filters, kernel_size_1d, \n",
    "                                        strides=conv_stride, \n",
    "                                        padding=conv_border_mode,\n",
    "                                        activation='relu',\n",
    "                                        name='conv_1d_01')(self.input_data)\n",
    "\n",
    "            self.bn_01_layer = BatchNormalization(name='bn_01_layer')(self.conv_1d_01)\n",
    "\n",
    "            self.conv_1d_02 = Conv1D(filters, kernel_size_1d, \n",
    "                                        strides=conv_stride, \n",
    "                                        padding=conv_border_mode,\n",
    "                                        activation='relu',\n",
    "                                        name='conv_1d_02')(self.bn_01_layer)\n",
    "\n",
    "            self.bn_02_layer = BatchNormalization(name='bn_02_layer')(self.conv_1d_02)\n",
    "\n",
    "        elif conv == '2D':\n",
    "            self.input_data = Input(name='the_input', shape=(T, D, 1), dtype='float32') #D=40\n",
    "        \n",
    "            self.conv_2d_01 = Conv2D(filters, kernel_size_2d, \n",
    "                                        strides=conv_stride, \n",
    "                                        padding=conv_border_mode,\n",
    "                                        activation='relu',\n",
    "                                        name='conv_2d_01')(self.input_data)\n",
    "\n",
    "            self.bn_01_layer = BatchNormalization(name='bn_01_layer')(self.conv_2d_01)\n",
    "\n",
    "            self.conv_2d_02 = Conv2D(filters, kernel_size_2d, \n",
    "                                        strides=conv_stride, \n",
    "                                        padding=conv_border_mode,\n",
    "                                        activation='relu',\n",
    "                                        name='conv_2d_02')(self.bn_01_layer)\n",
    "\n",
    "            self.bn_02_layer = BatchNormalization(name='bn_02_layer')(self.conv_1d_02)\n",
    "\n",
    "            self.bn_02_layer = Flatten()(self.bn_02_layer)        \n",
    "            self.bn_02_layer = Reshape((-1, D))(self.bn_022_layer)\n",
    "            self.bn_02_layer = TimeDistributed(Dense(D), name=\"td000\")(self.bn_02_layer)\n",
    "            \n",
    "        else:\n",
    "            print('conv_type=%s not supported' % conv_tpye)\n",
    "            \n",
    "        rnn0 = keras.layers.LSTM(units, return_sequences=True, dropout=0.1, name=\"rnn\")\n",
    "        self.bidir_rnn1 = Bidirectional(rnn0, name='bidir_rnn_1_layer')(self.bn_02_layer)\n",
    "        \n",
    "        self.bn_1 = BatchNormalization(name='bn_1_layer')(self.bidir_rnn1)\n",
    "        \n",
    "        rnn = keras.layers.LSTM(units, return_sequences=True, dropout=0.1, name=\"rnn2\")\n",
    "        self.bidir_rnn2 = Bidirectional(rnn, name='bidir_rnn_2_layer')(self.bn_1)\n",
    "        \n",
    "        self.bn_2 = BatchNormalization(name='bn_2_layer')(self.bidir_rnn2)\n",
    "        \n",
    "        self.outputs = TimeDistributed(Dense(C), name=\"td\")(self.bidir_rnn2)\n",
    "        \n",
    "        self.y_pred = Activation('softmax', name='softmax')(self.outputs)\n",
    "\n",
    "        self.labels = Input(name='the_labels', shape=[max_string_len], dtype='float32')\n",
    "        self.input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "        self.label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "        self.loss_out = self.CTC('ctc', [self.y_pred, self.labels, self.input_length, self.label_length])\n",
    "\n",
    "        self.model = Model(inputs=[self.input_data, self.labels, self.input_length, self.label_length], outputs=self.loss_out)\n",
    "\n",
    "        \n",
    "        #self.model.output_length = lambda x: cnn_output_length(x, kernel_size, conv_border_mode, conv_stride)\n",
    "        \n",
    "        self.model.summary()\n",
    "\n",
    "        #adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "        adam = Adam()\n",
    "        self.model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=adam)\n",
    "\n",
    "    def fit(self, X_train, Y_train, input_length, label_length, loss, epochs, \n",
    "            batch_size, callbacks, validation_split, verbose):\n",
    "      history = self.model.fit([X_train, Y_train, input_length, label_length], loss, \n",
    "                               epochs=epochs, batch_size=batch_size, \n",
    "                               callbacks=callbacks,\n",
    "                               validation_split=validation_split, verbose=verbose, )\n",
    "      return history \n",
    "      \n",
    "    def predict(self, input_batch):\n",
    "        return self.test_function([input_batch, True])[0]  # the first 0 indicates test\n",
    "\n",
    "    @property\n",
    "    def test_function(self):\n",
    "        # captures output of softmax so we can decode the output during visualization\n",
    "        #return K.function([self.input_data, K.symbolic_learning_phase()], [self.y_pred, K.symbolic_learning_phase()])\n",
    "        return K.function([self.input_data, K.symbolic_learning_phase()], [self.y_pred, K.symbolic_learning_phase()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (9889, 87, 40)\n",
      "Y_train.shape (9889, 10)\n",
      "T:%d 87\n",
      "D:%d 40\n",
      "input_length[0:2]: [87. 87.]\n",
      "input_length.shape (9889,)\n",
      "label_length[0:2]: [10. 10.]\n",
      "loss.shape[0:2] (9889,)\n",
      "C=nb_ipa_letters=40\n"
     ]
    }
   ],
   "source": [
    "# outputs = {'ctc': np.zeros([size])}  # dummy data for dummy loss function\n",
    "#input_length = X_train.shape[1]\n",
    "#print('input_length', input_length)\n",
    "\n",
    "print('X_train.shape', X_train.shape)\n",
    "print('Y_train.shape', Y_train.shape)\n",
    "      \n",
    "N = NB_TRAINING_SAMPLES\n",
    "T = mfccs.shape[1]\n",
    "print('T:%d', T)\n",
    "D = mfccs.shape[2]\n",
    "print('D:%d', D)\n",
    "\n",
    "input_length = np.zeros([N])\n",
    "for i in range(N):\n",
    "    input_length[i] = T\n",
    "print('input_length[0:2]:', input_length[0:2])\n",
    "print('input_length.shape', input_length.shape)\n",
    "\n",
    "label_length = np.zeros([N])\n",
    "for i in range(N):\n",
    "    label_length[i] = TARGET_PHONEMES_MAX\n",
    "print('label_length[0:2]:', label_length[0:2])\n",
    "\n",
    "#print('input_length.shape', input_length.shape)\n",
    "\n",
    "loss = np.zeros([N])\n",
    "\n",
    "print('loss.shape[0:2]', loss.shape[0:2])\n",
    "\n",
    "\n",
    "C = len(char_map.keys()) + 1\n",
    "print('C=nb_ipa_letters=%d' % C)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D=40, max_string_len=10, C=40\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          [(None, None, 40)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1d_01 (Conv1D)             (None, None, 512)    61952       the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_01_layer (BatchNormalization (None, None, 512)    2048        conv_1d_01[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_1d_02 (Conv1D)             (None, None, 512)    786944      bn_01_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_02_layer (BatchNormalization (None, None, 512)    2048        conv_1d_02[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidir_rnn_1_layer (Bidirectiona (None, None, 1024)   4198400     bn_02_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_1_layer (BatchNormalization) (None, None, 1024)   4096        bidir_rnn_1_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bidir_rnn_2_layer (Bidirectiona (None, None, 1024)   6295552     bn_1_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "td (TimeDistributed)            (None, None, 40)     41000       bidir_rnn_2_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, None, 40)     0           td[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 11,392,040\n",
      "Trainable params: 11,387,944\n",
      "Non-trainable params: 4,096\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mmodel = MyModel(D, TARGET_PHONEMES_MAX, C, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_output_length(input_length, filter_size, border_mode, stride,\n",
    "                       dilation=1):\n",
    "    \"\"\" Compute the length of the output sequence after 1D convolution along\n",
    "        time. Note that this function is in line with the function used in\n",
    "        Convolution1D class from Keras.\n",
    "    Params:\n",
    "        input_length (int): Length of the input sequence.\n",
    "        filter_size (int): Width of the convolution kernel.\n",
    "        border_mode (str): Only support `same` or `valid`.\n",
    "        stride (int): Stride size used in 1D convolution.\n",
    "        dilation (int)\n",
    "    \"\"\"\n",
    "    if input_length is None:\n",
    "        return None\n",
    "    assert border_mode in {'same', 'valid'}\n",
    "    dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n",
    "    if border_mode == 'same':\n",
    "        output_length = input_length\n",
    "    elif border_mode == 'valid':\n",
    "        output_length = input_length - dilated_filter_size + 1\n",
    "    return (output_length + stride - 1) // stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (9889, 87, 40)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#import numpy\n",
    "#numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train[6000:6001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5., 24.,  4., 22.,  2., 34.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abêtir'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abɛtiʁ'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prononciations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "279/279 [==============================] - 19s 68ms/step - loss: 16.1745 - val_loss: 37.0067\n",
      "Epoch 2/200\n",
      "279/279 [==============================] - 17s 62ms/step - loss: 5.9134 - val_loss: 6.6803\n",
      "Epoch 3/200\n",
      "279/279 [==============================] - 18s 65ms/step - loss: 3.9142 - val_loss: 3.8360\n",
      "Epoch 4/200\n",
      "279/279 [==============================] - 17s 62ms/step - loss: 3.0441 - val_loss: 3.8626\n",
      "Epoch 5/200\n",
      "279/279 [==============================] - 17s 61ms/step - loss: 2.4585 - val_loss: 3.1989\n",
      "Epoch 6/200\n",
      "279/279 [==============================] - 17s 61ms/step - loss: 2.2218 - val_loss: 5.1616\n",
      "Epoch 7/200\n",
      "279/279 [==============================] - 17s 62ms/step - loss: 1.7700 - val_loss: 2.8604\n",
      "Epoch 8/200\n",
      "279/279 [==============================] - 17s 62ms/step - loss: 1.4820 - val_loss: 2.7655\n",
      "Epoch 9/200\n",
      "279/279 [==============================] - 17s 62ms/step - loss: 1.3094 - val_loss: 2.7990\n",
      "Epoch 10/200\n",
      "279/279 [==============================] - 17s 62ms/step - loss: 1.2690 - val_loss: 2.8449\n",
      "Epoch 11/200\n",
      "279/279 [==============================] - 17s 62ms/step - loss: 1.1642 - val_loss: 2.6727\n",
      "Epoch 12/200\n",
      "279/279 [==============================] - 17s 62ms/step - loss: 0.9931 - val_loss: 2.9479\n",
      "Epoch 13/200\n",
      "279/279 [==============================] - 17s 62ms/step - loss: 1.0127 - val_loss: 2.8006\n",
      "Epoch 14/200\n",
      "279/279 [==============================] - 17s 62ms/step - loss: 0.8505 - val_loss: 2.7505\n",
      "Epoch 15/200\n",
      "279/279 [==============================] - 17s 62ms/step - loss: 0.7695 - val_loss: 2.9215\n",
      "Epoch 16/200\n",
      "279/279 [==============================] - 17s 62ms/step - loss: 0.7471 - val_loss: 3.0693\n",
      "Epoch 17/200\n",
      "279/279 [==============================] - 17s 62ms/step - loss: 0.6648 - val_loss: 2.7971\n",
      "Epoch 18/200\n",
      "279/279 [==============================] - 17s 62ms/step - loss: 0.6322 - val_loss: 3.0190\n",
      "Epoch 19/200\n",
      "279/279 [==============================] - 18s 66ms/step - loss: 0.6746 - val_loss: 2.7329\n",
      "Epoch 20/200\n",
      "279/279 [==============================] - 18s 66ms/step - loss: 0.7173 - val_loss: 2.9422\n",
      "Epoch 21/200\n",
      "279/279 [==============================] - 18s 66ms/step - loss: 0.6828 - val_loss: 3.1200\n"
     ]
    }
   ],
   "source": [
    "history = mmodel.fit(X_train, Y_train, input_length, label_length, loss, epochs=200, batch_size=32, callbacks=callbacks_list, validation_split=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 87, 40)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test NB_TEST_SAMPLES samples\n",
    "res = mmodel.predict(X_test[0:NB_TEST_SAMPLES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 87, 40)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:5943: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    }
   ],
   "source": [
    "s = K.ctc_decode(y_pred=res, input_length=input_length[0:res.shape[0]], greedy=True)\n",
    "#print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[MOT] /PRONONCIATION WIKTIONNAIRE/ vs /PPRONONCIATION PREDITE/<br>[ressortir] /ʁəsɔʁtiʁ/ vs /ʁəsɔʁtiʁ/: <span style=\"color: #00ff00\">ok</span><br>[téléthèse] /teletɛz/ vs /ʁeetɛz/: <span style=\"color: #ff0000\">ko</span><br>[abstrait] /apstʁɛ/ vs /akstʁɛ/: <span style=\"color: #ff0000\">ko</span><br>[celation] /səlasjɔ̃/ vs /slasjɔ̃/: <span style=\"color: #ff0000\">ko</span><br>[assécher] /aseʃe/ vs /aseʃe/: <span style=\"color: #00ff00\">ok</span><br>[fusiller] /fuzije/ vs /fyzje/: <span style=\"color: #ff0000\">ko</span><br>[feu] /fø/ vs /fl/: <span style=\"color: #ff0000\">ko</span><br>[oit] /wat/ vs /wat/: <span style=\"color: #00ff00\">ok</span><br>[embaucheuse] /ɑ̃boʃøz/ vs /ɑ̃bɔʃøz/: <span style=\"color: #ff0000\">ko</span><br>[commotion] /kɔmɔsjɔ̃/ vs /kosjɔ̃/: <span style=\"color: #ff0000\">ko</span><br>[régresser] /ʁeɡʁɛse/ vs /ʁeɡʁɛse/: <span style=\"color: #00ff00\">ok</span><br>[celui-ci] /səlɥisi/ vs /səlisi/: <span style=\"color: #ff0000\">ko</span><br>[abîmer] /abime/ vs /abime/: <span style=\"color: #00ff00\">ok</span><br>[acuminé] /akymine/ vs /akymine/: <span style=\"color: #00ff00\">ok</span><br>[lunistice] /lynistis/ vs /ynistis/: <span style=\"color: #ff0000\">ko</span><br>[mixtion] /mikstjɔ̃/ vs /mikstjɔ̃/: <span style=\"color: #00ff00\">ok</span><br>[gletter] /ɡlɛte/ vs /ɡlɛte/: <span style=\"color: #00ff00\">ok</span><br>[regeeker] /ʁəɡike/ vs /ʁəɡike/: <span style=\"color: #00ff00\">ok</span><br>[survirer] /syʁviʁe/ vs /syʁviʁe/: <span style=\"color: #00ff00\">ok</span><br>[pileuse] /piløz/ vs /piløz/: <span style=\"color: #00ff00\">ok</span><br>[bischof] /biʃɔf/ vs /biʃɔf/: <span style=\"color: #00ff00\">ok</span><br>[concourir] /kɔ̃kuʁiʁ/ vs /kɔ̃kuʁiʁ/: <span style=\"color: #00ff00\">ok</span><br>[balayeur] /balɛjœʁ/ vs /balɛjœʁ/: <span style=\"color: #00ff00\">ok</span><br>[brichauder] /bʁiʃode/ vs /bʁiʃode/: <span style=\"color: #00ff00\">ok</span><br>[suer] /sɥe/ vs /sɥe/: <span style=\"color: #00ff00\">ok</span><br>[tictacquer] /tiktake/ vs /tiktake/: <span style=\"color: #00ff00\">ok</span><br>[vendeuse] /vɑ̃døz/ vs /vɑ̃døz/: <span style=\"color: #00ff00\">ok</span><br>[marqueuse] /maʁkøz/ vs /maʁkøz/: <span style=\"color: #00ff00\">ok</span><br>[livre] /livʁ/ vs /livʁ/: <span style=\"color: #00ff00\">ok</span><br>[nu] /ny/ vs /ny/: <span style=\"color: #00ff00\">ok</span><br>[circuiter] /siʁkɥite/ vs /siʁkɥite/: <span style=\"color: #00ff00\">ok</span><br>[teube] /tœb/ vs /təb/: <span style=\"color: #ff0000\">ko</span><br>[gueules] /ɡœl/ vs /ɡl/: <span style=\"color: #ff0000\">ko</span><br>[râpé] /ʁape/ vs /ʁape/: <span style=\"color: #00ff00\">ok</span><br>[rigidement] /ʁiʒidmɑ̃/ vs /ʁiʒidmɑ̃/: <span style=\"color: #00ff00\">ok</span><br>[accordeuse] /akɔʁdøz/ vs /akɔʁdøz/: <span style=\"color: #00ff00\">ok</span><br>[tièdement] /tjɛdmɑ̃/ vs /tjɛdmɑ̃/: <span style=\"color: #00ff00\">ok</span><br>[métalleuse] /metaløz/ vs /metaløz/: <span style=\"color: #00ff00\">ok</span><br>[récriveuse] /ʁekʁivøz/ vs /ʁekivøz/: <span style=\"color: #ff0000\">ko</span><br>[fadet] /fadɛt/ vs /fade/: <span style=\"color: #ff0000\">ko</span><br>[raffermir] /ʁafɛʁmiʁ/ vs /ʁafɛʁmiʁ/: <span style=\"color: #00ff00\">ok</span><br>[accouardir] /akwaʁdiʁ/ vs /akwaʁdiʁ/: <span style=\"color: #00ff00\">ok</span><br>[pays] /pei/ vs /pɛi/: <span style=\"color: #ff0000\">ko</span><br>[télescope] /teleskɔp/ vs /tenɛskɔp/: <span style=\"color: #ff0000\">ko</span><br>[chaise] /ʃɛz/ vs /kaɛz/: <span style=\"color: #ff0000\">ko</span><br>[initiale] /inisjal/ vs /iisjal/: <span style=\"color: #ff0000\">ko</span><br>[alvéolé] /alveɔle/ vs /aləveɔle/: <span style=\"color: #ff0000\">ko</span><br>[optique] /ɔptik/ vs /pɔptik/: <span style=\"color: #ff0000\">ko</span><br>[mer] /mɛʁ/ vs /bɛʁ/: <span style=\"color: #ff0000\">ko</span><br>[panneau] /pano/ vs /pano/: <span style=\"color: #00ff00\">ok</span><br>[éjectile] /eʒɛktil/ vs /eʒɛktil/: <span style=\"color: #00ff00\">ok</span><br>[foirer] /fwaʁe/ vs /fwaʁe/: <span style=\"color: #00ff00\">ok</span><br>[reswitcher] /ʁəswitʃe/ vs /ʁəswtʃe/: <span style=\"color: #ff0000\">ko</span><br>[ronchemeler] /ʁɔ̃ʃməle/ vs /ʁɔ̃ʃməle/: <span style=\"color: #00ff00\">ok</span><br>[dévoler] /devɔle/ vs /devole/: <span style=\"color: #ff0000\">ko</span><br>[dévêtir] /devɛtiʁ/ vs /devetiʁ/: <span style=\"color: #ff0000\">ko</span><br>[assesseur] /asesœʁ/ vs /asesœʁ/: <span style=\"color: #00ff00\">ok</span><br>[jaleuse] /ʒaløz/ vs /ʒaløz/: <span style=\"color: #00ff00\">ok</span><br>[flonger] /flɔ̃ʒe/ vs /flɔ̃ʒe/: <span style=\"color: #00ff00\">ok</span><br>[cloquer] /klɔke/ vs /klɔke/: <span style=\"color: #00ff00\">ok</span><br>[dessouler] /dɛsule/ vs /deswle/: <span style=\"color: #ff0000\">ko</span><br>[caver] /kave/ vs /kave/: <span style=\"color: #00ff00\">ok</span><br>[prédiseuse] /pʁedizøz/ vs /pʁedizøz/: <span style=\"color: #00ff00\">ok</span><br>[choucrouteuse] /ʃukʁutøz/ vs /ʃukutøz/: <span style=\"color: #ff0000\">ko</span><br>[épinceuse] /epɛ̃søz/ vs /epɛ̃søz/: <span style=\"color: #00ff00\">ok</span><br>[échetiner] /eʃtine/ vs /eʃtine/: <span style=\"color: #00ff00\">ok</span><br>[front] /fʁɔ̃/ vs /fʁɔ̃/: <span style=\"color: #00ff00\">ok</span><br>[rogation] /ʁɔɡasjɔ̃/ vs /ʁɔɡasjɔ̃/: <span style=\"color: #00ff00\">ok</span><br>[bouillir] /bujiʁ/ vs /bujiʁ/: <span style=\"color: #00ff00\">ok</span><br>[acquiesçable] /akjesabl/ vs /atjɛsabl/: <span style=\"color: #ff0000\">ko</span><br>[dracher] /dʁaʃe/ vs /dɔaʃe/: <span style=\"color: #ff0000\">ko</span><br>[chichon] /ʃiʃɔ̃/ vs /ʃiʃɔ̃/: <span style=\"color: #00ff00\">ok</span><br>[bannière] /banjɛʁ/ vs /banjɛʁ/: <span style=\"color: #00ff00\">ok</span><br>[anima] /anima/ vs /adina/: <span style=\"color: #ff0000\">ko</span><br>[prester] /pʁɛste/ vs /pʁɛste/: <span style=\"color: #00ff00\">ok</span><br>[fuster] /fyste/ vs /fyste/: <span style=\"color: #00ff00\">ok</span><br>[guindailler] /ɡɛ̃dɑje/ vs /ɡadɑje/: <span style=\"color: #ff0000\">ko</span><br>[truquer] /tʁyke/ vs /tʁyke/: <span style=\"color: #00ff00\">ok</span><br>[rémanence] /ʁemanɑ̃s/ vs /ʁemanɑ̃s/: <span style=\"color: #00ff00\">ok</span><br>[dormeuse] /dɔʁmøz/ vs /dɔʁmøz/: <span style=\"color: #00ff00\">ok</span><br>[centre] /sɑ̃tʁ/ vs /sɑ̃tʁ/: <span style=\"color: #00ff00\">ok</span><br>[bimoteur] /bimɔtœʁ/ vs /bimwɔtœʁ/: <span style=\"color: #ff0000\">ko</span><br>[chuchoter] /ʃyʃɔte/ vs /ʃʃɔte/: <span style=\"color: #ff0000\">ko</span><br>[regaffer] /ʁəɡafe/ vs /ʁəɡafe/: <span style=\"color: #00ff00\">ok</span><br>[verdaille] /vɛʁdɑj/ vs /nɛʁdajj/: <span style=\"color: #ff0000\">ko</span><br>[blogueur] /blɔɡœʁ/ vs /blɔɡœʁ/: <span style=\"color: #00ff00\">ok</span><br>[pamphile] /pɑ̃fil/ vs /pɔfil/: <span style=\"color: #ff0000\">ko</span><br>[hiberner] /ibɛʁne/ vs /ibɛʁne/: <span style=\"color: #00ff00\">ok</span><br>[sapin] /sapɛ̃/ vs /sapɛ̃/: <span style=\"color: #00ff00\">ok</span><br>[alléger] /alleʒe/ vs /aleʒe/: <span style=\"color: #ff0000\">ko</span><br>[cogneuse] /kɔnjøz/ vs /kɔɲøz/: <span style=\"color: #ff0000\">ko</span><br>[rechiquer] /ʁəʃike/ vs /ʁəʃike/: <span style=\"color: #00ff00\">ok</span><br>[honnêtement] /ɔnɛtmɑ̃/ vs /ɔnɛtmɑ̃/: <span style=\"color: #00ff00\">ok</span><br>[limoner] /limɔne/ vs /limɔne/: <span style=\"color: #00ff00\">ok</span><br>[enclore] /ɑ̃klɔʁ/ vs /ɑ̃klɔʁ/: <span style=\"color: #00ff00\">ok</span><br>[abeillé] /abɛje/ vs /abeje/: <span style=\"color: #ff0000\">ko</span><br>[vaillamment] /vajamɑ̃/ vs /vajamɑ̃/: <span style=\"color: #00ff00\">ok</span><br>[allophone] /alɔfɔn/ vs /alɔfɔn/: <span style=\"color: #00ff00\">ok</span><br>[ancrage] /ɑ̃kʁaʒ/ vs /ɑ̃kʁaʒ/: <span style=\"color: #00ff00\">ok</span><br>[bieurler] /bjœʁle/ vs /bjɔʁle/: <span style=\"color: #ff0000\">ko</span><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tested:100, n_ok:63, n_ko:37\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "n_tested = 0\n",
    "n_ok = 0\n",
    "n_ko = 0\n",
    "results = np.asarray(s[0][0])\n",
    "debug_str = '[MOT] /PRONONCIATION WIKTIONNAIRE/ vs /PPRONONCIATION PREDITE/<br>'\n",
    "for i in range(NB_TEST_SAMPLES):\n",
    "    phonemes = ''\n",
    "    mot = mots[NB_TRAINING_SAMPLES + i]\n",
    "    prononciation = prononciations[NB_TRAINING_SAMPLES + i]\n",
    "    debug_str += '[' + mot + '] /' + prononciation + '/ vs '\n",
    "    for letter in range(results.shape[1]):\n",
    "        val = results[i, letter]\n",
    "        if val == -1:\n",
    "            continue\n",
    "        phoneme = index_map[val+1]\n",
    "        #print('r=',results[n,letter],end=',')\n",
    "        phonemes += phoneme\n",
    "    phonemes = phonemes.replace(\"\\'\",'')\n",
    "    debug_str += '/' + phonemes + '/'\n",
    "    n_tested += 1\n",
    "    if phonemes == prononciation:\n",
    "        debug_str += ': <span style=\"color: #00ff00\">ok</span><br>'\n",
    "        n_ok += 1\n",
    "    else:\n",
    "        debug_str += ': <span style=\"color: #ff0000\">ko</span><br>'  \n",
    "        n_ko += 1\n",
    "display (Markdown(debug_str))\n",
    "        \n",
    "print('n_tested:%d, n_ok:%d, n_ko:%d' % (n_tested, n_ok, n_ko))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "write_read_ANNs_v5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
