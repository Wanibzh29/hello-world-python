{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of characters in a word.\n",
    "# for instance abccba has nb_chars = 6\n",
    "nb_chars = 6\n",
    "\n",
    "# number of possible characters used during the encoding.\n",
    "# for instance abcde leads to 01234 has nb_letters = 5\n",
    "nb_letters = 26\n",
    "\n",
    "# number of words samples to be generated \n",
    "nb_words = 10000\n",
    "\n",
    "# percentage of words that will be used for validation\n",
    "percentage_split = 0.30\n",
    "\n",
    "# number of epochs for fitting the model training step\n",
    "nb_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308915776"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of combinations\n",
    "nb_letters**nb_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inputs(nb_words, nb_chars, nb_letters):\n",
    "    '''Create a numpy array of nb_words rows with nb_chars columns each element\n",
    "    being a random letter of nb_letters (a, b...)'''\n",
    "    words = np.zeros((nb_words, nb_chars), dtype=int)\n",
    "    \n",
    "    for w in range(nb_words):\n",
    "        optim_tentative = False\n",
    "        if optim_tentative == True and w%10 != 0:\n",
    "            i = random.randint(0, nb_letters-1)\n",
    "            for c in range(nb_chars):\n",
    "                words[w, c] = ord('a') + i\n",
    "        else:\n",
    "            for c in range(nb_chars):\n",
    "                i = random.randint(0, nb_letters-1)\n",
    "                words[w, c] = ord('a') + i\n",
    "                \n",
    "    return words\n",
    "\n",
    "\n",
    "def encrypt(words, nb_words, nb_chars):\n",
    "    '''Encrypt each element of a numpy array of nb_words rows with nb_chars \n",
    "    columns each item with a secret algorithm'''\n",
    "    \n",
    "    encrypted_words = words.copy()\n",
    "    encrypted_words_probs = np.zeros((nb_words, nb_chars, nb_chars))\n",
    "    \n",
    "    #val_max = -1\n",
    "    \n",
    "    for w in range(nb_words):\n",
    "        for c in range(nb_chars): # 0,1,2,3,4\n",
    "            encrypted_words[w,c] = int(words[w,c]) - 49\n",
    "            val = encrypted_words[w,c] - 48\n",
    "            \n",
    "            #if val > val_max:\n",
    "            #    val_max = val\n",
    "            \n",
    "            # add entropy (i.e. mistakes in the encryption)\n",
    "            #epsilon = random.randint(0, 100)\n",
    "            #if epsilon == 5 and val != val_max:\n",
    "            #val +=1\n",
    "            \n",
    "            #print('w:',w,', c:',c,', [wc]:', val)\n",
    "            #encrypted_words_probs[w, c, val ] = 1.0\n",
    "            encrypted_words[w,c] = val\n",
    "    return encrypted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_features = nb_chars\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = layers.Input(shape=(nb_chars,), dtype='float32', name='main_input')\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = layers.Dense(4096, activation='relu', name='hl_1')(inputs)\n",
    "#x = layers.Dense(2048, activation='relu', name='hl_1')(inputs)\n",
    "#x = layers.Dense(64, activation='relu', name='hl_2')(x)\n",
    "\n",
    "outputs = []\n",
    "losses = {}\n",
    "for o in range(nb_chars):\n",
    "    name_i = 'output_'+str(o)\n",
    "    output_i = layers.Dense(nb_letters, activation='softmax', dtype='float32', name=name_i)(x)\n",
    "    outputs.append(output_i)\n",
    "    losses[name_i] = 'categorical_crossentropy'\n",
    "\n",
    "coding_model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "coding_model.compile(optimizer='rmsprop',\n",
    "                     loss=losses,\n",
    "                     metrics=['accuracy'])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hl_1 (Dense)                    (None, 4096)         28672       main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output_0 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_2 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_3 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_4 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_5 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 667,804\n",
      "Trainable params: 667,804\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(coding_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_readable_inputs(x):\n",
    "    words = []\n",
    "    for w in x:\n",
    "        word = ''\n",
    "        for c in w:\n",
    "            word += chr(c)\n",
    "        words.append(word)\n",
    "   \n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_readable_outputs_(outputs, nb_words, nb_chars):\n",
    "    \n",
    "    # outputs are listed : first, per char, second by sample, third by letter probability\n",
    "    words = [''] * nb_words\n",
    "    \n",
    "    c_i = 0\n",
    "    for char in outputs:\n",
    "\n",
    "        s_i = 0\n",
    "        for sample in char:\n",
    "\n",
    "            l_i = 0\n",
    "            best_value = -float('inf')\n",
    "            best_letter = -1\n",
    "            for letter_probs in sample:\n",
    "                if letter_probs > best_value:\n",
    "                    best_value = letter_probs\n",
    "                    best_letter = l_i\n",
    "                l_i += 1\n",
    "            words[s_i] += str(best_letter)\n",
    "            if c_i != nb_chars - 1:\n",
    "                words[s_i] += ' '\n",
    "            s_i += 1\n",
    "        c_i += 1\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_readable_outputs(outputs, nb_words, nb_chars):\n",
    "    \n",
    "    # outputs are listed : first, per char, second by sample, third by letter probability\n",
    "    words = [''] * nb_words\n",
    "    c_i = 0\n",
    "    for char in outputs:\n",
    "        s_i = 0\n",
    "        for sample in char:\n",
    "            best_letter = np.argmax(sample)\n",
    "            words[s_i] += str(best_letter)\n",
    "            if c_i != nb_chars - 1:\n",
    "                words[s_i] += ' '\n",
    "            s_i += 1\n",
    "        c_i += 1\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (as readable inputs)\n",
      "['mwvrcj', 'kzfuxv', 'enxuah', 'raiold']\n",
      "x (partial):\n",
      " [[109 119 118 114  99 106]\n",
      " [107 122 102 117 120 118]\n",
      " [101 110 120 117  97 104]\n",
      " [114  97 105 111 108 100]] out of  10000\n",
      "\n",
      "x_train:\n",
      " [[-0.08164801  1.26169656  1.13668048  0.6181665  -1.40331438 -0.46845706]\n",
      " [-0.34842797  1.66022773 -0.98986883  1.01735273  1.39555751  1.1327406 ]\n",
      " [-1.14876786  0.06610304  1.40249915  1.01735273 -1.66987361 -0.73532334]\n",
      " [ 0.5853019  -1.66086538 -0.59114084  0.21898026 -0.20379786 -1.2690559 ]] out of  10000\n",
      "\n",
      "y (readable):\n",
      " [[12 22 21 17  2  9]\n",
      " [10 25  5 20 23 21]\n",
      " [ 4 13 23 20  0  7]\n",
      " ...\n",
      " [11  1  7 10 21  6]\n",
      " [ 7  7  5 16 14 11]\n",
      " [11 19 19 21 11 24]]\n",
      "\n",
      "y (less readable):\n",
      " [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   1. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "   0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   1. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]] out of  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "x = create_inputs(nb_words, nb_chars, nb_letters)\n",
    "print('x: (as readable inputs)')\n",
    "\n",
    "first_n_samples = 4\n",
    "\n",
    "print_readable_inputs(x[:first_n_samples])\n",
    "print('x (partial):\\n', x[:first_n_samples], 'out of ',len(x))\n",
    "print()\n",
    "\n",
    "# process the x data as useful ANN input data\n",
    "scaler = StandardScaler()\n",
    "x_train  = scaler.fit_transform(x)\n",
    "\n",
    "print('x_train:\\n', x_train[:first_n_samples], 'out of ',len(x_train))\n",
    "print()\n",
    "\n",
    "# create output data for training\n",
    "y = encrypt(x, nb_words, nb_chars)\n",
    "print('y (readable):\\n', y)\n",
    "print()\n",
    "\n",
    "# process the y data as useful ANN output data\n",
    "y_train0 = keras.utils.to_categorical(y, nb_letters)\n",
    "print('y (less readable):\\n', y_train0[:first_n_samples], 'out of ',len(y_train0))\n",
    "print('')\n",
    "\n",
    "# process the y data as useful ANN multiple-outputs data\n",
    "y_train = []\n",
    "for c in range(nb_chars):\n",
    "    # extract each 'char' colomn from the global y_train0 tensor\n",
    "    # in order to have multiplue yi_train outputs tensors\n",
    "    yi_train = y_train0[:,c,:]\n",
    "    y_train.append(yi_train)\n",
    "\n",
    "# Not really displayable, henced commented\n",
    "#print('y_train):')\n",
    "#print(y_train[:first_n_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/200\n",
      "7000/7000 [==============================] - 2s 259us/step - loss: 15.1059 - output_0_loss: 2.5172 - output_1_loss: 2.5157 - output_2_loss: 2.5133 - output_3_loss: 2.5302 - output_4_loss: 2.5181 - output_5_loss: 2.5114 - output_0_acc: 0.1614 - output_1_acc: 0.1541 - output_2_acc: 0.1603 - output_3_acc: 0.1574 - output_4_acc: 0.1546 - output_5_acc: 0.1656 - val_loss: 13.3627 - val_output_0_loss: 2.2243 - val_output_1_loss: 2.2519 - val_output_2_loss: 2.2190 - val_output_3_loss: 2.1919 - val_output_4_loss: 2.2482 - val_output_5_loss: 2.2274 - val_output_0_acc: 0.1960 - val_output_1_acc: 0.1953 - val_output_2_acc: 0.2010 - val_output_3_acc: 0.2143 - val_output_4_acc: 0.2167 - val_output_5_acc: 0.1840\n",
      "Epoch 2/200\n",
      "7000/7000 [==============================] - 1s 170us/step - loss: 12.5300 - output_0_loss: 2.0876 - output_1_loss: 2.0828 - output_2_loss: 2.0836 - output_3_loss: 2.0959 - output_4_loss: 2.0979 - output_5_loss: 2.0822 - output_0_acc: 0.2331 - output_1_acc: 0.2374 - output_2_acc: 0.2299 - output_3_acc: 0.2313 - output_4_acc: 0.2307 - output_5_acc: 0.2430 - val_loss: 12.3696 - val_output_0_loss: 2.1014 - val_output_1_loss: 2.0352 - val_output_2_loss: 2.0768 - val_output_3_loss: 2.0151 - val_output_4_loss: 2.0828 - val_output_5_loss: 2.0583 - val_output_0_acc: 0.2360 - val_output_1_acc: 0.2143 - val_output_2_acc: 0.2250 - val_output_3_acc: 0.2583 - val_output_4_acc: 0.2337 - val_output_5_acc: 0.2343\n",
      "Epoch 3/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 11.5235 - output_0_loss: 1.9231 - output_1_loss: 1.9152 - output_2_loss: 1.9026 - output_3_loss: 1.9300 - output_4_loss: 1.9377 - output_5_loss: 1.9148 - output_0_acc: 0.2710 - output_1_acc: 0.2746 - output_2_acc: 0.2810 - output_3_acc: 0.2757 - output_4_acc: 0.2646 - output_5_acc: 0.2711 - val_loss: 11.4982 - val_output_0_loss: 1.9337 - val_output_1_loss: 1.9010 - val_output_2_loss: 1.9128 - val_output_3_loss: 1.9045 - val_output_4_loss: 1.9349 - val_output_5_loss: 1.9112 - val_output_0_acc: 0.2797 - val_output_1_acc: 0.2753 - val_output_2_acc: 0.2447 - val_output_3_acc: 0.2623 - val_output_4_acc: 0.2577 - val_output_5_acc: 0.2693\n",
      "Epoch 4/200\n",
      "7000/7000 [==============================] - 1s 161us/step - loss: 10.8128 - output_0_loss: 1.8022 - output_1_loss: 1.7927 - output_2_loss: 1.7867 - output_3_loss: 1.8098 - output_4_loss: 1.8278 - output_5_loss: 1.7935 - output_0_acc: 0.3041 - output_1_acc: 0.3067 - output_2_acc: 0.3073 - output_3_acc: 0.2979 - output_4_acc: 0.2954 - output_5_acc: 0.3083 - val_loss: 10.8242 - val_output_0_loss: 1.8634 - val_output_1_loss: 1.7336 - val_output_2_loss: 1.7979 - val_output_3_loss: 1.7737 - val_output_4_loss: 1.8201 - val_output_5_loss: 1.8356 - val_output_0_acc: 0.2960 - val_output_1_acc: 0.3143 - val_output_2_acc: 0.2813 - val_output_3_acc: 0.2997 - val_output_4_acc: 0.2770 - val_output_5_acc: 0.2863\n",
      "Epoch 5/200\n",
      "7000/7000 [==============================] - 1s 160us/step - loss: 10.2228 - output_0_loss: 1.7070 - output_1_loss: 1.6881 - output_2_loss: 1.6949 - output_3_loss: 1.7046 - output_4_loss: 1.7330 - output_5_loss: 1.6951 - output_0_acc: 0.3284 - output_1_acc: 0.3430 - output_2_acc: 0.3360 - output_3_acc: 0.3400 - output_4_acc: 0.3273 - output_5_acc: 0.3456 - val_loss: 10.6060 - val_output_0_loss: 1.7247 - val_output_1_loss: 1.7191 - val_output_2_loss: 1.8148 - val_output_3_loss: 1.7817 - val_output_4_loss: 1.7931 - val_output_5_loss: 1.7727 - val_output_0_acc: 0.3250 - val_output_1_acc: 0.3223 - val_output_2_acc: 0.3123 - val_output_3_acc: 0.3123 - val_output_4_acc: 0.3013 - val_output_5_acc: 0.3193\n",
      "Epoch 6/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 9.7133 - output_0_loss: 1.6231 - output_1_loss: 1.6092 - output_2_loss: 1.5954 - output_3_loss: 1.6274 - output_4_loss: 1.6477 - output_5_loss: 1.6106 - output_0_acc: 0.3621 - output_1_acc: 0.3634 - output_2_acc: 0.3749 - output_3_acc: 0.3551 - output_4_acc: 0.3527 - output_5_acc: 0.3753 - val_loss: 9.8658 - val_output_0_loss: 1.6577 - val_output_1_loss: 1.6302 - val_output_2_loss: 1.6912 - val_output_3_loss: 1.5821 - val_output_4_loss: 1.6277 - val_output_5_loss: 1.6770 - val_output_0_acc: 0.3467 - val_output_1_acc: 0.3637 - val_output_2_acc: 0.2963 - val_output_3_acc: 0.3520 - val_output_4_acc: 0.3560 - val_output_5_acc: 0.3267\n",
      "Epoch 7/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 9.2634 - output_0_loss: 1.5464 - output_1_loss: 1.5253 - output_2_loss: 1.5271 - output_3_loss: 1.5551 - output_4_loss: 1.5767 - output_5_loss: 1.5328 - output_0_acc: 0.3901 - output_1_acc: 0.4003 - output_2_acc: 0.3923 - output_3_acc: 0.3841 - output_4_acc: 0.3749 - output_5_acc: 0.4050 - val_loss: 9.6845 - val_output_0_loss: 1.5837 - val_output_1_loss: 1.5962 - val_output_2_loss: 1.6957 - val_output_3_loss: 1.6227 - val_output_4_loss: 1.6095 - val_output_5_loss: 1.5767 - val_output_0_acc: 0.3730 - val_output_1_acc: 0.3680 - val_output_2_acc: 0.3507 - val_output_3_acc: 0.3567 - val_output_4_acc: 0.3463 - val_output_5_acc: 0.3567\n",
      "Epoch 8/200\n",
      "7000/7000 [==============================] - 1s 160us/step - loss: 8.8519 - output_0_loss: 1.4772 - output_1_loss: 1.4593 - output_2_loss: 1.4595 - output_3_loss: 1.4812 - output_4_loss: 1.5077 - output_5_loss: 1.4670 - output_0_acc: 0.4167 - output_1_acc: 0.4144 - output_2_acc: 0.4110 - output_3_acc: 0.4119 - output_4_acc: 0.3991 - output_5_acc: 0.4217 - val_loss: 9.2623 - val_output_0_loss: 1.5009 - val_output_1_loss: 1.4843 - val_output_2_loss: 1.4852 - val_output_3_loss: 1.4881 - val_output_4_loss: 1.6801 - val_output_5_loss: 1.6237 - val_output_0_acc: 0.3933 - val_output_1_acc: 0.4157 - val_output_2_acc: 0.4117 - val_output_3_acc: 0.4110 - val_output_4_acc: 0.3270 - val_output_5_acc: 0.3453\n",
      "Epoch 9/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 8.5000 - output_0_loss: 1.4284 - output_1_loss: 1.3946 - output_2_loss: 1.3946 - output_3_loss: 1.4300 - output_4_loss: 1.4499 - output_5_loss: 1.4025 - output_0_acc: 0.4360 - output_1_acc: 0.4466 - output_2_acc: 0.4370 - output_3_acc: 0.4267 - output_4_acc: 0.4283 - output_5_acc: 0.4436 - val_loss: 8.9051 - val_output_0_loss: 1.4936 - val_output_1_loss: 1.5237 - val_output_2_loss: 1.4314 - val_output_3_loss: 1.4541 - val_output_4_loss: 1.4684 - val_output_5_loss: 1.5339 - val_output_0_acc: 0.3677 - val_output_1_acc: 0.3860 - val_output_2_acc: 0.4173 - val_output_3_acc: 0.4300 - val_output_4_acc: 0.4137 - val_output_5_acc: 0.3603\n",
      "Epoch 10/200\n",
      "7000/7000 [==============================] - 1s 155us/step - loss: 8.1673 - output_0_loss: 1.3693 - output_1_loss: 1.3449 - output_2_loss: 1.3357 - output_3_loss: 1.3705 - output_4_loss: 1.3950 - output_5_loss: 1.3521 - output_0_acc: 0.4573 - output_1_acc: 0.4656 - output_2_acc: 0.4590 - output_3_acc: 0.4514 - output_4_acc: 0.4467 - output_5_acc: 0.4646 - val_loss: 8.7093 - val_output_0_loss: 1.4205 - val_output_1_loss: 1.4420 - val_output_2_loss: 1.4592 - val_output_3_loss: 1.4420 - val_output_4_loss: 1.4573 - val_output_5_loss: 1.4883 - val_output_0_acc: 0.4177 - val_output_1_acc: 0.3927 - val_output_2_acc: 0.4243 - val_output_3_acc: 0.4317 - val_output_4_acc: 0.4110 - val_output_5_acc: 0.4010\n",
      "Epoch 11/200\n",
      "7000/7000 [==============================] - 1s 168us/step - loss: 7.8660 - output_0_loss: 1.3261 - output_1_loss: 1.2994 - output_2_loss: 1.2831 - output_3_loss: 1.3210 - output_4_loss: 1.3469 - output_5_loss: 1.2895 - output_0_acc: 0.4689 - output_1_acc: 0.4823 - output_2_acc: 0.4877 - output_3_acc: 0.4659 - output_4_acc: 0.4576 - output_5_acc: 0.4863 - val_loss: 8.3160 - val_output_0_loss: 1.3734 - val_output_1_loss: 1.3912 - val_output_2_loss: 1.3370 - val_output_3_loss: 1.3419 - val_output_4_loss: 1.4360 - val_output_5_loss: 1.4366 - val_output_0_acc: 0.4323 - val_output_1_acc: 0.4250 - val_output_2_acc: 0.4407 - val_output_3_acc: 0.4623 - val_output_4_acc: 0.4077 - val_output_5_acc: 0.4200\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 169us/step - loss: 7.6086 - output_0_loss: 1.2785 - output_1_loss: 1.2504 - output_2_loss: 1.2451 - output_3_loss: 1.2772 - output_4_loss: 1.3064 - output_5_loss: 1.2510 - output_0_acc: 0.4890 - output_1_acc: 0.4976 - output_2_acc: 0.4983 - output_3_acc: 0.4846 - output_4_acc: 0.4746 - output_5_acc: 0.5034 - val_loss: 8.0371 - val_output_0_loss: 1.4199 - val_output_1_loss: 1.3511 - val_output_2_loss: 1.2703 - val_output_3_loss: 1.2817 - val_output_4_loss: 1.3876 - val_output_5_loss: 1.3266 - val_output_0_acc: 0.3943 - val_output_1_acc: 0.4407 - val_output_2_acc: 0.4883 - val_output_3_acc: 0.4900 - val_output_4_acc: 0.4693 - val_output_5_acc: 0.4497\n",
      "Epoch 13/200\n",
      "7000/7000 [==============================] - 1s 155us/step - loss: 7.3262 - output_0_loss: 1.2404 - output_1_loss: 1.2058 - output_2_loss: 1.1895 - output_3_loss: 1.2313 - output_4_loss: 1.2557 - output_5_loss: 1.2036 - output_0_acc: 0.5099 - output_1_acc: 0.5167 - output_2_acc: 0.5336 - output_3_acc: 0.5011 - output_4_acc: 0.4926 - output_5_acc: 0.5226 - val_loss: 7.8523 - val_output_0_loss: 1.3475 - val_output_1_loss: 1.3238 - val_output_2_loss: 1.2872 - val_output_3_loss: 1.2783 - val_output_4_loss: 1.2963 - val_output_5_loss: 1.3191 - val_output_0_acc: 0.4320 - val_output_1_acc: 0.4620 - val_output_2_acc: 0.4687 - val_output_3_acc: 0.4430 - val_output_4_acc: 0.4667 - val_output_5_acc: 0.4720\n",
      "Epoch 14/200\n",
      "7000/7000 [==============================] - 1s 158us/step - loss: 7.1087 - output_0_loss: 1.1993 - output_1_loss: 1.1677 - output_2_loss: 1.1549 - output_3_loss: 1.1850 - output_4_loss: 1.2254 - output_5_loss: 1.1763 - output_0_acc: 0.5197 - output_1_acc: 0.5406 - output_2_acc: 0.5304 - output_3_acc: 0.5293 - output_4_acc: 0.5153 - output_5_acc: 0.5300 - val_loss: 7.6790 - val_output_0_loss: 1.2710 - val_output_1_loss: 1.2711 - val_output_2_loss: 1.2596 - val_output_3_loss: 1.2441 - val_output_4_loss: 1.3161 - val_output_5_loss: 1.3171 - val_output_0_acc: 0.4560 - val_output_1_acc: 0.5087 - val_output_2_acc: 0.4963 - val_output_3_acc: 0.4913 - val_output_4_acc: 0.4343 - val_output_5_acc: 0.4353\n",
      "Epoch 15/200\n",
      "7000/7000 [==============================] - 1s 149us/step - loss: 6.8680 - output_0_loss: 1.1570 - output_1_loss: 1.1246 - output_2_loss: 1.1178 - output_3_loss: 1.1502 - output_4_loss: 1.1855 - output_5_loss: 1.1328 - output_0_acc: 0.5396 - output_1_acc: 0.5471 - output_2_acc: 0.5519 - output_3_acc: 0.5341 - output_4_acc: 0.5287 - output_5_acc: 0.5517 - val_loss: 7.4384 - val_output_0_loss: 1.2830 - val_output_1_loss: 1.2449 - val_output_2_loss: 1.1797 - val_output_3_loss: 1.3068 - val_output_4_loss: 1.2243 - val_output_5_loss: 1.1997 - val_output_0_acc: 0.4577 - val_output_1_acc: 0.4947 - val_output_2_acc: 0.4927 - val_output_3_acc: 0.4763 - val_output_4_acc: 0.5003 - val_output_5_acc: 0.5033\n",
      "Epoch 16/200\n",
      "7000/7000 [==============================] - 1s 152us/step - loss: 6.6629 - output_0_loss: 1.1215 - output_1_loss: 1.0942 - output_2_loss: 1.0815 - output_3_loss: 1.1148 - output_4_loss: 1.1510 - output_5_loss: 1.0999 - output_0_acc: 0.5563 - output_1_acc: 0.5650 - output_2_acc: 0.5657 - output_3_acc: 0.5579 - output_4_acc: 0.5404 - output_5_acc: 0.5587 - val_loss: 7.2288 - val_output_0_loss: 1.2525 - val_output_1_loss: 1.1693 - val_output_2_loss: 1.1585 - val_output_3_loss: 1.2349 - val_output_4_loss: 1.1906 - val_output_5_loss: 1.2230 - val_output_0_acc: 0.4657 - val_output_1_acc: 0.4943 - val_output_2_acc: 0.5377 - val_output_3_acc: 0.4843 - val_output_4_acc: 0.5157 - val_output_5_acc: 0.4783\n",
      "Epoch 17/200\n",
      "7000/7000 [==============================] - 1s 155us/step - loss: 6.4481 - output_0_loss: 1.0970 - output_1_loss: 1.0551 - output_2_loss: 1.0471 - output_3_loss: 1.0804 - output_4_loss: 1.1090 - output_5_loss: 1.0596 - output_0_acc: 0.5591 - output_1_acc: 0.5861 - output_2_acc: 0.5849 - output_3_acc: 0.5709 - output_4_acc: 0.5570 - output_5_acc: 0.5896 - val_loss: 7.3825 - val_output_0_loss: 1.2585 - val_output_1_loss: 1.2674 - val_output_2_loss: 1.1154 - val_output_3_loss: 1.2400 - val_output_4_loss: 1.2092 - val_output_5_loss: 1.2920 - val_output_0_acc: 0.4763 - val_output_1_acc: 0.4987 - val_output_2_acc: 0.5303 - val_output_3_acc: 0.5133 - val_output_4_acc: 0.4910 - val_output_5_acc: 0.4640\n",
      "Epoch 18/200\n",
      "7000/7000 [==============================] - 1s 158us/step - loss: 6.2673 - output_0_loss: 1.0572 - output_1_loss: 1.0233 - output_2_loss: 1.0144 - output_3_loss: 1.0550 - output_4_loss: 1.0811 - output_5_loss: 1.0363 - output_0_acc: 0.5839 - output_1_acc: 0.5890 - output_2_acc: 0.5934 - output_3_acc: 0.5879 - output_4_acc: 0.5727 - output_5_acc: 0.5896 - val_loss: 6.9367 - val_output_0_loss: 1.1424 - val_output_1_loss: 1.1281 - val_output_2_loss: 1.0751 - val_output_3_loss: 1.1706 - val_output_4_loss: 1.2468 - val_output_5_loss: 1.1737 - val_output_0_acc: 0.5500 - val_output_1_acc: 0.5600 - val_output_2_acc: 0.5767 - val_output_3_acc: 0.5060 - val_output_4_acc: 0.5047 - val_output_5_acc: 0.5503\n",
      "Epoch 19/200\n",
      "7000/7000 [==============================] - 1s 167us/step - loss: 6.0726 - output_0_loss: 1.0280 - output_1_loss: 0.9941 - output_2_loss: 0.9859 - output_3_loss: 1.0211 - output_4_loss: 1.0455 - output_5_loss: 0.9980 - output_0_acc: 0.5930 - output_1_acc: 0.6057 - output_2_acc: 0.6051 - output_3_acc: 0.5963 - output_4_acc: 0.5910 - output_5_acc: 0.6070 - val_loss: 6.8382 - val_output_0_loss: 1.1825 - val_output_1_loss: 1.1646 - val_output_2_loss: 1.0706 - val_output_3_loss: 1.1093 - val_output_4_loss: 1.1928 - val_output_5_loss: 1.1185 - val_output_0_acc: 0.5107 - val_output_1_acc: 0.5257 - val_output_2_acc: 0.5530 - val_output_3_acc: 0.5367 - val_output_4_acc: 0.5187 - val_output_5_acc: 0.5673\n",
      "Epoch 20/200\n",
      "7000/7000 [==============================] - 1s 146us/step - loss: 5.9234 - output_0_loss: 1.0013 - output_1_loss: 0.9735 - output_2_loss: 0.9476 - output_3_loss: 0.9962 - output_4_loss: 1.0285 - output_5_loss: 0.9762 - output_0_acc: 0.6050 - output_1_acc: 0.6196 - output_2_acc: 0.6270 - output_3_acc: 0.5974 - output_4_acc: 0.5837 - output_5_acc: 0.6110 - val_loss: 6.4779 - val_output_0_loss: 1.0582 - val_output_1_loss: 1.1558 - val_output_2_loss: 1.0899 - val_output_3_loss: 1.0844 - val_output_4_loss: 1.0522 - val_output_5_loss: 1.0375 - val_output_0_acc: 0.5607 - val_output_1_acc: 0.5323 - val_output_2_acc: 0.5280 - val_output_3_acc: 0.5423 - val_output_4_acc: 0.5613 - val_output_5_acc: 0.5970\n",
      "Epoch 21/200\n",
      "7000/7000 [==============================] - 1s 150us/step - loss: 5.7525 - output_0_loss: 0.9730 - output_1_loss: 0.9447 - output_2_loss: 0.9284 - output_3_loss: 0.9687 - output_4_loss: 0.9966 - output_5_loss: 0.9411 - output_0_acc: 0.6150 - output_1_acc: 0.6304 - output_2_acc: 0.6321 - output_3_acc: 0.6163 - output_4_acc: 0.6131 - output_5_acc: 0.6303 - val_loss: 6.3803 - val_output_0_loss: 1.1084 - val_output_1_loss: 1.0241 - val_output_2_loss: 0.9811 - val_output_3_loss: 1.0509 - val_output_4_loss: 1.1157 - val_output_5_loss: 1.1002 - val_output_0_acc: 0.5493 - val_output_1_acc: 0.5850 - val_output_2_acc: 0.6040 - val_output_3_acc: 0.5620 - val_output_4_acc: 0.5503 - val_output_5_acc: 0.5517\n",
      "Epoch 22/200\n",
      "7000/7000 [==============================] - 1s 159us/step - loss: 5.6016 - output_0_loss: 0.9509 - output_1_loss: 0.9175 - output_2_loss: 0.9005 - output_3_loss: 0.9359 - output_4_loss: 0.9721 - output_5_loss: 0.9246 - output_0_acc: 0.6230 - output_1_acc: 0.6394 - output_2_acc: 0.6424 - output_3_acc: 0.6330 - output_4_acc: 0.6199 - output_5_acc: 0.6341 - val_loss: 6.4441 - val_output_0_loss: 1.1206 - val_output_1_loss: 1.0383 - val_output_2_loss: 1.0517 - val_output_3_loss: 1.0919 - val_output_4_loss: 1.0671 - val_output_5_loss: 1.0745 - val_output_0_acc: 0.5177 - val_output_1_acc: 0.5830 - val_output_2_acc: 0.5613 - val_output_3_acc: 0.5597 - val_output_4_acc: 0.5563 - val_output_5_acc: 0.5503\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 162us/step - loss: 5.4533 - output_0_loss: 0.9196 - output_1_loss: 0.8931 - output_2_loss: 0.8809 - output_3_loss: 0.9124 - output_4_loss: 0.9480 - output_5_loss: 0.8995 - output_0_acc: 0.6366 - output_1_acc: 0.6536 - output_2_acc: 0.6597 - output_3_acc: 0.6467 - output_4_acc: 0.6327 - output_5_acc: 0.6499 - val_loss: 6.3647 - val_output_0_loss: 1.1190 - val_output_1_loss: 0.9998 - val_output_2_loss: 0.9923 - val_output_3_loss: 0.9553 - val_output_4_loss: 1.2240 - val_output_5_loss: 1.0743 - val_output_0_acc: 0.5233 - val_output_1_acc: 0.5767 - val_output_2_acc: 0.5883 - val_output_3_acc: 0.6130 - val_output_4_acc: 0.5107 - val_output_5_acc: 0.5597\n",
      "Epoch 24/200\n",
      "7000/7000 [==============================] - 1s 163us/step - loss: 5.3115 - output_0_loss: 0.8994 - output_1_loss: 0.8654 - output_2_loss: 0.8498 - output_3_loss: 0.8942 - output_4_loss: 0.9308 - output_5_loss: 0.8719 - output_0_acc: 0.6464 - output_1_acc: 0.6647 - output_2_acc: 0.6727 - output_3_acc: 0.6486 - output_4_acc: 0.6339 - output_5_acc: 0.6620 - val_loss: 6.0176 - val_output_0_loss: 1.0797 - val_output_1_loss: 0.9829 - val_output_2_loss: 0.9215 - val_output_3_loss: 0.9794 - val_output_4_loss: 1.0212 - val_output_5_loss: 1.0329 - val_output_0_acc: 0.5627 - val_output_1_acc: 0.6197 - val_output_2_acc: 0.6123 - val_output_3_acc: 0.5983 - val_output_4_acc: 0.5853 - val_output_5_acc: 0.5603\n",
      "Epoch 25/200\n",
      "7000/7000 [==============================] - 1s 165us/step - loss: 5.1746 - output_0_loss: 0.8787 - output_1_loss: 0.8442 - output_2_loss: 0.8321 - output_3_loss: 0.8702 - output_4_loss: 0.9008 - output_5_loss: 0.8486 - output_0_acc: 0.6589 - output_1_acc: 0.6679 - output_2_acc: 0.6809 - output_3_acc: 0.6560 - output_4_acc: 0.6560 - output_5_acc: 0.6747 - val_loss: 6.1092 - val_output_0_loss: 1.1011 - val_output_1_loss: 0.9752 - val_output_2_loss: 0.9771 - val_output_3_loss: 1.0437 - val_output_4_loss: 1.0173 - val_output_5_loss: 0.9948 - val_output_0_acc: 0.5160 - val_output_1_acc: 0.6157 - val_output_2_acc: 0.6083 - val_output_3_acc: 0.5330 - val_output_4_acc: 0.5723 - val_output_5_acc: 0.5603\n",
      "Epoch 26/200\n",
      "7000/7000 [==============================] - 1s 163us/step - loss: 5.0450 - output_0_loss: 0.8545 - output_1_loss: 0.8244 - output_2_loss: 0.8072 - output_3_loss: 0.8501 - output_4_loss: 0.8801 - output_5_loss: 0.8288 - output_0_acc: 0.6681 - output_1_acc: 0.6839 - output_2_acc: 0.6963 - output_3_acc: 0.6656 - output_4_acc: 0.6647 - output_5_acc: 0.6826 - val_loss: 5.9270 - val_output_0_loss: 1.0408 - val_output_1_loss: 0.9566 - val_output_2_loss: 1.0194 - val_output_3_loss: 0.9249 - val_output_4_loss: 1.0019 - val_output_5_loss: 0.9833 - val_output_0_acc: 0.5613 - val_output_1_acc: 0.5940 - val_output_2_acc: 0.5880 - val_output_3_acc: 0.6270 - val_output_4_acc: 0.5893 - val_output_5_acc: 0.5757\n",
      "Epoch 27/200\n",
      "7000/7000 [==============================] - 1s 152us/step - loss: 4.9298 - output_0_loss: 0.8324 - output_1_loss: 0.8048 - output_2_loss: 0.7847 - output_3_loss: 0.8310 - output_4_loss: 0.8671 - output_5_loss: 0.8098 - output_0_acc: 0.6786 - output_1_acc: 0.6896 - output_2_acc: 0.7047 - output_3_acc: 0.6766 - output_4_acc: 0.6611 - output_5_acc: 0.6901 - val_loss: 5.7248 - val_output_0_loss: 0.9772 - val_output_1_loss: 0.9107 - val_output_2_loss: 0.8966 - val_output_3_loss: 0.9317 - val_output_4_loss: 1.0089 - val_output_5_loss: 0.9997 - val_output_0_acc: 0.6140 - val_output_1_acc: 0.6173 - val_output_2_acc: 0.6267 - val_output_3_acc: 0.6237 - val_output_4_acc: 0.5847 - val_output_5_acc: 0.5563\n",
      "Epoch 28/200\n",
      "7000/7000 [==============================] - 1s 152us/step - loss: 4.8240 - output_0_loss: 0.8184 - output_1_loss: 0.7835 - output_2_loss: 0.7730 - output_3_loss: 0.8147 - output_4_loss: 0.8437 - output_5_loss: 0.7906 - output_0_acc: 0.6774 - output_1_acc: 0.7013 - output_2_acc: 0.7063 - output_3_acc: 0.6804 - output_4_acc: 0.6736 - output_5_acc: 0.6966 - val_loss: 5.6881 - val_output_0_loss: 1.0562 - val_output_1_loss: 0.8932 - val_output_2_loss: 0.8581 - val_output_3_loss: 0.9616 - val_output_4_loss: 0.9467 - val_output_5_loss: 0.9724 - val_output_0_acc: 0.5633 - val_output_1_acc: 0.6273 - val_output_2_acc: 0.6590 - val_output_3_acc: 0.6087 - val_output_4_acc: 0.6313 - val_output_5_acc: 0.5810\n",
      "Epoch 29/200\n",
      "7000/7000 [==============================] - 1s 148us/step - loss: 4.6928 - output_0_loss: 0.7943 - output_1_loss: 0.7659 - output_2_loss: 0.7491 - output_3_loss: 0.7878 - output_4_loss: 0.8196 - output_5_loss: 0.7761 - output_0_acc: 0.6959 - output_1_acc: 0.7114 - output_2_acc: 0.7159 - output_3_acc: 0.6930 - output_4_acc: 0.6870 - output_5_acc: 0.7087 - val_loss: 5.6378 - val_output_0_loss: 1.0706 - val_output_1_loss: 0.9149 - val_output_2_loss: 0.8433 - val_output_3_loss: 0.8506 - val_output_4_loss: 0.9756 - val_output_5_loss: 0.9828 - val_output_0_acc: 0.5560 - val_output_1_acc: 0.6250 - val_output_2_acc: 0.6750 - val_output_3_acc: 0.6563 - val_output_4_acc: 0.6050 - val_output_5_acc: 0.5553\n",
      "Epoch 30/200\n",
      "7000/7000 [==============================] - 1s 142us/step - loss: 4.5989 - output_0_loss: 0.7788 - output_1_loss: 0.7462 - output_2_loss: 0.7354 - output_3_loss: 0.7745 - output_4_loss: 0.8057 - output_5_loss: 0.7582 - output_0_acc: 0.7000 - output_1_acc: 0.7219 - output_2_acc: 0.7184 - output_3_acc: 0.6983 - output_4_acc: 0.6946 - output_5_acc: 0.7067 - val_loss: 5.4682 - val_output_0_loss: 0.9005 - val_output_1_loss: 0.8785 - val_output_2_loss: 0.9561 - val_output_3_loss: 0.9536 - val_output_4_loss: 0.9363 - val_output_5_loss: 0.8432 - val_output_0_acc: 0.6180 - val_output_1_acc: 0.6190 - val_output_2_acc: 0.6043 - val_output_3_acc: 0.5760 - val_output_4_acc: 0.6270 - val_output_5_acc: 0.6597\n",
      "Epoch 31/200\n",
      "7000/7000 [==============================] - 1s 147us/step - loss: 4.4782 - output_0_loss: 0.7570 - output_1_loss: 0.7269 - output_2_loss: 0.7116 - output_3_loss: 0.7606 - output_4_loss: 0.7875 - output_5_loss: 0.7346 - output_0_acc: 0.7090 - output_1_acc: 0.7310 - output_2_acc: 0.7386 - output_3_acc: 0.7034 - output_4_acc: 0.6976 - output_5_acc: 0.7200 - val_loss: 5.1703 - val_output_0_loss: 0.8870 - val_output_1_loss: 0.8461 - val_output_2_loss: 0.8409 - val_output_3_loss: 0.8789 - val_output_4_loss: 0.8673 - val_output_5_loss: 0.8501 - val_output_0_acc: 0.6200 - val_output_1_acc: 0.6440 - val_output_2_acc: 0.6487 - val_output_3_acc: 0.6270 - val_output_4_acc: 0.6500 - val_output_5_acc: 0.6700\n",
      "Epoch 32/200\n",
      "7000/7000 [==============================] - 1s 158us/step - loss: 4.3752 - output_0_loss: 0.7448 - output_1_loss: 0.7107 - output_2_loss: 0.6938 - output_3_loss: 0.7358 - output_4_loss: 0.7706 - output_5_loss: 0.7196 - output_0_acc: 0.7111 - output_1_acc: 0.7321 - output_2_acc: 0.7469 - output_3_acc: 0.7223 - output_4_acc: 0.7100 - output_5_acc: 0.7299 - val_loss: 5.2001 - val_output_0_loss: 0.8733 - val_output_1_loss: 0.8441 - val_output_2_loss: 0.8319 - val_output_3_loss: 0.8004 - val_output_4_loss: 0.9212 - val_output_5_loss: 0.9292 - val_output_0_acc: 0.6537 - val_output_1_acc: 0.6727 - val_output_2_acc: 0.6380 - val_output_3_acc: 0.6900 - val_output_4_acc: 0.6460 - val_output_5_acc: 0.6333\n",
      "Epoch 33/200\n",
      "7000/7000 [==============================] - 1s 159us/step - loss: 4.2920 - output_0_loss: 0.7321 - output_1_loss: 0.7000 - output_2_loss: 0.6791 - output_3_loss: 0.7256 - output_4_loss: 0.7521 - output_5_loss: 0.7030 - output_0_acc: 0.7189 - output_1_acc: 0.7280 - output_2_acc: 0.7510 - output_3_acc: 0.7277 - output_4_acc: 0.7186 - output_5_acc: 0.7356 - val_loss: 5.0921 - val_output_0_loss: 0.8363 - val_output_1_loss: 0.7964 - val_output_2_loss: 0.7802 - val_output_3_loss: 0.8635 - val_output_4_loss: 0.9981 - val_output_5_loss: 0.8177 - val_output_0_acc: 0.6843 - val_output_1_acc: 0.6917 - val_output_2_acc: 0.6807 - val_output_3_acc: 0.6320 - val_output_4_acc: 0.5917 - val_output_5_acc: 0.6750\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 155us/step - loss: 4.1626 - output_0_loss: 0.7043 - output_1_loss: 0.6727 - output_2_loss: 0.6618 - output_3_loss: 0.7015 - output_4_loss: 0.7367 - output_5_loss: 0.6856 - output_0_acc: 0.7370 - output_1_acc: 0.7494 - output_2_acc: 0.7661 - output_3_acc: 0.7371 - output_4_acc: 0.7244 - output_5_acc: 0.7511 - val_loss: 5.2635 - val_output_0_loss: 0.8314 - val_output_1_loss: 0.8802 - val_output_2_loss: 0.8206 - val_output_3_loss: 0.8551 - val_output_4_loss: 0.9459 - val_output_5_loss: 0.9304 - val_output_0_acc: 0.6617 - val_output_1_acc: 0.6180 - val_output_2_acc: 0.6637 - val_output_3_acc: 0.6700 - val_output_4_acc: 0.6080 - val_output_5_acc: 0.5943\n",
      "Epoch 35/200\n",
      "7000/7000 [==============================] - 1s 145us/step - loss: 4.1051 - output_0_loss: 0.6972 - output_1_loss: 0.6671 - output_2_loss: 0.6519 - output_3_loss: 0.6907 - output_4_loss: 0.7249 - output_5_loss: 0.6733 - output_0_acc: 0.7366 - output_1_acc: 0.7510 - output_2_acc: 0.7630 - output_3_acc: 0.7424 - output_4_acc: 0.7197 - output_5_acc: 0.7491 - val_loss: 4.9861 - val_output_0_loss: 0.8520 - val_output_1_loss: 0.7982 - val_output_2_loss: 0.7442 - val_output_3_loss: 0.7776 - val_output_4_loss: 0.9483 - val_output_5_loss: 0.8658 - val_output_0_acc: 0.6427 - val_output_1_acc: 0.6583 - val_output_2_acc: 0.7023 - val_output_3_acc: 0.6890 - val_output_4_acc: 0.6240 - val_output_5_acc: 0.6387\n",
      "Epoch 36/200\n",
      "7000/7000 [==============================] - 1s 141us/step - loss: 3.9897 - output_0_loss: 0.6723 - output_1_loss: 0.6455 - output_2_loss: 0.6314 - output_3_loss: 0.6704 - output_4_loss: 0.7125 - output_5_loss: 0.6577 - output_0_acc: 0.7486 - output_1_acc: 0.7660 - output_2_acc: 0.7671 - output_3_acc: 0.7547 - output_4_acc: 0.7291 - output_5_acc: 0.7571 - val_loss: 5.1226 - val_output_0_loss: 0.9260 - val_output_1_loss: 0.7881 - val_output_2_loss: 0.7889 - val_output_3_loss: 0.8135 - val_output_4_loss: 0.8621 - val_output_5_loss: 0.9440 - val_output_0_acc: 0.6093 - val_output_1_acc: 0.6777 - val_output_2_acc: 0.6443 - val_output_3_acc: 0.6647 - val_output_4_acc: 0.6440 - val_output_5_acc: 0.5930\n",
      "Epoch 37/200\n",
      "7000/7000 [==============================] - 1s 138us/step - loss: 3.9238 - output_0_loss: 0.6644 - output_1_loss: 0.6433 - output_2_loss: 0.6213 - output_3_loss: 0.6568 - output_4_loss: 0.6962 - output_5_loss: 0.6417 - output_0_acc: 0.7536 - output_1_acc: 0.7576 - output_2_acc: 0.7763 - output_3_acc: 0.7614 - output_4_acc: 0.7396 - output_5_acc: 0.7600 - val_loss: 5.0298 - val_output_0_loss: 0.8602 - val_output_1_loss: 0.7845 - val_output_2_loss: 0.7807 - val_output_3_loss: 0.8320 - val_output_4_loss: 0.8909 - val_output_5_loss: 0.8815 - val_output_0_acc: 0.6407 - val_output_1_acc: 0.6703 - val_output_2_acc: 0.6757 - val_output_3_acc: 0.6590 - val_output_4_acc: 0.5947 - val_output_5_acc: 0.6270\n",
      "Epoch 38/200\n",
      "7000/7000 [==============================] - 1s 140us/step - loss: 3.8309 - output_0_loss: 0.6513 - output_1_loss: 0.6154 - output_2_loss: 0.6022 - output_3_loss: 0.6472 - output_4_loss: 0.6868 - output_5_loss: 0.6278 - output_0_acc: 0.7596 - output_1_acc: 0.7809 - output_2_acc: 0.7874 - output_3_acc: 0.7606 - output_4_acc: 0.7427 - output_5_acc: 0.7743 - val_loss: 4.6783 - val_output_0_loss: 0.8255 - val_output_1_loss: 0.7602 - val_output_2_loss: 0.6632 - val_output_3_loss: 0.7664 - val_output_4_loss: 0.9325 - val_output_5_loss: 0.7306 - val_output_0_acc: 0.6660 - val_output_1_acc: 0.6830 - val_output_2_acc: 0.7780 - val_output_3_acc: 0.6913 - val_output_4_acc: 0.5890 - val_output_5_acc: 0.7190\n",
      "Epoch 39/200\n",
      "7000/7000 [==============================] - 1s 141us/step - loss: 3.7629 - output_0_loss: 0.6358 - output_1_loss: 0.6092 - output_2_loss: 0.5897 - output_3_loss: 0.6319 - output_4_loss: 0.6761 - output_5_loss: 0.6202 - output_0_acc: 0.7676 - output_1_acc: 0.7849 - output_2_acc: 0.7954 - output_3_acc: 0.7693 - output_4_acc: 0.7466 - output_5_acc: 0.7756 - val_loss: 4.6824 - val_output_0_loss: 0.8424 - val_output_1_loss: 0.7571 - val_output_2_loss: 0.7469 - val_output_3_loss: 0.7972 - val_output_4_loss: 0.7776 - val_output_5_loss: 0.7612 - val_output_0_acc: 0.6420 - val_output_1_acc: 0.6967 - val_output_2_acc: 0.7017 - val_output_3_acc: 0.6797 - val_output_4_acc: 0.6753 - val_output_5_acc: 0.6993\n",
      "Epoch 40/200\n",
      "7000/7000 [==============================] - 1s 159us/step - loss: 3.6918 - output_0_loss: 0.6271 - output_1_loss: 0.6007 - output_2_loss: 0.5742 - output_3_loss: 0.6233 - output_4_loss: 0.6597 - output_5_loss: 0.6067 - output_0_acc: 0.7679 - output_1_acc: 0.7841 - output_2_acc: 0.8020 - output_3_acc: 0.7750 - output_4_acc: 0.7590 - output_5_acc: 0.7801 - val_loss: 4.3823 - val_output_0_loss: 0.7617 - val_output_1_loss: 0.7759 - val_output_2_loss: 0.6259 - val_output_3_loss: 0.7335 - val_output_4_loss: 0.7371 - val_output_5_loss: 0.7483 - val_output_0_acc: 0.6990 - val_output_1_acc: 0.7050 - val_output_2_acc: 0.7820 - val_output_3_acc: 0.7010 - val_output_4_acc: 0.7000 - val_output_5_acc: 0.6870\n",
      "Epoch 41/200\n",
      "7000/7000 [==============================] - 1s 160us/step - loss: 3.5953 - output_0_loss: 0.6057 - output_1_loss: 0.5822 - output_2_loss: 0.5649 - output_3_loss: 0.6101 - output_4_loss: 0.6456 - output_5_loss: 0.5868 - output_0_acc: 0.7813 - output_1_acc: 0.7957 - output_2_acc: 0.8081 - output_3_acc: 0.7764 - output_4_acc: 0.7593 - output_5_acc: 0.7911 - val_loss: 4.5380 - val_output_0_loss: 0.8575 - val_output_1_loss: 0.6930 - val_output_2_loss: 0.6736 - val_output_3_loss: 0.7637 - val_output_4_loss: 0.8399 - val_output_5_loss: 0.7103 - val_output_0_acc: 0.6380 - val_output_1_acc: 0.7383 - val_output_2_acc: 0.7370 - val_output_3_acc: 0.6830 - val_output_4_acc: 0.6597 - val_output_5_acc: 0.7230\n",
      "Epoch 42/200\n",
      "7000/7000 [==============================] - 1s 149us/step - loss: 3.5206 - output_0_loss: 0.5997 - output_1_loss: 0.5729 - output_2_loss: 0.5505 - output_3_loss: 0.5961 - output_4_loss: 0.6248 - output_5_loss: 0.5766 - output_0_acc: 0.7841 - output_1_acc: 0.7946 - output_2_acc: 0.8099 - output_3_acc: 0.7827 - output_4_acc: 0.7771 - output_5_acc: 0.7979 - val_loss: 4.4920 - val_output_0_loss: 0.7691 - val_output_1_loss: 0.7980 - val_output_2_loss: 0.6015 - val_output_3_loss: 0.7482 - val_output_4_loss: 0.7742 - val_output_5_loss: 0.8011 - val_output_0_acc: 0.6943 - val_output_1_acc: 0.6473 - val_output_2_acc: 0.8033 - val_output_3_acc: 0.6833 - val_output_4_acc: 0.6987 - val_output_5_acc: 0.6657\n",
      "Epoch 43/200\n",
      "7000/7000 [==============================] - 1s 152us/step - loss: 3.4476 - output_0_loss: 0.5840 - output_1_loss: 0.5613 - output_2_loss: 0.5414 - output_3_loss: 0.5841 - output_4_loss: 0.6168 - output_5_loss: 0.5601 - output_0_acc: 0.7807 - output_1_acc: 0.8014 - output_2_acc: 0.8140 - output_3_acc: 0.7973 - output_4_acc: 0.7806 - output_5_acc: 0.8044 - val_loss: 4.3207 - val_output_0_loss: 0.7380 - val_output_1_loss: 0.7493 - val_output_2_loss: 0.6742 - val_output_3_loss: 0.6942 - val_output_4_loss: 0.7451 - val_output_5_loss: 0.7199 - val_output_0_acc: 0.7057 - val_output_1_acc: 0.7047 - val_output_2_acc: 0.7470 - val_output_3_acc: 0.7413 - val_output_4_acc: 0.6977 - val_output_5_acc: 0.7343\n",
      "Epoch 44/200\n",
      "7000/7000 [==============================] - 1s 147us/step - loss: 3.3915 - output_0_loss: 0.5704 - output_1_loss: 0.5453 - output_2_loss: 0.5275 - output_3_loss: 0.5815 - output_4_loss: 0.6082 - output_5_loss: 0.5587 - output_0_acc: 0.8000 - output_1_acc: 0.8071 - output_2_acc: 0.8247 - output_3_acc: 0.7866 - output_4_acc: 0.7794 - output_5_acc: 0.8030 - val_loss: 4.3488 - val_output_0_loss: 0.7897 - val_output_1_loss: 0.7421 - val_output_2_loss: 0.6585 - val_output_3_loss: 0.6917 - val_output_4_loss: 0.7732 - val_output_5_loss: 0.6935 - val_output_0_acc: 0.6620 - val_output_1_acc: 0.7023 - val_output_2_acc: 0.7400 - val_output_3_acc: 0.7133 - val_output_4_acc: 0.6690 - val_output_5_acc: 0.7393\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 151us/step - loss: 3.3123 - output_0_loss: 0.5606 - output_1_loss: 0.5391 - output_2_loss: 0.5131 - output_3_loss: 0.5633 - output_4_loss: 0.5985 - output_5_loss: 0.5377 - output_0_acc: 0.7970 - output_1_acc: 0.8084 - output_2_acc: 0.8281 - output_3_acc: 0.8047 - output_4_acc: 0.7844 - output_5_acc: 0.8124 - val_loss: 4.2546 - val_output_0_loss: 0.7260 - val_output_1_loss: 0.7182 - val_output_2_loss: 0.6251 - val_output_3_loss: 0.6763 - val_output_4_loss: 0.8134 - val_output_5_loss: 0.6956 - val_output_0_acc: 0.7120 - val_output_1_acc: 0.6993 - val_output_2_acc: 0.7633 - val_output_3_acc: 0.7473 - val_output_4_acc: 0.6543 - val_output_5_acc: 0.7150\n",
      "Epoch 46/200\n",
      "7000/7000 [==============================] - 1s 155us/step - loss: 3.2384 - output_0_loss: 0.5492 - output_1_loss: 0.5245 - output_2_loss: 0.5036 - output_3_loss: 0.5449 - output_4_loss: 0.5833 - output_5_loss: 0.5328 - output_0_acc: 0.8083 - output_1_acc: 0.8163 - output_2_acc: 0.8324 - output_3_acc: 0.8117 - output_4_acc: 0.7937 - output_5_acc: 0.8149 - val_loss: 4.2815 - val_output_0_loss: 0.7682 - val_output_1_loss: 0.6693 - val_output_2_loss: 0.6074 - val_output_3_loss: 0.6901 - val_output_4_loss: 0.7365 - val_output_5_loss: 0.8100 - val_output_0_acc: 0.6990 - val_output_1_acc: 0.7467 - val_output_2_acc: 0.7727 - val_output_3_acc: 0.7097 - val_output_4_acc: 0.7190 - val_output_5_acc: 0.6577\n",
      "Epoch 47/200\n",
      "7000/7000 [==============================] - 1s 147us/step - loss: 3.1838 - output_0_loss: 0.5393 - output_1_loss: 0.5127 - output_2_loss: 0.4965 - output_3_loss: 0.5409 - output_4_loss: 0.5722 - output_5_loss: 0.5222 - output_0_acc: 0.8150 - output_1_acc: 0.8243 - output_2_acc: 0.8384 - output_3_acc: 0.8146 - output_4_acc: 0.7981 - output_5_acc: 0.8199 - val_loss: 4.1269 - val_output_0_loss: 0.7839 - val_output_1_loss: 0.6616 - val_output_2_loss: 0.5703 - val_output_3_loss: 0.6446 - val_output_4_loss: 0.7635 - val_output_5_loss: 0.7030 - val_output_0_acc: 0.6363 - val_output_1_acc: 0.7333 - val_output_2_acc: 0.7943 - val_output_3_acc: 0.7543 - val_output_4_acc: 0.7010 - val_output_5_acc: 0.7307\n",
      "Epoch 48/200\n",
      "7000/7000 [==============================] - 1s 147us/step - loss: 3.1201 - output_0_loss: 0.5252 - output_1_loss: 0.5148 - output_2_loss: 0.4804 - output_3_loss: 0.5262 - output_4_loss: 0.5630 - output_5_loss: 0.5104 - output_0_acc: 0.8150 - output_1_acc: 0.8236 - output_2_acc: 0.8430 - output_3_acc: 0.8156 - output_4_acc: 0.7984 - output_5_acc: 0.8263 - val_loss: 4.2290 - val_output_0_loss: 0.8002 - val_output_1_loss: 0.6636 - val_output_2_loss: 0.6747 - val_output_3_loss: 0.7319 - val_output_4_loss: 0.7208 - val_output_5_loss: 0.6377 - val_output_0_acc: 0.6697 - val_output_1_acc: 0.7427 - val_output_2_acc: 0.7573 - val_output_3_acc: 0.6843 - val_output_4_acc: 0.7140 - val_output_5_acc: 0.7743\n",
      "Epoch 49/200\n",
      "7000/7000 [==============================] - 1s 148us/step - loss: 3.0686 - output_0_loss: 0.5237 - output_1_loss: 0.4975 - output_2_loss: 0.4709 - output_3_loss: 0.5207 - output_4_loss: 0.5588 - output_5_loss: 0.4970 - output_0_acc: 0.8197 - output_1_acc: 0.8297 - output_2_acc: 0.8494 - output_3_acc: 0.8196 - output_4_acc: 0.7999 - output_5_acc: 0.8333 - val_loss: 4.0662 - val_output_0_loss: 0.6710 - val_output_1_loss: 0.6346 - val_output_2_loss: 0.6805 - val_output_3_loss: 0.6463 - val_output_4_loss: 0.7495 - val_output_5_loss: 0.6843 - val_output_0_acc: 0.7350 - val_output_1_acc: 0.7670 - val_output_2_acc: 0.7163 - val_output_3_acc: 0.7423 - val_output_4_acc: 0.6757 - val_output_5_acc: 0.7210\n",
      "Epoch 50/200\n",
      "7000/7000 [==============================] - 1s 150us/step - loss: 2.9789 - output_0_loss: 0.5072 - output_1_loss: 0.4769 - output_2_loss: 0.4621 - output_3_loss: 0.5070 - output_4_loss: 0.5409 - output_5_loss: 0.4848 - output_0_acc: 0.8273 - output_1_acc: 0.8390 - output_2_acc: 0.8517 - output_3_acc: 0.8237 - output_4_acc: 0.8107 - output_5_acc: 0.8354 - val_loss: 3.8232 - val_output_0_loss: 0.7137 - val_output_1_loss: 0.5985 - val_output_2_loss: 0.5984 - val_output_3_loss: 0.6839 - val_output_4_loss: 0.6245 - val_output_5_loss: 0.6042 - val_output_0_acc: 0.6950 - val_output_1_acc: 0.7663 - val_output_2_acc: 0.7913 - val_output_3_acc: 0.6897 - val_output_4_acc: 0.7837 - val_output_5_acc: 0.7830\n",
      "Epoch 51/200\n",
      "7000/7000 [==============================] - 1s 145us/step - loss: 2.9381 - output_0_loss: 0.4936 - output_1_loss: 0.4766 - output_2_loss: 0.4544 - output_3_loss: 0.4943 - output_4_loss: 0.5369 - output_5_loss: 0.4824 - output_0_acc: 0.8367 - output_1_acc: 0.8353 - output_2_acc: 0.8516 - output_3_acc: 0.8289 - output_4_acc: 0.8107 - output_5_acc: 0.8417 - val_loss: 4.1374 - val_output_0_loss: 0.6900 - val_output_1_loss: 0.7252 - val_output_2_loss: 0.7124 - val_output_3_loss: 0.6560 - val_output_4_loss: 0.7059 - val_output_5_loss: 0.6480 - val_output_0_acc: 0.7093 - val_output_1_acc: 0.6980 - val_output_2_acc: 0.6727 - val_output_3_acc: 0.7620 - val_output_4_acc: 0.7053 - val_output_5_acc: 0.7493\n",
      "Epoch 52/200\n",
      "7000/7000 [==============================] - 1s 143us/step - loss: 2.8814 - output_0_loss: 0.4911 - output_1_loss: 0.4652 - output_2_loss: 0.4453 - output_3_loss: 0.4866 - output_4_loss: 0.5241 - output_5_loss: 0.4692 - output_0_acc: 0.8353 - output_1_acc: 0.8440 - output_2_acc: 0.8549 - output_3_acc: 0.8366 - output_4_acc: 0.8167 - output_5_acc: 0.8430 - val_loss: 4.0744 - val_output_0_loss: 0.7127 - val_output_1_loss: 0.7381 - val_output_2_loss: 0.6400 - val_output_3_loss: 0.6499 - val_output_4_loss: 0.6979 - val_output_5_loss: 0.6357 - val_output_0_acc: 0.7083 - val_output_1_acc: 0.6877 - val_output_2_acc: 0.7293 - val_output_3_acc: 0.7497 - val_output_4_acc: 0.7007 - val_output_5_acc: 0.7377\n",
      "Epoch 53/200\n",
      "7000/7000 [==============================] - 1s 144us/step - loss: 2.8187 - output_0_loss: 0.4770 - output_1_loss: 0.4542 - output_2_loss: 0.4310 - output_3_loss: 0.4786 - output_4_loss: 0.5138 - output_5_loss: 0.4641 - output_0_acc: 0.8363 - output_1_acc: 0.8557 - output_2_acc: 0.8687 - output_3_acc: 0.8437 - output_4_acc: 0.8239 - output_5_acc: 0.8437 - val_loss: 3.6754 - val_output_0_loss: 0.6858 - val_output_1_loss: 0.6151 - val_output_2_loss: 0.5597 - val_output_3_loss: 0.6067 - val_output_4_loss: 0.6346 - val_output_5_loss: 0.5734 - val_output_0_acc: 0.7213 - val_output_1_acc: 0.7787 - val_output_2_acc: 0.8010 - val_output_3_acc: 0.7687 - val_output_4_acc: 0.7483 - val_output_5_acc: 0.7927\n",
      "Epoch 54/200\n",
      "7000/7000 [==============================] - 1s 153us/step - loss: 2.7627 - output_0_loss: 0.4724 - output_1_loss: 0.4448 - output_2_loss: 0.4212 - output_3_loss: 0.4663 - output_4_loss: 0.5083 - output_5_loss: 0.4498 - output_0_acc: 0.8411 - output_1_acc: 0.8517 - output_2_acc: 0.8730 - output_3_acc: 0.8496 - output_4_acc: 0.8219 - output_5_acc: 0.8489 - val_loss: 3.6398 - val_output_0_loss: 0.5801 - val_output_1_loss: 0.6467 - val_output_2_loss: 0.5333 - val_output_3_loss: 0.5749 - val_output_4_loss: 0.6948 - val_output_5_loss: 0.6101 - val_output_0_acc: 0.8000 - val_output_1_acc: 0.7220 - val_output_2_acc: 0.8180 - val_output_3_acc: 0.7873 - val_output_4_acc: 0.7133 - val_output_5_acc: 0.7667\n",
      "Epoch 55/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 2.7163 - output_0_loss: 0.4575 - output_1_loss: 0.4405 - output_2_loss: 0.4098 - output_3_loss: 0.4638 - output_4_loss: 0.4992 - output_5_loss: 0.4455 - output_0_acc: 0.8497 - output_1_acc: 0.8527 - output_2_acc: 0.8776 - output_3_acc: 0.8491 - output_4_acc: 0.8219 - output_5_acc: 0.8554 - val_loss: 3.9138 - val_output_0_loss: 0.7496 - val_output_1_loss: 0.7488 - val_output_2_loss: 0.5436 - val_output_3_loss: 0.6401 - val_output_4_loss: 0.6340 - val_output_5_loss: 0.5977 - val_output_0_acc: 0.6917 - val_output_1_acc: 0.6780 - val_output_2_acc: 0.8027 - val_output_3_acc: 0.7417 - val_output_4_acc: 0.7490 - val_output_5_acc: 0.7793\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 148us/step - loss: 2.6546 - output_0_loss: 0.4520 - output_1_loss: 0.4309 - output_2_loss: 0.4024 - output_3_loss: 0.4486 - output_4_loss: 0.4849 - output_5_loss: 0.4357 - output_0_acc: 0.8496 - output_1_acc: 0.8584 - output_2_acc: 0.8754 - output_3_acc: 0.8570 - output_4_acc: 0.8317 - output_5_acc: 0.8559 - val_loss: 3.8361 - val_output_0_loss: 0.7052 - val_output_1_loss: 0.5675 - val_output_2_loss: 0.6110 - val_output_3_loss: 0.5917 - val_output_4_loss: 0.7129 - val_output_5_loss: 0.6478 - val_output_0_acc: 0.7177 - val_output_1_acc: 0.8027 - val_output_2_acc: 0.7463 - val_output_3_acc: 0.7610 - val_output_4_acc: 0.7157 - val_output_5_acc: 0.7283\n",
      "Epoch 57/200\n",
      "7000/7000 [==============================] - 1s 154us/step - loss: 2.6129 - output_0_loss: 0.4476 - output_1_loss: 0.4234 - output_2_loss: 0.3945 - output_3_loss: 0.4424 - output_4_loss: 0.4802 - output_5_loss: 0.4248 - output_0_acc: 0.8519 - output_1_acc: 0.8643 - output_2_acc: 0.8786 - output_3_acc: 0.8543 - output_4_acc: 0.8383 - output_5_acc: 0.8633 - val_loss: 3.7014 - val_output_0_loss: 0.6093 - val_output_1_loss: 0.6369 - val_output_2_loss: 0.5418 - val_output_3_loss: 0.5389 - val_output_4_loss: 0.7385 - val_output_5_loss: 0.6360 - val_output_0_acc: 0.7477 - val_output_1_acc: 0.7273 - val_output_2_acc: 0.7970 - val_output_3_acc: 0.8003 - val_output_4_acc: 0.6947 - val_output_5_acc: 0.7487\n",
      "Epoch 58/200\n",
      "7000/7000 [==============================] - 1s 153us/step - loss: 2.5716 - output_0_loss: 0.4367 - output_1_loss: 0.4149 - output_2_loss: 0.3869 - output_3_loss: 0.4281 - output_4_loss: 0.4817 - output_5_loss: 0.4233 - output_0_acc: 0.8597 - output_1_acc: 0.8671 - output_2_acc: 0.8817 - output_3_acc: 0.8653 - output_4_acc: 0.8297 - output_5_acc: 0.8604 - val_loss: 3.5544 - val_output_0_loss: 0.6101 - val_output_1_loss: 0.5573 - val_output_2_loss: 0.5506 - val_output_3_loss: 0.5753 - val_output_4_loss: 0.6367 - val_output_5_loss: 0.6243 - val_output_0_acc: 0.7647 - val_output_1_acc: 0.7873 - val_output_2_acc: 0.8013 - val_output_3_acc: 0.7823 - val_output_4_acc: 0.7567 - val_output_5_acc: 0.7413\n",
      "Epoch 59/200\n",
      "7000/7000 [==============================] - 1s 153us/step - loss: 2.5090 - output_0_loss: 0.4259 - output_1_loss: 0.4008 - output_2_loss: 0.3826 - output_3_loss: 0.4265 - output_4_loss: 0.4639 - output_5_loss: 0.4094 - output_0_acc: 0.8617 - output_1_acc: 0.8729 - output_2_acc: 0.8857 - output_3_acc: 0.8620 - output_4_acc: 0.8441 - output_5_acc: 0.8711 - val_loss: 3.5041 - val_output_0_loss: 0.6503 - val_output_1_loss: 0.5917 - val_output_2_loss: 0.5126 - val_output_3_loss: 0.5425 - val_output_4_loss: 0.6281 - val_output_5_loss: 0.5789 - val_output_0_acc: 0.7403 - val_output_1_acc: 0.7810 - val_output_2_acc: 0.8133 - val_output_3_acc: 0.8030 - val_output_4_acc: 0.7473 - val_output_5_acc: 0.7767\n",
      "Epoch 60/200\n",
      "7000/7000 [==============================] - 1s 168us/step - loss: 2.4585 - output_0_loss: 0.4162 - output_1_loss: 0.3969 - output_2_loss: 0.3708 - output_3_loss: 0.4139 - output_4_loss: 0.4581 - output_5_loss: 0.4026 - output_0_acc: 0.8676 - output_1_acc: 0.8749 - output_2_acc: 0.8880 - output_3_acc: 0.8650 - output_4_acc: 0.8439 - output_5_acc: 0.8720 - val_loss: 3.5928 - val_output_0_loss: 0.6994 - val_output_1_loss: 0.6573 - val_output_2_loss: 0.5745 - val_output_3_loss: 0.5616 - val_output_4_loss: 0.5699 - val_output_5_loss: 0.5302 - val_output_0_acc: 0.6747 - val_output_1_acc: 0.7427 - val_output_2_acc: 0.7683 - val_output_3_acc: 0.7930 - val_output_4_acc: 0.7970 - val_output_5_acc: 0.8163\n",
      "Epoch 61/200\n",
      "7000/7000 [==============================] - 1s 172us/step - loss: 2.4233 - output_0_loss: 0.4177 - output_1_loss: 0.3905 - output_2_loss: 0.3643 - output_3_loss: 0.4093 - output_4_loss: 0.4483 - output_5_loss: 0.3933 - output_0_acc: 0.8610 - output_1_acc: 0.8774 - output_2_acc: 0.8939 - output_3_acc: 0.8669 - output_4_acc: 0.8520 - output_5_acc: 0.8751 - val_loss: 3.4655 - val_output_0_loss: 0.5908 - val_output_1_loss: 0.5144 - val_output_2_loss: 0.4755 - val_output_3_loss: 0.5342 - val_output_4_loss: 0.6660 - val_output_5_loss: 0.6847 - val_output_0_acc: 0.7743 - val_output_1_acc: 0.8200 - val_output_2_acc: 0.8397 - val_output_3_acc: 0.8190 - val_output_4_acc: 0.7400 - val_output_5_acc: 0.7200\n",
      "Epoch 62/200\n",
      "7000/7000 [==============================] - 1s 156us/step - loss: 2.3662 - output_0_loss: 0.4048 - output_1_loss: 0.3813 - output_2_loss: 0.3547 - output_3_loss: 0.3995 - output_4_loss: 0.4397 - output_5_loss: 0.3863 - output_0_acc: 0.8740 - output_1_acc: 0.8814 - output_2_acc: 0.8943 - output_3_acc: 0.8746 - output_4_acc: 0.8459 - output_5_acc: 0.8767 - val_loss: 3.2886 - val_output_0_loss: 0.6030 - val_output_1_loss: 0.5098 - val_output_2_loss: 0.4849 - val_output_3_loss: 0.5475 - val_output_4_loss: 0.6173 - val_output_5_loss: 0.5260 - val_output_0_acc: 0.7743 - val_output_1_acc: 0.8223 - val_output_2_acc: 0.8173 - val_output_3_acc: 0.7833 - val_output_4_acc: 0.7573 - val_output_5_acc: 0.8077\n",
      "Epoch 63/200\n",
      "7000/7000 [==============================] - 1s 150us/step - loss: 2.3262 - output_0_loss: 0.3989 - output_1_loss: 0.3705 - output_2_loss: 0.3527 - output_3_loss: 0.3886 - output_4_loss: 0.4359 - output_5_loss: 0.3795 - output_0_acc: 0.8739 - output_1_acc: 0.8857 - output_2_acc: 0.8949 - output_3_acc: 0.8726 - output_4_acc: 0.8556 - output_5_acc: 0.8811 - val_loss: 3.3709 - val_output_0_loss: 0.5401 - val_output_1_loss: 0.5818 - val_output_2_loss: 0.5175 - val_output_3_loss: 0.5359 - val_output_4_loss: 0.6456 - val_output_5_loss: 0.5499 - val_output_0_acc: 0.8107 - val_output_1_acc: 0.7727 - val_output_2_acc: 0.8037 - val_output_3_acc: 0.8087 - val_output_4_acc: 0.7207 - val_output_5_acc: 0.7903\n",
      "Epoch 64/200\n",
      "7000/7000 [==============================] - 1s 151us/step - loss: 2.2849 - output_0_loss: 0.3901 - output_1_loss: 0.3690 - output_2_loss: 0.3421 - output_3_loss: 0.3815 - output_4_loss: 0.4285 - output_5_loss: 0.3736 - output_0_acc: 0.8754 - output_1_acc: 0.8857 - output_2_acc: 0.8984 - output_3_acc: 0.8794 - output_4_acc: 0.8559 - output_5_acc: 0.8869 - val_loss: 3.2738 - val_output_0_loss: 0.5866 - val_output_1_loss: 0.5053 - val_output_2_loss: 0.4996 - val_output_3_loss: 0.5058 - val_output_4_loss: 0.5953 - val_output_5_loss: 0.5813 - val_output_0_acc: 0.7680 - val_output_1_acc: 0.8183 - val_output_2_acc: 0.8227 - val_output_3_acc: 0.8290 - val_output_4_acc: 0.7620 - val_output_5_acc: 0.7580\n",
      "Epoch 65/200\n",
      "7000/7000 [==============================] - 1s 156us/step - loss: 2.2324 - output_0_loss: 0.3797 - output_1_loss: 0.3601 - output_2_loss: 0.3328 - output_3_loss: 0.3746 - output_4_loss: 0.4217 - output_5_loss: 0.3636 - output_0_acc: 0.8791 - output_1_acc: 0.8900 - output_2_acc: 0.9047 - output_3_acc: 0.8850 - output_4_acc: 0.8551 - output_5_acc: 0.8869 - val_loss: 3.4134 - val_output_0_loss: 0.6027 - val_output_1_loss: 0.6129 - val_output_2_loss: 0.5200 - val_output_3_loss: 0.5304 - val_output_4_loss: 0.6039 - val_output_5_loss: 0.5436 - val_output_0_acc: 0.7597 - val_output_1_acc: 0.7547 - val_output_2_acc: 0.8300 - val_output_3_acc: 0.8077 - val_output_4_acc: 0.7677 - val_output_5_acc: 0.7893\n",
      "Epoch 66/200\n",
      "7000/7000 [==============================] - 1s 153us/step - loss: 2.2038 - output_0_loss: 0.3716 - output_1_loss: 0.3581 - output_2_loss: 0.3281 - output_3_loss: 0.3709 - output_4_loss: 0.4158 - output_5_loss: 0.3592 - output_0_acc: 0.8834 - output_1_acc: 0.8916 - output_2_acc: 0.9034 - output_3_acc: 0.8866 - output_4_acc: 0.8599 - output_5_acc: 0.8901 - val_loss: 3.2735 - val_output_0_loss: 0.5910 - val_output_1_loss: 0.5332 - val_output_2_loss: 0.4705 - val_output_3_loss: 0.4775 - val_output_4_loss: 0.5593 - val_output_5_loss: 0.6419 - val_output_0_acc: 0.7623 - val_output_1_acc: 0.7987 - val_output_2_acc: 0.8430 - val_output_3_acc: 0.8430 - val_output_4_acc: 0.7913 - val_output_5_acc: 0.7210\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 145us/step - loss: 2.1440 - output_0_loss: 0.3653 - output_1_loss: 0.3427 - output_2_loss: 0.3211 - output_3_loss: 0.3617 - output_4_loss: 0.4034 - output_5_loss: 0.3497 - output_0_acc: 0.8870 - output_1_acc: 0.8933 - output_2_acc: 0.9074 - output_3_acc: 0.8849 - output_4_acc: 0.8659 - output_5_acc: 0.8903 - val_loss: 3.3507 - val_output_0_loss: 0.5300 - val_output_1_loss: 0.5889 - val_output_2_loss: 0.5032 - val_output_3_loss: 0.5197 - val_output_4_loss: 0.6881 - val_output_5_loss: 0.5208 - val_output_0_acc: 0.8040 - val_output_1_acc: 0.7567 - val_output_2_acc: 0.8247 - val_output_3_acc: 0.8067 - val_output_4_acc: 0.7613 - val_output_5_acc: 0.7977\n",
      "Epoch 68/200\n",
      "7000/7000 [==============================] - 1s 159us/step - loss: 2.1235 - output_0_loss: 0.3612 - output_1_loss: 0.3439 - output_2_loss: 0.3153 - output_3_loss: 0.3584 - output_4_loss: 0.4016 - output_5_loss: 0.3432 - output_0_acc: 0.8876 - output_1_acc: 0.8960 - output_2_acc: 0.9137 - output_3_acc: 0.8909 - output_4_acc: 0.8696 - output_5_acc: 0.8936 - val_loss: 3.2074 - val_output_0_loss: 0.5890 - val_output_1_loss: 0.5351 - val_output_2_loss: 0.4705 - val_output_3_loss: 0.5044 - val_output_4_loss: 0.6246 - val_output_5_loss: 0.4839 - val_output_0_acc: 0.7607 - val_output_1_acc: 0.7873 - val_output_2_acc: 0.8347 - val_output_3_acc: 0.8107 - val_output_4_acc: 0.7223 - val_output_5_acc: 0.8297\n",
      "Epoch 69/200\n",
      "7000/7000 [==============================] - 1s 150us/step - loss: 2.0684 - output_0_loss: 0.3522 - output_1_loss: 0.3309 - output_2_loss: 0.3046 - output_3_loss: 0.3465 - output_4_loss: 0.3942 - output_5_loss: 0.3400 - output_0_acc: 0.8923 - output_1_acc: 0.9010 - output_2_acc: 0.9126 - output_3_acc: 0.8979 - output_4_acc: 0.8704 - output_5_acc: 0.8964 - val_loss: 3.2007 - val_output_0_loss: 0.5684 - val_output_1_loss: 0.5593 - val_output_2_loss: 0.4385 - val_output_3_loss: 0.4825 - val_output_4_loss: 0.5546 - val_output_5_loss: 0.5974 - val_output_0_acc: 0.7700 - val_output_1_acc: 0.7880 - val_output_2_acc: 0.8483 - val_output_3_acc: 0.8180 - val_output_4_acc: 0.7890 - val_output_5_acc: 0.7587\n",
      "Epoch 70/200\n",
      "7000/7000 [==============================] - 1s 149us/step - loss: 2.0288 - output_0_loss: 0.3426 - output_1_loss: 0.3218 - output_2_loss: 0.3067 - output_3_loss: 0.3398 - output_4_loss: 0.3882 - output_5_loss: 0.3298 - output_0_acc: 0.8980 - output_1_acc: 0.9049 - output_2_acc: 0.9103 - output_3_acc: 0.8979 - output_4_acc: 0.8789 - output_5_acc: 0.9004 - val_loss: 3.1013 - val_output_0_loss: 0.5505 - val_output_1_loss: 0.5128 - val_output_2_loss: 0.5040 - val_output_3_loss: 0.4430 - val_output_4_loss: 0.6041 - val_output_5_loss: 0.4869 - val_output_0_acc: 0.7870 - val_output_1_acc: 0.8073 - val_output_2_acc: 0.8120 - val_output_3_acc: 0.8503 - val_output_4_acc: 0.7537 - val_output_5_acc: 0.8253\n",
      "Epoch 71/200\n",
      "7000/7000 [==============================] - 1s 152us/step - loss: 1.9991 - output_0_loss: 0.3443 - output_1_loss: 0.3167 - output_2_loss: 0.2931 - output_3_loss: 0.3397 - output_4_loss: 0.3787 - output_5_loss: 0.3266 - output_0_acc: 0.8937 - output_1_acc: 0.9064 - output_2_acc: 0.9169 - output_3_acc: 0.8969 - output_4_acc: 0.8784 - output_5_acc: 0.9093 - val_loss: 2.9001 - val_output_0_loss: 0.4716 - val_output_1_loss: 0.4871 - val_output_2_loss: 0.4288 - val_output_3_loss: 0.4665 - val_output_4_loss: 0.6017 - val_output_5_loss: 0.4444 - val_output_0_acc: 0.8433 - val_output_1_acc: 0.8073 - val_output_2_acc: 0.8610 - val_output_3_acc: 0.8283 - val_output_4_acc: 0.7650 - val_output_5_acc: 0.8563\n",
      "Epoch 72/200\n",
      "7000/7000 [==============================] - 1s 154us/step - loss: 1.9606 - output_0_loss: 0.3398 - output_1_loss: 0.3118 - output_2_loss: 0.2901 - output_3_loss: 0.3298 - output_4_loss: 0.3749 - output_5_loss: 0.3143 - output_0_acc: 0.8954 - output_1_acc: 0.9053 - output_2_acc: 0.9139 - output_3_acc: 0.8987 - output_4_acc: 0.8790 - output_5_acc: 0.9070 - val_loss: 2.9587 - val_output_0_loss: 0.5232 - val_output_1_loss: 0.4289 - val_output_2_loss: 0.4565 - val_output_3_loss: 0.4272 - val_output_4_loss: 0.6090 - val_output_5_loss: 0.5139 - val_output_0_acc: 0.8173 - val_output_1_acc: 0.8567 - val_output_2_acc: 0.8320 - val_output_3_acc: 0.8617 - val_output_4_acc: 0.7647 - val_output_5_acc: 0.8023\n",
      "Epoch 73/200\n",
      "7000/7000 [==============================] - 1s 143us/step - loss: 1.9194 - output_0_loss: 0.3275 - output_1_loss: 0.3091 - output_2_loss: 0.2826 - output_3_loss: 0.3178 - output_4_loss: 0.3699 - output_5_loss: 0.3125 - output_0_acc: 0.9004 - output_1_acc: 0.9073 - output_2_acc: 0.9204 - output_3_acc: 0.9084 - output_4_acc: 0.8796 - output_5_acc: 0.9096 - val_loss: 2.9966 - val_output_0_loss: 0.5760 - val_output_1_loss: 0.4361 - val_output_2_loss: 0.4246 - val_output_3_loss: 0.5015 - val_output_4_loss: 0.5742 - val_output_5_loss: 0.4842 - val_output_0_acc: 0.7770 - val_output_1_acc: 0.8503 - val_output_2_acc: 0.8493 - val_output_3_acc: 0.7983 - val_output_4_acc: 0.7770 - val_output_5_acc: 0.8227\n",
      "Epoch 74/200\n",
      "7000/7000 [==============================] - 1s 148us/step - loss: 1.8734 - output_0_loss: 0.3177 - output_1_loss: 0.3014 - output_2_loss: 0.2774 - output_3_loss: 0.3140 - output_4_loss: 0.3645 - output_5_loss: 0.2985 - output_0_acc: 0.9061 - output_1_acc: 0.9114 - output_2_acc: 0.9239 - output_3_acc: 0.9073 - output_4_acc: 0.8847 - output_5_acc: 0.9136 - val_loss: 2.9530 - val_output_0_loss: 0.5320 - val_output_1_loss: 0.4770 - val_output_2_loss: 0.4039 - val_output_3_loss: 0.4774 - val_output_4_loss: 0.5463 - val_output_5_loss: 0.5165 - val_output_0_acc: 0.7980 - val_output_1_acc: 0.8360 - val_output_2_acc: 0.8583 - val_output_3_acc: 0.8270 - val_output_4_acc: 0.7890 - val_output_5_acc: 0.7823\n",
      "Epoch 75/200\n",
      "7000/7000 [==============================] - 1s 154us/step - loss: 1.8446 - output_0_loss: 0.3145 - output_1_loss: 0.2922 - output_2_loss: 0.2690 - output_3_loss: 0.3107 - output_4_loss: 0.3596 - output_5_loss: 0.2986 - output_0_acc: 0.9073 - output_1_acc: 0.9161 - output_2_acc: 0.9294 - output_3_acc: 0.9091 - output_4_acc: 0.8833 - output_5_acc: 0.9123 - val_loss: 2.8930 - val_output_0_loss: 0.5096 - val_output_1_loss: 0.5413 - val_output_2_loss: 0.4529 - val_output_3_loss: 0.4957 - val_output_4_loss: 0.4650 - val_output_5_loss: 0.4285 - val_output_0_acc: 0.8113 - val_output_1_acc: 0.7787 - val_output_2_acc: 0.8330 - val_output_3_acc: 0.8020 - val_output_4_acc: 0.8323 - val_output_5_acc: 0.8457\n",
      "Epoch 76/200\n",
      "7000/7000 [==============================] - 1s 156us/step - loss: 1.8047 - output_0_loss: 0.3067 - output_1_loss: 0.2881 - output_2_loss: 0.2627 - output_3_loss: 0.3052 - output_4_loss: 0.3502 - output_5_loss: 0.2918 - output_0_acc: 0.9096 - output_1_acc: 0.9189 - output_2_acc: 0.9271 - output_3_acc: 0.9130 - output_4_acc: 0.8851 - output_5_acc: 0.9186 - val_loss: 2.6525 - val_output_0_loss: 0.4691 - val_output_1_loss: 0.4524 - val_output_2_loss: 0.3983 - val_output_3_loss: 0.3910 - val_output_4_loss: 0.5140 - val_output_5_loss: 0.4277 - val_output_0_acc: 0.8213 - val_output_1_acc: 0.8330 - val_output_2_acc: 0.8693 - val_output_3_acc: 0.8757 - val_output_4_acc: 0.8160 - val_output_5_acc: 0.8533\n",
      "Epoch 77/200\n",
      "7000/7000 [==============================] - 1s 153us/step - loss: 1.7778 - output_0_loss: 0.3004 - output_1_loss: 0.2887 - output_2_loss: 0.2604 - output_3_loss: 0.2932 - output_4_loss: 0.3445 - output_5_loss: 0.2907 - output_0_acc: 0.9140 - output_1_acc: 0.9150 - output_2_acc: 0.9303 - output_3_acc: 0.9149 - output_4_acc: 0.8873 - output_5_acc: 0.9163 - val_loss: 2.9998 - val_output_0_loss: 0.5551 - val_output_1_loss: 0.4879 - val_output_2_loss: 0.4422 - val_output_3_loss: 0.4568 - val_output_4_loss: 0.5806 - val_output_5_loss: 0.4772 - val_output_0_acc: 0.7940 - val_output_1_acc: 0.8127 - val_output_2_acc: 0.8403 - val_output_3_acc: 0.8343 - val_output_4_acc: 0.7753 - val_output_5_acc: 0.8280\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 152us/step - loss: 1.7525 - output_0_loss: 0.2985 - output_1_loss: 0.2794 - output_2_loss: 0.2582 - output_3_loss: 0.2957 - output_4_loss: 0.3378 - output_5_loss: 0.2827 - output_0_acc: 0.9106 - output_1_acc: 0.9230 - output_2_acc: 0.9320 - output_3_acc: 0.9139 - output_4_acc: 0.8916 - output_5_acc: 0.9141 - val_loss: 2.7422 - val_output_0_loss: 0.4836 - val_output_1_loss: 0.4514 - val_output_2_loss: 0.4250 - val_output_3_loss: 0.3980 - val_output_4_loss: 0.5153 - val_output_5_loss: 0.4689 - val_output_0_acc: 0.8183 - val_output_1_acc: 0.8317 - val_output_2_acc: 0.8500 - val_output_3_acc: 0.8707 - val_output_4_acc: 0.8057 - val_output_5_acc: 0.8330\n",
      "Epoch 79/200\n",
      "7000/7000 [==============================] - 1s 155us/step - loss: 1.7097 - output_0_loss: 0.2910 - output_1_loss: 0.2726 - output_2_loss: 0.2501 - output_3_loss: 0.2861 - output_4_loss: 0.3321 - output_5_loss: 0.2778 - output_0_acc: 0.9137 - output_1_acc: 0.9240 - output_2_acc: 0.9343 - output_3_acc: 0.9193 - output_4_acc: 0.8976 - output_5_acc: 0.9186 - val_loss: 2.7809 - val_output_0_loss: 0.4584 - val_output_1_loss: 0.4549 - val_output_2_loss: 0.3844 - val_output_3_loss: 0.4372 - val_output_4_loss: 0.6095 - val_output_5_loss: 0.4365 - val_output_0_acc: 0.8403 - val_output_1_acc: 0.8187 - val_output_2_acc: 0.8687 - val_output_3_acc: 0.8400 - val_output_4_acc: 0.7340 - val_output_5_acc: 0.8417\n",
      "Epoch 80/200\n",
      "7000/7000 [==============================] - 1s 151us/step - loss: 1.6929 - output_0_loss: 0.2878 - output_1_loss: 0.2690 - output_2_loss: 0.2492 - output_3_loss: 0.2822 - output_4_loss: 0.3290 - output_5_loss: 0.2756 - output_0_acc: 0.9127 - output_1_acc: 0.9239 - output_2_acc: 0.9316 - output_3_acc: 0.9147 - output_4_acc: 0.8936 - output_5_acc: 0.9189 - val_loss: 2.6880 - val_output_0_loss: 0.4848 - val_output_1_loss: 0.3871 - val_output_2_loss: 0.4794 - val_output_3_loss: 0.4205 - val_output_4_loss: 0.4965 - val_output_5_loss: 0.4197 - val_output_0_acc: 0.8163 - val_output_1_acc: 0.8780 - val_output_2_acc: 0.8147 - val_output_3_acc: 0.8373 - val_output_4_acc: 0.8163 - val_output_5_acc: 0.8680\n",
      "Epoch 81/200\n",
      "7000/7000 [==============================] - 1s 153us/step - loss: 1.6433 - output_0_loss: 0.2776 - output_1_loss: 0.2587 - output_2_loss: 0.2434 - output_3_loss: 0.2781 - output_4_loss: 0.3207 - output_5_loss: 0.2648 - output_0_acc: 0.9211 - output_1_acc: 0.9260 - output_2_acc: 0.9370 - output_3_acc: 0.9217 - output_4_acc: 0.8984 - output_5_acc: 0.9264 - val_loss: 2.6783 - val_output_0_loss: 0.4909 - val_output_1_loss: 0.4125 - val_output_2_loss: 0.4078 - val_output_3_loss: 0.4989 - val_output_4_loss: 0.4479 - val_output_5_loss: 0.4203 - val_output_0_acc: 0.7990 - val_output_1_acc: 0.8490 - val_output_2_acc: 0.8557 - val_output_3_acc: 0.7950 - val_output_4_acc: 0.8380 - val_output_5_acc: 0.8543\n",
      "Epoch 82/200\n",
      "7000/7000 [==============================] - 1s 158us/step - loss: 1.6315 - output_0_loss: 0.2750 - output_1_loss: 0.2604 - output_2_loss: 0.2388 - output_3_loss: 0.2748 - output_4_loss: 0.3144 - output_5_loss: 0.2681 - output_0_acc: 0.9231 - output_1_acc: 0.9224 - output_2_acc: 0.9361 - output_3_acc: 0.9189 - output_4_acc: 0.9006 - output_5_acc: 0.9210 - val_loss: 2.5790 - val_output_0_loss: 0.4561 - val_output_1_loss: 0.4139 - val_output_2_loss: 0.3896 - val_output_3_loss: 0.4451 - val_output_4_loss: 0.4761 - val_output_5_loss: 0.3982 - val_output_0_acc: 0.8287 - val_output_1_acc: 0.8630 - val_output_2_acc: 0.8687 - val_output_3_acc: 0.8377 - val_output_4_acc: 0.8110 - val_output_5_acc: 0.8750\n",
      "Epoch 83/200\n",
      "7000/7000 [==============================] - 1s 148us/step - loss: 1.5881 - output_0_loss: 0.2698 - output_1_loss: 0.2501 - output_2_loss: 0.2308 - output_3_loss: 0.2688 - output_4_loss: 0.3118 - output_5_loss: 0.2569 - output_0_acc: 0.9213 - output_1_acc: 0.9304 - output_2_acc: 0.9386 - output_3_acc: 0.9237 - output_4_acc: 0.9034 - output_5_acc: 0.9264 - val_loss: 2.7333 - val_output_0_loss: 0.5265 - val_output_1_loss: 0.4074 - val_output_2_loss: 0.3969 - val_output_3_loss: 0.4330 - val_output_4_loss: 0.4887 - val_output_5_loss: 0.4808 - val_output_0_acc: 0.8080 - val_output_1_acc: 0.8607 - val_output_2_acc: 0.8540 - val_output_3_acc: 0.8477 - val_output_4_acc: 0.8260 - val_output_5_acc: 0.8280\n",
      "Epoch 84/200\n",
      "7000/7000 [==============================] - 1s 161us/step - loss: 1.5572 - output_0_loss: 0.2662 - output_1_loss: 0.2475 - output_2_loss: 0.2278 - output_3_loss: 0.2617 - output_4_loss: 0.3050 - output_5_loss: 0.2491 - output_0_acc: 0.9246 - output_1_acc: 0.9334 - output_2_acc: 0.9404 - output_3_acc: 0.9283 - output_4_acc: 0.9019 - output_5_acc: 0.9307 - val_loss: 2.6258 - val_output_0_loss: 0.4557 - val_output_1_loss: 0.4318 - val_output_2_loss: 0.4226 - val_output_3_loss: 0.4587 - val_output_4_loss: 0.4605 - val_output_5_loss: 0.3967 - val_output_0_acc: 0.8323 - val_output_1_acc: 0.8400 - val_output_2_acc: 0.8513 - val_output_3_acc: 0.8390 - val_output_4_acc: 0.8280 - val_output_5_acc: 0.8700\n",
      "Epoch 85/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 1.5246 - output_0_loss: 0.2563 - output_1_loss: 0.2425 - output_2_loss: 0.2262 - output_3_loss: 0.2527 - output_4_loss: 0.2988 - output_5_loss: 0.2481 - output_0_acc: 0.9259 - output_1_acc: 0.9329 - output_2_acc: 0.9396 - output_3_acc: 0.9337 - output_4_acc: 0.9079 - output_5_acc: 0.9337 - val_loss: 2.6501 - val_output_0_loss: 0.5668 - val_output_1_loss: 0.4734 - val_output_2_loss: 0.3055 - val_output_3_loss: 0.4532 - val_output_4_loss: 0.4782 - val_output_5_loss: 0.3730 - val_output_0_acc: 0.7900 - val_output_1_acc: 0.8283 - val_output_2_acc: 0.9113 - val_output_3_acc: 0.8147 - val_output_4_acc: 0.8133 - val_output_5_acc: 0.8807\n",
      "Epoch 86/200\n",
      "7000/7000 [==============================] - 1s 155us/step - loss: 1.5047 - output_0_loss: 0.2577 - output_1_loss: 0.2347 - output_2_loss: 0.2173 - output_3_loss: 0.2518 - output_4_loss: 0.3006 - output_5_loss: 0.2426 - output_0_acc: 0.9277 - output_1_acc: 0.9371 - output_2_acc: 0.9411 - output_3_acc: 0.9320 - output_4_acc: 0.9051 - output_5_acc: 0.9337 - val_loss: 2.4945 - val_output_0_loss: 0.4211 - val_output_1_loss: 0.4879 - val_output_2_loss: 0.3160 - val_output_3_loss: 0.3685 - val_output_4_loss: 0.4502 - val_output_5_loss: 0.4508 - val_output_0_acc: 0.8487 - val_output_1_acc: 0.8200 - val_output_2_acc: 0.8973 - val_output_3_acc: 0.8750 - val_output_4_acc: 0.8187 - val_output_5_acc: 0.8393\n",
      "Epoch 87/200\n",
      "7000/7000 [==============================] - 1s 152us/step - loss: 1.4710 - output_0_loss: 0.2518 - output_1_loss: 0.2353 - output_2_loss: 0.2125 - output_3_loss: 0.2436 - output_4_loss: 0.2861 - output_5_loss: 0.2417 - output_0_acc: 0.9314 - output_1_acc: 0.9374 - output_2_acc: 0.9420 - output_3_acc: 0.9340 - output_4_acc: 0.9083 - output_5_acc: 0.9341 - val_loss: 2.6174 - val_output_0_loss: 0.4221 - val_output_1_loss: 0.3800 - val_output_2_loss: 0.3814 - val_output_3_loss: 0.4359 - val_output_4_loss: 0.5509 - val_output_5_loss: 0.4472 - val_output_0_acc: 0.8477 - val_output_1_acc: 0.8680 - val_output_2_acc: 0.8663 - val_output_3_acc: 0.8280 - val_output_4_acc: 0.7903 - val_output_5_acc: 0.8383\n",
      "Epoch 88/200\n",
      "7000/7000 [==============================] - 1s 163us/step - loss: 1.4578 - output_0_loss: 0.2547 - output_1_loss: 0.2267 - output_2_loss: 0.2127 - output_3_loss: 0.2412 - output_4_loss: 0.2867 - output_5_loss: 0.2358 - output_0_acc: 0.9273 - output_1_acc: 0.9403 - output_2_acc: 0.9437 - output_3_acc: 0.9331 - output_4_acc: 0.9123 - output_5_acc: 0.9336 - val_loss: 2.3146 - val_output_0_loss: 0.3868 - val_output_1_loss: 0.4070 - val_output_2_loss: 0.3061 - val_output_3_loss: 0.3927 - val_output_4_loss: 0.4223 - val_output_5_loss: 0.3998 - val_output_0_acc: 0.8690 - val_output_1_acc: 0.8657 - val_output_2_acc: 0.9063 - val_output_3_acc: 0.8613 - val_output_4_acc: 0.8523 - val_output_5_acc: 0.8560\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 151us/step - loss: 1.4181 - output_0_loss: 0.2406 - output_1_loss: 0.2235 - output_2_loss: 0.2087 - output_3_loss: 0.2351 - output_4_loss: 0.2820 - output_5_loss: 0.2282 - output_0_acc: 0.9311 - output_1_acc: 0.9419 - output_2_acc: 0.9414 - output_3_acc: 0.9346 - output_4_acc: 0.9149 - output_5_acc: 0.9403 - val_loss: 2.5770 - val_output_0_loss: 0.4260 - val_output_1_loss: 0.3968 - val_output_2_loss: 0.3660 - val_output_3_loss: 0.3282 - val_output_4_loss: 0.5878 - val_output_5_loss: 0.4722 - val_output_0_acc: 0.8420 - val_output_1_acc: 0.8637 - val_output_2_acc: 0.8843 - val_output_3_acc: 0.8953 - val_output_4_acc: 0.7833 - val_output_5_acc: 0.8130\n",
      "Epoch 90/200\n",
      "7000/7000 [==============================] - 1s 147us/step - loss: 1.3991 - output_0_loss: 0.2337 - output_1_loss: 0.2249 - output_2_loss: 0.2060 - output_3_loss: 0.2304 - output_4_loss: 0.2776 - output_5_loss: 0.2265 - output_0_acc: 0.9376 - output_1_acc: 0.9386 - output_2_acc: 0.9460 - output_3_acc: 0.9376 - output_4_acc: 0.9156 - output_5_acc: 0.9411 - val_loss: 2.3936 - val_output_0_loss: 0.4093 - val_output_1_loss: 0.3354 - val_output_2_loss: 0.3511 - val_output_3_loss: 0.3903 - val_output_4_loss: 0.5213 - val_output_5_loss: 0.3863 - val_output_0_acc: 0.8543 - val_output_1_acc: 0.9013 - val_output_2_acc: 0.8767 - val_output_3_acc: 0.8573 - val_output_4_acc: 0.8060 - val_output_5_acc: 0.8700\n",
      "Epoch 91/200\n",
      "7000/7000 [==============================] - 1s 141us/step - loss: 1.3756 - output_0_loss: 0.2305 - output_1_loss: 0.2175 - output_2_loss: 0.1981 - output_3_loss: 0.2294 - output_4_loss: 0.2753 - output_5_loss: 0.2248 - output_0_acc: 0.9397 - output_1_acc: 0.9426 - output_2_acc: 0.9476 - output_3_acc: 0.9391 - output_4_acc: 0.9141 - output_5_acc: 0.9399 - val_loss: 2.4267 - val_output_0_loss: 0.3667 - val_output_1_loss: 0.3610 - val_output_2_loss: 0.3722 - val_output_3_loss: 0.3858 - val_output_4_loss: 0.5675 - val_output_5_loss: 0.3734 - val_output_0_acc: 0.8827 - val_output_1_acc: 0.8773 - val_output_2_acc: 0.8610 - val_output_3_acc: 0.8480 - val_output_4_acc: 0.7767 - val_output_5_acc: 0.8563\n",
      "Epoch 92/200\n",
      "7000/7000 [==============================] - 1s 141us/step - loss: 1.3505 - output_0_loss: 0.2297 - output_1_loss: 0.2152 - output_2_loss: 0.1968 - output_3_loss: 0.2277 - output_4_loss: 0.2671 - output_5_loss: 0.2140 - output_0_acc: 0.9349 - output_1_acc: 0.9399 - output_2_acc: 0.9480 - output_3_acc: 0.9373 - output_4_acc: 0.9159 - output_5_acc: 0.9456 - val_loss: 2.3653 - val_output_0_loss: 0.4383 - val_output_1_loss: 0.3764 - val_output_2_loss: 0.3756 - val_output_3_loss: 0.3386 - val_output_4_loss: 0.4051 - val_output_5_loss: 0.4313 - val_output_0_acc: 0.8283 - val_output_1_acc: 0.8687 - val_output_2_acc: 0.8593 - val_output_3_acc: 0.8850 - val_output_4_acc: 0.8583 - val_output_5_acc: 0.8447\n",
      "Epoch 93/200\n",
      "7000/7000 [==============================] - 1s 142us/step - loss: 1.3148 - output_0_loss: 0.2241 - output_1_loss: 0.2069 - output_2_loss: 0.1904 - output_3_loss: 0.2199 - output_4_loss: 0.2623 - output_5_loss: 0.2112 - output_0_acc: 0.9370 - output_1_acc: 0.9461 - output_2_acc: 0.9493 - output_3_acc: 0.9413 - output_4_acc: 0.9227 - output_5_acc: 0.9449 - val_loss: 2.3013 - val_output_0_loss: 0.3836 - val_output_1_loss: 0.3870 - val_output_2_loss: 0.3775 - val_output_3_loss: 0.3648 - val_output_4_loss: 0.4337 - val_output_5_loss: 0.3547 - val_output_0_acc: 0.8560 - val_output_1_acc: 0.8643 - val_output_2_acc: 0.8663 - val_output_3_acc: 0.8757 - val_output_4_acc: 0.8283 - val_output_5_acc: 0.8763\n",
      "Epoch 94/200\n",
      "7000/7000 [==============================] - 1s 150us/step - loss: 1.3037 - output_0_loss: 0.2190 - output_1_loss: 0.2057 - output_2_loss: 0.1891 - output_3_loss: 0.2168 - output_4_loss: 0.2638 - output_5_loss: 0.2092 - output_0_acc: 0.9391 - output_1_acc: 0.9459 - output_2_acc: 0.9464 - output_3_acc: 0.9403 - output_4_acc: 0.9197 - output_5_acc: 0.9463 - val_loss: 2.2603 - val_output_0_loss: 0.4197 - val_output_1_loss: 0.3220 - val_output_2_loss: 0.3682 - val_output_3_loss: 0.3501 - val_output_4_loss: 0.4356 - val_output_5_loss: 0.3646 - val_output_0_acc: 0.8417 - val_output_1_acc: 0.8993 - val_output_2_acc: 0.8683 - val_output_3_acc: 0.8817 - val_output_4_acc: 0.8397 - val_output_5_acc: 0.8690\n",
      "Epoch 95/200\n",
      "7000/7000 [==============================] - 1s 150us/step - loss: 1.2666 - output_0_loss: 0.2112 - output_1_loss: 0.2009 - output_2_loss: 0.1856 - output_3_loss: 0.2099 - output_4_loss: 0.2567 - output_5_loss: 0.2024 - output_0_acc: 0.9471 - output_1_acc: 0.9466 - output_2_acc: 0.9514 - output_3_acc: 0.9426 - output_4_acc: 0.9240 - output_5_acc: 0.9483 - val_loss: 2.3332 - val_output_0_loss: 0.4311 - val_output_1_loss: 0.3480 - val_output_2_loss: 0.3573 - val_output_3_loss: 0.3975 - val_output_4_loss: 0.4630 - val_output_5_loss: 0.3363 - val_output_0_acc: 0.8543 - val_output_1_acc: 0.8847 - val_output_2_acc: 0.8743 - val_output_3_acc: 0.8527 - val_output_4_acc: 0.8137 - val_output_5_acc: 0.8930\n",
      "Epoch 96/200\n",
      "7000/7000 [==============================] - 1s 153us/step - loss: 1.2481 - output_0_loss: 0.2134 - output_1_loss: 0.1951 - output_2_loss: 0.1806 - output_3_loss: 0.2085 - output_4_loss: 0.2516 - output_5_loss: 0.1989 - output_0_acc: 0.9429 - output_1_acc: 0.9503 - output_2_acc: 0.9513 - output_3_acc: 0.9471 - output_4_acc: 0.9296 - output_5_acc: 0.9499 - val_loss: 2.3682 - val_output_0_loss: 0.3979 - val_output_1_loss: 0.4201 - val_output_2_loss: 0.3682 - val_output_3_loss: 0.3875 - val_output_4_loss: 0.4402 - val_output_5_loss: 0.3544 - val_output_0_acc: 0.8563 - val_output_1_acc: 0.8313 - val_output_2_acc: 0.8727 - val_output_3_acc: 0.8507 - val_output_4_acc: 0.8420 - val_output_5_acc: 0.8790\n",
      "Epoch 97/200\n",
      "7000/7000 [==============================] - 1s 145us/step - loss: 1.2239 - output_0_loss: 0.2055 - output_1_loss: 0.1945 - output_2_loss: 0.1796 - output_3_loss: 0.2066 - output_4_loss: 0.2454 - output_5_loss: 0.1924 - output_0_acc: 0.9470 - output_1_acc: 0.9523 - output_2_acc: 0.9524 - output_3_acc: 0.9433 - output_4_acc: 0.9283 - output_5_acc: 0.9494 - val_loss: 2.1781 - val_output_0_loss: 0.3892 - val_output_1_loss: 0.3789 - val_output_2_loss: 0.3078 - val_output_3_loss: 0.3526 - val_output_4_loss: 0.4050 - val_output_5_loss: 0.3445 - val_output_0_acc: 0.8673 - val_output_1_acc: 0.8607 - val_output_2_acc: 0.8920 - val_output_3_acc: 0.8753 - val_output_4_acc: 0.8543 - val_output_5_acc: 0.8817\n",
      "Epoch 98/200\n",
      "7000/7000 [==============================] - 1s 163us/step - loss: 1.2031 - output_0_loss: 0.2047 - output_1_loss: 0.1916 - output_2_loss: 0.1691 - output_3_loss: 0.2001 - output_4_loss: 0.2434 - output_5_loss: 0.1942 - output_0_acc: 0.9473 - output_1_acc: 0.9486 - output_2_acc: 0.9566 - output_3_acc: 0.9464 - output_4_acc: 0.9266 - output_5_acc: 0.9510 - val_loss: 2.2489 - val_output_0_loss: 0.5185 - val_output_1_loss: 0.3409 - val_output_2_loss: 0.3328 - val_output_3_loss: 0.2924 - val_output_4_loss: 0.4156 - val_output_5_loss: 0.3487 - val_output_0_acc: 0.8023 - val_output_1_acc: 0.8870 - val_output_2_acc: 0.8830 - val_output_3_acc: 0.9077 - val_output_4_acc: 0.8427 - val_output_5_acc: 0.8730\n",
      "Epoch 99/200\n",
      "7000/7000 [==============================] - 1s 159us/step - loss: 1.1808 - output_0_loss: 0.1999 - output_1_loss: 0.1865 - output_2_loss: 0.1729 - output_3_loss: 0.1964 - output_4_loss: 0.2403 - output_5_loss: 0.1849 - output_0_acc: 0.9476 - output_1_acc: 0.9506 - output_2_acc: 0.9533 - output_3_acc: 0.9460 - output_4_acc: 0.9303 - output_5_acc: 0.9519 - val_loss: 2.1309 - val_output_0_loss: 0.3428 - val_output_1_loss: 0.3317 - val_output_2_loss: 0.2882 - val_output_3_loss: 0.3421 - val_output_4_loss: 0.4318 - val_output_5_loss: 0.3942 - val_output_0_acc: 0.8893 - val_output_1_acc: 0.8880 - val_output_2_acc: 0.9020 - val_output_3_acc: 0.8727 - val_output_4_acc: 0.8353 - val_output_5_acc: 0.8640\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 156us/step - loss: 1.1646 - output_0_loss: 0.1974 - output_1_loss: 0.1862 - output_2_loss: 0.1671 - output_3_loss: 0.1948 - output_4_loss: 0.2341 - output_5_loss: 0.1850 - output_0_acc: 0.9493 - output_1_acc: 0.9537 - output_2_acc: 0.9577 - output_3_acc: 0.9459 - output_4_acc: 0.9331 - output_5_acc: 0.9517 - val_loss: 2.1482 - val_output_0_loss: 0.3233 - val_output_1_loss: 0.3910 - val_output_2_loss: 0.2963 - val_output_3_loss: 0.3332 - val_output_4_loss: 0.3937 - val_output_5_loss: 0.4105 - val_output_0_acc: 0.8973 - val_output_1_acc: 0.8563 - val_output_2_acc: 0.8983 - val_output_3_acc: 0.9027 - val_output_4_acc: 0.8547 - val_output_5_acc: 0.8323\n",
      "Epoch 101/200\n",
      "7000/7000 [==============================] - 1s 155us/step - loss: 1.1306 - output_0_loss: 0.1894 - output_1_loss: 0.1799 - output_2_loss: 0.1622 - output_3_loss: 0.1864 - output_4_loss: 0.2301 - output_5_loss: 0.1826 - output_0_acc: 0.9511 - output_1_acc: 0.9529 - output_2_acc: 0.9580 - output_3_acc: 0.9541 - output_4_acc: 0.9346 - output_5_acc: 0.9540 - val_loss: 2.0931 - val_output_0_loss: 0.3811 - val_output_1_loss: 0.3324 - val_output_2_loss: 0.2753 - val_output_3_loss: 0.3492 - val_output_4_loss: 0.4296 - val_output_5_loss: 0.3255 - val_output_0_acc: 0.8620 - val_output_1_acc: 0.8860 - val_output_2_acc: 0.9123 - val_output_3_acc: 0.8733 - val_output_4_acc: 0.8360 - val_output_5_acc: 0.8927\n",
      "Epoch 102/200\n",
      "7000/7000 [==============================] - 1s 149us/step - loss: 1.1288 - output_0_loss: 0.1893 - output_1_loss: 0.1801 - output_2_loss: 0.1661 - output_3_loss: 0.1868 - output_4_loss: 0.2302 - output_5_loss: 0.1763 - output_0_acc: 0.9480 - output_1_acc: 0.9520 - output_2_acc: 0.9554 - output_3_acc: 0.9507 - output_4_acc: 0.9370 - output_5_acc: 0.9596 - val_loss: 2.1656 - val_output_0_loss: 0.3813 - val_output_1_loss: 0.4002 - val_output_2_loss: 0.2631 - val_output_3_loss: 0.3471 - val_output_4_loss: 0.4213 - val_output_5_loss: 0.3526 - val_output_0_acc: 0.8653 - val_output_1_acc: 0.8547 - val_output_2_acc: 0.9137 - val_output_3_acc: 0.8870 - val_output_4_acc: 0.8277 - val_output_5_acc: 0.8780\n",
      "Epoch 103/200\n",
      "7000/7000 [==============================] - 1s 147us/step - loss: 1.1028 - output_0_loss: 0.1851 - output_1_loss: 0.1745 - output_2_loss: 0.1570 - output_3_loss: 0.1864 - output_4_loss: 0.2212 - output_5_loss: 0.1786 - output_0_acc: 0.9546 - output_1_acc: 0.9543 - output_2_acc: 0.9600 - output_3_acc: 0.9481 - output_4_acc: 0.9381 - output_5_acc: 0.9550 - val_loss: 2.1626 - val_output_0_loss: 0.4417 - val_output_1_loss: 0.3218 - val_output_2_loss: 0.2849 - val_output_3_loss: 0.3043 - val_output_4_loss: 0.5165 - val_output_5_loss: 0.2934 - val_output_0_acc: 0.8370 - val_output_1_acc: 0.8943 - val_output_2_acc: 0.9023 - val_output_3_acc: 0.9053 - val_output_4_acc: 0.8043 - val_output_5_acc: 0.9057\n",
      "Epoch 104/200\n",
      "7000/7000 [==============================] - 1s 149us/step - loss: 1.0828 - output_0_loss: 0.1814 - output_1_loss: 0.1714 - output_2_loss: 0.1558 - output_3_loss: 0.1802 - output_4_loss: 0.2229 - output_5_loss: 0.1711 - output_0_acc: 0.9560 - output_1_acc: 0.9554 - output_2_acc: 0.9594 - output_3_acc: 0.9519 - output_4_acc: 0.9337 - output_5_acc: 0.9571 - val_loss: 1.9463 - val_output_0_loss: 0.4384 - val_output_1_loss: 0.3142 - val_output_2_loss: 0.2469 - val_output_3_loss: 0.2863 - val_output_4_loss: 0.3467 - val_output_5_loss: 0.3138 - val_output_0_acc: 0.8253 - val_output_1_acc: 0.8940 - val_output_2_acc: 0.9227 - val_output_3_acc: 0.9087 - val_output_4_acc: 0.8777 - val_output_5_acc: 0.8943\n",
      "Epoch 105/200\n",
      "7000/7000 [==============================] - 1s 149us/step - loss: 1.0558 - output_0_loss: 0.1770 - output_1_loss: 0.1663 - output_2_loss: 0.1505 - output_3_loss: 0.1752 - output_4_loss: 0.2188 - output_5_loss: 0.1680 - output_0_acc: 0.9549 - output_1_acc: 0.9579 - output_2_acc: 0.9616 - output_3_acc: 0.9547 - output_4_acc: 0.9347 - output_5_acc: 0.9594 - val_loss: 2.1470 - val_output_0_loss: 0.3399 - val_output_1_loss: 0.3734 - val_output_2_loss: 0.2648 - val_output_3_loss: 0.3936 - val_output_4_loss: 0.4013 - val_output_5_loss: 0.3739 - val_output_0_acc: 0.8847 - val_output_1_acc: 0.8673 - val_output_2_acc: 0.9150 - val_output_3_acc: 0.8540 - val_output_4_acc: 0.8383 - val_output_5_acc: 0.8570\n",
      "Epoch 106/200\n",
      "7000/7000 [==============================] - 1s 155us/step - loss: 1.0423 - output_0_loss: 0.1771 - output_1_loss: 0.1655 - output_2_loss: 0.1493 - output_3_loss: 0.1713 - output_4_loss: 0.2133 - output_5_loss: 0.1657 - output_0_acc: 0.9550 - output_1_acc: 0.9564 - output_2_acc: 0.9623 - output_3_acc: 0.9579 - output_4_acc: 0.9403 - output_5_acc: 0.9606 - val_loss: 1.9925 - val_output_0_loss: 0.3512 - val_output_1_loss: 0.3732 - val_output_2_loss: 0.2901 - val_output_3_loss: 0.2922 - val_output_4_loss: 0.3640 - val_output_5_loss: 0.3219 - val_output_0_acc: 0.8857 - val_output_1_acc: 0.8580 - val_output_2_acc: 0.9067 - val_output_3_acc: 0.8987 - val_output_4_acc: 0.8673 - val_output_5_acc: 0.8877\n",
      "Epoch 107/200\n",
      "7000/7000 [==============================] - 1s 162us/step - loss: 1.0181 - output_0_loss: 0.1682 - output_1_loss: 0.1632 - output_2_loss: 0.1464 - output_3_loss: 0.1645 - output_4_loss: 0.2141 - output_5_loss: 0.1617 - output_0_acc: 0.9589 - output_1_acc: 0.9609 - output_2_acc: 0.9613 - output_3_acc: 0.9591 - output_4_acc: 0.9416 - output_5_acc: 0.9591 - val_loss: 1.9679 - val_output_0_loss: 0.3227 - val_output_1_loss: 0.3931 - val_output_2_loss: 0.2870 - val_output_3_loss: 0.3036 - val_output_4_loss: 0.3619 - val_output_5_loss: 0.2997 - val_output_0_acc: 0.8927 - val_output_1_acc: 0.8623 - val_output_2_acc: 0.9063 - val_output_3_acc: 0.8927 - val_output_4_acc: 0.8703 - val_output_5_acc: 0.9010\n",
      "Epoch 108/200\n",
      "7000/7000 [==============================] - 1s 153us/step - loss: 1.0081 - output_0_loss: 0.1703 - output_1_loss: 0.1600 - output_2_loss: 0.1462 - output_3_loss: 0.1659 - output_4_loss: 0.2059 - output_5_loss: 0.1600 - output_0_acc: 0.9577 - output_1_acc: 0.9627 - output_2_acc: 0.9633 - output_3_acc: 0.9561 - output_4_acc: 0.9413 - output_5_acc: 0.9596 - val_loss: 1.8566 - val_output_0_loss: 0.3548 - val_output_1_loss: 0.2988 - val_output_2_loss: 0.2293 - val_output_3_loss: 0.2757 - val_output_4_loss: 0.3548 - val_output_5_loss: 0.3434 - val_output_0_acc: 0.8740 - val_output_1_acc: 0.8937 - val_output_2_acc: 0.9307 - val_output_3_acc: 0.9103 - val_output_4_acc: 0.8630 - val_output_5_acc: 0.8727\n",
      "Epoch 109/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 0.9840 - output_0_loss: 0.1641 - output_1_loss: 0.1588 - output_2_loss: 0.1409 - output_3_loss: 0.1626 - output_4_loss: 0.2037 - output_5_loss: 0.1538 - output_0_acc: 0.9596 - output_1_acc: 0.9564 - output_2_acc: 0.9631 - output_3_acc: 0.9551 - output_4_acc: 0.9431 - output_5_acc: 0.9623 - val_loss: 1.9368 - val_output_0_loss: 0.3429 - val_output_1_loss: 0.2968 - val_output_2_loss: 0.3080 - val_output_3_loss: 0.3512 - val_output_4_loss: 0.3354 - val_output_5_loss: 0.3023 - val_output_0_acc: 0.8627 - val_output_1_acc: 0.9070 - val_output_2_acc: 0.8993 - val_output_3_acc: 0.8693 - val_output_4_acc: 0.8810 - val_output_5_acc: 0.8923\n",
      "Epoch 110/200\n",
      "7000/7000 [==============================] - 1s 159us/step - loss: 0.9732 - output_0_loss: 0.1640 - output_1_loss: 0.1525 - output_2_loss: 0.1396 - output_3_loss: 0.1628 - output_4_loss: 0.1975 - output_5_loss: 0.1567 - output_0_acc: 0.9551 - output_1_acc: 0.9616 - output_2_acc: 0.9643 - output_3_acc: 0.9580 - output_4_acc: 0.9473 - output_5_acc: 0.9621 - val_loss: 1.8415 - val_output_0_loss: 0.3123 - val_output_1_loss: 0.3216 - val_output_2_loss: 0.2372 - val_output_3_loss: 0.2784 - val_output_4_loss: 0.3653 - val_output_5_loss: 0.3267 - val_output_0_acc: 0.8943 - val_output_1_acc: 0.8740 - val_output_2_acc: 0.9267 - val_output_3_acc: 0.9143 - val_output_4_acc: 0.8683 - val_output_5_acc: 0.8827\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 153us/step - loss: 0.9442 - output_0_loss: 0.1560 - output_1_loss: 0.1490 - output_2_loss: 0.1375 - output_3_loss: 0.1569 - output_4_loss: 0.1926 - output_5_loss: 0.1522 - output_0_acc: 0.9620 - output_1_acc: 0.9660 - output_2_acc: 0.9660 - output_3_acc: 0.9576 - output_4_acc: 0.9440 - output_5_acc: 0.9629 - val_loss: 1.7983 - val_output_0_loss: 0.3354 - val_output_1_loss: 0.2599 - val_output_2_loss: 0.2546 - val_output_3_loss: 0.3191 - val_output_4_loss: 0.3835 - val_output_5_loss: 0.2458 - val_output_0_acc: 0.8867 - val_output_1_acc: 0.9163 - val_output_2_acc: 0.9190 - val_output_3_acc: 0.8817 - val_output_4_acc: 0.8610 - val_output_5_acc: 0.9277\n",
      "Epoch 112/200\n",
      "7000/7000 [==============================] - 1s 155us/step - loss: 0.9258 - output_0_loss: 0.1553 - output_1_loss: 0.1492 - output_2_loss: 0.1300 - output_3_loss: 0.1527 - output_4_loss: 0.1923 - output_5_loss: 0.1464 - output_0_acc: 0.9610 - output_1_acc: 0.9620 - output_2_acc: 0.9700 - output_3_acc: 0.9610 - output_4_acc: 0.9454 - output_5_acc: 0.9659 - val_loss: 1.9220 - val_output_0_loss: 0.3474 - val_output_1_loss: 0.2593 - val_output_2_loss: 0.3119 - val_output_3_loss: 0.2858 - val_output_4_loss: 0.3528 - val_output_5_loss: 0.3648 - val_output_0_acc: 0.8703 - val_output_1_acc: 0.9180 - val_output_2_acc: 0.9037 - val_output_3_acc: 0.8987 - val_output_4_acc: 0.8670 - val_output_5_acc: 0.8733\n",
      "Epoch 113/200\n",
      "7000/7000 [==============================] - 1s 150us/step - loss: 0.9072 - output_0_loss: 0.1503 - output_1_loss: 0.1444 - output_2_loss: 0.1305 - output_3_loss: 0.1505 - output_4_loss: 0.1874 - output_5_loss: 0.1441 - output_0_acc: 0.9646 - output_1_acc: 0.9651 - output_2_acc: 0.9636 - output_3_acc: 0.9631 - output_4_acc: 0.9474 - output_5_acc: 0.9693 - val_loss: 1.9002 - val_output_0_loss: 0.3521 - val_output_1_loss: 0.2659 - val_output_2_loss: 0.2531 - val_output_3_loss: 0.3064 - val_output_4_loss: 0.3568 - val_output_5_loss: 0.3659 - val_output_0_acc: 0.8790 - val_output_1_acc: 0.9083 - val_output_2_acc: 0.9107 - val_output_3_acc: 0.8840 - val_output_4_acc: 0.8697 - val_output_5_acc: 0.8593\n",
      "Epoch 114/200\n",
      "7000/7000 [==============================] - 1s 168us/step - loss: 0.8988 - output_0_loss: 0.1524 - output_1_loss: 0.1409 - output_2_loss: 0.1275 - output_3_loss: 0.1460 - output_4_loss: 0.1866 - output_5_loss: 0.1455 - output_0_acc: 0.9627 - output_1_acc: 0.9653 - output_2_acc: 0.9667 - output_3_acc: 0.9661 - output_4_acc: 0.9501 - output_5_acc: 0.9639 - val_loss: 2.0096 - val_output_0_loss: 0.3424 - val_output_1_loss: 0.3696 - val_output_2_loss: 0.2844 - val_output_3_loss: 0.2794 - val_output_4_loss: 0.4007 - val_output_5_loss: 0.3331 - val_output_0_acc: 0.8770 - val_output_1_acc: 0.8577 - val_output_2_acc: 0.9090 - val_output_3_acc: 0.9157 - val_output_4_acc: 0.8443 - val_output_5_acc: 0.8780\n",
      "Epoch 115/200\n",
      "7000/7000 [==============================] - 1s 144us/step - loss: 0.8831 - output_0_loss: 0.1462 - output_1_loss: 0.1402 - output_2_loss: 0.1256 - output_3_loss: 0.1465 - output_4_loss: 0.1818 - output_5_loss: 0.1427 - output_0_acc: 0.9659 - output_1_acc: 0.9636 - output_2_acc: 0.9697 - output_3_acc: 0.9634 - output_4_acc: 0.9541 - output_5_acc: 0.9670 - val_loss: 1.8917 - val_output_0_loss: 0.3882 - val_output_1_loss: 0.3066 - val_output_2_loss: 0.2662 - val_output_3_loss: 0.2474 - val_output_4_loss: 0.3884 - val_output_5_loss: 0.2949 - val_output_0_acc: 0.8513 - val_output_1_acc: 0.8830 - val_output_2_acc: 0.9077 - val_output_3_acc: 0.9213 - val_output_4_acc: 0.8477 - val_output_5_acc: 0.8920\n",
      "Epoch 116/200\n",
      "7000/7000 [==============================] - 1s 153us/step - loss: 0.8684 - output_0_loss: 0.1502 - output_1_loss: 0.1348 - output_2_loss: 0.1213 - output_3_loss: 0.1436 - output_4_loss: 0.1813 - output_5_loss: 0.1373 - output_0_acc: 0.9630 - output_1_acc: 0.9670 - output_2_acc: 0.9719 - output_3_acc: 0.9649 - output_4_acc: 0.9509 - output_5_acc: 0.9697 - val_loss: 1.7678 - val_output_0_loss: 0.2979 - val_output_1_loss: 0.2791 - val_output_2_loss: 0.2314 - val_output_3_loss: 0.2867 - val_output_4_loss: 0.3587 - val_output_5_loss: 0.3141 - val_output_0_acc: 0.9013 - val_output_1_acc: 0.8990 - val_output_2_acc: 0.9247 - val_output_3_acc: 0.8913 - val_output_4_acc: 0.8743 - val_output_5_acc: 0.8913\n",
      "Epoch 117/200\n",
      "7000/7000 [==============================] - 1s 156us/step - loss: 0.8504 - output_0_loss: 0.1429 - output_1_loss: 0.1368 - output_2_loss: 0.1214 - output_3_loss: 0.1387 - output_4_loss: 0.1762 - output_5_loss: 0.1344 - output_0_acc: 0.9640 - output_1_acc: 0.9664 - output_2_acc: 0.9691 - output_3_acc: 0.9684 - output_4_acc: 0.9510 - output_5_acc: 0.9701 - val_loss: 1.8208 - val_output_0_loss: 0.3987 - val_output_1_loss: 0.2517 - val_output_2_loss: 0.2322 - val_output_3_loss: 0.3021 - val_output_4_loss: 0.3438 - val_output_5_loss: 0.2924 - val_output_0_acc: 0.8517 - val_output_1_acc: 0.9157 - val_output_2_acc: 0.9213 - val_output_3_acc: 0.8893 - val_output_4_acc: 0.8797 - val_output_5_acc: 0.9047\n",
      "Epoch 118/200\n",
      "7000/7000 [==============================] - 1s 146us/step - loss: 0.8409 - output_0_loss: 0.1411 - output_1_loss: 0.1352 - output_2_loss: 0.1196 - output_3_loss: 0.1365 - output_4_loss: 0.1755 - output_5_loss: 0.1331 - output_0_acc: 0.9653 - output_1_acc: 0.9659 - output_2_acc: 0.9696 - output_3_acc: 0.9644 - output_4_acc: 0.9520 - output_5_acc: 0.9706 - val_loss: 1.6811 - val_output_0_loss: 0.3241 - val_output_1_loss: 0.2351 - val_output_2_loss: 0.2639 - val_output_3_loss: 0.2687 - val_output_4_loss: 0.3036 - val_output_5_loss: 0.2857 - val_output_0_acc: 0.8820 - val_output_1_acc: 0.9257 - val_output_2_acc: 0.9043 - val_output_3_acc: 0.9090 - val_output_4_acc: 0.8957 - val_output_5_acc: 0.8993\n",
      "Epoch 119/200\n",
      "7000/7000 [==============================] - 1s 150us/step - loss: 0.8169 - output_0_loss: 0.1350 - output_1_loss: 0.1297 - output_2_loss: 0.1192 - output_3_loss: 0.1367 - output_4_loss: 0.1694 - output_5_loss: 0.1270 - output_0_acc: 0.9681 - output_1_acc: 0.9694 - output_2_acc: 0.9710 - output_3_acc: 0.9683 - output_4_acc: 0.9544 - output_5_acc: 0.9720 - val_loss: 1.7129 - val_output_0_loss: 0.3373 - val_output_1_loss: 0.2970 - val_output_2_loss: 0.2603 - val_output_3_loss: 0.2386 - val_output_4_loss: 0.3088 - val_output_5_loss: 0.2710 - val_output_0_acc: 0.8833 - val_output_1_acc: 0.9023 - val_output_2_acc: 0.9153 - val_output_3_acc: 0.9233 - val_output_4_acc: 0.8893 - val_output_5_acc: 0.9153\n",
      "Epoch 120/200\n",
      "7000/7000 [==============================] - 1s 154us/step - loss: 0.8055 - output_0_loss: 0.1363 - output_1_loss: 0.1273 - output_2_loss: 0.1136 - output_3_loss: 0.1346 - output_4_loss: 0.1666 - output_5_loss: 0.1271 - output_0_acc: 0.9664 - output_1_acc: 0.9689 - output_2_acc: 0.9729 - output_3_acc: 0.9674 - output_4_acc: 0.9569 - output_5_acc: 0.9696 - val_loss: 1.8734 - val_output_0_loss: 0.3653 - val_output_1_loss: 0.2829 - val_output_2_loss: 0.2647 - val_output_3_loss: 0.3031 - val_output_4_loss: 0.3825 - val_output_5_loss: 0.2748 - val_output_0_acc: 0.8713 - val_output_1_acc: 0.9000 - val_output_2_acc: 0.9007 - val_output_3_acc: 0.8920 - val_output_4_acc: 0.8677 - val_output_5_acc: 0.9083\n",
      "Epoch 121/200\n",
      "7000/7000 [==============================] - 1s 175us/step - loss: 0.7922 - output_0_loss: 0.1358 - output_1_loss: 0.1257 - output_2_loss: 0.1136 - output_3_loss: 0.1286 - output_4_loss: 0.1638 - output_5_loss: 0.1246 - output_0_acc: 0.9673 - output_1_acc: 0.9686 - output_2_acc: 0.9736 - output_3_acc: 0.9690 - output_4_acc: 0.9566 - output_5_acc: 0.9704 - val_loss: 1.6240 - val_output_0_loss: 0.3030 - val_output_1_loss: 0.2666 - val_output_2_loss: 0.2502 - val_output_3_loss: 0.2463 - val_output_4_loss: 0.3114 - val_output_5_loss: 0.2466 - val_output_0_acc: 0.9030 - val_output_1_acc: 0.9113 - val_output_2_acc: 0.9230 - val_output_3_acc: 0.9177 - val_output_4_acc: 0.8910 - val_output_5_acc: 0.9187\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 146us/step - loss: 0.7719 - output_0_loss: 0.1286 - output_1_loss: 0.1212 - output_2_loss: 0.1110 - output_3_loss: 0.1277 - output_4_loss: 0.1608 - output_5_loss: 0.1226 - output_0_acc: 0.9670 - output_1_acc: 0.9694 - output_2_acc: 0.9724 - output_3_acc: 0.9680 - output_4_acc: 0.9569 - output_5_acc: 0.9729 - val_loss: 1.5741 - val_output_0_loss: 0.2801 - val_output_1_loss: 0.2632 - val_output_2_loss: 0.2253 - val_output_3_loss: 0.2634 - val_output_4_loss: 0.3045 - val_output_5_loss: 0.2376 - val_output_0_acc: 0.9100 - val_output_1_acc: 0.9107 - val_output_2_acc: 0.9273 - val_output_3_acc: 0.9130 - val_output_4_acc: 0.8933 - val_output_5_acc: 0.9220\n",
      "Epoch 123/200\n",
      "7000/7000 [==============================] - 1s 149us/step - loss: 0.7551 - output_0_loss: 0.1227 - output_1_loss: 0.1215 - output_2_loss: 0.1055 - output_3_loss: 0.1257 - output_4_loss: 0.1617 - output_5_loss: 0.1179 - output_0_acc: 0.9704 - output_1_acc: 0.9694 - output_2_acc: 0.9731 - output_3_acc: 0.9710 - output_4_acc: 0.9570 - output_5_acc: 0.9717 - val_loss: 1.7536 - val_output_0_loss: 0.3339 - val_output_1_loss: 0.2275 - val_output_2_loss: 0.2104 - val_output_3_loss: 0.2268 - val_output_4_loss: 0.4422 - val_output_5_loss: 0.3126 - val_output_0_acc: 0.8793 - val_output_1_acc: 0.9290 - val_output_2_acc: 0.9327 - val_output_3_acc: 0.9220 - val_output_4_acc: 0.8313 - val_output_5_acc: 0.8873\n",
      "Epoch 124/200\n",
      "7000/7000 [==============================] - 1s 154us/step - loss: 0.7387 - output_0_loss: 0.1243 - output_1_loss: 0.1185 - output_2_loss: 0.1057 - output_3_loss: 0.1226 - output_4_loss: 0.1520 - output_5_loss: 0.1157 - output_0_acc: 0.9710 - output_1_acc: 0.9710 - output_2_acc: 0.9760 - output_3_acc: 0.9707 - output_4_acc: 0.9621 - output_5_acc: 0.9731 - val_loss: 1.5859 - val_output_0_loss: 0.3294 - val_output_1_loss: 0.2420 - val_output_2_loss: 0.2110 - val_output_3_loss: 0.2077 - val_output_4_loss: 0.3667 - val_output_5_loss: 0.2291 - val_output_0_acc: 0.8740 - val_output_1_acc: 0.9223 - val_output_2_acc: 0.9233 - val_output_3_acc: 0.9353 - val_output_4_acc: 0.8707 - val_output_5_acc: 0.9347\n",
      "Epoch 125/200\n",
      "7000/7000 [==============================] - 1s 159us/step - loss: 0.7214 - output_0_loss: 0.1203 - output_1_loss: 0.1179 - output_2_loss: 0.0999 - output_3_loss: 0.1179 - output_4_loss: 0.1525 - output_5_loss: 0.1129 - output_0_acc: 0.9716 - output_1_acc: 0.9710 - output_2_acc: 0.9786 - output_3_acc: 0.9717 - output_4_acc: 0.9596 - output_5_acc: 0.9760 - val_loss: 1.8765 - val_output_0_loss: 0.4333 - val_output_1_loss: 0.2317 - val_output_2_loss: 0.2031 - val_output_3_loss: 0.2529 - val_output_4_loss: 0.3773 - val_output_5_loss: 0.3783 - val_output_0_acc: 0.8313 - val_output_1_acc: 0.9207 - val_output_2_acc: 0.9330 - val_output_3_acc: 0.9130 - val_output_4_acc: 0.8560 - val_output_5_acc: 0.8507\n",
      "Epoch 126/200\n",
      "7000/7000 [==============================] - 1s 147us/step - loss: 0.7230 - output_0_loss: 0.1192 - output_1_loss: 0.1178 - output_2_loss: 0.1010 - output_3_loss: 0.1192 - output_4_loss: 0.1532 - output_5_loss: 0.1126 - output_0_acc: 0.9710 - output_1_acc: 0.9724 - output_2_acc: 0.9741 - output_3_acc: 0.9713 - output_4_acc: 0.9580 - output_5_acc: 0.9761 - val_loss: 1.5691 - val_output_0_loss: 0.2370 - val_output_1_loss: 0.2645 - val_output_2_loss: 0.2083 - val_output_3_loss: 0.2525 - val_output_4_loss: 0.2990 - val_output_5_loss: 0.3077 - val_output_0_acc: 0.9270 - val_output_1_acc: 0.9077 - val_output_2_acc: 0.9327 - val_output_3_acc: 0.9167 - val_output_4_acc: 0.8927 - val_output_5_acc: 0.8997\n",
      "Epoch 127/200\n",
      "7000/7000 [==============================] - 1s 145us/step - loss: 0.6969 - output_0_loss: 0.1164 - output_1_loss: 0.1126 - output_2_loss: 0.0979 - output_3_loss: 0.1147 - output_4_loss: 0.1427 - output_5_loss: 0.1127 - output_0_acc: 0.9726 - output_1_acc: 0.9729 - output_2_acc: 0.9771 - output_3_acc: 0.9731 - output_4_acc: 0.9631 - output_5_acc: 0.9731 - val_loss: 1.7057 - val_output_0_loss: 0.2685 - val_output_1_loss: 0.3250 - val_output_2_loss: 0.2045 - val_output_3_loss: 0.2678 - val_output_4_loss: 0.3045 - val_output_5_loss: 0.3354 - val_output_0_acc: 0.9110 - val_output_1_acc: 0.8770 - val_output_2_acc: 0.9357 - val_output_3_acc: 0.8993 - val_output_4_acc: 0.8913 - val_output_5_acc: 0.8750\n",
      "Epoch 128/200\n",
      "7000/7000 [==============================] - 1s 145us/step - loss: 0.6954 - output_0_loss: 0.1169 - output_1_loss: 0.1100 - output_2_loss: 0.1007 - output_3_loss: 0.1143 - output_4_loss: 0.1428 - output_5_loss: 0.1107 - output_0_acc: 0.9721 - output_1_acc: 0.9744 - output_2_acc: 0.9764 - output_3_acc: 0.9720 - output_4_acc: 0.9646 - output_5_acc: 0.9740 - val_loss: 1.5593 - val_output_0_loss: 0.2505 - val_output_1_loss: 0.2457 - val_output_2_loss: 0.2088 - val_output_3_loss: 0.2926 - val_output_4_loss: 0.2865 - val_output_5_loss: 0.2752 - val_output_0_acc: 0.9183 - val_output_1_acc: 0.9137 - val_output_2_acc: 0.9363 - val_output_3_acc: 0.8880 - val_output_4_acc: 0.8933 - val_output_5_acc: 0.9077\n",
      "Epoch 129/200\n",
      "7000/7000 [==============================] - 1s 153us/step - loss: 0.6742 - output_0_loss: 0.1117 - output_1_loss: 0.1088 - output_2_loss: 0.0967 - output_3_loss: 0.1109 - output_4_loss: 0.1411 - output_5_loss: 0.1050 - output_0_acc: 0.9723 - output_1_acc: 0.9746 - output_2_acc: 0.9764 - output_3_acc: 0.9731 - output_4_acc: 0.9636 - output_5_acc: 0.9767 - val_loss: 1.4957 - val_output_0_loss: 0.2647 - val_output_1_loss: 0.2419 - val_output_2_loss: 0.2641 - val_output_3_loss: 0.2285 - val_output_4_loss: 0.2431 - val_output_5_loss: 0.2534 - val_output_0_acc: 0.9097 - val_output_1_acc: 0.9177 - val_output_2_acc: 0.9040 - val_output_3_acc: 0.9220 - val_output_4_acc: 0.9260 - val_output_5_acc: 0.9120\n",
      "Epoch 130/200\n",
      "7000/7000 [==============================] - 1s 153us/step - loss: 0.6607 - output_0_loss: 0.1107 - output_1_loss: 0.1063 - output_2_loss: 0.0946 - output_3_loss: 0.1087 - output_4_loss: 0.1364 - output_5_loss: 0.1041 - output_0_acc: 0.9744 - output_1_acc: 0.9747 - output_2_acc: 0.9771 - output_3_acc: 0.9756 - output_4_acc: 0.9687 - output_5_acc: 0.9780 - val_loss: 1.4865 - val_output_0_loss: 0.2744 - val_output_1_loss: 0.2490 - val_output_2_loss: 0.2307 - val_output_3_loss: 0.2321 - val_output_4_loss: 0.2721 - val_output_5_loss: 0.2282 - val_output_0_acc: 0.9140 - val_output_1_acc: 0.9173 - val_output_2_acc: 0.9260 - val_output_3_acc: 0.9150 - val_output_4_acc: 0.9107 - val_output_5_acc: 0.9330\n",
      "Epoch 131/200\n",
      "7000/7000 [==============================] - 1s 153us/step - loss: 0.6552 - output_0_loss: 0.1121 - output_1_loss: 0.1009 - output_2_loss: 0.0923 - output_3_loss: 0.1076 - output_4_loss: 0.1384 - output_5_loss: 0.1039 - output_0_acc: 0.9720 - output_1_acc: 0.9770 - output_2_acc: 0.9797 - output_3_acc: 0.9746 - output_4_acc: 0.9650 - output_5_acc: 0.9790 - val_loss: 1.5389 - val_output_0_loss: 0.2412 - val_output_1_loss: 0.3092 - val_output_2_loss: 0.1879 - val_output_3_loss: 0.2861 - val_output_4_loss: 0.2676 - val_output_5_loss: 0.2469 - val_output_0_acc: 0.9223 - val_output_1_acc: 0.8810 - val_output_2_acc: 0.9290 - val_output_3_acc: 0.8933 - val_output_4_acc: 0.9150 - val_output_5_acc: 0.9230\n",
      "Epoch 132/200\n",
      "7000/7000 [==============================] - 1s 147us/step - loss: 0.6397 - output_0_loss: 0.1063 - output_1_loss: 0.1021 - output_2_loss: 0.0928 - output_3_loss: 0.1055 - output_4_loss: 0.1332 - output_5_loss: 0.0998 - output_0_acc: 0.9753 - output_1_acc: 0.9764 - output_2_acc: 0.9787 - output_3_acc: 0.9740 - output_4_acc: 0.9681 - output_5_acc: 0.9780 - val_loss: 1.4890 - val_output_0_loss: 0.2852 - val_output_1_loss: 0.2005 - val_output_2_loss: 0.2383 - val_output_3_loss: 0.2047 - val_output_4_loss: 0.2847 - val_output_5_loss: 0.2756 - val_output_0_acc: 0.8937 - val_output_1_acc: 0.9380 - val_output_2_acc: 0.9223 - val_output_3_acc: 0.9333 - val_output_4_acc: 0.8920 - val_output_5_acc: 0.9060\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 145us/step - loss: 0.6360 - output_0_loss: 0.1070 - output_1_loss: 0.0998 - output_2_loss: 0.0914 - output_3_loss: 0.1045 - output_4_loss: 0.1331 - output_5_loss: 0.1002 - output_0_acc: 0.9753 - output_1_acc: 0.9783 - output_2_acc: 0.9794 - output_3_acc: 0.9747 - output_4_acc: 0.9676 - output_5_acc: 0.9783 - val_loss: 1.4243 - val_output_0_loss: 0.3067 - val_output_1_loss: 0.2216 - val_output_2_loss: 0.1840 - val_output_3_loss: 0.1870 - val_output_4_loss: 0.2766 - val_output_5_loss: 0.2483 - val_output_0_acc: 0.8757 - val_output_1_acc: 0.9300 - val_output_2_acc: 0.9397 - val_output_3_acc: 0.9400 - val_output_4_acc: 0.9020 - val_output_5_acc: 0.9080\n",
      "Epoch 134/200\n",
      "7000/7000 [==============================] - 1s 149us/step - loss: 0.6161 - output_0_loss: 0.1024 - output_1_loss: 0.1000 - output_2_loss: 0.0890 - output_3_loss: 0.0981 - output_4_loss: 0.1324 - output_5_loss: 0.0942 - output_0_acc: 0.9771 - output_1_acc: 0.9774 - output_2_acc: 0.9786 - output_3_acc: 0.9781 - output_4_acc: 0.9679 - output_5_acc: 0.9806 - val_loss: 1.5049 - val_output_0_loss: 0.2264 - val_output_1_loss: 0.2558 - val_output_2_loss: 0.2762 - val_output_3_loss: 0.2099 - val_output_4_loss: 0.3054 - val_output_5_loss: 0.2312 - val_output_0_acc: 0.9293 - val_output_1_acc: 0.9100 - val_output_2_acc: 0.8903 - val_output_3_acc: 0.9327 - val_output_4_acc: 0.8897 - val_output_5_acc: 0.9270\n",
      "Epoch 135/200\n",
      "7000/7000 [==============================] - 1s 150us/step - loss: 0.6090 - output_0_loss: 0.1016 - output_1_loss: 0.0955 - output_2_loss: 0.0890 - output_3_loss: 0.0954 - output_4_loss: 0.1301 - output_5_loss: 0.0974 - output_0_acc: 0.9779 - output_1_acc: 0.9780 - output_2_acc: 0.9774 - output_3_acc: 0.9809 - output_4_acc: 0.9679 - output_5_acc: 0.9777 - val_loss: 1.5153 - val_output_0_loss: 0.2429 - val_output_1_loss: 0.2273 - val_output_2_loss: 0.1608 - val_output_3_loss: 0.3367 - val_output_4_loss: 0.3149 - val_output_5_loss: 0.2327 - val_output_0_acc: 0.9213 - val_output_1_acc: 0.9253 - val_output_2_acc: 0.9510 - val_output_3_acc: 0.8700 - val_output_4_acc: 0.8837 - val_output_5_acc: 0.9130\n",
      "Epoch 136/200\n",
      "7000/7000 [==============================] - 1s 156us/step - loss: 0.5891 - output_0_loss: 0.0989 - output_1_loss: 0.0967 - output_2_loss: 0.0827 - output_3_loss: 0.0936 - output_4_loss: 0.1239 - output_5_loss: 0.0932 - output_0_acc: 0.9763 - output_1_acc: 0.9777 - output_2_acc: 0.9819 - output_3_acc: 0.9806 - output_4_acc: 0.9693 - output_5_acc: 0.9797 - val_loss: 1.3088 - val_output_0_loss: 0.2664 - val_output_1_loss: 0.2011 - val_output_2_loss: 0.1630 - val_output_3_loss: 0.1991 - val_output_4_loss: 0.2491 - val_output_5_loss: 0.2300 - val_output_0_acc: 0.9097 - val_output_1_acc: 0.9313 - val_output_2_acc: 0.9523 - val_output_3_acc: 0.9390 - val_output_4_acc: 0.9117 - val_output_5_acc: 0.9243\n",
      "Epoch 137/200\n",
      "7000/7000 [==============================] - 1s 154us/step - loss: 0.5825 - output_0_loss: 0.0976 - output_1_loss: 0.0913 - output_2_loss: 0.0815 - output_3_loss: 0.0979 - output_4_loss: 0.1209 - output_5_loss: 0.0933 - output_0_acc: 0.9787 - output_1_acc: 0.9796 - output_2_acc: 0.9804 - output_3_acc: 0.9763 - output_4_acc: 0.9701 - output_5_acc: 0.9791 - val_loss: 1.5420 - val_output_0_loss: 0.3163 - val_output_1_loss: 0.3200 - val_output_2_loss: 0.1968 - val_output_3_loss: 0.2397 - val_output_4_loss: 0.2368 - val_output_5_loss: 0.2323 - val_output_0_acc: 0.8853 - val_output_1_acc: 0.8827 - val_output_2_acc: 0.9337 - val_output_3_acc: 0.9090 - val_output_4_acc: 0.9247 - val_output_5_acc: 0.9200\n",
      "Epoch 138/200\n",
      "7000/7000 [==============================] - 1s 161us/step - loss: 0.5659 - output_0_loss: 0.0940 - output_1_loss: 0.0906 - output_2_loss: 0.0782 - output_3_loss: 0.0917 - output_4_loss: 0.1189 - output_5_loss: 0.0925 - output_0_acc: 0.9806 - output_1_acc: 0.9794 - output_2_acc: 0.9826 - output_3_acc: 0.9796 - output_4_acc: 0.9720 - output_5_acc: 0.9826 - val_loss: 1.4560 - val_output_0_loss: 0.2780 - val_output_1_loss: 0.1971 - val_output_2_loss: 0.2469 - val_output_3_loss: 0.2455 - val_output_4_loss: 0.2756 - val_output_5_loss: 0.2128 - val_output_0_acc: 0.8993 - val_output_1_acc: 0.9373 - val_output_2_acc: 0.9073 - val_output_3_acc: 0.9120 - val_output_4_acc: 0.8973 - val_output_5_acc: 0.9310\n",
      "Epoch 139/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 0.5608 - output_0_loss: 0.0932 - output_1_loss: 0.0869 - output_2_loss: 0.0801 - output_3_loss: 0.0926 - output_4_loss: 0.1175 - output_5_loss: 0.0906 - output_0_acc: 0.9799 - output_1_acc: 0.9817 - output_2_acc: 0.9824 - output_3_acc: 0.9783 - output_4_acc: 0.9717 - output_5_acc: 0.9801 - val_loss: 1.5774 - val_output_0_loss: 0.2954 - val_output_1_loss: 0.2549 - val_output_2_loss: 0.2732 - val_output_3_loss: 0.2276 - val_output_4_loss: 0.2871 - val_output_5_loss: 0.2391 - val_output_0_acc: 0.8927 - val_output_1_acc: 0.9110 - val_output_2_acc: 0.9123 - val_output_3_acc: 0.9273 - val_output_4_acc: 0.9020 - val_output_5_acc: 0.9163\n",
      "Epoch 140/200\n",
      "7000/7000 [==============================] - 1s 156us/step - loss: 0.5495 - output_0_loss: 0.0910 - output_1_loss: 0.0889 - output_2_loss: 0.0780 - output_3_loss: 0.0870 - output_4_loss: 0.1159 - output_5_loss: 0.0887 - output_0_acc: 0.9779 - output_1_acc: 0.9796 - output_2_acc: 0.9833 - output_3_acc: 0.9820 - output_4_acc: 0.9723 - output_5_acc: 0.9807 - val_loss: 1.6550 - val_output_0_loss: 0.2424 - val_output_1_loss: 0.2847 - val_output_2_loss: 0.3480 - val_output_3_loss: 0.2432 - val_output_4_loss: 0.3288 - val_output_5_loss: 0.2079 - val_output_0_acc: 0.9193 - val_output_1_acc: 0.9007 - val_output_2_acc: 0.8553 - val_output_3_acc: 0.9077 - val_output_4_acc: 0.8733 - val_output_5_acc: 0.9320\n",
      "Epoch 141/200\n",
      "7000/7000 [==============================] - 1s 152us/step - loss: 0.5354 - output_0_loss: 0.0872 - output_1_loss: 0.0849 - output_2_loss: 0.0758 - output_3_loss: 0.0867 - output_4_loss: 0.1157 - output_5_loss: 0.0851 - output_0_acc: 0.9791 - output_1_acc: 0.9801 - output_2_acc: 0.9833 - output_3_acc: 0.9810 - output_4_acc: 0.9717 - output_5_acc: 0.9820 - val_loss: 1.3299 - val_output_0_loss: 0.2306 - val_output_1_loss: 0.1964 - val_output_2_loss: 0.2130 - val_output_3_loss: 0.1761 - val_output_4_loss: 0.2810 - val_output_5_loss: 0.2327 - val_output_0_acc: 0.9213 - val_output_1_acc: 0.9360 - val_output_2_acc: 0.9210 - val_output_3_acc: 0.9477 - val_output_4_acc: 0.8917 - val_output_5_acc: 0.9147\n",
      "Epoch 142/200\n",
      "7000/7000 [==============================] - 1s 169us/step - loss: 0.5295 - output_0_loss: 0.0856 - output_1_loss: 0.0859 - output_2_loss: 0.0745 - output_3_loss: 0.0862 - output_4_loss: 0.1144 - output_5_loss: 0.0829 - output_0_acc: 0.9797 - output_1_acc: 0.9797 - output_2_acc: 0.9830 - output_3_acc: 0.9800 - output_4_acc: 0.9729 - output_5_acc: 0.9813 - val_loss: 1.3813 - val_output_0_loss: 0.2266 - val_output_1_loss: 0.1940 - val_output_2_loss: 0.2109 - val_output_3_loss: 0.2050 - val_output_4_loss: 0.2956 - val_output_5_loss: 0.2492 - val_output_0_acc: 0.9267 - val_output_1_acc: 0.9387 - val_output_2_acc: 0.9323 - val_output_3_acc: 0.9337 - val_output_4_acc: 0.8847 - val_output_5_acc: 0.9163\n",
      "Epoch 143/200\n",
      "7000/7000 [==============================] - 1s 171us/step - loss: 0.5147 - output_0_loss: 0.0837 - output_1_loss: 0.0838 - output_2_loss: 0.0728 - output_3_loss: 0.0844 - output_4_loss: 0.1071 - output_5_loss: 0.0830 - output_0_acc: 0.9827 - output_1_acc: 0.9820 - output_2_acc: 0.9853 - output_3_acc: 0.9796 - output_4_acc: 0.9769 - output_5_acc: 0.9833 - val_loss: 1.3192 - val_output_0_loss: 0.2622 - val_output_1_loss: 0.2094 - val_output_2_loss: 0.2080 - val_output_3_loss: 0.1614 - val_output_4_loss: 0.2674 - val_output_5_loss: 0.2109 - val_output_0_acc: 0.9110 - val_output_1_acc: 0.9293 - val_output_2_acc: 0.9330 - val_output_3_acc: 0.9510 - val_output_4_acc: 0.9057 - val_output_5_acc: 0.9273\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 152us/step - loss: 0.5071 - output_0_loss: 0.0873 - output_1_loss: 0.0834 - output_2_loss: 0.0696 - output_3_loss: 0.0802 - output_4_loss: 0.1077 - output_5_loss: 0.0789 - output_0_acc: 0.9816 - output_1_acc: 0.9809 - output_2_acc: 0.9873 - output_3_acc: 0.9821 - output_4_acc: 0.9744 - output_5_acc: 0.9841 - val_loss: 1.2349 - val_output_0_loss: 0.2055 - val_output_1_loss: 0.1976 - val_output_2_loss: 0.1684 - val_output_3_loss: 0.1821 - val_output_4_loss: 0.2477 - val_output_5_loss: 0.2336 - val_output_0_acc: 0.9360 - val_output_1_acc: 0.9310 - val_output_2_acc: 0.9490 - val_output_3_acc: 0.9390 - val_output_4_acc: 0.9207 - val_output_5_acc: 0.9137\n",
      "Epoch 145/200\n",
      "7000/7000 [==============================] - 1s 143us/step - loss: 0.4978 - output_0_loss: 0.0809 - output_1_loss: 0.0809 - output_2_loss: 0.0717 - output_3_loss: 0.0810 - output_4_loss: 0.1041 - output_5_loss: 0.0792 - output_0_acc: 0.9817 - output_1_acc: 0.9833 - output_2_acc: 0.9840 - output_3_acc: 0.9830 - output_4_acc: 0.9757 - output_5_acc: 0.9829 - val_loss: 1.2858 - val_output_0_loss: 0.2788 - val_output_1_loss: 0.2292 - val_output_2_loss: 0.1546 - val_output_3_loss: 0.1849 - val_output_4_loss: 0.2517 - val_output_5_loss: 0.1866 - val_output_0_acc: 0.9013 - val_output_1_acc: 0.9180 - val_output_2_acc: 0.9507 - val_output_3_acc: 0.9423 - val_output_4_acc: 0.9110 - val_output_5_acc: 0.9447\n",
      "Epoch 146/200\n",
      "7000/7000 [==============================] - 1s 159us/step - loss: 0.4857 - output_0_loss: 0.0826 - output_1_loss: 0.0764 - output_2_loss: 0.0663 - output_3_loss: 0.0796 - output_4_loss: 0.1048 - output_5_loss: 0.0759 - output_0_acc: 0.9824 - output_1_acc: 0.9816 - output_2_acc: 0.9857 - output_3_acc: 0.9834 - output_4_acc: 0.9759 - output_5_acc: 0.9850 - val_loss: 1.4260 - val_output_0_loss: 0.1964 - val_output_1_loss: 0.2668 - val_output_2_loss: 0.2011 - val_output_3_loss: 0.3018 - val_output_4_loss: 0.2876 - val_output_5_loss: 0.1722 - val_output_0_acc: 0.9427 - val_output_1_acc: 0.9073 - val_output_2_acc: 0.9403 - val_output_3_acc: 0.8867 - val_output_4_acc: 0.8933 - val_output_5_acc: 0.9443\n",
      "Epoch 147/200\n",
      "7000/7000 [==============================] - 1s 148us/step - loss: 0.4796 - output_0_loss: 0.0785 - output_1_loss: 0.0792 - output_2_loss: 0.0671 - output_3_loss: 0.0775 - output_4_loss: 0.1013 - output_5_loss: 0.0761 - output_0_acc: 0.9827 - output_1_acc: 0.9829 - output_2_acc: 0.9866 - output_3_acc: 0.9836 - output_4_acc: 0.9777 - output_5_acc: 0.9841 - val_loss: 1.2135 - val_output_0_loss: 0.2117 - val_output_1_loss: 0.1831 - val_output_2_loss: 0.1990 - val_output_3_loss: 0.1713 - val_output_4_loss: 0.2123 - val_output_5_loss: 0.2361 - val_output_0_acc: 0.9310 - val_output_1_acc: 0.9387 - val_output_2_acc: 0.9313 - val_output_3_acc: 0.9443 - val_output_4_acc: 0.9247 - val_output_5_acc: 0.9153\n",
      "Epoch 148/200\n",
      "7000/7000 [==============================] - 1s 168us/step - loss: 0.4675 - output_0_loss: 0.0785 - output_1_loss: 0.0762 - output_2_loss: 0.0662 - output_3_loss: 0.0756 - output_4_loss: 0.0999 - output_5_loss: 0.0712 - output_0_acc: 0.9830 - output_1_acc: 0.9834 - output_2_acc: 0.9857 - output_3_acc: 0.9834 - output_4_acc: 0.9774 - output_5_acc: 0.9871 - val_loss: 1.2728 - val_output_0_loss: 0.2112 - val_output_1_loss: 0.2344 - val_output_2_loss: 0.1634 - val_output_3_loss: 0.2073 - val_output_4_loss: 0.2546 - val_output_5_loss: 0.2018 - val_output_0_acc: 0.9350 - val_output_1_acc: 0.9230 - val_output_2_acc: 0.9497 - val_output_3_acc: 0.9287 - val_output_4_acc: 0.9090 - val_output_5_acc: 0.9330\n",
      "Epoch 149/200\n",
      "7000/7000 [==============================] - 1s 158us/step - loss: 0.4545 - output_0_loss: 0.0772 - output_1_loss: 0.0742 - output_2_loss: 0.0613 - output_3_loss: 0.0720 - output_4_loss: 0.1001 - output_5_loss: 0.0697 - output_0_acc: 0.9827 - output_1_acc: 0.9834 - output_2_acc: 0.9879 - output_3_acc: 0.9846 - output_4_acc: 0.9783 - output_5_acc: 0.9869 - val_loss: 1.3466 - val_output_0_loss: 0.2649 - val_output_1_loss: 0.1844 - val_output_2_loss: 0.1555 - val_output_3_loss: 0.1918 - val_output_4_loss: 0.3505 - val_output_5_loss: 0.1995 - val_output_0_acc: 0.9053 - val_output_1_acc: 0.9403 - val_output_2_acc: 0.9563 - val_output_3_acc: 0.9393 - val_output_4_acc: 0.8687 - val_output_5_acc: 0.9310\n",
      "Epoch 150/200\n",
      "7000/7000 [==============================] - 1s 166us/step - loss: 0.4498 - output_0_loss: 0.0735 - output_1_loss: 0.0739 - output_2_loss: 0.0638 - output_3_loss: 0.0734 - output_4_loss: 0.0930 - output_5_loss: 0.0722 - output_0_acc: 0.9854 - output_1_acc: 0.9827 - output_2_acc: 0.9870 - output_3_acc: 0.9840 - output_4_acc: 0.9796 - output_5_acc: 0.9846 - val_loss: 1.1342 - val_output_0_loss: 0.2103 - val_output_1_loss: 0.1603 - val_output_2_loss: 0.1425 - val_output_3_loss: 0.1620 - val_output_4_loss: 0.2615 - val_output_5_loss: 0.1977 - val_output_0_acc: 0.9303 - val_output_1_acc: 0.9520 - val_output_2_acc: 0.9507 - val_output_3_acc: 0.9510 - val_output_4_acc: 0.9057 - val_output_5_acc: 0.9400\n",
      "Epoch 151/200\n",
      "7000/7000 [==============================] - 1s 158us/step - loss: 0.4428 - output_0_loss: 0.0740 - output_1_loss: 0.0699 - output_2_loss: 0.0596 - output_3_loss: 0.0684 - output_4_loss: 0.0980 - output_5_loss: 0.0728 - output_0_acc: 0.9850 - output_1_acc: 0.9854 - output_2_acc: 0.9877 - output_3_acc: 0.9871 - output_4_acc: 0.9783 - output_5_acc: 0.9850 - val_loss: 1.1106 - val_output_0_loss: 0.1967 - val_output_1_loss: 0.1833 - val_output_2_loss: 0.1497 - val_output_3_loss: 0.1981 - val_output_4_loss: 0.1980 - val_output_5_loss: 0.1848 - val_output_0_acc: 0.9393 - val_output_1_acc: 0.9420 - val_output_2_acc: 0.9520 - val_output_3_acc: 0.9270 - val_output_4_acc: 0.9390 - val_output_5_acc: 0.9377\n",
      "Epoch 152/200\n",
      "7000/7000 [==============================] - 1s 162us/step - loss: 0.4261 - output_0_loss: 0.0699 - output_1_loss: 0.0692 - output_2_loss: 0.0587 - output_3_loss: 0.0714 - output_4_loss: 0.0903 - output_5_loss: 0.0666 - output_0_acc: 0.9859 - output_1_acc: 0.9847 - output_2_acc: 0.9877 - output_3_acc: 0.9856 - output_4_acc: 0.9806 - output_5_acc: 0.9870 - val_loss: 1.2618 - val_output_0_loss: 0.2392 - val_output_1_loss: 0.2329 - val_output_2_loss: 0.1605 - val_output_3_loss: 0.1891 - val_output_4_loss: 0.2464 - val_output_5_loss: 0.1937 - val_output_0_acc: 0.9127 - val_output_1_acc: 0.9177 - val_output_2_acc: 0.9483 - val_output_3_acc: 0.9347 - val_output_4_acc: 0.9130 - val_output_5_acc: 0.9377\n",
      "Epoch 153/200\n",
      "7000/7000 [==============================] - 1s 164us/step - loss: 0.4248 - output_0_loss: 0.0711 - output_1_loss: 0.0691 - output_2_loss: 0.0574 - output_3_loss: 0.0673 - output_4_loss: 0.0928 - output_5_loss: 0.0672 - output_0_acc: 0.9841 - output_1_acc: 0.9851 - output_2_acc: 0.9893 - output_3_acc: 0.9863 - output_4_acc: 0.9796 - output_5_acc: 0.9874 - val_loss: 1.2820 - val_output_0_loss: 0.1984 - val_output_1_loss: 0.2742 - val_output_2_loss: 0.1828 - val_output_3_loss: 0.1311 - val_output_4_loss: 0.3038 - val_output_5_loss: 0.1917 - val_output_0_acc: 0.9347 - val_output_1_acc: 0.9040 - val_output_2_acc: 0.9390 - val_output_3_acc: 0.9643 - val_output_4_acc: 0.8817 - val_output_5_acc: 0.9340\n",
      "Epoch 154/200\n",
      "7000/7000 [==============================] - 1s 154us/step - loss: 0.4147 - output_0_loss: 0.0696 - output_1_loss: 0.0677 - output_2_loss: 0.0559 - output_3_loss: 0.0680 - output_4_loss: 0.0874 - output_5_loss: 0.0660 - output_0_acc: 0.9830 - output_1_acc: 0.9847 - output_2_acc: 0.9879 - output_3_acc: 0.9863 - output_4_acc: 0.9820 - output_5_acc: 0.9867 - val_loss: 1.3932 - val_output_0_loss: 0.2328 - val_output_1_loss: 0.2046 - val_output_2_loss: 0.2047 - val_output_3_loss: 0.2354 - val_output_4_loss: 0.3553 - val_output_5_loss: 0.1603 - val_output_0_acc: 0.9197 - val_output_1_acc: 0.9263 - val_output_2_acc: 0.9270 - val_output_3_acc: 0.9150 - val_output_4_acc: 0.8673 - val_output_5_acc: 0.9577\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 148us/step - loss: 0.4058 - output_0_loss: 0.0705 - output_1_loss: 0.0648 - output_2_loss: 0.0556 - output_3_loss: 0.0666 - output_4_loss: 0.0864 - output_5_loss: 0.0619 - output_0_acc: 0.9850 - output_1_acc: 0.9863 - output_2_acc: 0.9877 - output_3_acc: 0.9866 - output_4_acc: 0.9817 - output_5_acc: 0.9889 - val_loss: 1.1463 - val_output_0_loss: 0.2095 - val_output_1_loss: 0.1776 - val_output_2_loss: 0.1359 - val_output_3_loss: 0.1446 - val_output_4_loss: 0.2887 - val_output_5_loss: 0.1900 - val_output_0_acc: 0.9277 - val_output_1_acc: 0.9407 - val_output_2_acc: 0.9553 - val_output_3_acc: 0.9530 - val_output_4_acc: 0.8903 - val_output_5_acc: 0.9407\n",
      "Epoch 156/200\n",
      "7000/7000 [==============================] - 1s 159us/step - loss: 0.3978 - output_0_loss: 0.0656 - output_1_loss: 0.0620 - output_2_loss: 0.0543 - output_3_loss: 0.0651 - output_4_loss: 0.0847 - output_5_loss: 0.0661 - output_0_acc: 0.9853 - output_1_acc: 0.9876 - output_2_acc: 0.9904 - output_3_acc: 0.9879 - output_4_acc: 0.9816 - output_5_acc: 0.9877 - val_loss: 1.1385 - val_output_0_loss: 0.1997 - val_output_1_loss: 0.1504 - val_output_2_loss: 0.1582 - val_output_3_loss: 0.1497 - val_output_4_loss: 0.2978 - val_output_5_loss: 0.1827 - val_output_0_acc: 0.9363 - val_output_1_acc: 0.9537 - val_output_2_acc: 0.9490 - val_output_3_acc: 0.9577 - val_output_4_acc: 0.8843 - val_output_5_acc: 0.9417\n",
      "Epoch 157/200\n",
      "7000/7000 [==============================] - 1s 162us/step - loss: 0.3866 - output_0_loss: 0.0640 - output_1_loss: 0.0625 - output_2_loss: 0.0526 - output_3_loss: 0.0634 - output_4_loss: 0.0836 - output_5_loss: 0.0605 - output_0_acc: 0.9879 - output_1_acc: 0.9864 - output_2_acc: 0.9901 - output_3_acc: 0.9856 - output_4_acc: 0.9827 - output_5_acc: 0.9881 - val_loss: 1.2269 - val_output_0_loss: 0.2423 - val_output_1_loss: 0.2005 - val_output_2_loss: 0.2037 - val_output_3_loss: 0.1535 - val_output_4_loss: 0.2143 - val_output_5_loss: 0.2127 - val_output_0_acc: 0.9143 - val_output_1_acc: 0.9377 - val_output_2_acc: 0.9293 - val_output_3_acc: 0.9520 - val_output_4_acc: 0.9247 - val_output_5_acc: 0.9207\n",
      "Epoch 158/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 0.3801 - output_0_loss: 0.0616 - output_1_loss: 0.0624 - output_2_loss: 0.0520 - output_3_loss: 0.0607 - output_4_loss: 0.0818 - output_5_loss: 0.0616 - output_0_acc: 0.9889 - output_1_acc: 0.9873 - output_2_acc: 0.9886 - output_3_acc: 0.9883 - output_4_acc: 0.9824 - output_5_acc: 0.9890 - val_loss: 1.0733 - val_output_0_loss: 0.1828 - val_output_1_loss: 0.1666 - val_output_2_loss: 0.1673 - val_output_3_loss: 0.2185 - val_output_4_loss: 0.1690 - val_output_5_loss: 0.1692 - val_output_0_acc: 0.9400 - val_output_1_acc: 0.9390 - val_output_2_acc: 0.9383 - val_output_3_acc: 0.9137 - val_output_4_acc: 0.9493 - val_output_5_acc: 0.9460\n",
      "Epoch 159/200\n",
      "7000/7000 [==============================] - 1s 151us/step - loss: 0.3723 - output_0_loss: 0.0599 - output_1_loss: 0.0618 - output_2_loss: 0.0519 - output_3_loss: 0.0585 - output_4_loss: 0.0788 - output_5_loss: 0.0614 - output_0_acc: 0.9897 - output_1_acc: 0.9871 - output_2_acc: 0.9891 - output_3_acc: 0.9883 - output_4_acc: 0.9854 - output_5_acc: 0.9874 - val_loss: 1.1366 - val_output_0_loss: 0.1940 - val_output_1_loss: 0.1805 - val_output_2_loss: 0.1402 - val_output_3_loss: 0.1702 - val_output_4_loss: 0.2449 - val_output_5_loss: 0.2067 - val_output_0_acc: 0.9387 - val_output_1_acc: 0.9407 - val_output_2_acc: 0.9563 - val_output_3_acc: 0.9367 - val_output_4_acc: 0.9140 - val_output_5_acc: 0.9173\n",
      "Epoch 160/200\n",
      "7000/7000 [==============================] - 1s 159us/step - loss: 0.3626 - output_0_loss: 0.0586 - output_1_loss: 0.0579 - output_2_loss: 0.0491 - output_3_loss: 0.0585 - output_4_loss: 0.0793 - output_5_loss: 0.0592 - output_0_acc: 0.9883 - output_1_acc: 0.9880 - output_2_acc: 0.9911 - output_3_acc: 0.9880 - output_4_acc: 0.9826 - output_5_acc: 0.9886 - val_loss: 1.2744 - val_output_0_loss: 0.2392 - val_output_1_loss: 0.1568 - val_output_2_loss: 0.1689 - val_output_3_loss: 0.2232 - val_output_4_loss: 0.2709 - val_output_5_loss: 0.2152 - val_output_0_acc: 0.9130 - val_output_1_acc: 0.9503 - val_output_2_acc: 0.9423 - val_output_3_acc: 0.9200 - val_output_4_acc: 0.8937 - val_output_5_acc: 0.9277\n",
      "Epoch 161/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 0.3596 - output_0_loss: 0.0611 - output_1_loss: 0.0596 - output_2_loss: 0.0483 - output_3_loss: 0.0571 - output_4_loss: 0.0770 - output_5_loss: 0.0565 - output_0_acc: 0.9894 - output_1_acc: 0.9871 - output_2_acc: 0.9891 - output_3_acc: 0.9897 - output_4_acc: 0.9817 - output_5_acc: 0.9877 - val_loss: 1.1746 - val_output_0_loss: 0.2431 - val_output_1_loss: 0.1885 - val_output_2_loss: 0.1745 - val_output_3_loss: 0.1655 - val_output_4_loss: 0.2495 - val_output_5_loss: 0.1535 - val_output_0_acc: 0.9117 - val_output_1_acc: 0.9303 - val_output_2_acc: 0.9370 - val_output_3_acc: 0.9340 - val_output_4_acc: 0.9133 - val_output_5_acc: 0.9523\n",
      "Epoch 162/200\n",
      "7000/7000 [==============================] - 1s 163us/step - loss: 0.3454 - output_0_loss: 0.0574 - output_1_loss: 0.0552 - output_2_loss: 0.0468 - output_3_loss: 0.0546 - output_4_loss: 0.0752 - output_5_loss: 0.0562 - output_0_acc: 0.9889 - output_1_acc: 0.9904 - output_2_acc: 0.9913 - output_3_acc: 0.9884 - output_4_acc: 0.9844 - output_5_acc: 0.9893 - val_loss: 1.1761 - val_output_0_loss: 0.2345 - val_output_1_loss: 0.2109 - val_output_2_loss: 0.1502 - val_output_3_loss: 0.2238 - val_output_4_loss: 0.1713 - val_output_5_loss: 0.1854 - val_output_0_acc: 0.9190 - val_output_1_acc: 0.9283 - val_output_2_acc: 0.9520 - val_output_3_acc: 0.9143 - val_output_4_acc: 0.9490 - val_output_5_acc: 0.9380\n",
      "Epoch 163/200\n",
      "7000/7000 [==============================] - 1s 156us/step - loss: 0.3494 - output_0_loss: 0.0580 - output_1_loss: 0.0572 - output_2_loss: 0.0474 - output_3_loss: 0.0547 - output_4_loss: 0.0754 - output_5_loss: 0.0566 - output_0_acc: 0.9876 - output_1_acc: 0.9891 - output_2_acc: 0.9911 - output_3_acc: 0.9891 - output_4_acc: 0.9830 - output_5_acc: 0.9901 - val_loss: 1.1347 - val_output_0_loss: 0.2028 - val_output_1_loss: 0.1844 - val_output_2_loss: 0.1058 - val_output_3_loss: 0.1702 - val_output_4_loss: 0.2198 - val_output_5_loss: 0.2517 - val_output_0_acc: 0.9297 - val_output_1_acc: 0.9407 - val_output_2_acc: 0.9650 - val_output_3_acc: 0.9407 - val_output_4_acc: 0.9133 - val_output_5_acc: 0.9143\n",
      "Epoch 164/200\n",
      "7000/7000 [==============================] - 1s 152us/step - loss: 0.3390 - output_0_loss: 0.0576 - output_1_loss: 0.0573 - output_2_loss: 0.0444 - output_3_loss: 0.0510 - output_4_loss: 0.0753 - output_5_loss: 0.0534 - output_0_acc: 0.9906 - output_1_acc: 0.9891 - output_2_acc: 0.9921 - output_3_acc: 0.9893 - output_4_acc: 0.9816 - output_5_acc: 0.9903 - val_loss: 1.0905 - val_output_0_loss: 0.2703 - val_output_1_loss: 0.1381 - val_output_2_loss: 0.1230 - val_output_3_loss: 0.1906 - val_output_4_loss: 0.2140 - val_output_5_loss: 0.1544 - val_output_0_acc: 0.9147 - val_output_1_acc: 0.9600 - val_output_2_acc: 0.9593 - val_output_3_acc: 0.9267 - val_output_4_acc: 0.9227 - val_output_5_acc: 0.9490\n",
      "Epoch 165/200\n",
      "7000/7000 [==============================] - 1s 146us/step - loss: 0.3316 - output_0_loss: 0.0560 - output_1_loss: 0.0540 - output_2_loss: 0.0459 - output_3_loss: 0.0523 - output_4_loss: 0.0696 - output_5_loss: 0.0537 - output_0_acc: 0.9887 - output_1_acc: 0.9894 - output_2_acc: 0.9904 - output_3_acc: 0.9903 - output_4_acc: 0.9851 - output_5_acc: 0.9899 - val_loss: 0.9663 - val_output_0_loss: 0.1748 - val_output_1_loss: 0.1404 - val_output_2_loss: 0.1156 - val_output_3_loss: 0.1468 - val_output_4_loss: 0.2304 - val_output_5_loss: 0.1584 - val_output_0_acc: 0.9437 - val_output_1_acc: 0.9537 - val_output_2_acc: 0.9660 - val_output_3_acc: 0.9513 - val_output_4_acc: 0.9133 - val_output_5_acc: 0.9530\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 151us/step - loss: 0.3212 - output_0_loss: 0.0518 - output_1_loss: 0.0533 - output_2_loss: 0.0450 - output_3_loss: 0.0516 - output_4_loss: 0.0685 - output_5_loss: 0.0510 - output_0_acc: 0.9911 - output_1_acc: 0.9893 - output_2_acc: 0.9917 - output_3_acc: 0.9893 - output_4_acc: 0.9877 - output_5_acc: 0.9903 - val_loss: 1.0559 - val_output_0_loss: 0.1954 - val_output_1_loss: 0.1211 - val_output_2_loss: 0.1274 - val_output_3_loss: 0.1405 - val_output_4_loss: 0.2131 - val_output_5_loss: 0.2584 - val_output_0_acc: 0.9293 - val_output_1_acc: 0.9610 - val_output_2_acc: 0.9587 - val_output_3_acc: 0.9557 - val_output_4_acc: 0.9257 - val_output_5_acc: 0.9027\n",
      "Epoch 167/200\n",
      "7000/7000 [==============================] - 1s 169us/step - loss: 0.3149 - output_0_loss: 0.0528 - output_1_loss: 0.0511 - output_2_loss: 0.0431 - output_3_loss: 0.0492 - output_4_loss: 0.0679 - output_5_loss: 0.0507 - output_0_acc: 0.9899 - output_1_acc: 0.9914 - output_2_acc: 0.9911 - output_3_acc: 0.9913 - output_4_acc: 0.9869 - output_5_acc: 0.9906 - val_loss: 1.0448 - val_output_0_loss: 0.1340 - val_output_1_loss: 0.1617 - val_output_2_loss: 0.1369 - val_output_3_loss: 0.1591 - val_output_4_loss: 0.1625 - val_output_5_loss: 0.2907 - val_output_0_acc: 0.9627 - val_output_1_acc: 0.9473 - val_output_2_acc: 0.9513 - val_output_3_acc: 0.9350 - val_output_4_acc: 0.9507 - val_output_5_acc: 0.8990\n",
      "Epoch 168/200\n",
      "7000/7000 [==============================] - 1s 164us/step - loss: 0.3110 - output_0_loss: 0.0511 - output_1_loss: 0.0517 - output_2_loss: 0.0424 - output_3_loss: 0.0484 - output_4_loss: 0.0680 - output_5_loss: 0.0496 - output_0_acc: 0.9914 - output_1_acc: 0.9894 - output_2_acc: 0.9923 - output_3_acc: 0.9917 - output_4_acc: 0.9856 - output_5_acc: 0.9913 - val_loss: 0.9459 - val_output_0_loss: 0.1651 - val_output_1_loss: 0.1329 - val_output_2_loss: 0.1268 - val_output_3_loss: 0.1246 - val_output_4_loss: 0.2186 - val_output_5_loss: 0.1780 - val_output_0_acc: 0.9503 - val_output_1_acc: 0.9627 - val_output_2_acc: 0.9610 - val_output_3_acc: 0.9617 - val_output_4_acc: 0.9307 - val_output_5_acc: 0.9407\n",
      "Epoch 169/200\n",
      "7000/7000 [==============================] - 1s 154us/step - loss: 0.3077 - output_0_loss: 0.0533 - output_1_loss: 0.0494 - output_2_loss: 0.0430 - output_3_loss: 0.0465 - output_4_loss: 0.0669 - output_5_loss: 0.0486 - output_0_acc: 0.9896 - output_1_acc: 0.9900 - output_2_acc: 0.9919 - output_3_acc: 0.9906 - output_4_acc: 0.9859 - output_5_acc: 0.9910 - val_loss: 1.1639 - val_output_0_loss: 0.2097 - val_output_1_loss: 0.2289 - val_output_2_loss: 0.1611 - val_output_3_loss: 0.1087 - val_output_4_loss: 0.2728 - val_output_5_loss: 0.1826 - val_output_0_acc: 0.9293 - val_output_1_acc: 0.9183 - val_output_2_acc: 0.9453 - val_output_3_acc: 0.9720 - val_output_4_acc: 0.9017 - val_output_5_acc: 0.9467\n",
      "Epoch 170/200\n",
      "7000/7000 [==============================] - 1s 154us/step - loss: 0.2987 - output_0_loss: 0.0483 - output_1_loss: 0.0474 - output_2_loss: 0.0420 - output_3_loss: 0.0454 - output_4_loss: 0.0668 - output_5_loss: 0.0489 - output_0_acc: 0.9909 - output_1_acc: 0.9904 - output_2_acc: 0.9913 - output_3_acc: 0.9919 - output_4_acc: 0.9876 - output_5_acc: 0.9927 - val_loss: 0.9356 - val_output_0_loss: 0.1513 - val_output_1_loss: 0.1590 - val_output_2_loss: 0.1411 - val_output_3_loss: 0.1646 - val_output_4_loss: 0.1574 - val_output_5_loss: 0.1621 - val_output_0_acc: 0.9523 - val_output_1_acc: 0.9443 - val_output_2_acc: 0.9543 - val_output_3_acc: 0.9407 - val_output_4_acc: 0.9517 - val_output_5_acc: 0.9407\n",
      "Epoch 171/200\n",
      "7000/7000 [==============================] - 1s 156us/step - loss: 0.2904 - output_0_loss: 0.0479 - output_1_loss: 0.0488 - output_2_loss: 0.0387 - output_3_loss: 0.0459 - output_4_loss: 0.0637 - output_5_loss: 0.0454 - output_0_acc: 0.9929 - output_1_acc: 0.9896 - output_2_acc: 0.9933 - output_3_acc: 0.9910 - output_4_acc: 0.9881 - output_5_acc: 0.9933 - val_loss: 0.9072 - val_output_0_loss: 0.2204 - val_output_1_loss: 0.1321 - val_output_2_loss: 0.1325 - val_output_3_loss: 0.1364 - val_output_4_loss: 0.1403 - val_output_5_loss: 0.1455 - val_output_0_acc: 0.9157 - val_output_1_acc: 0.9617 - val_output_2_acc: 0.9557 - val_output_3_acc: 0.9590 - val_output_4_acc: 0.9643 - val_output_5_acc: 0.9557\n",
      "Epoch 172/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 0.2916 - output_0_loss: 0.0479 - output_1_loss: 0.0479 - output_2_loss: 0.0403 - output_3_loss: 0.0438 - output_4_loss: 0.0630 - output_5_loss: 0.0487 - output_0_acc: 0.9910 - output_1_acc: 0.9913 - output_2_acc: 0.9921 - output_3_acc: 0.9920 - output_4_acc: 0.9877 - output_5_acc: 0.9904 - val_loss: 0.8300 - val_output_0_loss: 0.1898 - val_output_1_loss: 0.1340 - val_output_2_loss: 0.0901 - val_output_3_loss: 0.1230 - val_output_4_loss: 0.1548 - val_output_5_loss: 0.1384 - val_output_0_acc: 0.9373 - val_output_1_acc: 0.9570 - val_output_2_acc: 0.9727 - val_output_3_acc: 0.9620 - val_output_4_acc: 0.9560 - val_output_5_acc: 0.9547\n",
      "Epoch 173/200\n",
      "7000/7000 [==============================] - 1s 161us/step - loss: 0.2823 - output_0_loss: 0.0454 - output_1_loss: 0.0459 - output_2_loss: 0.0373 - output_3_loss: 0.0444 - output_4_loss: 0.0623 - output_5_loss: 0.0470 - output_0_acc: 0.9919 - output_1_acc: 0.9906 - output_2_acc: 0.9934 - output_3_acc: 0.9909 - output_4_acc: 0.9870 - output_5_acc: 0.9904 - val_loss: 0.9538 - val_output_0_loss: 0.1447 - val_output_1_loss: 0.1389 - val_output_2_loss: 0.1169 - val_output_3_loss: 0.2297 - val_output_4_loss: 0.1907 - val_output_5_loss: 0.1329 - val_output_0_acc: 0.9560 - val_output_1_acc: 0.9557 - val_output_2_acc: 0.9677 - val_output_3_acc: 0.9127 - val_output_4_acc: 0.9340 - val_output_5_acc: 0.9573\n",
      "Epoch 174/200\n",
      "7000/7000 [==============================] - 1s 158us/step - loss: 0.2751 - output_0_loss: 0.0424 - output_1_loss: 0.0456 - output_2_loss: 0.0376 - output_3_loss: 0.0423 - output_4_loss: 0.0610 - output_5_loss: 0.0463 - output_0_acc: 0.9939 - output_1_acc: 0.9916 - output_2_acc: 0.9939 - output_3_acc: 0.9930 - output_4_acc: 0.9876 - output_5_acc: 0.9916 - val_loss: 1.0177 - val_output_0_loss: 0.1694 - val_output_1_loss: 0.2187 - val_output_2_loss: 0.1042 - val_output_3_loss: 0.2215 - val_output_4_loss: 0.1546 - val_output_5_loss: 0.1493 - val_output_0_acc: 0.9417 - val_output_1_acc: 0.9137 - val_output_2_acc: 0.9680 - val_output_3_acc: 0.9150 - val_output_4_acc: 0.9493 - val_output_5_acc: 0.9537\n",
      "Epoch 175/200\n",
      "7000/7000 [==============================] - 1s 162us/step - loss: 0.2650 - output_0_loss: 0.0438 - output_1_loss: 0.0423 - output_2_loss: 0.0369 - output_3_loss: 0.0405 - output_4_loss: 0.0582 - output_5_loss: 0.0434 - output_0_acc: 0.9920 - output_1_acc: 0.9929 - output_2_acc: 0.9916 - output_3_acc: 0.9941 - output_4_acc: 0.9867 - output_5_acc: 0.9931 - val_loss: 0.8775 - val_output_0_loss: 0.1780 - val_output_1_loss: 0.1351 - val_output_2_loss: 0.1134 - val_output_3_loss: 0.0934 - val_output_4_loss: 0.2163 - val_output_5_loss: 0.1412 - val_output_0_acc: 0.9420 - val_output_1_acc: 0.9563 - val_output_2_acc: 0.9633 - val_output_3_acc: 0.9713 - val_output_4_acc: 0.9177 - val_output_5_acc: 0.9530\n",
      "Epoch 176/200\n",
      "7000/7000 [==============================] - 1s 153us/step - loss: 0.2642 - output_0_loss: 0.0426 - output_1_loss: 0.0423 - output_2_loss: 0.0359 - output_3_loss: 0.0382 - output_4_loss: 0.0600 - output_5_loss: 0.0452 - output_0_acc: 0.9937 - output_1_acc: 0.9924 - output_2_acc: 0.9929 - output_3_acc: 0.9933 - output_4_acc: 0.9891 - output_5_acc: 0.9920 - val_loss: 0.8030 - val_output_0_loss: 0.1458 - val_output_1_loss: 0.1287 - val_output_2_loss: 0.0892 - val_output_3_loss: 0.1570 - val_output_4_loss: 0.1388 - val_output_5_loss: 0.1436 - val_output_0_acc: 0.9550 - val_output_1_acc: 0.9603 - val_output_2_acc: 0.9753 - val_output_3_acc: 0.9453 - val_output_4_acc: 0.9580 - val_output_5_acc: 0.9527\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 156us/step - loss: 0.2572 - output_0_loss: 0.0419 - output_1_loss: 0.0411 - output_2_loss: 0.0358 - output_3_loss: 0.0408 - output_4_loss: 0.0556 - output_5_loss: 0.0420 - output_0_acc: 0.9911 - output_1_acc: 0.9924 - output_2_acc: 0.9930 - output_3_acc: 0.9920 - output_4_acc: 0.9894 - output_5_acc: 0.9917 - val_loss: 0.9514 - val_output_0_loss: 0.1798 - val_output_1_loss: 0.1687 - val_output_2_loss: 0.1330 - val_output_3_loss: 0.1217 - val_output_4_loss: 0.1549 - val_output_5_loss: 0.1934 - val_output_0_acc: 0.9353 - val_output_1_acc: 0.9397 - val_output_2_acc: 0.9500 - val_output_3_acc: 0.9603 - val_output_4_acc: 0.9510 - val_output_5_acc: 0.9340\n",
      "Epoch 178/200\n",
      "7000/7000 [==============================] - 1s 161us/step - loss: 0.2528 - output_0_loss: 0.0423 - output_1_loss: 0.0418 - output_2_loss: 0.0340 - output_3_loss: 0.0380 - output_4_loss: 0.0569 - output_5_loss: 0.0398 - output_0_acc: 0.9927 - output_1_acc: 0.9914 - output_2_acc: 0.9947 - output_3_acc: 0.9929 - output_4_acc: 0.9890 - output_5_acc: 0.9943 - val_loss: 0.8206 - val_output_0_loss: 0.1630 - val_output_1_loss: 0.1279 - val_output_2_loss: 0.0821 - val_output_3_loss: 0.1431 - val_output_4_loss: 0.1929 - val_output_5_loss: 0.1116 - val_output_0_acc: 0.9450 - val_output_1_acc: 0.9590 - val_output_2_acc: 0.9780 - val_output_3_acc: 0.9420 - val_output_4_acc: 0.9387 - val_output_5_acc: 0.9663\n",
      "Epoch 179/200\n",
      "7000/7000 [==============================] - 1s 160us/step - loss: 0.2439 - output_0_loss: 0.0408 - output_1_loss: 0.0414 - output_2_loss: 0.0337 - output_3_loss: 0.0362 - output_4_loss: 0.0534 - output_5_loss: 0.0384 - output_0_acc: 0.9927 - output_1_acc: 0.9923 - output_2_acc: 0.9943 - output_3_acc: 0.9949 - output_4_acc: 0.9900 - output_5_acc: 0.9926 - val_loss: 0.8397 - val_output_0_loss: 0.1894 - val_output_1_loss: 0.1240 - val_output_2_loss: 0.1046 - val_output_3_loss: 0.1158 - val_output_4_loss: 0.1530 - val_output_5_loss: 0.1530 - val_output_0_acc: 0.9330 - val_output_1_acc: 0.9590 - val_output_2_acc: 0.9670 - val_output_3_acc: 0.9657 - val_output_4_acc: 0.9477 - val_output_5_acc: 0.9503\n",
      "Epoch 180/200\n",
      "7000/7000 [==============================] - 1s 161us/step - loss: 0.2475 - output_0_loss: 0.0442 - output_1_loss: 0.0391 - output_2_loss: 0.0328 - output_3_loss: 0.0387 - output_4_loss: 0.0526 - output_5_loss: 0.0401 - output_0_acc: 0.9896 - output_1_acc: 0.9927 - output_2_acc: 0.9953 - output_3_acc: 0.9920 - output_4_acc: 0.9900 - output_5_acc: 0.9929 - val_loss: 0.7768 - val_output_0_loss: 0.1221 - val_output_1_loss: 0.1296 - val_output_2_loss: 0.1299 - val_output_3_loss: 0.0883 - val_output_4_loss: 0.1511 - val_output_5_loss: 0.1558 - val_output_0_acc: 0.9677 - val_output_1_acc: 0.9597 - val_output_2_acc: 0.9593 - val_output_3_acc: 0.9800 - val_output_4_acc: 0.9520 - val_output_5_acc: 0.9437\n",
      "Epoch 181/200\n",
      "7000/7000 [==============================] - 1s 160us/step - loss: 0.2374 - output_0_loss: 0.0379 - output_1_loss: 0.0393 - output_2_loss: 0.0334 - output_3_loss: 0.0346 - output_4_loss: 0.0527 - output_5_loss: 0.0395 - output_0_acc: 0.9926 - output_1_acc: 0.9926 - output_2_acc: 0.9930 - output_3_acc: 0.9940 - output_4_acc: 0.9899 - output_5_acc: 0.9931 - val_loss: 0.8859 - val_output_0_loss: 0.1369 - val_output_1_loss: 0.1214 - val_output_2_loss: 0.1836 - val_output_3_loss: 0.1112 - val_output_4_loss: 0.2032 - val_output_5_loss: 0.1295 - val_output_0_acc: 0.9610 - val_output_1_acc: 0.9637 - val_output_2_acc: 0.9357 - val_output_3_acc: 0.9670 - val_output_4_acc: 0.9287 - val_output_5_acc: 0.9617\n",
      "Epoch 182/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 0.2332 - output_0_loss: 0.0382 - output_1_loss: 0.0394 - output_2_loss: 0.0311 - output_3_loss: 0.0346 - output_4_loss: 0.0520 - output_5_loss: 0.0379 - output_0_acc: 0.9931 - output_1_acc: 0.9924 - output_2_acc: 0.9940 - output_3_acc: 0.9941 - output_4_acc: 0.9899 - output_5_acc: 0.9926 - val_loss: 0.8368 - val_output_0_loss: 0.1658 - val_output_1_loss: 0.1047 - val_output_2_loss: 0.1091 - val_output_3_loss: 0.1593 - val_output_4_loss: 0.1595 - val_output_5_loss: 0.1383 - val_output_0_acc: 0.9473 - val_output_1_acc: 0.9717 - val_output_2_acc: 0.9657 - val_output_3_acc: 0.9450 - val_output_4_acc: 0.9500 - val_output_5_acc: 0.9577\n",
      "Epoch 183/200\n",
      "7000/7000 [==============================] - 1s 162us/step - loss: 0.2302 - output_0_loss: 0.0388 - output_1_loss: 0.0382 - output_2_loss: 0.0309 - output_3_loss: 0.0336 - output_4_loss: 0.0512 - output_5_loss: 0.0375 - output_0_acc: 0.9909 - output_1_acc: 0.9919 - output_2_acc: 0.9943 - output_3_acc: 0.9940 - output_4_acc: 0.9904 - output_5_acc: 0.9937 - val_loss: 0.8538 - val_output_0_loss: 0.1459 - val_output_1_loss: 0.1326 - val_output_2_loss: 0.1610 - val_output_3_loss: 0.0876 - val_output_4_loss: 0.1599 - val_output_5_loss: 0.1669 - val_output_0_acc: 0.9530 - val_output_1_acc: 0.9547 - val_output_2_acc: 0.9427 - val_output_3_acc: 0.9783 - val_output_4_acc: 0.9437 - val_output_5_acc: 0.9390\n",
      "Epoch 184/200\n",
      "7000/7000 [==============================] - 1s 159us/step - loss: 0.2213 - output_0_loss: 0.0360 - output_1_loss: 0.0358 - output_2_loss: 0.0309 - output_3_loss: 0.0326 - output_4_loss: 0.0493 - output_5_loss: 0.0368 - output_0_acc: 0.9931 - output_1_acc: 0.9944 - output_2_acc: 0.9950 - output_3_acc: 0.9946 - output_4_acc: 0.9906 - output_5_acc: 0.9937 - val_loss: 0.8087 - val_output_0_loss: 0.1135 - val_output_1_loss: 0.1052 - val_output_2_loss: 0.1167 - val_output_3_loss: 0.1152 - val_output_4_loss: 0.1580 - val_output_5_loss: 0.2001 - val_output_0_acc: 0.9670 - val_output_1_acc: 0.9673 - val_output_2_acc: 0.9597 - val_output_3_acc: 0.9610 - val_output_4_acc: 0.9427 - val_output_5_acc: 0.9287\n",
      "Epoch 185/200\n",
      "7000/7000 [==============================] - 1s 151us/step - loss: 0.2161 - output_0_loss: 0.0343 - output_1_loss: 0.0377 - output_2_loss: 0.0294 - output_3_loss: 0.0327 - output_4_loss: 0.0459 - output_5_loss: 0.0361 - output_0_acc: 0.9943 - output_1_acc: 0.9924 - output_2_acc: 0.9950 - output_3_acc: 0.9951 - output_4_acc: 0.9926 - output_5_acc: 0.9944 - val_loss: 0.8068 - val_output_0_loss: 0.1578 - val_output_1_loss: 0.1769 - val_output_2_loss: 0.0931 - val_output_3_loss: 0.0903 - val_output_4_loss: 0.1543 - val_output_5_loss: 0.1345 - val_output_0_acc: 0.9440 - val_output_1_acc: 0.9413 - val_output_2_acc: 0.9717 - val_output_3_acc: 0.9753 - val_output_4_acc: 0.9507 - val_output_5_acc: 0.9583\n",
      "Epoch 186/200\n",
      "7000/7000 [==============================] - 1s 159us/step - loss: 0.2166 - output_0_loss: 0.0346 - output_1_loss: 0.0374 - output_2_loss: 0.0291 - output_3_loss: 0.0328 - output_4_loss: 0.0465 - output_5_loss: 0.0362 - output_0_acc: 0.9941 - output_1_acc: 0.9911 - output_2_acc: 0.9944 - output_3_acc: 0.9937 - output_4_acc: 0.9909 - output_5_acc: 0.9939 - val_loss: 0.8814 - val_output_0_loss: 0.1930 - val_output_1_loss: 0.1576 - val_output_2_loss: 0.0872 - val_output_3_loss: 0.1742 - val_output_4_loss: 0.1363 - val_output_5_loss: 0.1331 - val_output_0_acc: 0.9317 - val_output_1_acc: 0.9447 - val_output_2_acc: 0.9767 - val_output_3_acc: 0.9377 - val_output_4_acc: 0.9573 - val_output_5_acc: 0.9553\n",
      "Epoch 187/200\n",
      "7000/7000 [==============================] - 1s 160us/step - loss: 0.2071 - output_0_loss: 0.0344 - output_1_loss: 0.0327 - output_2_loss: 0.0277 - output_3_loss: 0.0311 - output_4_loss: 0.0467 - output_5_loss: 0.0344 - output_0_acc: 0.9936 - output_1_acc: 0.9944 - output_2_acc: 0.9954 - output_3_acc: 0.9947 - output_4_acc: 0.9914 - output_5_acc: 0.9943 - val_loss: 0.8421 - val_output_0_loss: 0.1322 - val_output_1_loss: 0.1173 - val_output_2_loss: 0.1014 - val_output_3_loss: 0.1607 - val_output_4_loss: 0.1732 - val_output_5_loss: 0.1574 - val_output_0_acc: 0.9593 - val_output_1_acc: 0.9617 - val_output_2_acc: 0.9673 - val_output_3_acc: 0.9460 - val_output_4_acc: 0.9423 - val_output_5_acc: 0.9460\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 162us/step - loss: 0.2065 - output_0_loss: 0.0334 - output_1_loss: 0.0333 - output_2_loss: 0.0279 - output_3_loss: 0.0311 - output_4_loss: 0.0465 - output_5_loss: 0.0344 - output_0_acc: 0.9943 - output_1_acc: 0.9944 - output_2_acc: 0.9954 - output_3_acc: 0.9957 - output_4_acc: 0.9909 - output_5_acc: 0.9941 - val_loss: 0.7949 - val_output_0_loss: 0.1213 - val_output_1_loss: 0.1615 - val_output_2_loss: 0.0830 - val_output_3_loss: 0.1552 - val_output_4_loss: 0.1550 - val_output_5_loss: 0.1189 - val_output_0_acc: 0.9630 - val_output_1_acc: 0.9353 - val_output_2_acc: 0.9733 - val_output_3_acc: 0.9423 - val_output_4_acc: 0.9487 - val_output_5_acc: 0.9613\n",
      "Epoch 189/200\n",
      "7000/7000 [==============================] - 1s 160us/step - loss: 0.2011 - output_0_loss: 0.0345 - output_1_loss: 0.0306 - output_2_loss: 0.0281 - output_3_loss: 0.0301 - output_4_loss: 0.0444 - output_5_loss: 0.0333 - output_0_acc: 0.9937 - output_1_acc: 0.9957 - output_2_acc: 0.9953 - output_3_acc: 0.9950 - output_4_acc: 0.9913 - output_5_acc: 0.9941 - val_loss: 0.8396 - val_output_0_loss: 0.1717 - val_output_1_loss: 0.1255 - val_output_2_loss: 0.0913 - val_output_3_loss: 0.1269 - val_output_4_loss: 0.1795 - val_output_5_loss: 0.1446 - val_output_0_acc: 0.9420 - val_output_1_acc: 0.9610 - val_output_2_acc: 0.9690 - val_output_3_acc: 0.9483 - val_output_4_acc: 0.9410 - val_output_5_acc: 0.9533\n",
      "Epoch 190/200\n",
      "7000/7000 [==============================] - 1s 162us/step - loss: 0.1962 - output_0_loss: 0.0309 - output_1_loss: 0.0322 - output_2_loss: 0.0254 - output_3_loss: 0.0299 - output_4_loss: 0.0444 - output_5_loss: 0.0334 - output_0_acc: 0.9959 - output_1_acc: 0.9939 - output_2_acc: 0.9964 - output_3_acc: 0.9941 - output_4_acc: 0.9917 - output_5_acc: 0.9943 - val_loss: 0.8123 - val_output_0_loss: 0.1585 - val_output_1_loss: 0.1954 - val_output_2_loss: 0.0844 - val_output_3_loss: 0.0868 - val_output_4_loss: 0.1723 - val_output_5_loss: 0.1149 - val_output_0_acc: 0.9500 - val_output_1_acc: 0.9347 - val_output_2_acc: 0.9777 - val_output_3_acc: 0.9730 - val_output_4_acc: 0.9387 - val_output_5_acc: 0.9620\n",
      "Epoch 191/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 0.1968 - output_0_loss: 0.0334 - output_1_loss: 0.0325 - output_2_loss: 0.0251 - output_3_loss: 0.0296 - output_4_loss: 0.0440 - output_5_loss: 0.0322 - output_0_acc: 0.9933 - output_1_acc: 0.9947 - output_2_acc: 0.9954 - output_3_acc: 0.9953 - output_4_acc: 0.9913 - output_5_acc: 0.9941 - val_loss: 0.9365 - val_output_0_loss: 0.1606 - val_output_1_loss: 0.1090 - val_output_2_loss: 0.1327 - val_output_3_loss: 0.1622 - val_output_4_loss: 0.1527 - val_output_5_loss: 0.2193 - val_output_0_acc: 0.9477 - val_output_1_acc: 0.9693 - val_output_2_acc: 0.9553 - val_output_3_acc: 0.9433 - val_output_4_acc: 0.9473 - val_output_5_acc: 0.9170\n",
      "Epoch 192/200\n",
      "7000/7000 [==============================] - 1s 156us/step - loss: 0.1832 - output_0_loss: 0.0320 - output_1_loss: 0.0299 - output_2_loss: 0.0261 - output_3_loss: 0.0256 - output_4_loss: 0.0396 - output_5_loss: 0.0300 - output_0_acc: 0.9953 - output_1_acc: 0.9953 - output_2_acc: 0.9950 - output_3_acc: 0.9960 - output_4_acc: 0.9937 - output_5_acc: 0.9950 - val_loss: 0.6805 - val_output_0_loss: 0.1231 - val_output_1_loss: 0.1191 - val_output_2_loss: 0.0902 - val_output_3_loss: 0.0983 - val_output_4_loss: 0.1181 - val_output_5_loss: 0.1318 - val_output_0_acc: 0.9623 - val_output_1_acc: 0.9610 - val_output_2_acc: 0.9720 - val_output_3_acc: 0.9707 - val_output_4_acc: 0.9647 - val_output_5_acc: 0.9577\n",
      "Epoch 193/200\n",
      "7000/7000 [==============================] - 1s 161us/step - loss: 0.1807 - output_0_loss: 0.0308 - output_1_loss: 0.0301 - output_2_loss: 0.0235 - output_3_loss: 0.0250 - output_4_loss: 0.0405 - output_5_loss: 0.0307 - output_0_acc: 0.9951 - output_1_acc: 0.9950 - output_2_acc: 0.9961 - output_3_acc: 0.9964 - output_4_acc: 0.9921 - output_5_acc: 0.9947 - val_loss: 0.8457 - val_output_0_loss: 0.1534 - val_output_1_loss: 0.1131 - val_output_2_loss: 0.0825 - val_output_3_loss: 0.1336 - val_output_4_loss: 0.2150 - val_output_5_loss: 0.1480 - val_output_0_acc: 0.9483 - val_output_1_acc: 0.9620 - val_output_2_acc: 0.9757 - val_output_3_acc: 0.9540 - val_output_4_acc: 0.9173 - val_output_5_acc: 0.9463\n",
      "Epoch 194/200\n",
      "7000/7000 [==============================] - 1s 162us/step - loss: 0.1809 - output_0_loss: 0.0313 - output_1_loss: 0.0291 - output_2_loss: 0.0246 - output_3_loss: 0.0272 - output_4_loss: 0.0387 - output_5_loss: 0.0301 - output_0_acc: 0.9946 - output_1_acc: 0.9963 - output_2_acc: 0.9953 - output_3_acc: 0.9954 - output_4_acc: 0.9931 - output_5_acc: 0.9959 - val_loss: 0.7352 - val_output_0_loss: 0.1052 - val_output_1_loss: 0.0990 - val_output_2_loss: 0.0988 - val_output_3_loss: 0.1443 - val_output_4_loss: 0.1700 - val_output_5_loss: 0.1178 - val_output_0_acc: 0.9700 - val_output_1_acc: 0.9693 - val_output_2_acc: 0.9673 - val_output_3_acc: 0.9473 - val_output_4_acc: 0.9453 - val_output_5_acc: 0.9610\n",
      "Epoch 195/200\n",
      "7000/7000 [==============================] - 1s 154us/step - loss: 0.1787 - output_0_loss: 0.0268 - output_1_loss: 0.0315 - output_2_loss: 0.0235 - output_3_loss: 0.0265 - output_4_loss: 0.0396 - output_5_loss: 0.0308 - output_0_acc: 0.9949 - output_1_acc: 0.9944 - output_2_acc: 0.9966 - output_3_acc: 0.9963 - output_4_acc: 0.9916 - output_5_acc: 0.9943 - val_loss: 0.7420 - val_output_0_loss: 0.2085 - val_output_1_loss: 0.0927 - val_output_2_loss: 0.0855 - val_output_3_loss: 0.0867 - val_output_4_loss: 0.1520 - val_output_5_loss: 0.1167 - val_output_0_acc: 0.9310 - val_output_1_acc: 0.9723 - val_output_2_acc: 0.9763 - val_output_3_acc: 0.9737 - val_output_4_acc: 0.9463 - val_output_5_acc: 0.9663\n",
      "Epoch 196/200\n",
      "7000/7000 [==============================] - 1s 161us/step - loss: 0.1715 - output_0_loss: 0.0292 - output_1_loss: 0.0288 - output_2_loss: 0.0230 - output_3_loss: 0.0247 - output_4_loss: 0.0388 - output_5_loss: 0.0270 - output_0_acc: 0.9950 - output_1_acc: 0.9959 - output_2_acc: 0.9960 - output_3_acc: 0.9970 - output_4_acc: 0.9913 - output_5_acc: 0.9961 - val_loss: 0.6837 - val_output_0_loss: 0.1243 - val_output_1_loss: 0.1030 - val_output_2_loss: 0.0765 - val_output_3_loss: 0.0973 - val_output_4_loss: 0.1347 - val_output_5_loss: 0.1479 - val_output_0_acc: 0.9623 - val_output_1_acc: 0.9693 - val_output_2_acc: 0.9770 - val_output_3_acc: 0.9700 - val_output_4_acc: 0.9563 - val_output_5_acc: 0.9537\n",
      "Epoch 197/200\n",
      "7000/7000 [==============================] - 1s 169us/step - loss: 0.1726 - output_0_loss: 0.0273 - output_1_loss: 0.0295 - output_2_loss: 0.0235 - output_3_loss: 0.0246 - output_4_loss: 0.0392 - output_5_loss: 0.0284 - output_0_acc: 0.9957 - output_1_acc: 0.9947 - output_2_acc: 0.9957 - output_3_acc: 0.9966 - output_4_acc: 0.9929 - output_5_acc: 0.9961 - val_loss: 0.8247 - val_output_0_loss: 0.1517 - val_output_1_loss: 0.1799 - val_output_2_loss: 0.1146 - val_output_3_loss: 0.0948 - val_output_4_loss: 0.1360 - val_output_5_loss: 0.1477 - val_output_0_acc: 0.9503 - val_output_1_acc: 0.9380 - val_output_2_acc: 0.9657 - val_output_3_acc: 0.9690 - val_output_4_acc: 0.9573 - val_output_5_acc: 0.9537\n",
      "Epoch 198/200\n",
      "7000/7000 [==============================] - 1s 167us/step - loss: 0.1628 - output_0_loss: 0.0261 - output_1_loss: 0.0277 - output_2_loss: 0.0230 - output_3_loss: 0.0232 - output_4_loss: 0.0343 - output_5_loss: 0.0284 - output_0_acc: 0.9963 - output_1_acc: 0.9953 - output_2_acc: 0.9964 - output_3_acc: 0.9967 - output_4_acc: 0.9944 - output_5_acc: 0.9949 - val_loss: 0.7377 - val_output_0_loss: 0.1335 - val_output_1_loss: 0.1583 - val_output_2_loss: 0.1334 - val_output_3_loss: 0.0896 - val_output_4_loss: 0.1218 - val_output_5_loss: 0.1010 - val_output_0_acc: 0.9560 - val_output_1_acc: 0.9477 - val_output_2_acc: 0.9527 - val_output_3_acc: 0.9753 - val_output_4_acc: 0.9633 - val_output_5_acc: 0.9680\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 159us/step - loss: 0.1644 - output_0_loss: 0.0253 - output_1_loss: 0.0262 - output_2_loss: 0.0216 - output_3_loss: 0.0247 - output_4_loss: 0.0384 - output_5_loss: 0.0283 - output_0_acc: 0.9966 - output_1_acc: 0.9954 - output_2_acc: 0.9967 - output_3_acc: 0.9964 - output_4_acc: 0.9929 - output_5_acc: 0.9953 - val_loss: 0.8152 - val_output_0_loss: 0.2035 - val_output_1_loss: 0.1559 - val_output_2_loss: 0.0948 - val_output_3_loss: 0.1020 - val_output_4_loss: 0.1367 - val_output_5_loss: 0.1223 - val_output_0_acc: 0.9303 - val_output_1_acc: 0.9437 - val_output_2_acc: 0.9687 - val_output_3_acc: 0.9637 - val_output_4_acc: 0.9577 - val_output_5_acc: 0.9640\n",
      "Epoch 200/200\n",
      "7000/7000 [==============================] - 1s 162us/step - loss: 0.1600 - output_0_loss: 0.0260 - output_1_loss: 0.0273 - output_2_loss: 0.0216 - output_3_loss: 0.0223 - output_4_loss: 0.0370 - output_5_loss: 0.0259 - output_0_acc: 0.9960 - output_1_acc: 0.9947 - output_2_acc: 0.9966 - output_3_acc: 0.9966 - output_4_acc: 0.9930 - output_5_acc: 0.9963 - val_loss: 0.7166 - val_output_0_loss: 0.1412 - val_output_1_loss: 0.1475 - val_output_2_loss: 0.0989 - val_output_3_loss: 0.0980 - val_output_4_loss: 0.1344 - val_output_5_loss: 0.0966 - val_output_0_acc: 0.9557 - val_output_1_acc: 0.9543 - val_output_2_acc: 0.9687 - val_output_3_acc: 0.9713 - val_output_4_acc: 0.9563 - val_output_5_acc: 0.9773\n"
     ]
    }
   ],
   "source": [
    "history = coding_model.fit(x_train, y_train, validation_split=percentage_split, batch_size=32, epochs=nb_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values (of first char only)\n",
    "plt.plot(history.history['output_0_acc'])\n",
    "plt.plot(history.history['val_output_0_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot training & validation loss values (of first char only)\n",
    "plt.plot(history.history['output_0_loss'])\n",
    "plt.plot(history.history['val_output_0_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n",
      " 6016/10000 [=================>............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 18us/step\n",
      "loss : 0.6605998941421509\n",
      "output_0_loss : 0.1295211825966835\n",
      "output_1_loss : 0.12847152075767518\n",
      "output_2_loss : 0.09500231258273124\n",
      "output_3_loss : 0.08859642367362976\n",
      "output_4_loss : 0.12913943295478822\n",
      "output_5_loss : 0.08986902555823326\n",
      "output_0_acc : 0.9532\n",
      "output_1_acc : 0.9573\n",
      "output_2_acc : 0.9727\n",
      "output_3_acc : 0.9767\n",
      "output_4_acc : 0.9602\n",
      "output_5_acc : 0.9736\n"
     ]
    }
   ],
   "source": [
    "nb_words_to_test = 10000\n",
    "\n",
    "x_test = create_inputs(nb_words_to_test, nb_chars, nb_letters)\n",
    "x_test_scaled  = scaler.transform(x_test)\n",
    "\n",
    "y_test_raw = encrypt(x_test, nb_words_to_test, nb_chars)\n",
    "y_test_raw_cate = keras.utils.to_categorical(y_test_raw, nb_letters)\n",
    "\n",
    "# process the y data as useful ANN multiple-outputs data\n",
    "y_test = []\n",
    "for c in range(nb_chars):\n",
    "    # extract each 'char' colomn from the global y_train0 tensor\n",
    "    # in order to have multiplue yi_train outputs tensors\n",
    "    yi_test = y_test_raw_cate[:,c,:]\n",
    "    y_test.append(yi_test)\n",
    "\n",
    "\n",
    "print('\\n# Evaluate on test data')\n",
    "results = coding_model.evaluate(x_test_scaled, y_test, batch_size=128)\n",
    "for r in range(len(results)):\n",
    "    print(coding_model.metrics_names[r],':',results[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wllydw', 'hdcnnd', 'jznzbg']\n",
      "x_test=\n",
      " [[119 108 108 121 100 119]\n",
      " [104 100  99 110 110 100]\n",
      " [106 122 110 122  98 103]]\n",
      "x_test_scaled=\n",
      " [[ 1.25225181 -0.19958441 -0.19241284  1.54960105 -1.27003477  1.26617374]\n",
      " [-0.74859791 -1.26233421 -1.38859683  0.08591818  0.06276137 -1.2690559 ]\n",
      " [-0.48181795  1.66022773  0.07340582  1.68266313 -1.536594   -0.86875648]]\n",
      "-->\n",
      "prediction\n",
      "['22 11 11 24 3 22', '7 3 2 13 13 3', '9 25 13 25 1 6']\n",
      "check prediction\n",
      "y_test=\n",
      " [[22 11 11 24  3 22]\n",
      " [ 7  3  2 13 13  3]\n",
      " [ 9 25 13 25  1  6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "nb_words_to_test = 3\n",
    "\n",
    "x_test = create_inputs(nb_words_to_test, nb_chars, nb_letters)\n",
    "print_readable_inputs(x_test)\n",
    "print(\"x_test=\\n\", x_test)\n",
    "\n",
    "x_test_scaled  = scaler.transform(x_test)\n",
    "print(\"x_test_scaled=\\n\", x_test_scaled)\n",
    "print('-->')\n",
    "\n",
    "prediction = coding_model.predict(x_test_scaled)\n",
    "#print(prediction)\n",
    "print('prediction')\n",
    "print_readable_outputs(prediction, nb_words_to_test, nb_chars)\n",
    "\n",
    "print('check prediction')\n",
    "y_test = encrypt(x_test, nb_words_to_test, nb_chars)\n",
    "print(\"y_test=\\n\", y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
