{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of characters in a word.\n",
    "# for instance abccba has nb_chars = 6\n",
    "nb_chars = 5\n",
    "\n",
    "# number of possible characters used during the encoding.\n",
    "# for instance abcde leads to 01234 has nb_letters = 5\n",
    "nb_letters = 26\n",
    "\n",
    "# number of words samples to be generated \n",
    "nb_words = 10000\n",
    "\n",
    "# percentage of words that will be used for validation\n",
    "percentage_split = 0.60\n",
    "\n",
    "# number of epochs for fitting the model training step\n",
    "nb_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11881376"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of combinations\n",
    "nb_letters**nb_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inputs(nb_words, nb_chars, nb_letters):\n",
    "    '''Create a numpy array of nb_words rows with nb_chars columns each element\n",
    "    being a random letter of nb_letters (a, b...)'''\n",
    "    words = np.zeros((nb_words, nb_chars), dtype=int)\n",
    "    \n",
    "    for w in range(nb_words):\n",
    "        optim_tentative = False\n",
    "        if optim_tentative == True and w%10 != 0:\n",
    "            i = random.randint(0, nb_letters-1)\n",
    "            for c in range(nb_chars):\n",
    "                words[w, c] = ord('a') + i\n",
    "        else:\n",
    "            for c in range(nb_chars):\n",
    "                i = random.randint(0, nb_letters-1)\n",
    "                words[w, c] = ord('a') + i\n",
    "                \n",
    "    return words\n",
    "\n",
    "\n",
    "def encrypt(words, nb_words, nb_chars):\n",
    "    '''Encrypt each element of a numpy array of nb_words rows with nb_chars \n",
    "    columns each item with a secret algorithm'''\n",
    "    \n",
    "    encrypted_words = words.copy()\n",
    "    encrypted_words_probs = np.zeros((nb_words, nb_chars, nb_chars))\n",
    "    \n",
    "    #val_max = -1\n",
    "    \n",
    "    for w in range(nb_words):\n",
    "        for c in range(nb_chars): # 0,1,2,3,4\n",
    "            encrypted_words[w,c] = int(words[w,c]) - 49\n",
    "            val = encrypted_words[w,c] - 48\n",
    "            \n",
    "            #if val > val_max:\n",
    "            #    val_max = val\n",
    "            \n",
    "            # add entropy (i.e. mistakes in the encryption)\n",
    "            #epsilon = random.randint(0, 100)\n",
    "            #if epsilon == 5 and val != val_max:\n",
    "            #val +=1\n",
    "            \n",
    "            #print('w:',w,', c:',c,', [wc]:', val)\n",
    "            #encrypted_words_probs[w, c, val ] = 1.0\n",
    "            encrypted_words[w,c] = val\n",
    "    return encrypted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_features = nb_chars\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = layers.Input(shape=(nb_chars,), dtype='float32', name='main_input')\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = layers.Dense(4096, activation='relu', name='hl_1')(inputs)\n",
    "#x = layers.Dense(2048, activation='relu', name='hl_1')(inputs)\n",
    "#x = layers.Dense(64, activation='relu', name='hl_2')(x)\n",
    "\n",
    "outputs = []\n",
    "losses = {}\n",
    "for o in range(nb_chars):\n",
    "    name_i = 'output_'+str(o)\n",
    "    output_i = layers.Dense(nb_letters, activation='softmax', dtype='float32', name=name_i)(x)\n",
    "    outputs.append(output_i)\n",
    "    losses[name_i] = 'categorical_crossentropy'\n",
    "\n",
    "coding_model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "coding_model.compile(optimizer='rmsprop',\n",
    "                     loss=losses,\n",
    "                     metrics=['accuracy'])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hl_1 (Dense)                    (None, 4096)         24576       main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output_0 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_2 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_3 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_4 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 557,186\n",
      "Trainable params: 557,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(coding_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_readable_inputs(x):\n",
    "    words = []\n",
    "    for w in x:\n",
    "        word = ''\n",
    "        for c in w:\n",
    "            word += chr(c)\n",
    "        words.append(word)\n",
    "   \n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_readable_outputs_(outputs, nb_words, nb_chars):\n",
    "    \n",
    "    # outputs are listed : first, per char, second by sample, third by letter probability\n",
    "    words = [''] * nb_words\n",
    "    \n",
    "    c_i = 0\n",
    "    for char in outputs:\n",
    "\n",
    "        s_i = 0\n",
    "        for sample in char:\n",
    "\n",
    "            l_i = 0\n",
    "            best_value = -float('inf')\n",
    "            best_letter = -1\n",
    "            for letter_probs in sample:\n",
    "                if letter_probs > best_value:\n",
    "                    best_value = letter_probs\n",
    "                    best_letter = l_i\n",
    "                l_i += 1\n",
    "            words[s_i] += str(best_letter)\n",
    "            if c_i != nb_chars - 1:\n",
    "                words[s_i] += ' '\n",
    "            s_i += 1\n",
    "        c_i += 1\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_readable_outputs(outputs, nb_words, nb_chars):\n",
    "    \n",
    "    # outputs are listed : first, per char, second by sample, third by letter probability\n",
    "    words = [''] * nb_words\n",
    "    c_i = 0\n",
    "    for char in outputs:\n",
    "        s_i = 0\n",
    "        for sample in char:\n",
    "            best_letter = np.argmax(sample)\n",
    "            words[s_i] += str(best_letter)\n",
    "            if c_i != nb_chars - 1:\n",
    "                words[s_i] += ' '\n",
    "            s_i += 1\n",
    "        c_i += 1\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (as readable inputs)\n",
      "['kfzlc', 'piusm', 'tsbil', 'hiixq']\n",
      "x (partial):\n",
      " [[107 102 122 108  99]\n",
      " [112 105 117 115 109]\n",
      " [116 115  98 105 108]\n",
      " [104 105 105 120 113]] out of  10000\n",
      "\n",
      "x_train:\n",
      " [[-0.32792525 -0.99875678  1.65344344 -0.20652286 -1.397286  ]\n",
      " [ 0.33959348 -0.60076114  0.98416862  0.72960357 -0.0735971 ]\n",
      " [ 0.87360846  0.72589097 -1.55907569 -0.6077199  -0.20596599]\n",
      " [-0.72843648 -0.60076114 -0.62209094  1.3982653   0.45587846]] out of  10000\n",
      "\n",
      "y (readable):\n",
      " [[10  5 25 11  2]\n",
      " [15  8 20 18 12]\n",
      " [19 18  1  8 11]\n",
      " ...\n",
      " [16 15  7 17  9]\n",
      " [12  4 10 11 14]\n",
      " [ 4 23 16  9 17]]\n",
      "\n",
      "y (less readable):\n",
      " [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   1. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]] out of  10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "x = create_inputs(nb_words, nb_chars, nb_letters)\n",
    "print('x: (as readable inputs)')\n",
    "\n",
    "first_n_samples = 4\n",
    "\n",
    "print_readable_inputs(x[:first_n_samples])\n",
    "print('x (partial):\\n', x[:first_n_samples], 'out of ',len(x))\n",
    "print()\n",
    "\n",
    "# process the x data as useful ANN input data\n",
    "scaler = StandardScaler()\n",
    "x_train  = scaler.fit_transform(x)\n",
    "\n",
    "print('x_train:\\n', x_train[:first_n_samples], 'out of ',len(x_train))\n",
    "print()\n",
    "\n",
    "# create output data for training\n",
    "y = encrypt(x, nb_words, nb_chars)\n",
    "print('y (readable):\\n', y)\n",
    "print()\n",
    "\n",
    "# process the y data as useful ANN output data\n",
    "y_train0 = keras.utils.to_categorical(y, nb_letters)\n",
    "print('y (less readable):\\n', y_train0[:first_n_samples], 'out of ',len(y_train0))\n",
    "print('')\n",
    "\n",
    "# process the y data as useful ANN multiple-outputs data\n",
    "y_train = []\n",
    "for c in range(nb_chars):\n",
    "    # extract each 'char' colomn from the global y_train0 tensor\n",
    "    # in order to have multiplue yi_train outputs tensors\n",
    "    yi_train = y_train0[:,c,:]\n",
    "    y_train.append(yi_train)\n",
    "\n",
    "# Not really displayable, henced commented\n",
    "#print('y_train):')\n",
    "#print(y_train[:first_n_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 6000 samples\n",
      "Epoch 1/200\n",
      "4000/4000 [==============================] - 1s 341us/step - loss: 13.1881 - output_0_loss: 2.6374 - output_1_loss: 2.6306 - output_2_loss: 2.6425 - output_3_loss: 2.6458 - output_4_loss: 2.6317 - output_0_acc: 0.1438 - output_1_acc: 0.1390 - output_2_acc: 0.1408 - output_3_acc: 0.1397 - output_4_acc: 0.1490 - val_loss: 11.7739 - val_output_0_loss: 2.3508 - val_output_1_loss: 2.3466 - val_output_2_loss: 2.3722 - val_output_3_loss: 2.3417 - val_output_4_loss: 2.3627 - val_output_0_acc: 0.1880 - val_output_1_acc: 0.1722 - val_output_2_acc: 0.1737 - val_output_3_acc: 0.1868 - val_output_4_acc: 0.1720\n",
      "Epoch 2/200\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 11.0172 - output_0_loss: 2.2014 - output_1_loss: 2.2061 - output_2_loss: 2.2083 - output_3_loss: 2.2110 - output_4_loss: 2.1903 - output_0_acc: 0.2245 - output_1_acc: 0.2102 - output_2_acc: 0.2142 - output_3_acc: 0.2093 - output_4_acc: 0.2198 - val_loss: 10.6746 - val_output_0_loss: 2.1230 - val_output_1_loss: 2.1451 - val_output_2_loss: 2.1326 - val_output_3_loss: 2.1587 - val_output_4_loss: 2.1151 - val_output_0_acc: 0.2158 - val_output_1_acc: 0.2137 - val_output_2_acc: 0.2157 - val_output_3_acc: 0.2123 - val_output_4_acc: 0.2220\n",
      "Epoch 3/200\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 10.1447 - output_0_loss: 2.0223 - output_1_loss: 2.0348 - output_2_loss: 2.0366 - output_3_loss: 2.0369 - output_4_loss: 2.0141 - output_0_acc: 0.2642 - output_1_acc: 0.2485 - output_2_acc: 0.2420 - output_3_acc: 0.2442 - output_4_acc: 0.2595 - val_loss: 9.9794 - val_output_0_loss: 2.0168 - val_output_1_loss: 1.9941 - val_output_2_loss: 1.9901 - val_output_3_loss: 1.9839 - val_output_4_loss: 1.9945 - val_output_0_acc: 0.2408 - val_output_1_acc: 0.2467 - val_output_2_acc: 0.2593 - val_output_3_acc: 0.2445 - val_output_4_acc: 0.2395\n",
      "Epoch 4/200\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 9.5551 - output_0_loss: 1.9083 - output_1_loss: 1.9260 - output_2_loss: 1.9085 - output_3_loss: 1.9152 - output_4_loss: 1.8971 - output_0_acc: 0.2830 - output_1_acc: 0.2700 - output_2_acc: 0.2883 - output_3_acc: 0.2767 - output_4_acc: 0.2830 - val_loss: 9.5679 - val_output_0_loss: 1.9372 - val_output_1_loss: 1.8968 - val_output_2_loss: 1.9127 - val_output_3_loss: 1.9376 - val_output_4_loss: 1.8837 - val_output_0_acc: 0.2438 - val_output_1_acc: 0.2595 - val_output_2_acc: 0.2568 - val_output_3_acc: 0.2698 - val_output_4_acc: 0.2802\n",
      "Epoch 5/200\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 9.0907 - output_0_loss: 1.8222 - output_1_loss: 1.8300 - output_2_loss: 1.8177 - output_3_loss: 1.8229 - output_4_loss: 1.7978 - output_0_acc: 0.3088 - output_1_acc: 0.3017 - output_2_acc: 0.3095 - output_3_acc: 0.3010 - output_4_acc: 0.3230 - val_loss: 9.1703 - val_output_0_loss: 1.8181 - val_output_1_loss: 1.8288 - val_output_2_loss: 1.8941 - val_output_3_loss: 1.7993 - val_output_4_loss: 1.8300 - val_output_0_acc: 0.2942 - val_output_1_acc: 0.2728 - val_output_2_acc: 0.2607 - val_output_3_acc: 0.2905 - val_output_4_acc: 0.2843\n",
      "Epoch 6/200\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 8.6595 - output_0_loss: 1.7203 - output_1_loss: 1.7490 - output_2_loss: 1.7375 - output_3_loss: 1.7334 - output_4_loss: 1.7192 - output_0_acc: 0.3392 - output_1_acc: 0.3188 - output_2_acc: 0.3280 - output_3_acc: 0.3340 - output_4_acc: 0.3402 - val_loss: 8.8132 - val_output_0_loss: 1.7986 - val_output_1_loss: 1.7783 - val_output_2_loss: 1.7640 - val_output_3_loss: 1.7330 - val_output_4_loss: 1.7392 - val_output_0_acc: 0.2928 - val_output_1_acc: 0.3260 - val_output_2_acc: 0.3070 - val_output_3_acc: 0.3267 - val_output_4_acc: 0.3145\n",
      "Epoch 7/200\n",
      "4000/4000 [==============================] - 1s 160us/step - loss: 8.3267 - output_0_loss: 1.6583 - output_1_loss: 1.6799 - output_2_loss: 1.6621 - output_3_loss: 1.6674 - output_4_loss: 1.6591 - output_0_acc: 0.3550 - output_1_acc: 0.3485 - output_2_acc: 0.3415 - output_3_acc: 0.3525 - output_4_acc: 0.3460 - val_loss: 8.5341 - val_output_0_loss: 1.6802 - val_output_1_loss: 1.7029 - val_output_2_loss: 1.6884 - val_output_3_loss: 1.7005 - val_output_4_loss: 1.7623 - val_output_0_acc: 0.3263 - val_output_1_acc: 0.3223 - val_output_2_acc: 0.3165 - val_output_3_acc: 0.3058 - val_output_4_acc: 0.3267\n",
      "Epoch 8/200\n",
      "4000/4000 [==============================] - 1s 162us/step - loss: 7.9822 - output_0_loss: 1.5928 - output_1_loss: 1.6156 - output_2_loss: 1.5955 - output_3_loss: 1.5974 - output_4_loss: 1.5810 - output_0_acc: 0.3832 - output_1_acc: 0.3623 - output_2_acc: 0.3695 - output_3_acc: 0.3728 - output_4_acc: 0.3832 - val_loss: 8.1554 - val_output_0_loss: 1.6856 - val_output_1_loss: 1.6192 - val_output_2_loss: 1.5576 - val_output_3_loss: 1.6494 - val_output_4_loss: 1.6437 - val_output_0_acc: 0.3225 - val_output_1_acc: 0.3583 - val_output_2_acc: 0.3825 - val_output_3_acc: 0.3260 - val_output_4_acc: 0.3588\n",
      "Epoch 9/200\n",
      "4000/4000 [==============================] - 1s 169us/step - loss: 7.6968 - output_0_loss: 1.5393 - output_1_loss: 1.5603 - output_2_loss: 1.5354 - output_3_loss: 1.5374 - output_4_loss: 1.5244 - output_0_acc: 0.4022 - output_1_acc: 0.3815 - output_2_acc: 0.3955 - output_3_acc: 0.3900 - output_4_acc: 0.3942 - val_loss: 7.9822 - val_output_0_loss: 1.5970 - val_output_1_loss: 1.5764 - val_output_2_loss: 1.6297 - val_output_3_loss: 1.6300 - val_output_4_loss: 1.5490 - val_output_0_acc: 0.3735 - val_output_1_acc: 0.3772 - val_output_2_acc: 0.3327 - val_output_3_acc: 0.3495 - val_output_4_acc: 0.3937\n",
      "Epoch 10/200\n",
      "4000/4000 [==============================] - 1s 166us/step - loss: 7.4401 - output_0_loss: 1.4873 - output_1_loss: 1.5055 - output_2_loss: 1.4710 - output_3_loss: 1.4962 - output_4_loss: 1.4801 - output_0_acc: 0.4150 - output_1_acc: 0.3972 - output_2_acc: 0.4312 - output_3_acc: 0.4108 - output_4_acc: 0.4160 - val_loss: 7.7654 - val_output_0_loss: 1.5389 - val_output_1_loss: 1.5070 - val_output_2_loss: 1.5630 - val_output_3_loss: 1.5511 - val_output_4_loss: 1.6054 - val_output_0_acc: 0.3635 - val_output_1_acc: 0.4015 - val_output_2_acc: 0.3645 - val_output_3_acc: 0.3790 - val_output_4_acc: 0.3612\n",
      "Epoch 11/200\n",
      "4000/4000 [==============================] - 1s 177us/step - loss: 7.1842 - output_0_loss: 1.4271 - output_1_loss: 1.4560 - output_2_loss: 1.4360 - output_3_loss: 1.4379 - output_4_loss: 1.4272 - output_0_acc: 0.4368 - output_1_acc: 0.4163 - output_2_acc: 0.4378 - output_3_acc: 0.4365 - output_4_acc: 0.4267 - val_loss: 7.5532 - val_output_0_loss: 1.4726 - val_output_1_loss: 1.5377 - val_output_2_loss: 1.5122 - val_output_3_loss: 1.5288 - val_output_4_loss: 1.5019 - val_output_0_acc: 0.3883 - val_output_1_acc: 0.3585 - val_output_2_acc: 0.3850 - val_output_3_acc: 0.3733 - val_output_4_acc: 0.3997\n",
      "Epoch 12/200\n",
      "4000/4000 [==============================] - 1s 165us/step - loss: 6.9615 - output_0_loss: 1.3912 - output_1_loss: 1.4129 - output_2_loss: 1.3940 - output_3_loss: 1.3944 - output_4_loss: 1.3690 - output_0_acc: 0.4465 - output_1_acc: 0.4365 - output_2_acc: 0.4515 - output_3_acc: 0.4462 - output_4_acc: 0.4557 - val_loss: 7.3401 - val_output_0_loss: 1.4685 - val_output_1_loss: 1.4361 - val_output_2_loss: 1.5056 - val_output_3_loss: 1.4428 - val_output_4_loss: 1.4872 - val_output_0_acc: 0.4033 - val_output_1_acc: 0.4505 - val_output_2_acc: 0.3750 - val_output_3_acc: 0.3953 - val_output_4_acc: 0.3793\n",
      "Epoch 13/200\n",
      "4000/4000 [==============================] - 1s 164us/step - loss: 6.7411 - output_0_loss: 1.3347 - output_1_loss: 1.3667 - output_2_loss: 1.3502 - output_3_loss: 1.3533 - output_4_loss: 1.3362 - output_0_acc: 0.4770 - output_1_acc: 0.4520 - output_2_acc: 0.4632 - output_3_acc: 0.4625 - output_4_acc: 0.4738 - val_loss: 7.1142 - val_output_0_loss: 1.4732 - val_output_1_loss: 1.4464 - val_output_2_loss: 1.3640 - val_output_3_loss: 1.3822 - val_output_4_loss: 1.4484 - val_output_0_acc: 0.3837 - val_output_1_acc: 0.4135 - val_output_2_acc: 0.4565 - val_output_3_acc: 0.4415 - val_output_4_acc: 0.4142\n",
      "Epoch 14/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 162us/step - loss: 6.5364 - output_0_loss: 1.3047 - output_1_loss: 1.3204 - output_2_loss: 1.3039 - output_3_loss: 1.3134 - output_4_loss: 1.2940 - output_0_acc: 0.4768 - output_1_acc: 0.4850 - output_2_acc: 0.4778 - output_3_acc: 0.4793 - output_4_acc: 0.4847 - val_loss: 6.9679 - val_output_0_loss: 1.4419 - val_output_1_loss: 1.4042 - val_output_2_loss: 1.4371 - val_output_3_loss: 1.3242 - val_output_4_loss: 1.3606 - val_output_0_acc: 0.4267 - val_output_1_acc: 0.4197 - val_output_2_acc: 0.4210 - val_output_3_acc: 0.4737 - val_output_4_acc: 0.4422\n",
      "Epoch 15/200\n",
      "4000/4000 [==============================] - 1s 175us/step - loss: 6.3527 - output_0_loss: 1.2722 - output_1_loss: 1.2857 - output_2_loss: 1.2730 - output_3_loss: 1.2668 - output_4_loss: 1.2550 - output_0_acc: 0.4903 - output_1_acc: 0.4840 - output_2_acc: 0.4873 - output_3_acc: 0.4982 - output_4_acc: 0.5010 - val_loss: 6.8221 - val_output_0_loss: 1.4683 - val_output_1_loss: 1.3773 - val_output_2_loss: 1.3582 - val_output_3_loss: 1.2996 - val_output_4_loss: 1.3187 - val_output_0_acc: 0.4448 - val_output_1_acc: 0.4313 - val_output_2_acc: 0.4605 - val_output_3_acc: 0.4767 - val_output_4_acc: 0.4438\n",
      "Epoch 16/200\n",
      "4000/4000 [==============================] - 1s 170us/step - loss: 6.1924 - output_0_loss: 1.2399 - output_1_loss: 1.2582 - output_2_loss: 1.2314 - output_3_loss: 1.2406 - output_4_loss: 1.2223 - output_0_acc: 0.5067 - output_1_acc: 0.4988 - output_2_acc: 0.5065 - output_3_acc: 0.5135 - output_4_acc: 0.5190 - val_loss: 6.5932 - val_output_0_loss: 1.2500 - val_output_1_loss: 1.3540 - val_output_2_loss: 1.3713 - val_output_3_loss: 1.2643 - val_output_4_loss: 1.3535 - val_output_0_acc: 0.5047 - val_output_1_acc: 0.4638 - val_output_2_acc: 0.4267 - val_output_3_acc: 0.4842 - val_output_4_acc: 0.4648\n",
      "Epoch 17/200\n",
      "4000/4000 [==============================] - 1s 173us/step - loss: 6.0228 - output_0_loss: 1.1991 - output_1_loss: 1.2256 - output_2_loss: 1.1996 - output_3_loss: 1.2034 - output_4_loss: 1.1951 - output_0_acc: 0.5270 - output_1_acc: 0.5035 - output_2_acc: 0.5265 - output_3_acc: 0.5298 - output_4_acc: 0.5252 - val_loss: 6.6047 - val_output_0_loss: 1.4005 - val_output_1_loss: 1.3032 - val_output_2_loss: 1.3973 - val_output_3_loss: 1.2497 - val_output_4_loss: 1.2539 - val_output_0_acc: 0.4393 - val_output_1_acc: 0.4592 - val_output_2_acc: 0.4220 - val_output_3_acc: 0.5007 - val_output_4_acc: 0.4583\n",
      "Epoch 18/200\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 5.8550 - output_0_loss: 1.1719 - output_1_loss: 1.1866 - output_2_loss: 1.1647 - output_3_loss: 1.1715 - output_4_loss: 1.1603 - output_0_acc: 0.5298 - output_1_acc: 0.5275 - output_2_acc: 0.5335 - output_3_acc: 0.5367 - output_4_acc: 0.5333 - val_loss: 6.3743 - val_output_0_loss: 1.2539 - val_output_1_loss: 1.3202 - val_output_2_loss: 1.2718 - val_output_3_loss: 1.3160 - val_output_4_loss: 1.2125 - val_output_0_acc: 0.4992 - val_output_1_acc: 0.4687 - val_output_2_acc: 0.4825 - val_output_3_acc: 0.4722 - val_output_4_acc: 0.5132\n",
      "Epoch 19/200\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 5.7058 - output_0_loss: 1.1321 - output_1_loss: 1.1493 - output_2_loss: 1.1395 - output_3_loss: 1.1493 - output_4_loss: 1.1356 - output_0_acc: 0.5635 - output_1_acc: 0.5487 - output_2_acc: 0.5470 - output_3_acc: 0.5345 - output_4_acc: 0.5505 - val_loss: 6.0244 - val_output_0_loss: 1.1712 - val_output_1_loss: 1.2221 - val_output_2_loss: 1.1969 - val_output_3_loss: 1.2357 - val_output_4_loss: 1.1985 - val_output_0_acc: 0.5308 - val_output_1_acc: 0.5090 - val_output_2_acc: 0.5283 - val_output_3_acc: 0.4847 - val_output_4_acc: 0.5183\n",
      "Epoch 20/200\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 5.5692 - output_0_loss: 1.1170 - output_1_loss: 1.1280 - output_2_loss: 1.1064 - output_3_loss: 1.1137 - output_4_loss: 1.1041 - output_0_acc: 0.5523 - output_1_acc: 0.5480 - output_2_acc: 0.5590 - output_3_acc: 0.5530 - output_4_acc: 0.5533 - val_loss: 6.0317 - val_output_0_loss: 1.1908 - val_output_1_loss: 1.1992 - val_output_2_loss: 1.2793 - val_output_3_loss: 1.1982 - val_output_4_loss: 1.1643 - val_output_0_acc: 0.5180 - val_output_1_acc: 0.5112 - val_output_2_acc: 0.4663 - val_output_3_acc: 0.5077 - val_output_4_acc: 0.5213\n",
      "Epoch 21/200\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 5.4580 - output_0_loss: 1.0879 - output_1_loss: 1.1103 - output_2_loss: 1.0866 - output_3_loss: 1.0916 - output_4_loss: 1.0816 - output_0_acc: 0.5640 - output_1_acc: 0.5530 - output_2_acc: 0.5647 - output_3_acc: 0.5640 - output_4_acc: 0.5710 - val_loss: 5.9934 - val_output_0_loss: 1.1761 - val_output_1_loss: 1.1879 - val_output_2_loss: 1.2022 - val_output_3_loss: 1.2046 - val_output_4_loss: 1.2227 - val_output_0_acc: 0.5408 - val_output_1_acc: 0.5075 - val_output_2_acc: 0.4837 - val_output_3_acc: 0.4918 - val_output_4_acc: 0.4650\n",
      "Epoch 22/200\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 5.2921 - output_0_loss: 1.0586 - output_1_loss: 1.0815 - output_2_loss: 1.0477 - output_3_loss: 1.0576 - output_4_loss: 1.0467 - output_0_acc: 0.5885 - output_1_acc: 0.5720 - output_2_acc: 0.5895 - output_3_acc: 0.5803 - output_4_acc: 0.5850 - val_loss: 5.7767 - val_output_0_loss: 1.2078 - val_output_1_loss: 1.1619 - val_output_2_loss: 1.0955 - val_output_3_loss: 1.1482 - val_output_4_loss: 1.1634 - val_output_0_acc: 0.4853 - val_output_1_acc: 0.5055 - val_output_2_acc: 0.5553 - val_output_3_acc: 0.5247 - val_output_4_acc: 0.5203\n",
      "Epoch 23/200\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 5.2049 - output_0_loss: 1.0316 - output_1_loss: 1.0631 - output_2_loss: 1.0359 - output_3_loss: 1.0405 - output_4_loss: 1.0338 - output_0_acc: 0.5880 - output_1_acc: 0.5725 - output_2_acc: 0.5865 - output_3_acc: 0.5952 - output_4_acc: 0.5893 - val_loss: 5.8161 - val_output_0_loss: 1.0999 - val_output_1_loss: 1.1598 - val_output_2_loss: 1.2265 - val_output_3_loss: 1.1794 - val_output_4_loss: 1.1505 - val_output_0_acc: 0.5493 - val_output_1_acc: 0.5277 - val_output_2_acc: 0.5048 - val_output_3_acc: 0.4950 - val_output_4_acc: 0.5135\n",
      "Epoch 24/200\n",
      "4000/4000 [==============================] - 1s 173us/step - loss: 5.0537 - output_0_loss: 1.0055 - output_1_loss: 1.0330 - output_2_loss: 1.0047 - output_3_loss: 1.0146 - output_4_loss: 0.9959 - output_0_acc: 0.6020 - output_1_acc: 0.5883 - output_2_acc: 0.6033 - output_3_acc: 0.5958 - output_4_acc: 0.6120 - val_loss: 5.6674 - val_output_0_loss: 1.1370 - val_output_1_loss: 1.1894 - val_output_2_loss: 1.1045 - val_output_3_loss: 1.1094 - val_output_4_loss: 1.1270 - val_output_0_acc: 0.5420 - val_output_1_acc: 0.5140 - val_output_2_acc: 0.5348 - val_output_3_acc: 0.5580 - val_output_4_acc: 0.5270\n",
      "Epoch 25/200\n",
      "4000/4000 [==============================] - 1s 177us/step - loss: 4.9656 - output_0_loss: 0.9880 - output_1_loss: 1.0109 - output_2_loss: 0.9837 - output_3_loss: 0.9992 - output_4_loss: 0.9838 - output_0_acc: 0.6148 - output_1_acc: 0.5932 - output_2_acc: 0.6178 - output_3_acc: 0.6025 - output_4_acc: 0.6098 - val_loss: 5.4492 - val_output_0_loss: 1.0675 - val_output_1_loss: 1.1017 - val_output_2_loss: 1.1158 - val_output_3_loss: 1.0902 - val_output_4_loss: 1.0740 - val_output_0_acc: 0.5765 - val_output_1_acc: 0.5393 - val_output_2_acc: 0.5433 - val_output_3_acc: 0.5325 - val_output_4_acc: 0.5518\n",
      "Epoch 26/200\n",
      "4000/4000 [==============================] - 1s 165us/step - loss: 4.8478 - output_0_loss: 0.9667 - output_1_loss: 0.9911 - output_2_loss: 0.9577 - output_3_loss: 0.9743 - output_4_loss: 0.9580 - output_0_acc: 0.6162 - output_1_acc: 0.6065 - output_2_acc: 0.6285 - output_3_acc: 0.6120 - output_4_acc: 0.6162 - val_loss: 5.3908 - val_output_0_loss: 1.0939 - val_output_1_loss: 1.0495 - val_output_2_loss: 1.0610 - val_output_3_loss: 1.0923 - val_output_4_loss: 1.0941 - val_output_0_acc: 0.5608 - val_output_1_acc: 0.5752 - val_output_2_acc: 0.5675 - val_output_3_acc: 0.5517 - val_output_4_acc: 0.5733\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 161us/step - loss: 4.7407 - output_0_loss: 0.9441 - output_1_loss: 0.9657 - output_2_loss: 0.9423 - output_3_loss: 0.9438 - output_4_loss: 0.9449 - output_0_acc: 0.6275 - output_1_acc: 0.6145 - output_2_acc: 0.6280 - output_3_acc: 0.6342 - output_4_acc: 0.6268 - val_loss: 5.2696 - val_output_0_loss: 1.0702 - val_output_1_loss: 1.0289 - val_output_2_loss: 1.0706 - val_output_3_loss: 1.0243 - val_output_4_loss: 1.0755 - val_output_0_acc: 0.5688 - val_output_1_acc: 0.6003 - val_output_2_acc: 0.5542 - val_output_3_acc: 0.5728 - val_output_4_acc: 0.5623\n",
      "Epoch 28/200\n",
      "4000/4000 [==============================] - 1s 164us/step - loss: 4.6139 - output_0_loss: 0.9198 - output_1_loss: 0.9439 - output_2_loss: 0.9147 - output_3_loss: 0.9218 - output_4_loss: 0.9138 - output_0_acc: 0.6370 - output_1_acc: 0.6255 - output_2_acc: 0.6390 - output_3_acc: 0.6445 - output_4_acc: 0.6470 - val_loss: 5.2352 - val_output_0_loss: 1.0568 - val_output_1_loss: 1.0556 - val_output_2_loss: 1.0388 - val_output_3_loss: 1.0573 - val_output_4_loss: 1.0268 - val_output_0_acc: 0.5633 - val_output_1_acc: 0.5653 - val_output_2_acc: 0.5702 - val_output_3_acc: 0.5362 - val_output_4_acc: 0.5853\n",
      "Epoch 29/200\n",
      "4000/4000 [==============================] - 1s 166us/step - loss: 4.5419 - output_0_loss: 0.9123 - output_1_loss: 0.9276 - output_2_loss: 0.9037 - output_3_loss: 0.9050 - output_4_loss: 0.8932 - output_0_acc: 0.6492 - output_1_acc: 0.6355 - output_2_acc: 0.6462 - output_3_acc: 0.6482 - output_4_acc: 0.6518 - val_loss: 5.1354 - val_output_0_loss: 1.0232 - val_output_1_loss: 1.0001 - val_output_2_loss: 1.0474 - val_output_3_loss: 1.0656 - val_output_4_loss: 0.9991 - val_output_0_acc: 0.5367 - val_output_1_acc: 0.6123 - val_output_2_acc: 0.5585 - val_output_3_acc: 0.5518 - val_output_4_acc: 0.5668\n",
      "Epoch 30/200\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 4.4303 - output_0_loss: 0.8881 - output_1_loss: 0.9036 - output_2_loss: 0.8859 - output_3_loss: 0.8873 - output_4_loss: 0.8654 - output_0_acc: 0.6485 - output_1_acc: 0.6482 - output_2_acc: 0.6568 - output_3_acc: 0.6515 - output_4_acc: 0.6610 - val_loss: 4.8040 - val_output_0_loss: 0.9366 - val_output_1_loss: 0.9997 - val_output_2_loss: 0.9564 - val_output_3_loss: 0.9190 - val_output_4_loss: 0.9923 - val_output_0_acc: 0.6318 - val_output_1_acc: 0.5933 - val_output_2_acc: 0.6103 - val_output_3_acc: 0.6705 - val_output_4_acc: 0.5793\n",
      "Epoch 31/200\n",
      "4000/4000 [==============================] - 1s 166us/step - loss: 4.3351 - output_0_loss: 0.8644 - output_1_loss: 0.8899 - output_2_loss: 0.8556 - output_3_loss: 0.8730 - output_4_loss: 0.8522 - output_0_acc: 0.6718 - output_1_acc: 0.6548 - output_2_acc: 0.6680 - output_3_acc: 0.6530 - output_4_acc: 0.6700 - val_loss: 4.8986 - val_output_0_loss: 1.0000 - val_output_1_loss: 0.9772 - val_output_2_loss: 0.9526 - val_output_3_loss: 0.9062 - val_output_4_loss: 1.0626 - val_output_0_acc: 0.5758 - val_output_1_acc: 0.5895 - val_output_2_acc: 0.6157 - val_output_3_acc: 0.6398 - val_output_4_acc: 0.5537\n",
      "Epoch 32/200\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 4.2476 - output_0_loss: 0.8513 - output_1_loss: 0.8600 - output_2_loss: 0.8483 - output_3_loss: 0.8456 - output_4_loss: 0.8423 - output_0_acc: 0.6667 - output_1_acc: 0.6703 - output_2_acc: 0.6695 - output_3_acc: 0.6665 - output_4_acc: 0.6753 - val_loss: 4.7627 - val_output_0_loss: 1.0025 - val_output_1_loss: 0.9464 - val_output_2_loss: 0.9112 - val_output_3_loss: 0.9471 - val_output_4_loss: 0.9554 - val_output_0_acc: 0.5972 - val_output_1_acc: 0.6217 - val_output_2_acc: 0.6405 - val_output_3_acc: 0.5987 - val_output_4_acc: 0.6395\n",
      "Epoch 33/200\n",
      "4000/4000 [==============================] - 1s 181us/step - loss: 4.1535 - output_0_loss: 0.8133 - output_1_loss: 0.8594 - output_2_loss: 0.8286 - output_3_loss: 0.8290 - output_4_loss: 0.8232 - output_0_acc: 0.6955 - output_1_acc: 0.6680 - output_2_acc: 0.6797 - output_3_acc: 0.6823 - output_4_acc: 0.6893 - val_loss: 4.9020 - val_output_0_loss: 1.0007 - val_output_1_loss: 0.9351 - val_output_2_loss: 0.9755 - val_output_3_loss: 0.9651 - val_output_4_loss: 1.0254 - val_output_0_acc: 0.6157 - val_output_1_acc: 0.6240 - val_output_2_acc: 0.5958 - val_output_3_acc: 0.6082 - val_output_4_acc: 0.5727\n",
      "Epoch 34/200\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 4.0875 - output_0_loss: 0.8184 - output_1_loss: 0.8285 - output_2_loss: 0.8195 - output_3_loss: 0.8124 - output_4_loss: 0.8086 - output_0_acc: 0.6937 - output_1_acc: 0.6825 - output_2_acc: 0.6810 - output_3_acc: 0.6945 - output_4_acc: 0.6910 - val_loss: 4.7392 - val_output_0_loss: 0.9661 - val_output_1_loss: 1.0244 - val_output_2_loss: 0.9035 - val_output_3_loss: 0.9186 - val_output_4_loss: 0.9266 - val_output_0_acc: 0.6205 - val_output_1_acc: 0.5828 - val_output_2_acc: 0.6380 - val_output_3_acc: 0.6045 - val_output_4_acc: 0.6255\n",
      "Epoch 35/200\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 3.9985 - output_0_loss: 0.8028 - output_1_loss: 0.8163 - output_2_loss: 0.7924 - output_3_loss: 0.7957 - output_4_loss: 0.7914 - output_0_acc: 0.6947 - output_1_acc: 0.6855 - output_2_acc: 0.6965 - output_3_acc: 0.7023 - output_4_acc: 0.7017 - val_loss: 4.6596 - val_output_0_loss: 0.9230 - val_output_1_loss: 0.9405 - val_output_2_loss: 0.8781 - val_output_3_loss: 0.9696 - val_output_4_loss: 0.9485 - val_output_0_acc: 0.6370 - val_output_1_acc: 0.6183 - val_output_2_acc: 0.6568 - val_output_3_acc: 0.5893 - val_output_4_acc: 0.6107\n",
      "Epoch 36/200\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 3.9392 - output_0_loss: 0.7855 - output_1_loss: 0.7974 - output_2_loss: 0.7822 - output_3_loss: 0.7926 - output_4_loss: 0.7814 - output_0_acc: 0.7025 - output_1_acc: 0.6935 - output_2_acc: 0.7043 - output_3_acc: 0.6950 - output_4_acc: 0.7013 - val_loss: 4.4502 - val_output_0_loss: 0.9155 - val_output_1_loss: 0.8998 - val_output_2_loss: 0.8504 - val_output_3_loss: 0.8838 - val_output_4_loss: 0.9007 - val_output_0_acc: 0.6242 - val_output_1_acc: 0.6290 - val_output_2_acc: 0.6592 - val_output_3_acc: 0.6443 - val_output_4_acc: 0.6500\n",
      "Epoch 37/200\n",
      "4000/4000 [==============================] - 1s 168us/step - loss: 3.8349 - output_0_loss: 0.7618 - output_1_loss: 0.7816 - output_2_loss: 0.7656 - output_3_loss: 0.7700 - output_4_loss: 0.7558 - output_0_acc: 0.7223 - output_1_acc: 0.7055 - output_2_acc: 0.7157 - output_3_acc: 0.7040 - output_4_acc: 0.7135 - val_loss: 4.4579 - val_output_0_loss: 0.8909 - val_output_1_loss: 0.9470 - val_output_2_loss: 0.8982 - val_output_3_loss: 0.8440 - val_output_4_loss: 0.8779 - val_output_0_acc: 0.6448 - val_output_1_acc: 0.6148 - val_output_2_acc: 0.6267 - val_output_3_acc: 0.6620 - val_output_4_acc: 0.6510\n",
      "Epoch 38/200\n",
      "4000/4000 [==============================] - 1s 164us/step - loss: 3.8022 - output_0_loss: 0.7589 - output_1_loss: 0.7720 - output_2_loss: 0.7624 - output_3_loss: 0.7557 - output_4_loss: 0.7532 - output_0_acc: 0.7137 - output_1_acc: 0.7092 - output_2_acc: 0.7075 - output_3_acc: 0.7152 - output_4_acc: 0.7175 - val_loss: 4.4245 - val_output_0_loss: 0.8817 - val_output_1_loss: 0.8862 - val_output_2_loss: 0.8716 - val_output_3_loss: 0.8382 - val_output_4_loss: 0.9469 - val_output_0_acc: 0.6363 - val_output_1_acc: 0.6555 - val_output_2_acc: 0.6482 - val_output_3_acc: 0.6650 - val_output_4_acc: 0.5880\n",
      "Epoch 39/200\n",
      "4000/4000 [==============================] - 1s 168us/step - loss: 3.7101 - output_0_loss: 0.7394 - output_1_loss: 0.7583 - output_2_loss: 0.7357 - output_3_loss: 0.7456 - output_4_loss: 0.7311 - output_0_acc: 0.7223 - output_1_acc: 0.7125 - output_2_acc: 0.7218 - output_3_acc: 0.7163 - output_4_acc: 0.7212 - val_loss: 4.2557 - val_output_0_loss: 0.8530 - val_output_1_loss: 0.8273 - val_output_2_loss: 0.8498 - val_output_3_loss: 0.8625 - val_output_4_loss: 0.8630 - val_output_0_acc: 0.6700 - val_output_1_acc: 0.6900 - val_output_2_acc: 0.6625 - val_output_3_acc: 0.6743 - val_output_4_acc: 0.6383\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 172us/step - loss: 3.6365 - output_0_loss: 0.7315 - output_1_loss: 0.7389 - output_2_loss: 0.7259 - output_3_loss: 0.7233 - output_4_loss: 0.7169 - output_0_acc: 0.7255 - output_1_acc: 0.7250 - output_2_acc: 0.7318 - output_3_acc: 0.7340 - output_4_acc: 0.7240 - val_loss: 4.1628 - val_output_0_loss: 0.8495 - val_output_1_loss: 0.8375 - val_output_2_loss: 0.8739 - val_output_3_loss: 0.7739 - val_output_4_loss: 0.8280 - val_output_0_acc: 0.6637 - val_output_1_acc: 0.6478 - val_output_2_acc: 0.6525 - val_output_3_acc: 0.7075 - val_output_4_acc: 0.6832\n",
      "Epoch 41/200\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 3.5764 - output_0_loss: 0.7106 - output_1_loss: 0.7292 - output_2_loss: 0.7108 - output_3_loss: 0.7160 - output_4_loss: 0.7098 - output_0_acc: 0.7385 - output_1_acc: 0.7268 - output_2_acc: 0.7390 - output_3_acc: 0.7358 - output_4_acc: 0.7380 - val_loss: 4.1831 - val_output_0_loss: 0.8230 - val_output_1_loss: 0.8489 - val_output_2_loss: 0.8145 - val_output_3_loss: 0.8708 - val_output_4_loss: 0.8259 - val_output_0_acc: 0.6883 - val_output_1_acc: 0.6855 - val_output_2_acc: 0.6855 - val_output_3_acc: 0.6340 - val_output_4_acc: 0.6868\n",
      "Epoch 42/200\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 3.4898 - output_0_loss: 0.6980 - output_1_loss: 0.7135 - output_2_loss: 0.6967 - output_3_loss: 0.6960 - output_4_loss: 0.6855 - output_0_acc: 0.7448 - output_1_acc: 0.7410 - output_2_acc: 0.7365 - output_3_acc: 0.7433 - output_4_acc: 0.7440 - val_loss: 4.2469 - val_output_0_loss: 0.8409 - val_output_1_loss: 0.8333 - val_output_2_loss: 0.9127 - val_output_3_loss: 0.8248 - val_output_4_loss: 0.8351 - val_output_0_acc: 0.6290 - val_output_1_acc: 0.6582 - val_output_2_acc: 0.6490 - val_output_3_acc: 0.6618 - val_output_4_acc: 0.6527\n",
      "Epoch 43/200\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 3.4514 - output_0_loss: 0.6818 - output_1_loss: 0.7140 - output_2_loss: 0.6875 - output_3_loss: 0.6857 - output_4_loss: 0.6825 - output_0_acc: 0.7505 - output_1_acc: 0.7385 - output_2_acc: 0.7370 - output_3_acc: 0.7493 - output_4_acc: 0.7490 - val_loss: 4.0155 - val_output_0_loss: 0.8257 - val_output_1_loss: 0.8162 - val_output_2_loss: 0.7915 - val_output_3_loss: 0.7594 - val_output_4_loss: 0.8227 - val_output_0_acc: 0.6528 - val_output_1_acc: 0.6778 - val_output_2_acc: 0.6697 - val_output_3_acc: 0.7117 - val_output_4_acc: 0.6547\n",
      "Epoch 44/200\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 3.3898 - output_0_loss: 0.6776 - output_1_loss: 0.6931 - output_2_loss: 0.6742 - output_3_loss: 0.6706 - output_4_loss: 0.6745 - output_0_acc: 0.7532 - output_1_acc: 0.7452 - output_2_acc: 0.7535 - output_3_acc: 0.7612 - output_4_acc: 0.7485 - val_loss: 3.8810 - val_output_0_loss: 0.7460 - val_output_1_loss: 0.8365 - val_output_2_loss: 0.8143 - val_output_3_loss: 0.7477 - val_output_4_loss: 0.7365 - val_output_0_acc: 0.7400 - val_output_1_acc: 0.6815 - val_output_2_acc: 0.6682 - val_output_3_acc: 0.7172 - val_output_4_acc: 0.7367\n",
      "Epoch 45/200\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 3.3142 - output_0_loss: 0.6570 - output_1_loss: 0.6830 - output_2_loss: 0.6599 - output_3_loss: 0.6589 - output_4_loss: 0.6554 - output_0_acc: 0.7642 - output_1_acc: 0.7482 - output_2_acc: 0.7635 - output_3_acc: 0.7630 - output_4_acc: 0.7640 - val_loss: 3.9591 - val_output_0_loss: 0.7781 - val_output_1_loss: 0.8266 - val_output_2_loss: 0.7968 - val_output_3_loss: 0.7658 - val_output_4_loss: 0.7918 - val_output_0_acc: 0.6955 - val_output_1_acc: 0.6822 - val_output_2_acc: 0.6680 - val_output_3_acc: 0.7062 - val_output_4_acc: 0.6967\n",
      "Epoch 46/200\n",
      "4000/4000 [==============================] - 1s 160us/step - loss: 3.2577 - output_0_loss: 0.6467 - output_1_loss: 0.6659 - output_2_loss: 0.6465 - output_3_loss: 0.6504 - output_4_loss: 0.6482 - output_0_acc: 0.7690 - output_1_acc: 0.7585 - output_2_acc: 0.7635 - output_3_acc: 0.7605 - output_4_acc: 0.7698 - val_loss: 4.0005 - val_output_0_loss: 0.7493 - val_output_1_loss: 0.9295 - val_output_2_loss: 0.7326 - val_output_3_loss: 0.7401 - val_output_4_loss: 0.8489 - val_output_0_acc: 0.7123 - val_output_1_acc: 0.6208 - val_output_2_acc: 0.7410 - val_output_3_acc: 0.6982 - val_output_4_acc: 0.6402\n",
      "Epoch 47/200\n",
      "4000/4000 [==============================] - 1s 165us/step - loss: 3.1912 - output_0_loss: 0.6390 - output_1_loss: 0.6604 - output_2_loss: 0.6279 - output_3_loss: 0.6354 - output_4_loss: 0.6285 - output_0_acc: 0.7725 - output_1_acc: 0.7585 - output_2_acc: 0.7802 - output_3_acc: 0.7700 - output_4_acc: 0.7762 - val_loss: 3.9916 - val_output_0_loss: 0.8037 - val_output_1_loss: 0.8648 - val_output_2_loss: 0.8379 - val_output_3_loss: 0.7650 - val_output_4_loss: 0.7202 - val_output_0_acc: 0.6773 - val_output_1_acc: 0.6455 - val_output_2_acc: 0.6307 - val_output_3_acc: 0.6975 - val_output_4_acc: 0.7233\n",
      "Epoch 48/200\n",
      "4000/4000 [==============================] - 1s 170us/step - loss: 3.1502 - output_0_loss: 0.6288 - output_1_loss: 0.6375 - output_2_loss: 0.6297 - output_3_loss: 0.6286 - output_4_loss: 0.6257 - output_0_acc: 0.7750 - output_1_acc: 0.7670 - output_2_acc: 0.7755 - output_3_acc: 0.7770 - output_4_acc: 0.7855 - val_loss: 3.9092 - val_output_0_loss: 0.7843 - val_output_1_loss: 0.8130 - val_output_2_loss: 0.8081 - val_output_3_loss: 0.7623 - val_output_4_loss: 0.7414 - val_output_0_acc: 0.6710 - val_output_1_acc: 0.6697 - val_output_2_acc: 0.6603 - val_output_3_acc: 0.7032 - val_output_4_acc: 0.6945\n",
      "Epoch 49/200\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 3.0707 - output_0_loss: 0.6166 - output_1_loss: 0.6319 - output_2_loss: 0.6111 - output_3_loss: 0.6063 - output_4_loss: 0.6048 - output_0_acc: 0.7802 - output_1_acc: 0.7635 - output_2_acc: 0.7790 - output_3_acc: 0.7840 - output_4_acc: 0.7895 - val_loss: 3.8500 - val_output_0_loss: 0.8035 - val_output_1_loss: 0.7451 - val_output_2_loss: 0.7346 - val_output_3_loss: 0.7675 - val_output_4_loss: 0.7992 - val_output_0_acc: 0.6833 - val_output_1_acc: 0.7068 - val_output_2_acc: 0.7268 - val_output_3_acc: 0.7030 - val_output_4_acc: 0.6632\n",
      "Epoch 50/200\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 3.0436 - output_0_loss: 0.6041 - output_1_loss: 0.6248 - output_2_loss: 0.6029 - output_3_loss: 0.6085 - output_4_loss: 0.6033 - output_0_acc: 0.7855 - output_1_acc: 0.7795 - output_2_acc: 0.7910 - output_3_acc: 0.7777 - output_4_acc: 0.7917 - val_loss: 3.5668 - val_output_0_loss: 0.7293 - val_output_1_loss: 0.6980 - val_output_2_loss: 0.6859 - val_output_3_loss: 0.6683 - val_output_4_loss: 0.7852 - val_output_0_acc: 0.7212 - val_output_1_acc: 0.7585 - val_output_2_acc: 0.7547 - val_output_3_acc: 0.7727 - val_output_4_acc: 0.6793\n",
      "Epoch 51/200\n",
      "4000/4000 [==============================] - 1s 165us/step - loss: 2.9856 - output_0_loss: 0.5941 - output_1_loss: 0.6114 - output_2_loss: 0.5957 - output_3_loss: 0.5900 - output_4_loss: 0.5943 - output_0_acc: 0.7893 - output_1_acc: 0.7830 - output_2_acc: 0.7887 - output_3_acc: 0.7910 - output_4_acc: 0.7947 - val_loss: 3.5883 - val_output_0_loss: 0.7794 - val_output_1_loss: 0.7284 - val_output_2_loss: 0.6943 - val_output_3_loss: 0.7153 - val_output_4_loss: 0.6710 - val_output_0_acc: 0.6730 - val_output_1_acc: 0.7118 - val_output_2_acc: 0.7505 - val_output_3_acc: 0.6985 - val_output_4_acc: 0.7630\n",
      "Epoch 52/200\n",
      "4000/4000 [==============================] - 1s 164us/step - loss: 2.9313 - output_0_loss: 0.5862 - output_1_loss: 0.5999 - output_2_loss: 0.5806 - output_3_loss: 0.5854 - output_4_loss: 0.5793 - output_0_acc: 0.7973 - output_1_acc: 0.7920 - output_2_acc: 0.8010 - output_3_acc: 0.7867 - output_4_acc: 0.8058 - val_loss: 3.7293 - val_output_0_loss: 0.7993 - val_output_1_loss: 0.7392 - val_output_2_loss: 0.7148 - val_output_3_loss: 0.7166 - val_output_4_loss: 0.7595 - val_output_0_acc: 0.6783 - val_output_1_acc: 0.6910 - val_output_2_acc: 0.7297 - val_output_3_acc: 0.7148 - val_output_4_acc: 0.7148\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 171us/step - loss: 2.8794 - output_0_loss: 0.5713 - output_1_loss: 0.5976 - output_2_loss: 0.5721 - output_3_loss: 0.5580 - output_4_loss: 0.5804 - output_0_acc: 0.8045 - output_1_acc: 0.7945 - output_2_acc: 0.7993 - output_3_acc: 0.8083 - output_4_acc: 0.7963 - val_loss: 3.7743 - val_output_0_loss: 0.7403 - val_output_1_loss: 0.7756 - val_output_2_loss: 0.7173 - val_output_3_loss: 0.8652 - val_output_4_loss: 0.6759 - val_output_0_acc: 0.7015 - val_output_1_acc: 0.6987 - val_output_2_acc: 0.7113 - val_output_3_acc: 0.6153 - val_output_4_acc: 0.7508\n",
      "Epoch 54/200\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 2.8393 - output_0_loss: 0.5631 - output_1_loss: 0.5842 - output_2_loss: 0.5628 - output_3_loss: 0.5737 - output_4_loss: 0.5556 - output_0_acc: 0.8060 - output_1_acc: 0.7977 - output_2_acc: 0.8053 - output_3_acc: 0.7940 - output_4_acc: 0.8150 - val_loss: 3.5624 - val_output_0_loss: 0.7406 - val_output_1_loss: 0.7351 - val_output_2_loss: 0.7743 - val_output_3_loss: 0.6773 - val_output_4_loss: 0.6352 - val_output_0_acc: 0.7100 - val_output_1_acc: 0.7145 - val_output_2_acc: 0.6888 - val_output_3_acc: 0.7390 - val_output_4_acc: 0.7882\n",
      "Epoch 55/200\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 2.7801 - output_0_loss: 0.5504 - output_1_loss: 0.5806 - output_2_loss: 0.5591 - output_3_loss: 0.5416 - output_4_loss: 0.5483 - output_0_acc: 0.8105 - output_1_acc: 0.7983 - output_2_acc: 0.8045 - output_3_acc: 0.8192 - output_4_acc: 0.8097 - val_loss: 3.4724 - val_output_0_loss: 0.6953 - val_output_1_loss: 0.7101 - val_output_2_loss: 0.6728 - val_output_3_loss: 0.6748 - val_output_4_loss: 0.7194 - val_output_0_acc: 0.7483 - val_output_1_acc: 0.7298 - val_output_2_acc: 0.7423 - val_output_3_acc: 0.7327 - val_output_4_acc: 0.7388\n",
      "Epoch 56/200\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 2.7289 - output_0_loss: 0.5474 - output_1_loss: 0.5650 - output_2_loss: 0.5448 - output_3_loss: 0.5348 - output_4_loss: 0.5369 - output_0_acc: 0.8123 - output_1_acc: 0.7987 - output_2_acc: 0.8157 - output_3_acc: 0.8180 - output_4_acc: 0.8143 - val_loss: 3.3738 - val_output_0_loss: 0.6483 - val_output_1_loss: 0.6948 - val_output_2_loss: 0.6684 - val_output_3_loss: 0.6710 - val_output_4_loss: 0.6912 - val_output_0_acc: 0.7795 - val_output_1_acc: 0.7393 - val_output_2_acc: 0.7517 - val_output_3_acc: 0.7457 - val_output_4_acc: 0.7557\n",
      "Epoch 57/200\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 2.6912 - output_0_loss: 0.5348 - output_1_loss: 0.5559 - output_2_loss: 0.5368 - output_3_loss: 0.5317 - output_4_loss: 0.5320 - output_0_acc: 0.8190 - output_1_acc: 0.8150 - output_2_acc: 0.8157 - output_3_acc: 0.8123 - output_4_acc: 0.8243 - val_loss: 3.4103 - val_output_0_loss: 0.6774 - val_output_1_loss: 0.6982 - val_output_2_loss: 0.6930 - val_output_3_loss: 0.6844 - val_output_4_loss: 0.6573 - val_output_0_acc: 0.7330 - val_output_1_acc: 0.7307 - val_output_2_acc: 0.7298 - val_output_3_acc: 0.7197 - val_output_4_acc: 0.7258\n",
      "Epoch 58/200\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 2.6459 - output_0_loss: 0.5249 - output_1_loss: 0.5481 - output_2_loss: 0.5297 - output_3_loss: 0.5172 - output_4_loss: 0.5260 - output_0_acc: 0.8227 - output_1_acc: 0.8100 - output_2_acc: 0.8170 - output_3_acc: 0.8250 - output_4_acc: 0.8220 - val_loss: 3.2560 - val_output_0_loss: 0.6502 - val_output_1_loss: 0.6849 - val_output_2_loss: 0.6327 - val_output_3_loss: 0.6609 - val_output_4_loss: 0.6273 - val_output_0_acc: 0.7613 - val_output_1_acc: 0.7417 - val_output_2_acc: 0.7548 - val_output_3_acc: 0.7527 - val_output_4_acc: 0.7685\n",
      "Epoch 59/200\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 2.5872 - output_0_loss: 0.5191 - output_1_loss: 0.5330 - output_2_loss: 0.5166 - output_3_loss: 0.5076 - output_4_loss: 0.5109 - output_0_acc: 0.8203 - output_1_acc: 0.8217 - output_2_acc: 0.8317 - output_3_acc: 0.8273 - output_4_acc: 0.8337 - val_loss: 3.3952 - val_output_0_loss: 0.6731 - val_output_1_loss: 0.6663 - val_output_2_loss: 0.6268 - val_output_3_loss: 0.6832 - val_output_4_loss: 0.7458 - val_output_0_acc: 0.7450 - val_output_1_acc: 0.7363 - val_output_2_acc: 0.7640 - val_output_3_acc: 0.7153 - val_output_4_acc: 0.6868\n",
      "Epoch 60/200\n",
      "4000/4000 [==============================] - 1s 165us/step - loss: 2.5614 - output_0_loss: 0.5062 - output_1_loss: 0.5383 - output_2_loss: 0.5128 - output_3_loss: 0.5028 - output_4_loss: 0.5014 - output_0_acc: 0.8293 - output_1_acc: 0.8170 - output_2_acc: 0.8297 - output_3_acc: 0.8375 - output_4_acc: 0.8303 - val_loss: 3.2217 - val_output_0_loss: 0.6139 - val_output_1_loss: 0.6452 - val_output_2_loss: 0.6625 - val_output_3_loss: 0.6416 - val_output_4_loss: 0.6584 - val_output_0_acc: 0.8025 - val_output_1_acc: 0.7728 - val_output_2_acc: 0.7357 - val_output_3_acc: 0.7512 - val_output_4_acc: 0.7372\n",
      "Epoch 61/200\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 2.5129 - output_0_loss: 0.4991 - output_1_loss: 0.5151 - output_2_loss: 0.4949 - output_3_loss: 0.5007 - output_4_loss: 0.5032 - output_0_acc: 0.8337 - output_1_acc: 0.8267 - output_2_acc: 0.8458 - output_3_acc: 0.8340 - output_4_acc: 0.8297 - val_loss: 3.1599 - val_output_0_loss: 0.6847 - val_output_1_loss: 0.6706 - val_output_2_loss: 0.6275 - val_output_3_loss: 0.6142 - val_output_4_loss: 0.5628 - val_output_0_acc: 0.7097 - val_output_1_acc: 0.7452 - val_output_2_acc: 0.7560 - val_output_3_acc: 0.7797 - val_output_4_acc: 0.8185\n",
      "Epoch 62/200\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 2.4620 - output_0_loss: 0.4983 - output_1_loss: 0.5119 - output_2_loss: 0.4867 - output_3_loss: 0.4810 - output_4_loss: 0.4841 - output_0_acc: 0.8397 - output_1_acc: 0.8305 - output_2_acc: 0.8455 - output_3_acc: 0.8423 - output_4_acc: 0.8460 - val_loss: 3.1291 - val_output_0_loss: 0.5817 - val_output_1_loss: 0.6578 - val_output_2_loss: 0.6526 - val_output_3_loss: 0.5421 - val_output_4_loss: 0.6949 - val_output_0_acc: 0.8012 - val_output_1_acc: 0.7627 - val_output_2_acc: 0.7510 - val_output_3_acc: 0.8460 - val_output_4_acc: 0.7045\n",
      "Epoch 63/200\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 2.4461 - output_0_loss: 0.4836 - output_1_loss: 0.5086 - output_2_loss: 0.4849 - output_3_loss: 0.4790 - output_4_loss: 0.4900 - output_0_acc: 0.8407 - output_1_acc: 0.8255 - output_2_acc: 0.8315 - output_3_acc: 0.8515 - output_4_acc: 0.8353 - val_loss: 3.1192 - val_output_0_loss: 0.6159 - val_output_1_loss: 0.6508 - val_output_2_loss: 0.5790 - val_output_3_loss: 0.6916 - val_output_4_loss: 0.5819 - val_output_0_acc: 0.7615 - val_output_1_acc: 0.7462 - val_output_2_acc: 0.7938 - val_output_3_acc: 0.6870 - val_output_4_acc: 0.7835\n",
      "Epoch 64/200\n",
      "4000/4000 [==============================] - 1s 166us/step - loss: 2.4022 - output_0_loss: 0.4786 - output_1_loss: 0.4940 - output_2_loss: 0.4797 - output_3_loss: 0.4764 - output_4_loss: 0.4735 - output_0_acc: 0.8423 - output_1_acc: 0.8380 - output_2_acc: 0.8445 - output_3_acc: 0.8432 - output_4_acc: 0.8470 - val_loss: 3.2712 - val_output_0_loss: 0.7097 - val_output_1_loss: 0.6571 - val_output_2_loss: 0.6389 - val_output_3_loss: 0.6239 - val_output_4_loss: 0.6416 - val_output_0_acc: 0.7072 - val_output_1_acc: 0.7498 - val_output_2_acc: 0.7440 - val_output_3_acc: 0.7455 - val_output_4_acc: 0.7323\n",
      "Epoch 65/200\n",
      "4000/4000 [==============================] - 1s 173us/step - loss: 2.3599 - output_0_loss: 0.4712 - output_1_loss: 0.4897 - output_2_loss: 0.4656 - output_3_loss: 0.4654 - output_4_loss: 0.4680 - output_0_acc: 0.8478 - output_1_acc: 0.8363 - output_2_acc: 0.8518 - output_3_acc: 0.8530 - output_4_acc: 0.8485 - val_loss: 3.2408 - val_output_0_loss: 0.6451 - val_output_1_loss: 0.6899 - val_output_2_loss: 0.7334 - val_output_3_loss: 0.6033 - val_output_4_loss: 0.5692 - val_output_0_acc: 0.7300 - val_output_1_acc: 0.7103 - val_output_2_acc: 0.7213 - val_output_3_acc: 0.7605 - val_output_4_acc: 0.8132\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 170us/step - loss: 2.3146 - output_0_loss: 0.4676 - output_1_loss: 0.4771 - output_2_loss: 0.4642 - output_3_loss: 0.4501 - output_4_loss: 0.4556 - output_0_acc: 0.8445 - output_1_acc: 0.8520 - output_2_acc: 0.8518 - output_3_acc: 0.8548 - output_4_acc: 0.8580 - val_loss: 3.0680 - val_output_0_loss: 0.5719 - val_output_1_loss: 0.6248 - val_output_2_loss: 0.5807 - val_output_3_loss: 0.6486 - val_output_4_loss: 0.6420 - val_output_0_acc: 0.8033 - val_output_1_acc: 0.7587 - val_output_2_acc: 0.7825 - val_output_3_acc: 0.7515 - val_output_4_acc: 0.7432\n",
      "Epoch 67/200\n",
      "4000/4000 [==============================] - 1s 166us/step - loss: 2.2732 - output_0_loss: 0.4541 - output_1_loss: 0.4718 - output_2_loss: 0.4576 - output_3_loss: 0.4483 - output_4_loss: 0.4415 - output_0_acc: 0.8568 - output_1_acc: 0.8505 - output_2_acc: 0.8570 - output_3_acc: 0.8565 - output_4_acc: 0.8640 - val_loss: 3.0119 - val_output_0_loss: 0.5786 - val_output_1_loss: 0.5735 - val_output_2_loss: 0.5255 - val_output_3_loss: 0.5879 - val_output_4_loss: 0.7464 - val_output_0_acc: 0.7775 - val_output_1_acc: 0.8110 - val_output_2_acc: 0.8302 - val_output_3_acc: 0.7665 - val_output_4_acc: 0.6772\n",
      "Epoch 68/200\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 2.2309 - output_0_loss: 0.4389 - output_1_loss: 0.4674 - output_2_loss: 0.4439 - output_3_loss: 0.4375 - output_4_loss: 0.4432 - output_0_acc: 0.8668 - output_1_acc: 0.8518 - output_2_acc: 0.8600 - output_3_acc: 0.8623 - output_4_acc: 0.8560 - val_loss: 2.8753 - val_output_0_loss: 0.5937 - val_output_1_loss: 0.6087 - val_output_2_loss: 0.5039 - val_output_3_loss: 0.5790 - val_output_4_loss: 0.5899 - val_output_0_acc: 0.7862 - val_output_1_acc: 0.7620 - val_output_2_acc: 0.8518 - val_output_3_acc: 0.7958 - val_output_4_acc: 0.7887\n",
      "Epoch 69/200\n",
      "4000/4000 [==============================] - 1s 173us/step - loss: 2.1855 - output_0_loss: 0.4363 - output_1_loss: 0.4486 - output_2_loss: 0.4365 - output_3_loss: 0.4272 - output_4_loss: 0.4368 - output_0_acc: 0.8582 - output_1_acc: 0.8662 - output_2_acc: 0.8578 - output_3_acc: 0.8658 - output_4_acc: 0.8658 - val_loss: 2.9121 - val_output_0_loss: 0.6330 - val_output_1_loss: 0.5883 - val_output_2_loss: 0.5598 - val_output_3_loss: 0.5696 - val_output_4_loss: 0.5614 - val_output_0_acc: 0.7583 - val_output_1_acc: 0.7925 - val_output_2_acc: 0.8038 - val_output_3_acc: 0.7830 - val_output_4_acc: 0.7995\n",
      "Epoch 70/200\n",
      "4000/4000 [==============================] - 1s 170us/step - loss: 2.1668 - output_0_loss: 0.4350 - output_1_loss: 0.4533 - output_2_loss: 0.4282 - output_3_loss: 0.4201 - output_4_loss: 0.4302 - output_0_acc: 0.8665 - output_1_acc: 0.8605 - output_2_acc: 0.8665 - output_3_acc: 0.8690 - output_4_acc: 0.8600 - val_loss: 2.8465 - val_output_0_loss: 0.5689 - val_output_1_loss: 0.6309 - val_output_2_loss: 0.5492 - val_output_3_loss: 0.5376 - val_output_4_loss: 0.5598 - val_output_0_acc: 0.7932 - val_output_1_acc: 0.7590 - val_output_2_acc: 0.8088 - val_output_3_acc: 0.8095 - val_output_4_acc: 0.7953\n",
      "Epoch 71/200\n",
      "4000/4000 [==============================] - 1s 163us/step - loss: 2.1187 - output_0_loss: 0.4248 - output_1_loss: 0.4417 - output_2_loss: 0.4160 - output_3_loss: 0.4155 - output_4_loss: 0.4207 - output_0_acc: 0.8675 - output_1_acc: 0.8538 - output_2_acc: 0.8743 - output_3_acc: 0.8755 - output_4_acc: 0.8710 - val_loss: 2.9316 - val_output_0_loss: 0.5695 - val_output_1_loss: 0.5863 - val_output_2_loss: 0.5677 - val_output_3_loss: 0.6512 - val_output_4_loss: 0.5568 - val_output_0_acc: 0.7878 - val_output_1_acc: 0.7855 - val_output_2_acc: 0.7753 - val_output_3_acc: 0.7093 - val_output_4_acc: 0.7897\n",
      "Epoch 72/200\n",
      "4000/4000 [==============================] - 1s 166us/step - loss: 2.1019 - output_0_loss: 0.4151 - output_1_loss: 0.4357 - output_2_loss: 0.4268 - output_3_loss: 0.4100 - output_4_loss: 0.4142 - output_0_acc: 0.8760 - output_1_acc: 0.8635 - output_2_acc: 0.8665 - output_3_acc: 0.8710 - output_4_acc: 0.8713 - val_loss: 2.6757 - val_output_0_loss: 0.5864 - val_output_1_loss: 0.5690 - val_output_2_loss: 0.5205 - val_output_3_loss: 0.4865 - val_output_4_loss: 0.5133 - val_output_0_acc: 0.7803 - val_output_1_acc: 0.7885 - val_output_2_acc: 0.8212 - val_output_3_acc: 0.8520 - val_output_4_acc: 0.8222\n",
      "Epoch 73/200\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 2.0393 - output_0_loss: 0.4063 - output_1_loss: 0.4275 - output_2_loss: 0.4041 - output_3_loss: 0.3967 - output_4_loss: 0.4047 - output_0_acc: 0.8775 - output_1_acc: 0.8650 - output_2_acc: 0.8805 - output_3_acc: 0.8868 - output_4_acc: 0.8743 - val_loss: 2.8431 - val_output_0_loss: 0.5663 - val_output_1_loss: 0.6214 - val_output_2_loss: 0.5557 - val_output_3_loss: 0.5457 - val_output_4_loss: 0.5540 - val_output_0_acc: 0.8115 - val_output_1_acc: 0.7503 - val_output_2_acc: 0.7903 - val_output_3_acc: 0.7865 - val_output_4_acc: 0.7848\n",
      "Epoch 74/200\n",
      "4000/4000 [==============================] - 1s 164us/step - loss: 2.0118 - output_0_loss: 0.4050 - output_1_loss: 0.4172 - output_2_loss: 0.3956 - output_3_loss: 0.3979 - output_4_loss: 0.3961 - output_0_acc: 0.8840 - output_1_acc: 0.8665 - output_2_acc: 0.8795 - output_3_acc: 0.8822 - output_4_acc: 0.8772 - val_loss: 2.7221 - val_output_0_loss: 0.5525 - val_output_1_loss: 0.5427 - val_output_2_loss: 0.5653 - val_output_3_loss: 0.5130 - val_output_4_loss: 0.5485 - val_output_0_acc: 0.8147 - val_output_1_acc: 0.8085 - val_output_2_acc: 0.7715 - val_output_3_acc: 0.8255 - val_output_4_acc: 0.8027\n",
      "Epoch 75/200\n",
      "4000/4000 [==============================] - 1s 168us/step - loss: 2.0008 - output_0_loss: 0.4011 - output_1_loss: 0.4154 - output_2_loss: 0.3967 - output_3_loss: 0.3903 - output_4_loss: 0.3974 - output_0_acc: 0.8738 - output_1_acc: 0.8728 - output_2_acc: 0.8802 - output_3_acc: 0.8870 - output_4_acc: 0.8825 - val_loss: 2.4880 - val_output_0_loss: 0.5167 - val_output_1_loss: 0.5346 - val_output_2_loss: 0.4656 - val_output_3_loss: 0.4710 - val_output_4_loss: 0.5001 - val_output_0_acc: 0.8170 - val_output_1_acc: 0.8043 - val_output_2_acc: 0.8525 - val_output_3_acc: 0.8580 - val_output_4_acc: 0.8247\n",
      "Epoch 76/200\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 1.9470 - output_0_loss: 0.3854 - output_1_loss: 0.4048 - output_2_loss: 0.3818 - output_3_loss: 0.3850 - output_4_loss: 0.3900 - output_0_acc: 0.8877 - output_1_acc: 0.8780 - output_2_acc: 0.8847 - output_3_acc: 0.8912 - output_4_acc: 0.8888 - val_loss: 2.6739 - val_output_0_loss: 0.5305 - val_output_1_loss: 0.5422 - val_output_2_loss: 0.5671 - val_output_3_loss: 0.4845 - val_output_4_loss: 0.5496 - val_output_0_acc: 0.8188 - val_output_1_acc: 0.8010 - val_output_2_acc: 0.8057 - val_output_3_acc: 0.8397 - val_output_4_acc: 0.7880\n",
      "Epoch 77/200\n",
      "4000/4000 [==============================] - 1s 184us/step - loss: 1.9125 - output_0_loss: 0.3844 - output_1_loss: 0.3957 - output_2_loss: 0.3759 - output_3_loss: 0.3779 - output_4_loss: 0.3786 - output_0_acc: 0.8838 - output_1_acc: 0.8820 - output_2_acc: 0.8910 - output_3_acc: 0.8932 - output_4_acc: 0.8858 - val_loss: 2.6481 - val_output_0_loss: 0.5244 - val_output_1_loss: 0.5893 - val_output_2_loss: 0.5341 - val_output_3_loss: 0.4915 - val_output_4_loss: 0.5089 - val_output_0_acc: 0.8115 - val_output_1_acc: 0.7647 - val_output_2_acc: 0.7960 - val_output_3_acc: 0.8273 - val_output_4_acc: 0.8350\n",
      "Epoch 78/200\n",
      "4000/4000 [==============================] - 1s 166us/step - loss: 1.8980 - output_0_loss: 0.3768 - output_1_loss: 0.3930 - output_2_loss: 0.3751 - output_3_loss: 0.3701 - output_4_loss: 0.3829 - output_0_acc: 0.8902 - output_1_acc: 0.8812 - output_2_acc: 0.8930 - output_3_acc: 0.8918 - output_4_acc: 0.8860 - val_loss: 2.6608 - val_output_0_loss: 0.5890 - val_output_1_loss: 0.5524 - val_output_2_loss: 0.5042 - val_output_3_loss: 0.5015 - val_output_4_loss: 0.5137 - val_output_0_acc: 0.7835 - val_output_1_acc: 0.7878 - val_output_2_acc: 0.8222 - val_output_3_acc: 0.8223 - val_output_4_acc: 0.8268\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 170us/step - loss: 1.8583 - output_0_loss: 0.3690 - output_1_loss: 0.3853 - output_2_loss: 0.3688 - output_3_loss: 0.3627 - output_4_loss: 0.3724 - output_0_acc: 0.8967 - output_1_acc: 0.8817 - output_2_acc: 0.8955 - output_3_acc: 0.8967 - output_4_acc: 0.8905 - val_loss: 2.5213 - val_output_0_loss: 0.4910 - val_output_1_loss: 0.5645 - val_output_2_loss: 0.4940 - val_output_3_loss: 0.4712 - val_output_4_loss: 0.5006 - val_output_0_acc: 0.8350 - val_output_1_acc: 0.7875 - val_output_2_acc: 0.8138 - val_output_3_acc: 0.8377 - val_output_4_acc: 0.8263\n",
      "Epoch 80/200\n",
      "4000/4000 [==============================] - 1s 162us/step - loss: 1.8265 - output_0_loss: 0.3589 - output_1_loss: 0.3860 - output_2_loss: 0.3610 - output_3_loss: 0.3557 - output_4_loss: 0.3648 - output_0_acc: 0.8942 - output_1_acc: 0.8860 - output_2_acc: 0.9000 - output_3_acc: 0.8922 - output_4_acc: 0.8892 - val_loss: 2.6847 - val_output_0_loss: 0.5893 - val_output_1_loss: 0.4975 - val_output_2_loss: 0.6133 - val_output_3_loss: 0.4639 - val_output_4_loss: 0.5207 - val_output_0_acc: 0.7568 - val_output_1_acc: 0.8332 - val_output_2_acc: 0.7302 - val_output_3_acc: 0.8490 - val_output_4_acc: 0.8057\n",
      "Epoch 81/200\n",
      "4000/4000 [==============================] - 1s 163us/step - loss: 1.7905 - output_0_loss: 0.3610 - output_1_loss: 0.3679 - output_2_loss: 0.3578 - output_3_loss: 0.3464 - output_4_loss: 0.3574 - output_0_acc: 0.9012 - output_1_acc: 0.8955 - output_2_acc: 0.8955 - output_3_acc: 0.9027 - output_4_acc: 0.8922 - val_loss: 2.5127 - val_output_0_loss: 0.4997 - val_output_1_loss: 0.5055 - val_output_2_loss: 0.5384 - val_output_3_loss: 0.5230 - val_output_4_loss: 0.4460 - val_output_0_acc: 0.8280 - val_output_1_acc: 0.8347 - val_output_2_acc: 0.7895 - val_output_3_acc: 0.8027 - val_output_4_acc: 0.8483\n",
      "Epoch 82/200\n",
      "4000/4000 [==============================] - 1s 169us/step - loss: 1.7644 - output_0_loss: 0.3469 - output_1_loss: 0.3737 - output_2_loss: 0.3481 - output_3_loss: 0.3437 - output_4_loss: 0.3520 - output_0_acc: 0.9040 - output_1_acc: 0.8948 - output_2_acc: 0.9040 - output_3_acc: 0.9012 - output_4_acc: 0.8935 - val_loss: 2.4432 - val_output_0_loss: 0.4942 - val_output_1_loss: 0.4763 - val_output_2_loss: 0.4896 - val_output_3_loss: 0.5054 - val_output_4_loss: 0.4776 - val_output_0_acc: 0.8313 - val_output_1_acc: 0.8472 - val_output_2_acc: 0.8265 - val_output_3_acc: 0.8340 - val_output_4_acc: 0.8330\n",
      "Epoch 83/200\n",
      "4000/4000 [==============================] - 1s 170us/step - loss: 1.7378 - output_0_loss: 0.3525 - output_1_loss: 0.3623 - output_2_loss: 0.3437 - output_3_loss: 0.3341 - output_4_loss: 0.3452 - output_0_acc: 0.8982 - output_1_acc: 0.8892 - output_2_acc: 0.9045 - output_3_acc: 0.9057 - output_4_acc: 0.8932 - val_loss: 2.4985 - val_output_0_loss: 0.5306 - val_output_1_loss: 0.4572 - val_output_2_loss: 0.5289 - val_output_3_loss: 0.4794 - val_output_4_loss: 0.5024 - val_output_0_acc: 0.8092 - val_output_1_acc: 0.8543 - val_output_2_acc: 0.8015 - val_output_3_acc: 0.8335 - val_output_4_acc: 0.8342\n",
      "Epoch 84/200\n",
      "4000/4000 [==============================] - 1s 165us/step - loss: 1.7285 - output_0_loss: 0.3425 - output_1_loss: 0.3599 - output_2_loss: 0.3465 - output_3_loss: 0.3391 - output_4_loss: 0.3405 - output_0_acc: 0.8995 - output_1_acc: 0.8962 - output_2_acc: 0.9038 - output_3_acc: 0.9095 - output_4_acc: 0.9040 - val_loss: 2.4068 - val_output_0_loss: 0.5058 - val_output_1_loss: 0.5651 - val_output_2_loss: 0.4216 - val_output_3_loss: 0.4302 - val_output_4_loss: 0.4842 - val_output_0_acc: 0.8088 - val_output_1_acc: 0.7742 - val_output_2_acc: 0.8737 - val_output_3_acc: 0.8682 - val_output_4_acc: 0.8293\n",
      "Epoch 85/200\n",
      "4000/4000 [==============================] - 1s 164us/step - loss: 1.6634 - output_0_loss: 0.3275 - output_1_loss: 0.3481 - output_2_loss: 0.3282 - output_3_loss: 0.3254 - output_4_loss: 0.3342 - output_0_acc: 0.9135 - output_1_acc: 0.8975 - output_2_acc: 0.9137 - output_3_acc: 0.9135 - output_4_acc: 0.9040 - val_loss: 2.2920 - val_output_0_loss: 0.4369 - val_output_1_loss: 0.5000 - val_output_2_loss: 0.4362 - val_output_3_loss: 0.4443 - val_output_4_loss: 0.4745 - val_output_0_acc: 0.8585 - val_output_1_acc: 0.8160 - val_output_2_acc: 0.8653 - val_output_3_acc: 0.8440 - val_output_4_acc: 0.8298\n",
      "Epoch 86/200\n",
      "4000/4000 [==============================] - 1s 165us/step - loss: 1.6478 - output_0_loss: 0.3252 - output_1_loss: 0.3467 - output_2_loss: 0.3288 - output_3_loss: 0.3198 - output_4_loss: 0.3273 - output_0_acc: 0.9120 - output_1_acc: 0.9022 - output_2_acc: 0.9093 - output_3_acc: 0.9087 - output_4_acc: 0.9105 - val_loss: 2.2418 - val_output_0_loss: 0.4383 - val_output_1_loss: 0.4718 - val_output_2_loss: 0.4276 - val_output_3_loss: 0.4587 - val_output_4_loss: 0.4453 - val_output_0_acc: 0.8485 - val_output_1_acc: 0.8405 - val_output_2_acc: 0.8773 - val_output_3_acc: 0.8377 - val_output_4_acc: 0.8555\n",
      "Epoch 87/200\n",
      "4000/4000 [==============================] - 1s 167us/step - loss: 1.6221 - output_0_loss: 0.3261 - output_1_loss: 0.3375 - output_2_loss: 0.3183 - output_3_loss: 0.3133 - output_4_loss: 0.3269 - output_0_acc: 0.9062 - output_1_acc: 0.9010 - output_2_acc: 0.9110 - output_3_acc: 0.9177 - output_4_acc: 0.9077 - val_loss: 2.2798 - val_output_0_loss: 0.4420 - val_output_1_loss: 0.4614 - val_output_2_loss: 0.4978 - val_output_3_loss: 0.4120 - val_output_4_loss: 0.4666 - val_output_0_acc: 0.8520 - val_output_1_acc: 0.8480 - val_output_2_acc: 0.8340 - val_output_3_acc: 0.8848 - val_output_4_acc: 0.8365\n",
      "Epoch 88/200\n",
      "4000/4000 [==============================] - 1s 168us/step - loss: 1.5965 - output_0_loss: 0.3157 - output_1_loss: 0.3375 - output_2_loss: 0.3148 - output_3_loss: 0.3116 - output_4_loss: 0.3168 - output_0_acc: 0.9145 - output_1_acc: 0.9025 - output_2_acc: 0.9145 - output_3_acc: 0.9160 - output_4_acc: 0.9125 - val_loss: 2.1682 - val_output_0_loss: 0.4445 - val_output_1_loss: 0.4375 - val_output_2_loss: 0.4517 - val_output_3_loss: 0.4485 - val_output_4_loss: 0.3860 - val_output_0_acc: 0.8520 - val_output_1_acc: 0.8647 - val_output_2_acc: 0.8400 - val_output_3_acc: 0.8423 - val_output_4_acc: 0.8962\n",
      "Epoch 89/200\n",
      "4000/4000 [==============================] - 1s 169us/step - loss: 1.5517 - output_0_loss: 0.3117 - output_1_loss: 0.3243 - output_2_loss: 0.3053 - output_3_loss: 0.3016 - output_4_loss: 0.3088 - output_0_acc: 0.9173 - output_1_acc: 0.9098 - output_2_acc: 0.9210 - output_3_acc: 0.9235 - output_4_acc: 0.9115 - val_loss: 2.2863 - val_output_0_loss: 0.4659 - val_output_1_loss: 0.5098 - val_output_2_loss: 0.4633 - val_output_3_loss: 0.4160 - val_output_4_loss: 0.4313 - val_output_0_acc: 0.8345 - val_output_1_acc: 0.8152 - val_output_2_acc: 0.8407 - val_output_3_acc: 0.8690 - val_output_4_acc: 0.8590\n",
      "Epoch 90/200\n",
      "4000/4000 [==============================] - 1s 164us/step - loss: 1.5393 - output_0_loss: 0.2998 - output_1_loss: 0.3212 - output_2_loss: 0.3036 - output_3_loss: 0.3043 - output_4_loss: 0.3103 - output_0_acc: 0.9207 - output_1_acc: 0.9120 - output_2_acc: 0.9195 - output_3_acc: 0.9170 - output_4_acc: 0.9150 - val_loss: 2.2685 - val_output_0_loss: 0.4341 - val_output_1_loss: 0.5582 - val_output_2_loss: 0.4279 - val_output_3_loss: 0.4195 - val_output_4_loss: 0.4289 - val_output_0_acc: 0.8563 - val_output_1_acc: 0.7843 - val_output_2_acc: 0.8638 - val_output_3_acc: 0.8602 - val_output_4_acc: 0.8585\n",
      "Epoch 91/200\n",
      "4000/4000 [==============================] - 1s 166us/step - loss: 1.5146 - output_0_loss: 0.3039 - output_1_loss: 0.3232 - output_2_loss: 0.2966 - output_3_loss: 0.2940 - output_4_loss: 0.2968 - output_0_acc: 0.9227 - output_1_acc: 0.9060 - output_2_acc: 0.9233 - output_3_acc: 0.9230 - output_4_acc: 0.9180 - val_loss: 2.1764 - val_output_0_loss: 0.4551 - val_output_1_loss: 0.4188 - val_output_2_loss: 0.4026 - val_output_3_loss: 0.4794 - val_output_4_loss: 0.4205 - val_output_0_acc: 0.8340 - val_output_1_acc: 0.8690 - val_output_2_acc: 0.8722 - val_output_3_acc: 0.8102 - val_output_4_acc: 0.8633\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 166us/step - loss: 1.4949 - output_0_loss: 0.3000 - output_1_loss: 0.3158 - output_2_loss: 0.2897 - output_3_loss: 0.2929 - output_4_loss: 0.2966 - output_0_acc: 0.9167 - output_1_acc: 0.9077 - output_2_acc: 0.9290 - output_3_acc: 0.9207 - output_4_acc: 0.9213 - val_loss: 2.2638 - val_output_0_loss: 0.4462 - val_output_1_loss: 0.5101 - val_output_2_loss: 0.4049 - val_output_3_loss: 0.4022 - val_output_4_loss: 0.5004 - val_output_0_acc: 0.8425 - val_output_1_acc: 0.8052 - val_output_2_acc: 0.8767 - val_output_3_acc: 0.8697 - val_output_4_acc: 0.8088\n",
      "Epoch 93/200\n",
      "4000/4000 [==============================] - 1s 162us/step - loss: 1.4725 - output_0_loss: 0.2885 - output_1_loss: 0.3073 - output_2_loss: 0.2900 - output_3_loss: 0.2876 - output_4_loss: 0.2991 - output_0_acc: 0.9253 - output_1_acc: 0.9185 - output_2_acc: 0.9263 - output_3_acc: 0.9248 - output_4_acc: 0.9128 - val_loss: 2.0967 - val_output_0_loss: 0.4599 - val_output_1_loss: 0.4813 - val_output_2_loss: 0.4026 - val_output_3_loss: 0.3646 - val_output_4_loss: 0.3884 - val_output_0_acc: 0.8273 - val_output_1_acc: 0.8303 - val_output_2_acc: 0.8708 - val_output_3_acc: 0.9047 - val_output_4_acc: 0.8783\n",
      "Epoch 94/200\n",
      "4000/4000 [==============================] - 1s 162us/step - loss: 1.4298 - output_0_loss: 0.2804 - output_1_loss: 0.3030 - output_2_loss: 0.2854 - output_3_loss: 0.2785 - output_4_loss: 0.2826 - output_0_acc: 0.9275 - output_1_acc: 0.9155 - output_2_acc: 0.9267 - output_3_acc: 0.9287 - output_4_acc: 0.9225 - val_loss: 1.9606 - val_output_0_loss: 0.3933 - val_output_1_loss: 0.4021 - val_output_2_loss: 0.3638 - val_output_3_loss: 0.3828 - val_output_4_loss: 0.4187 - val_output_0_acc: 0.8797 - val_output_1_acc: 0.8792 - val_output_2_acc: 0.9075 - val_output_3_acc: 0.8883 - val_output_4_acc: 0.8753\n",
      "Epoch 95/200\n",
      "4000/4000 [==============================] - 1s 161us/step - loss: 1.4179 - output_0_loss: 0.2786 - output_1_loss: 0.3025 - output_2_loss: 0.2762 - output_3_loss: 0.2749 - output_4_loss: 0.2856 - output_0_acc: 0.9263 - output_1_acc: 0.9145 - output_2_acc: 0.9290 - output_3_acc: 0.9343 - output_4_acc: 0.9248 - val_loss: 2.1120 - val_output_0_loss: 0.4476 - val_output_1_loss: 0.4667 - val_output_2_loss: 0.4214 - val_output_3_loss: 0.3927 - val_output_4_loss: 0.3837 - val_output_0_acc: 0.8277 - val_output_1_acc: 0.8330 - val_output_2_acc: 0.8645 - val_output_3_acc: 0.8747 - val_output_4_acc: 0.8810\n",
      "Epoch 96/200\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 1.3953 - output_0_loss: 0.2783 - output_1_loss: 0.2954 - output_2_loss: 0.2729 - output_3_loss: 0.2715 - output_4_loss: 0.2772 - output_0_acc: 0.9245 - output_1_acc: 0.9215 - output_2_acc: 0.9315 - output_3_acc: 0.9343 - output_4_acc: 0.9255 - val_loss: 2.0468 - val_output_0_loss: 0.3820 - val_output_1_loss: 0.4563 - val_output_2_loss: 0.3561 - val_output_3_loss: 0.4139 - val_output_4_loss: 0.4386 - val_output_0_acc: 0.8817 - val_output_1_acc: 0.8362 - val_output_2_acc: 0.9077 - val_output_3_acc: 0.8563 - val_output_4_acc: 0.8405\n",
      "Epoch 97/200\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 1.3692 - output_0_loss: 0.2653 - output_1_loss: 0.2917 - output_2_loss: 0.2671 - output_3_loss: 0.2674 - output_4_loss: 0.2777 - output_0_acc: 0.9373 - output_1_acc: 0.9185 - output_2_acc: 0.9353 - output_3_acc: 0.9387 - output_4_acc: 0.9233 - val_loss: 2.0281 - val_output_0_loss: 0.4446 - val_output_1_loss: 0.4086 - val_output_2_loss: 0.3695 - val_output_3_loss: 0.4038 - val_output_4_loss: 0.4016 - val_output_0_acc: 0.8362 - val_output_1_acc: 0.8665 - val_output_2_acc: 0.9033 - val_output_3_acc: 0.8553 - val_output_4_acc: 0.8690\n",
      "Epoch 98/200\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 1.3477 - output_0_loss: 0.2609 - output_1_loss: 0.2868 - output_2_loss: 0.2614 - output_3_loss: 0.2657 - output_4_loss: 0.2728 - output_0_acc: 0.9347 - output_1_acc: 0.9218 - output_2_acc: 0.9407 - output_3_acc: 0.9343 - output_4_acc: 0.9278 - val_loss: 2.0534 - val_output_0_loss: 0.3831 - val_output_1_loss: 0.4252 - val_output_2_loss: 0.4038 - val_output_3_loss: 0.4202 - val_output_4_loss: 0.4211 - val_output_0_acc: 0.8773 - val_output_1_acc: 0.8607 - val_output_2_acc: 0.8635 - val_output_3_acc: 0.8608 - val_output_4_acc: 0.8505\n",
      "Epoch 99/200\n",
      "4000/4000 [==============================] - 1s 196us/step - loss: 1.3222 - output_0_loss: 0.2609 - output_1_loss: 0.2827 - output_2_loss: 0.2572 - output_3_loss: 0.2558 - output_4_loss: 0.2656 - output_0_acc: 0.9357 - output_1_acc: 0.9243 - output_2_acc: 0.9385 - output_3_acc: 0.9400 - output_4_acc: 0.9300 - val_loss: 1.9102 - val_output_0_loss: 0.4068 - val_output_1_loss: 0.4267 - val_output_2_loss: 0.3629 - val_output_3_loss: 0.3385 - val_output_4_loss: 0.3753 - val_output_0_acc: 0.8618 - val_output_1_acc: 0.8597 - val_output_2_acc: 0.8937 - val_output_3_acc: 0.9062 - val_output_4_acc: 0.8798\n",
      "Epoch 100/200\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 1.2938 - output_0_loss: 0.2553 - output_1_loss: 0.2723 - output_2_loss: 0.2518 - output_3_loss: 0.2516 - output_4_loss: 0.2628 - output_0_acc: 0.9368 - output_1_acc: 0.9278 - output_2_acc: 0.9338 - output_3_acc: 0.9407 - output_4_acc: 0.9313 - val_loss: 2.0960 - val_output_0_loss: 0.3857 - val_output_1_loss: 0.4852 - val_output_2_loss: 0.3920 - val_output_3_loss: 0.3921 - val_output_4_loss: 0.4410 - val_output_0_acc: 0.8807 - val_output_1_acc: 0.8125 - val_output_2_acc: 0.8867 - val_output_3_acc: 0.8692 - val_output_4_acc: 0.8412\n",
      "Epoch 101/200\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 1.2793 - output_0_loss: 0.2500 - output_1_loss: 0.2708 - output_2_loss: 0.2456 - output_3_loss: 0.2501 - output_4_loss: 0.2628 - output_0_acc: 0.9387 - output_1_acc: 0.9295 - output_2_acc: 0.9475 - output_3_acc: 0.9400 - output_4_acc: 0.9310 - val_loss: 1.9586 - val_output_0_loss: 0.4505 - val_output_1_loss: 0.3792 - val_output_2_loss: 0.3646 - val_output_3_loss: 0.4146 - val_output_4_loss: 0.3497 - val_output_0_acc: 0.8240 - val_output_1_acc: 0.8895 - val_output_2_acc: 0.8907 - val_output_3_acc: 0.8388 - val_output_4_acc: 0.9057\n",
      "Epoch 102/200\n",
      "4000/4000 [==============================] - 1s 169us/step - loss: 1.2573 - output_0_loss: 0.2482 - output_1_loss: 0.2689 - output_2_loss: 0.2464 - output_3_loss: 0.2393 - output_4_loss: 0.2545 - output_0_acc: 0.9395 - output_1_acc: 0.9273 - output_2_acc: 0.9417 - output_3_acc: 0.9437 - output_4_acc: 0.9368 - val_loss: 1.8702 - val_output_0_loss: 0.4371 - val_output_1_loss: 0.3755 - val_output_2_loss: 0.3360 - val_output_3_loss: 0.3462 - val_output_4_loss: 0.3755 - val_output_0_acc: 0.8368 - val_output_1_acc: 0.8837 - val_output_2_acc: 0.9113 - val_output_3_acc: 0.8982 - val_output_4_acc: 0.8838\n",
      "Epoch 103/200\n",
      "4000/4000 [==============================] - 1s 170us/step - loss: 1.2348 - output_0_loss: 0.2358 - output_1_loss: 0.2647 - output_2_loss: 0.2426 - output_3_loss: 0.2446 - output_4_loss: 0.2471 - output_0_acc: 0.9445 - output_1_acc: 0.9248 - output_2_acc: 0.9442 - output_3_acc: 0.9417 - output_4_acc: 0.9345 - val_loss: 1.8800 - val_output_0_loss: 0.3694 - val_output_1_loss: 0.4284 - val_output_2_loss: 0.3639 - val_output_3_loss: 0.3188 - val_output_4_loss: 0.3995 - val_output_0_acc: 0.8833 - val_output_1_acc: 0.8512 - val_output_2_acc: 0.8887 - val_output_3_acc: 0.9178 - val_output_4_acc: 0.8597\n",
      "Epoch 104/200\n",
      "4000/4000 [==============================] - 1s 169us/step - loss: 1.2162 - output_0_loss: 0.2421 - output_1_loss: 0.2561 - output_2_loss: 0.2370 - output_3_loss: 0.2364 - output_4_loss: 0.2447 - output_0_acc: 0.9382 - output_1_acc: 0.9353 - output_2_acc: 0.9435 - output_3_acc: 0.9430 - output_4_acc: 0.9377 - val_loss: 1.8364 - val_output_0_loss: 0.3745 - val_output_1_loss: 0.4107 - val_output_2_loss: 0.3676 - val_output_3_loss: 0.3273 - val_output_4_loss: 0.3562 - val_output_0_acc: 0.8775 - val_output_1_acc: 0.8695 - val_output_2_acc: 0.8863 - val_output_3_acc: 0.9040 - val_output_4_acc: 0.8835\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 193us/step - loss: 1.1944 - output_0_loss: 0.2326 - output_1_loss: 0.2575 - output_2_loss: 0.2304 - output_3_loss: 0.2322 - output_4_loss: 0.2417 - output_0_acc: 0.9455 - output_1_acc: 0.9353 - output_2_acc: 0.9450 - output_3_acc: 0.9412 - output_4_acc: 0.9353 - val_loss: 1.8544 - val_output_0_loss: 0.3818 - val_output_1_loss: 0.3756 - val_output_2_loss: 0.3802 - val_output_3_loss: 0.2853 - val_output_4_loss: 0.4316 - val_output_0_acc: 0.8682 - val_output_1_acc: 0.8780 - val_output_2_acc: 0.8632 - val_output_3_acc: 0.9387 - val_output_4_acc: 0.8405\n",
      "Epoch 106/200\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 1.1781 - output_0_loss: 0.2306 - output_1_loss: 0.2499 - output_2_loss: 0.2320 - output_3_loss: 0.2227 - output_4_loss: 0.2429 - output_0_acc: 0.9417 - output_1_acc: 0.9340 - output_2_acc: 0.9483 - output_3_acc: 0.9490 - output_4_acc: 0.9375 - val_loss: 1.7630 - val_output_0_loss: 0.3356 - val_output_1_loss: 0.3810 - val_output_2_loss: 0.3234 - val_output_3_loss: 0.3157 - val_output_4_loss: 0.4073 - val_output_0_acc: 0.9013 - val_output_1_acc: 0.8773 - val_output_2_acc: 0.9082 - val_output_3_acc: 0.9150 - val_output_4_acc: 0.8522\n",
      "Epoch 107/200\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 1.1485 - output_0_loss: 0.2242 - output_1_loss: 0.2494 - output_2_loss: 0.2210 - output_3_loss: 0.2227 - output_4_loss: 0.2312 - output_0_acc: 0.9450 - output_1_acc: 0.9327 - output_2_acc: 0.9500 - output_3_acc: 0.9487 - output_4_acc: 0.9407 - val_loss: 1.8443 - val_output_0_loss: 0.3495 - val_output_1_loss: 0.4184 - val_output_2_loss: 0.3785 - val_output_3_loss: 0.3418 - val_output_4_loss: 0.3561 - val_output_0_acc: 0.8907 - val_output_1_acc: 0.8482 - val_output_2_acc: 0.8592 - val_output_3_acc: 0.8882 - val_output_4_acc: 0.8925\n",
      "Epoch 108/200\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 1.1246 - output_0_loss: 0.2250 - output_1_loss: 0.2402 - output_2_loss: 0.2166 - output_3_loss: 0.2098 - output_4_loss: 0.2330 - output_0_acc: 0.9437 - output_1_acc: 0.9390 - output_2_acc: 0.9520 - output_3_acc: 0.9532 - output_4_acc: 0.9390 - val_loss: 1.8168 - val_output_0_loss: 0.3268 - val_output_1_loss: 0.4072 - val_output_2_loss: 0.3538 - val_output_3_loss: 0.3358 - val_output_4_loss: 0.3932 - val_output_0_acc: 0.9043 - val_output_1_acc: 0.8497 - val_output_2_acc: 0.8852 - val_output_3_acc: 0.8898 - val_output_4_acc: 0.8592\n",
      "Epoch 109/200\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 1.1063 - output_0_loss: 0.2178 - output_1_loss: 0.2349 - output_2_loss: 0.2151 - output_3_loss: 0.2118 - output_4_loss: 0.2267 - output_0_acc: 0.9460 - output_1_acc: 0.9433 - output_2_acc: 0.9500 - output_3_acc: 0.9525 - output_4_acc: 0.9400 - val_loss: 1.8879 - val_output_0_loss: 0.3421 - val_output_1_loss: 0.3513 - val_output_2_loss: 0.4083 - val_output_3_loss: 0.4341 - val_output_4_loss: 0.3522 - val_output_0_acc: 0.9015 - val_output_1_acc: 0.8970 - val_output_2_acc: 0.8567 - val_output_3_acc: 0.8295 - val_output_4_acc: 0.8938\n",
      "Epoch 110/200\n",
      "4000/4000 [==============================] - 1s 164us/step - loss: 1.1065 - output_0_loss: 0.2165 - output_1_loss: 0.2331 - output_2_loss: 0.2218 - output_3_loss: 0.2166 - output_4_loss: 0.2184 - output_0_acc: 0.9480 - output_1_acc: 0.9393 - output_2_acc: 0.9425 - output_3_acc: 0.9527 - output_4_acc: 0.9470 - val_loss: 1.7594 - val_output_0_loss: 0.3331 - val_output_1_loss: 0.3615 - val_output_2_loss: 0.3322 - val_output_3_loss: 0.3123 - val_output_4_loss: 0.4204 - val_output_0_acc: 0.8947 - val_output_1_acc: 0.8782 - val_output_2_acc: 0.8982 - val_output_3_acc: 0.9162 - val_output_4_acc: 0.8485\n",
      "Epoch 111/200\n",
      "4000/4000 [==============================] - 1s 166us/step - loss: 1.0722 - output_0_loss: 0.2099 - output_1_loss: 0.2278 - output_2_loss: 0.2076 - output_3_loss: 0.2059 - output_4_loss: 0.2209 - output_0_acc: 0.9535 - output_1_acc: 0.9400 - output_2_acc: 0.9562 - output_3_acc: 0.9577 - output_4_acc: 0.9450 - val_loss: 1.7908 - val_output_0_loss: 0.4143 - val_output_1_loss: 0.3438 - val_output_2_loss: 0.3663 - val_output_3_loss: 0.3025 - val_output_4_loss: 0.3638 - val_output_0_acc: 0.8462 - val_output_1_acc: 0.8943 - val_output_2_acc: 0.8825 - val_output_3_acc: 0.9108 - val_output_4_acc: 0.8733\n",
      "Epoch 112/200\n",
      "4000/4000 [==============================] - 1s 175us/step - loss: 1.0650 - output_0_loss: 0.2087 - output_1_loss: 0.2291 - output_2_loss: 0.2021 - output_3_loss: 0.2083 - output_4_loss: 0.2168 - output_0_acc: 0.9497 - output_1_acc: 0.9405 - output_2_acc: 0.9585 - output_3_acc: 0.9550 - output_4_acc: 0.9410 - val_loss: 1.6923 - val_output_0_loss: 0.3515 - val_output_1_loss: 0.3114 - val_output_2_loss: 0.3433 - val_output_3_loss: 0.3119 - val_output_4_loss: 0.3743 - val_output_0_acc: 0.8910 - val_output_1_acc: 0.9113 - val_output_2_acc: 0.8903 - val_output_3_acc: 0.9057 - val_output_4_acc: 0.8690\n",
      "Epoch 113/200\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 1.0433 - output_0_loss: 0.2022 - output_1_loss: 0.2261 - output_2_loss: 0.2039 - output_3_loss: 0.1979 - output_4_loss: 0.2132 - output_0_acc: 0.9543 - output_1_acc: 0.9457 - output_2_acc: 0.9535 - output_3_acc: 0.9590 - output_4_acc: 0.9437 - val_loss: 1.6641 - val_output_0_loss: 0.2980 - val_output_1_loss: 0.3858 - val_output_2_loss: 0.3263 - val_output_3_loss: 0.3098 - val_output_4_loss: 0.3443 - val_output_0_acc: 0.9162 - val_output_1_acc: 0.8740 - val_output_2_acc: 0.8928 - val_output_3_acc: 0.9033 - val_output_4_acc: 0.8900\n",
      "Epoch 114/200\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 1.0292 - output_0_loss: 0.1985 - output_1_loss: 0.2229 - output_2_loss: 0.1943 - output_3_loss: 0.2008 - output_4_loss: 0.2127 - output_0_acc: 0.9580 - output_1_acc: 0.9440 - output_2_acc: 0.9603 - output_3_acc: 0.9550 - output_4_acc: 0.9465 - val_loss: 1.6615 - val_output_0_loss: 0.3009 - val_output_1_loss: 0.3467 - val_output_2_loss: 0.3647 - val_output_3_loss: 0.2852 - val_output_4_loss: 0.3639 - val_output_0_acc: 0.9097 - val_output_1_acc: 0.8960 - val_output_2_acc: 0.8707 - val_output_3_acc: 0.9260 - val_output_4_acc: 0.8820\n",
      "Epoch 115/200\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 1.0193 - output_0_loss: 0.2006 - output_1_loss: 0.2140 - output_2_loss: 0.2025 - output_3_loss: 0.1961 - output_4_loss: 0.2061 - output_0_acc: 0.9550 - output_1_acc: 0.9483 - output_2_acc: 0.9550 - output_3_acc: 0.9543 - output_4_acc: 0.9465 - val_loss: 1.5922 - val_output_0_loss: 0.3187 - val_output_1_loss: 0.3487 - val_output_2_loss: 0.2498 - val_output_3_loss: 0.3146 - val_output_4_loss: 0.3604 - val_output_0_acc: 0.9102 - val_output_1_acc: 0.8925 - val_output_2_acc: 0.9512 - val_output_3_acc: 0.8965 - val_output_4_acc: 0.8688\n",
      "Epoch 116/200\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.9856 - output_0_loss: 0.1945 - output_1_loss: 0.2179 - output_2_loss: 0.1881 - output_3_loss: 0.1848 - output_4_loss: 0.2002 - output_0_acc: 0.9587 - output_1_acc: 0.9447 - output_2_acc: 0.9625 - output_3_acc: 0.9620 - output_4_acc: 0.9513 - val_loss: 1.7453 - val_output_0_loss: 0.3409 - val_output_1_loss: 0.4405 - val_output_2_loss: 0.2912 - val_output_3_loss: 0.3171 - val_output_4_loss: 0.3555 - val_output_0_acc: 0.8882 - val_output_1_acc: 0.8322 - val_output_2_acc: 0.9162 - val_output_3_acc: 0.9007 - val_output_4_acc: 0.8868\n",
      "Epoch 117/200\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 0.9727 - output_0_loss: 0.1864 - output_1_loss: 0.2071 - output_2_loss: 0.1929 - output_3_loss: 0.1851 - output_4_loss: 0.2013 - output_0_acc: 0.9615 - output_1_acc: 0.9487 - output_2_acc: 0.9570 - output_3_acc: 0.9585 - output_4_acc: 0.9477 - val_loss: 1.6207 - val_output_0_loss: 0.3313 - val_output_1_loss: 0.3872 - val_output_2_loss: 0.3444 - val_output_3_loss: 0.2693 - val_output_4_loss: 0.2885 - val_output_0_acc: 0.8957 - val_output_1_acc: 0.8522 - val_output_2_acc: 0.8795 - val_output_3_acc: 0.9305 - val_output_4_acc: 0.9192\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 164us/step - loss: 0.9646 - output_0_loss: 0.1869 - output_1_loss: 0.2093 - output_2_loss: 0.1894 - output_3_loss: 0.1830 - output_4_loss: 0.1960 - output_0_acc: 0.9575 - output_1_acc: 0.9470 - output_2_acc: 0.9585 - output_3_acc: 0.9610 - output_4_acc: 0.9513 - val_loss: 1.6489 - val_output_0_loss: 0.3491 - val_output_1_loss: 0.3532 - val_output_2_loss: 0.2828 - val_output_3_loss: 0.3048 - val_output_4_loss: 0.3589 - val_output_0_acc: 0.8855 - val_output_1_acc: 0.8863 - val_output_2_acc: 0.9202 - val_output_3_acc: 0.9012 - val_output_4_acc: 0.8690\n",
      "Epoch 119/200\n",
      "4000/4000 [==============================] - 1s 173us/step - loss: 0.9536 - output_0_loss: 0.1853 - output_1_loss: 0.2075 - output_2_loss: 0.1847 - output_3_loss: 0.1813 - output_4_loss: 0.1948 - output_0_acc: 0.9577 - output_1_acc: 0.9472 - output_2_acc: 0.9615 - output_3_acc: 0.9617 - output_4_acc: 0.9495 - val_loss: 1.6825 - val_output_0_loss: 0.3524 - val_output_1_loss: 0.3155 - val_output_2_loss: 0.3000 - val_output_3_loss: 0.4134 - val_output_4_loss: 0.3012 - val_output_0_acc: 0.8718 - val_output_1_acc: 0.9018 - val_output_2_acc: 0.8925 - val_output_3_acc: 0.8400 - val_output_4_acc: 0.9090\n",
      "Epoch 120/200\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.9319 - output_0_loss: 0.1816 - output_1_loss: 0.2002 - output_2_loss: 0.1777 - output_3_loss: 0.1832 - output_4_loss: 0.1891 - output_0_acc: 0.9585 - output_1_acc: 0.9500 - output_2_acc: 0.9617 - output_3_acc: 0.9567 - output_4_acc: 0.9523 - val_loss: 1.5461 - val_output_0_loss: 0.3332 - val_output_1_loss: 0.3485 - val_output_2_loss: 0.2870 - val_output_3_loss: 0.2804 - val_output_4_loss: 0.2969 - val_output_0_acc: 0.8810 - val_output_1_acc: 0.8805 - val_output_2_acc: 0.9182 - val_output_3_acc: 0.9165 - val_output_4_acc: 0.9132\n",
      "Epoch 121/200\n",
      "4000/4000 [==============================] - 1s 175us/step - loss: 0.9082 - output_0_loss: 0.1730 - output_1_loss: 0.2003 - output_2_loss: 0.1755 - output_3_loss: 0.1775 - output_4_loss: 0.1819 - output_0_acc: 0.9633 - output_1_acc: 0.9487 - output_2_acc: 0.9645 - output_3_acc: 0.9633 - output_4_acc: 0.9570 - val_loss: 1.6015 - val_output_0_loss: 0.2919 - val_output_1_loss: 0.3514 - val_output_2_loss: 0.3485 - val_output_3_loss: 0.2945 - val_output_4_loss: 0.3152 - val_output_0_acc: 0.9073 - val_output_1_acc: 0.8743 - val_output_2_acc: 0.8743 - val_output_3_acc: 0.9092 - val_output_4_acc: 0.9000\n",
      "Epoch 122/200\n",
      "4000/4000 [==============================] - 1s 164us/step - loss: 0.8884 - output_0_loss: 0.1739 - output_1_loss: 0.1949 - output_2_loss: 0.1684 - output_3_loss: 0.1719 - output_4_loss: 0.1793 - output_0_acc: 0.9603 - output_1_acc: 0.9537 - output_2_acc: 0.9652 - output_3_acc: 0.9675 - output_4_acc: 0.9590 - val_loss: 1.5069 - val_output_0_loss: 0.3278 - val_output_1_loss: 0.2865 - val_output_2_loss: 0.3086 - val_output_3_loss: 0.2579 - val_output_4_loss: 0.3262 - val_output_0_acc: 0.8863 - val_output_1_acc: 0.9205 - val_output_2_acc: 0.9078 - val_output_3_acc: 0.9283 - val_output_4_acc: 0.8903\n",
      "Epoch 123/200\n",
      "4000/4000 [==============================] - 1s 165us/step - loss: 0.8731 - output_0_loss: 0.1692 - output_1_loss: 0.1926 - output_2_loss: 0.1677 - output_3_loss: 0.1633 - output_4_loss: 0.1803 - output_0_acc: 0.9650 - output_1_acc: 0.9505 - output_2_acc: 0.9670 - output_3_acc: 0.9677 - output_4_acc: 0.9547 - val_loss: 1.4158 - val_output_0_loss: 0.2811 - val_output_1_loss: 0.3078 - val_output_2_loss: 0.2979 - val_output_3_loss: 0.2440 - val_output_4_loss: 0.2851 - val_output_0_acc: 0.9217 - val_output_1_acc: 0.9042 - val_output_2_acc: 0.8965 - val_output_3_acc: 0.9357 - val_output_4_acc: 0.9188\n",
      "Epoch 124/200\n",
      "4000/4000 [==============================] - 1s 175us/step - loss: 0.8634 - output_0_loss: 0.1683 - output_1_loss: 0.1877 - output_2_loss: 0.1629 - output_3_loss: 0.1690 - output_4_loss: 0.1755 - output_0_acc: 0.9615 - output_1_acc: 0.9532 - output_2_acc: 0.9670 - output_3_acc: 0.9607 - output_4_acc: 0.9592 - val_loss: 1.5615 - val_output_0_loss: 0.3441 - val_output_1_loss: 0.3378 - val_output_2_loss: 0.3271 - val_output_3_loss: 0.2626 - val_output_4_loss: 0.2898 - val_output_0_acc: 0.8788 - val_output_1_acc: 0.8813 - val_output_2_acc: 0.8970 - val_output_3_acc: 0.9267 - val_output_4_acc: 0.9060\n",
      "Epoch 125/200\n",
      "4000/4000 [==============================] - 1s 163us/step - loss: 0.8445 - output_0_loss: 0.1627 - output_1_loss: 0.1850 - output_2_loss: 0.1615 - output_3_loss: 0.1632 - output_4_loss: 0.1721 - output_0_acc: 0.9667 - output_1_acc: 0.9540 - output_2_acc: 0.9657 - output_3_acc: 0.9645 - output_4_acc: 0.9583 - val_loss: 1.4510 - val_output_0_loss: 0.3160 - val_output_1_loss: 0.3695 - val_output_2_loss: 0.2526 - val_output_3_loss: 0.2673 - val_output_4_loss: 0.2458 - val_output_0_acc: 0.8862 - val_output_1_acc: 0.8595 - val_output_2_acc: 0.9303 - val_output_3_acc: 0.9242 - val_output_4_acc: 0.9392\n",
      "Epoch 126/200\n",
      "4000/4000 [==============================] - 1s 167us/step - loss: 0.8393 - output_0_loss: 0.1571 - output_1_loss: 0.1819 - output_2_loss: 0.1620 - output_3_loss: 0.1622 - output_4_loss: 0.1760 - output_0_acc: 0.9708 - output_1_acc: 0.9585 - output_2_acc: 0.9677 - output_3_acc: 0.9688 - output_4_acc: 0.9555 - val_loss: 1.3227 - val_output_0_loss: 0.2903 - val_output_1_loss: 0.2907 - val_output_2_loss: 0.2229 - val_output_3_loss: 0.2231 - val_output_4_loss: 0.2955 - val_output_0_acc: 0.9057 - val_output_1_acc: 0.9157 - val_output_2_acc: 0.9522 - val_output_3_acc: 0.9523 - val_output_4_acc: 0.9115\n",
      "Epoch 127/200\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 0.8226 - output_0_loss: 0.1620 - output_1_loss: 0.1796 - output_2_loss: 0.1561 - output_3_loss: 0.1577 - output_4_loss: 0.1672 - output_0_acc: 0.9657 - output_1_acc: 0.9553 - output_2_acc: 0.9702 - output_3_acc: 0.9680 - output_4_acc: 0.9600 - val_loss: 1.3558 - val_output_0_loss: 0.2726 - val_output_1_loss: 0.3058 - val_output_2_loss: 0.2271 - val_output_3_loss: 0.2383 - val_output_4_loss: 0.3120 - val_output_0_acc: 0.9192 - val_output_1_acc: 0.9043 - val_output_2_acc: 0.9458 - val_output_3_acc: 0.9368 - val_output_4_acc: 0.9050\n",
      "Epoch 128/200\n",
      "4000/4000 [==============================] - 1s 164us/step - loss: 0.8060 - output_0_loss: 0.1548 - output_1_loss: 0.1734 - output_2_loss: 0.1578 - output_3_loss: 0.1568 - output_4_loss: 0.1632 - output_0_acc: 0.9708 - output_1_acc: 0.9605 - output_2_acc: 0.9663 - output_3_acc: 0.9685 - output_4_acc: 0.9620 - val_loss: 1.4040 - val_output_0_loss: 0.2701 - val_output_1_loss: 0.3364 - val_output_2_loss: 0.2463 - val_output_3_loss: 0.2726 - val_output_4_loss: 0.2786 - val_output_0_acc: 0.9138 - val_output_1_acc: 0.8742 - val_output_2_acc: 0.9340 - val_output_3_acc: 0.9113 - val_output_4_acc: 0.9088\n",
      "Epoch 129/200\n",
      "4000/4000 [==============================] - 1s 163us/step - loss: 0.7888 - output_0_loss: 0.1534 - output_1_loss: 0.1724 - output_2_loss: 0.1502 - output_3_loss: 0.1522 - output_4_loss: 0.1606 - output_0_acc: 0.9693 - output_1_acc: 0.9573 - output_2_acc: 0.9665 - output_3_acc: 0.9695 - output_4_acc: 0.9655 - val_loss: 1.5896 - val_output_0_loss: 0.3242 - val_output_1_loss: 0.3357 - val_output_2_loss: 0.3568 - val_output_3_loss: 0.2622 - val_output_4_loss: 0.3107 - val_output_0_acc: 0.8920 - val_output_1_acc: 0.8823 - val_output_2_acc: 0.8737 - val_output_3_acc: 0.9235 - val_output_4_acc: 0.8905\n",
      "Epoch 130/200\n",
      "4000/4000 [==============================] - 1s 175us/step - loss: 0.7870 - output_0_loss: 0.1520 - output_1_loss: 0.1715 - output_2_loss: 0.1488 - output_3_loss: 0.1506 - output_4_loss: 0.1642 - output_0_acc: 0.9645 - output_1_acc: 0.9567 - output_2_acc: 0.9715 - output_3_acc: 0.9728 - output_4_acc: 0.9607 - val_loss: 1.2812 - val_output_0_loss: 0.2543 - val_output_1_loss: 0.3141 - val_output_2_loss: 0.2475 - val_output_3_loss: 0.2165 - val_output_4_loss: 0.2488 - val_output_0_acc: 0.9320 - val_output_1_acc: 0.9002 - val_output_2_acc: 0.9285 - val_output_3_acc: 0.9503 - val_output_4_acc: 0.9295\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 174us/step - loss: 0.7633 - output_0_loss: 0.1496 - output_1_loss: 0.1674 - output_2_loss: 0.1493 - output_3_loss: 0.1422 - output_4_loss: 0.1547 - output_0_acc: 0.9682 - output_1_acc: 0.9633 - output_2_acc: 0.9715 - output_3_acc: 0.9753 - output_4_acc: 0.9635 - val_loss: 1.4223 - val_output_0_loss: 0.2502 - val_output_1_loss: 0.3645 - val_output_2_loss: 0.2849 - val_output_3_loss: 0.2499 - val_output_4_loss: 0.2729 - val_output_0_acc: 0.9278 - val_output_1_acc: 0.8665 - val_output_2_acc: 0.9210 - val_output_3_acc: 0.9230 - val_output_4_acc: 0.9198\n",
      "Epoch 132/200\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.7509 - output_0_loss: 0.1474 - output_1_loss: 0.1598 - output_2_loss: 0.1413 - output_3_loss: 0.1465 - output_4_loss: 0.1559 - output_0_acc: 0.9680 - output_1_acc: 0.9607 - output_2_acc: 0.9720 - output_3_acc: 0.9700 - output_4_acc: 0.9627 - val_loss: 1.2604 - val_output_0_loss: 0.2210 - val_output_1_loss: 0.2938 - val_output_2_loss: 0.2374 - val_output_3_loss: 0.2169 - val_output_4_loss: 0.2913 - val_output_0_acc: 0.9472 - val_output_1_acc: 0.9045 - val_output_2_acc: 0.9347 - val_output_3_acc: 0.9510 - val_output_4_acc: 0.9030\n",
      "Epoch 133/200\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.7431 - output_0_loss: 0.1428 - output_1_loss: 0.1616 - output_2_loss: 0.1448 - output_3_loss: 0.1433 - output_4_loss: 0.1505 - output_0_acc: 0.9718 - output_1_acc: 0.9617 - output_2_acc: 0.9680 - output_3_acc: 0.9720 - output_4_acc: 0.9643 - val_loss: 1.2562 - val_output_0_loss: 0.2755 - val_output_1_loss: 0.2702 - val_output_2_loss: 0.2126 - val_output_3_loss: 0.2506 - val_output_4_loss: 0.2474 - val_output_0_acc: 0.9125 - val_output_1_acc: 0.9087 - val_output_2_acc: 0.9445 - val_output_3_acc: 0.9265 - val_output_4_acc: 0.9267\n",
      "Epoch 134/200\n",
      "4000/4000 [==============================] - 1s 183us/step - loss: 0.7279 - output_0_loss: 0.1381 - output_1_loss: 0.1630 - output_2_loss: 0.1374 - output_3_loss: 0.1375 - output_4_loss: 0.1519 - output_0_acc: 0.9712 - output_1_acc: 0.9605 - output_2_acc: 0.9702 - output_3_acc: 0.9762 - output_4_acc: 0.9647 - val_loss: 1.2451 - val_output_0_loss: 0.2262 - val_output_1_loss: 0.2816 - val_output_2_loss: 0.2355 - val_output_3_loss: 0.2281 - val_output_4_loss: 0.2737 - val_output_0_acc: 0.9362 - val_output_1_acc: 0.9100 - val_output_2_acc: 0.9352 - val_output_3_acc: 0.9423 - val_output_4_acc: 0.9062\n",
      "Epoch 135/200\n",
      "4000/4000 [==============================] - 1s 166us/step - loss: 0.7153 - output_0_loss: 0.1403 - output_1_loss: 0.1580 - output_2_loss: 0.1379 - output_3_loss: 0.1350 - output_4_loss: 0.1442 - output_0_acc: 0.9730 - output_1_acc: 0.9580 - output_2_acc: 0.9735 - output_3_acc: 0.9735 - output_4_acc: 0.9695 - val_loss: 1.2470 - val_output_0_loss: 0.1917 - val_output_1_loss: 0.2462 - val_output_2_loss: 0.2382 - val_output_3_loss: 0.2777 - val_output_4_loss: 0.2932 - val_output_0_acc: 0.9558 - val_output_1_acc: 0.9337 - val_output_2_acc: 0.9320 - val_output_3_acc: 0.9150 - val_output_4_acc: 0.9090\n",
      "Epoch 136/200\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 0.6954 - output_0_loss: 0.1339 - output_1_loss: 0.1592 - output_2_loss: 0.1295 - output_3_loss: 0.1288 - output_4_loss: 0.1439 - output_0_acc: 0.9720 - output_1_acc: 0.9615 - output_2_acc: 0.9748 - output_3_acc: 0.9768 - output_4_acc: 0.9680 - val_loss: 1.3566 - val_output_0_loss: 0.2429 - val_output_1_loss: 0.3050 - val_output_2_loss: 0.2715 - val_output_3_loss: 0.2214 - val_output_4_loss: 0.3159 - val_output_0_acc: 0.9325 - val_output_1_acc: 0.8957 - val_output_2_acc: 0.9098 - val_output_3_acc: 0.9403 - val_output_4_acc: 0.8942\n",
      "Epoch 137/200\n",
      "4000/4000 [==============================] - 1s 177us/step - loss: 0.6836 - output_0_loss: 0.1299 - output_1_loss: 0.1527 - output_2_loss: 0.1287 - output_3_loss: 0.1299 - output_4_loss: 0.1424 - output_0_acc: 0.9753 - output_1_acc: 0.9635 - output_2_acc: 0.9772 - output_3_acc: 0.9762 - output_4_acc: 0.9698 - val_loss: 1.2494 - val_output_0_loss: 0.2626 - val_output_1_loss: 0.2664 - val_output_2_loss: 0.2180 - val_output_3_loss: 0.2857 - val_output_4_loss: 0.2167 - val_output_0_acc: 0.9163 - val_output_1_acc: 0.9123 - val_output_2_acc: 0.9465 - val_output_3_acc: 0.9020 - val_output_4_acc: 0.9437\n",
      "Epoch 138/200\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 0.6768 - output_0_loss: 0.1294 - output_1_loss: 0.1515 - output_2_loss: 0.1277 - output_3_loss: 0.1283 - output_4_loss: 0.1399 - output_0_acc: 0.9750 - output_1_acc: 0.9645 - output_2_acc: 0.9760 - output_3_acc: 0.9765 - output_4_acc: 0.9677 - val_loss: 1.2052 - val_output_0_loss: 0.2393 - val_output_1_loss: 0.2856 - val_output_2_loss: 0.2429 - val_output_3_loss: 0.2116 - val_output_4_loss: 0.2258 - val_output_0_acc: 0.9325 - val_output_1_acc: 0.9088 - val_output_2_acc: 0.9233 - val_output_3_acc: 0.9443 - val_output_4_acc: 0.9373\n",
      "Epoch 139/200\n",
      "4000/4000 [==============================] - 1s 174us/step - loss: 0.6688 - output_0_loss: 0.1288 - output_1_loss: 0.1495 - output_2_loss: 0.1248 - output_3_loss: 0.1256 - output_4_loss: 0.1402 - output_0_acc: 0.9742 - output_1_acc: 0.9647 - output_2_acc: 0.9742 - output_3_acc: 0.9783 - output_4_acc: 0.9667 - val_loss: 1.0945 - val_output_0_loss: 0.2471 - val_output_1_loss: 0.2548 - val_output_2_loss: 0.2101 - val_output_3_loss: 0.1873 - val_output_4_loss: 0.1951 - val_output_0_acc: 0.9315 - val_output_1_acc: 0.9158 - val_output_2_acc: 0.9457 - val_output_3_acc: 0.9612 - val_output_4_acc: 0.9548\n",
      "Epoch 140/200\n",
      "4000/4000 [==============================] - 1s 167us/step - loss: 0.6492 - output_0_loss: 0.1245 - output_1_loss: 0.1465 - output_2_loss: 0.1228 - output_3_loss: 0.1217 - output_4_loss: 0.1337 - output_0_acc: 0.9738 - output_1_acc: 0.9652 - output_2_acc: 0.9783 - output_3_acc: 0.9788 - output_4_acc: 0.9690 - val_loss: 1.3169 - val_output_0_loss: 0.2251 - val_output_1_loss: 0.3101 - val_output_2_loss: 0.2196 - val_output_3_loss: 0.3335 - val_output_4_loss: 0.2286 - val_output_0_acc: 0.9368 - val_output_1_acc: 0.8955 - val_output_2_acc: 0.9480 - val_output_3_acc: 0.8683 - val_output_4_acc: 0.9368\n",
      "Epoch 141/200\n",
      "4000/4000 [==============================] - 1s 163us/step - loss: 0.6454 - output_0_loss: 0.1235 - output_1_loss: 0.1409 - output_2_loss: 0.1228 - output_3_loss: 0.1240 - output_4_loss: 0.1342 - output_0_acc: 0.9730 - output_1_acc: 0.9682 - output_2_acc: 0.9772 - output_3_acc: 0.9765 - output_4_acc: 0.9673 - val_loss: 1.2748 - val_output_0_loss: 0.2606 - val_output_1_loss: 0.2798 - val_output_2_loss: 0.2415 - val_output_3_loss: 0.2430 - val_output_4_loss: 0.2498 - val_output_0_acc: 0.9167 - val_output_1_acc: 0.9047 - val_output_2_acc: 0.9192 - val_output_3_acc: 0.9217 - val_output_4_acc: 0.9163\n",
      "Epoch 142/200\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.6290 - output_0_loss: 0.1174 - output_1_loss: 0.1419 - output_2_loss: 0.1192 - output_3_loss: 0.1177 - output_4_loss: 0.1328 - output_0_acc: 0.9813 - output_1_acc: 0.9667 - output_2_acc: 0.9755 - output_3_acc: 0.9798 - output_4_acc: 0.9695 - val_loss: 1.1362 - val_output_0_loss: 0.1928 - val_output_1_loss: 0.2963 - val_output_2_loss: 0.2173 - val_output_3_loss: 0.1915 - val_output_4_loss: 0.2383 - val_output_0_acc: 0.9493 - val_output_1_acc: 0.8950 - val_output_2_acc: 0.9380 - val_output_3_acc: 0.9585 - val_output_4_acc: 0.9233\n",
      "Epoch 143/200\n",
      "4000/4000 [==============================] - 1s 191us/step - loss: 0.6290 - output_0_loss: 0.1200 - output_1_loss: 0.1397 - output_2_loss: 0.1189 - output_3_loss: 0.1205 - output_4_loss: 0.1300 - output_0_acc: 0.9753 - output_1_acc: 0.9647 - output_2_acc: 0.9775 - output_3_acc: 0.9768 - output_4_acc: 0.9682 - val_loss: 1.1672 - val_output_0_loss: 0.2686 - val_output_1_loss: 0.2391 - val_output_2_loss: 0.2256 - val_output_3_loss: 0.2123 - val_output_4_loss: 0.2216 - val_output_0_acc: 0.9083 - val_output_1_acc: 0.9292 - val_output_2_acc: 0.9280 - val_output_3_acc: 0.9360 - val_output_4_acc: 0.9333\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.6101 - output_0_loss: 0.1159 - output_1_loss: 0.1393 - output_2_loss: 0.1110 - output_3_loss: 0.1160 - output_4_loss: 0.1278 - output_0_acc: 0.9770 - output_1_acc: 0.9700 - output_2_acc: 0.9828 - output_3_acc: 0.9772 - output_4_acc: 0.9698 - val_loss: 1.0931 - val_output_0_loss: 0.1861 - val_output_1_loss: 0.2859 - val_output_2_loss: 0.2076 - val_output_3_loss: 0.1860 - val_output_4_loss: 0.2274 - val_output_0_acc: 0.9545 - val_output_1_acc: 0.9072 - val_output_2_acc: 0.9435 - val_output_3_acc: 0.9542 - val_output_4_acc: 0.9367\n",
      "Epoch 145/200\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.5983 - output_0_loss: 0.1151 - output_1_loss: 0.1317 - output_2_loss: 0.1089 - output_3_loss: 0.1152 - output_4_loss: 0.1275 - output_0_acc: 0.9772 - output_1_acc: 0.9730 - output_2_acc: 0.9820 - output_3_acc: 0.9805 - output_4_acc: 0.9735 - val_loss: 1.2095 - val_output_0_loss: 0.2097 - val_output_1_loss: 0.2797 - val_output_2_loss: 0.2411 - val_output_3_loss: 0.2159 - val_output_4_loss: 0.2631 - val_output_0_acc: 0.9445 - val_output_1_acc: 0.9085 - val_output_2_acc: 0.9272 - val_output_3_acc: 0.9422 - val_output_4_acc: 0.9067\n",
      "Epoch 146/200\n",
      "4000/4000 [==============================] - 1s 173us/step - loss: 0.5830 - output_0_loss: 0.1112 - output_1_loss: 0.1286 - output_2_loss: 0.1124 - output_3_loss: 0.1112 - output_4_loss: 0.1196 - output_0_acc: 0.9753 - output_1_acc: 0.9715 - output_2_acc: 0.9790 - output_3_acc: 0.9802 - output_4_acc: 0.9748 - val_loss: 0.9870 - val_output_0_loss: 0.1827 - val_output_1_loss: 0.2172 - val_output_2_loss: 0.1887 - val_output_3_loss: 0.2002 - val_output_4_loss: 0.1982 - val_output_0_acc: 0.9533 - val_output_1_acc: 0.9413 - val_output_2_acc: 0.9535 - val_output_3_acc: 0.9520 - val_output_4_acc: 0.9463\n",
      "Epoch 147/200\n",
      "4000/4000 [==============================] - 1s 160us/step - loss: 0.5763 - output_0_loss: 0.1114 - output_1_loss: 0.1305 - output_2_loss: 0.1048 - output_3_loss: 0.1075 - output_4_loss: 0.1220 - output_0_acc: 0.9778 - output_1_acc: 0.9695 - output_2_acc: 0.9830 - output_3_acc: 0.9848 - output_4_acc: 0.9725 - val_loss: 1.0419 - val_output_0_loss: 0.1821 - val_output_1_loss: 0.2338 - val_output_2_loss: 0.1913 - val_output_3_loss: 0.2035 - val_output_4_loss: 0.2311 - val_output_0_acc: 0.9615 - val_output_1_acc: 0.9265 - val_output_2_acc: 0.9520 - val_output_3_acc: 0.9437 - val_output_4_acc: 0.9298\n",
      "Epoch 148/200\n",
      "4000/4000 [==============================] - 1s 163us/step - loss: 0.5679 - output_0_loss: 0.1052 - output_1_loss: 0.1301 - output_2_loss: 0.1079 - output_3_loss: 0.1074 - output_4_loss: 0.1174 - output_0_acc: 0.9813 - output_1_acc: 0.9735 - output_2_acc: 0.9818 - output_3_acc: 0.9828 - output_4_acc: 0.9740 - val_loss: 1.2033 - val_output_0_loss: 0.2106 - val_output_1_loss: 0.3039 - val_output_2_loss: 0.2128 - val_output_3_loss: 0.2581 - val_output_4_loss: 0.2178 - val_output_0_acc: 0.9357 - val_output_1_acc: 0.8922 - val_output_2_acc: 0.9383 - val_output_3_acc: 0.9098 - val_output_4_acc: 0.9342\n",
      "Epoch 149/200\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.5717 - output_0_loss: 0.1108 - output_1_loss: 0.1347 - output_2_loss: 0.1023 - output_3_loss: 0.1029 - output_4_loss: 0.1211 - output_0_acc: 0.9785 - output_1_acc: 0.9663 - output_2_acc: 0.9825 - output_3_acc: 0.9838 - output_4_acc: 0.9710 - val_loss: 0.9982 - val_output_0_loss: 0.1788 - val_output_1_loss: 0.2432 - val_output_2_loss: 0.1802 - val_output_3_loss: 0.1512 - val_output_4_loss: 0.2448 - val_output_0_acc: 0.9597 - val_output_1_acc: 0.9242 - val_output_2_acc: 0.9577 - val_output_3_acc: 0.9718 - val_output_4_acc: 0.9178\n",
      "Epoch 150/200\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.5469 - output_0_loss: 0.1019 - output_1_loss: 0.1228 - output_2_loss: 0.1040 - output_3_loss: 0.1017 - output_4_loss: 0.1166 - output_0_acc: 0.9843 - output_1_acc: 0.9740 - output_2_acc: 0.9838 - output_3_acc: 0.9820 - output_4_acc: 0.9732 - val_loss: 0.9722 - val_output_0_loss: 0.1939 - val_output_1_loss: 0.2173 - val_output_2_loss: 0.1843 - val_output_3_loss: 0.1931 - val_output_4_loss: 0.1836 - val_output_0_acc: 0.9525 - val_output_1_acc: 0.9313 - val_output_2_acc: 0.9505 - val_output_3_acc: 0.9432 - val_output_4_acc: 0.9592\n",
      "Epoch 151/200\n",
      "4000/4000 [==============================] - 1s 164us/step - loss: 0.5430 - output_0_loss: 0.1035 - output_1_loss: 0.1243 - output_2_loss: 0.1005 - output_3_loss: 0.1000 - output_4_loss: 0.1147 - output_0_acc: 0.9813 - output_1_acc: 0.9710 - output_2_acc: 0.9828 - output_3_acc: 0.9835 - output_4_acc: 0.9778 - val_loss: 1.0024 - val_output_0_loss: 0.2044 - val_output_1_loss: 0.2170 - val_output_2_loss: 0.2007 - val_output_3_loss: 0.1869 - val_output_4_loss: 0.1933 - val_output_0_acc: 0.9432 - val_output_1_acc: 0.9345 - val_output_2_acc: 0.9442 - val_output_3_acc: 0.9520 - val_output_4_acc: 0.9470\n",
      "Epoch 152/200\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.5306 - output_0_loss: 0.0984 - output_1_loss: 0.1160 - output_2_loss: 0.1048 - output_3_loss: 0.0992 - output_4_loss: 0.1123 - output_0_acc: 0.9805 - output_1_acc: 0.9738 - output_2_acc: 0.9808 - output_3_acc: 0.9845 - output_4_acc: 0.9760 - val_loss: 1.1554 - val_output_0_loss: 0.2617 - val_output_1_loss: 0.2573 - val_output_2_loss: 0.1659 - val_output_3_loss: 0.2363 - val_output_4_loss: 0.2342 - val_output_0_acc: 0.9052 - val_output_1_acc: 0.9148 - val_output_2_acc: 0.9627 - val_output_3_acc: 0.9250 - val_output_4_acc: 0.9182\n",
      "Epoch 153/200\n",
      "4000/4000 [==============================] - 1s 170us/step - loss: 0.5203 - output_0_loss: 0.0994 - output_1_loss: 0.1204 - output_2_loss: 0.0950 - output_3_loss: 0.0985 - output_4_loss: 0.1068 - output_0_acc: 0.9822 - output_1_acc: 0.9715 - output_2_acc: 0.9830 - output_3_acc: 0.9818 - output_4_acc: 0.9778 - val_loss: 1.0831 - val_output_0_loss: 0.1757 - val_output_1_loss: 0.2278 - val_output_2_loss: 0.2406 - val_output_3_loss: 0.1652 - val_output_4_loss: 0.2739 - val_output_0_acc: 0.9527 - val_output_1_acc: 0.9310 - val_output_2_acc: 0.9162 - val_output_3_acc: 0.9627 - val_output_4_acc: 0.9117\n",
      "Epoch 154/200\n",
      "4000/4000 [==============================] - 1s 166us/step - loss: 0.5032 - output_0_loss: 0.0933 - output_1_loss: 0.1154 - output_2_loss: 0.0959 - output_3_loss: 0.0931 - output_4_loss: 0.1056 - output_0_acc: 0.9848 - output_1_acc: 0.9775 - output_2_acc: 0.9818 - output_3_acc: 0.9870 - output_4_acc: 0.9775 - val_loss: 1.0921 - val_output_0_loss: 0.2644 - val_output_1_loss: 0.2778 - val_output_2_loss: 0.1772 - val_output_3_loss: 0.1634 - val_output_4_loss: 0.2094 - val_output_0_acc: 0.9092 - val_output_1_acc: 0.9112 - val_output_2_acc: 0.9575 - val_output_3_acc: 0.9625 - val_output_4_acc: 0.9372\n",
      "Epoch 155/200\n",
      "4000/4000 [==============================] - 1s 169us/step - loss: 0.5035 - output_0_loss: 0.0961 - output_1_loss: 0.1110 - output_2_loss: 0.0940 - output_3_loss: 0.0959 - output_4_loss: 0.1065 - output_0_acc: 0.9815 - output_1_acc: 0.9750 - output_2_acc: 0.9822 - output_3_acc: 0.9828 - output_4_acc: 0.9768 - val_loss: 0.9744 - val_output_0_loss: 0.1728 - val_output_1_loss: 0.2255 - val_output_2_loss: 0.2044 - val_output_3_loss: 0.1555 - val_output_4_loss: 0.2161 - val_output_0_acc: 0.9592 - val_output_1_acc: 0.9280 - val_output_2_acc: 0.9367 - val_output_3_acc: 0.9692 - val_output_4_acc: 0.9318\n",
      "Epoch 156/200\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.4942 - output_0_loss: 0.0918 - output_1_loss: 0.1157 - output_2_loss: 0.0928 - output_3_loss: 0.0898 - output_4_loss: 0.1041 - output_0_acc: 0.9858 - output_1_acc: 0.9723 - output_2_acc: 0.9845 - output_3_acc: 0.9862 - output_4_acc: 0.9772 - val_loss: 1.0266 - val_output_0_loss: 0.1794 - val_output_1_loss: 0.2386 - val_output_2_loss: 0.2123 - val_output_3_loss: 0.1978 - val_output_4_loss: 0.1986 - val_output_0_acc: 0.9480 - val_output_1_acc: 0.9225 - val_output_2_acc: 0.9302 - val_output_3_acc: 0.9402 - val_output_4_acc: 0.9367\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.4790 - output_0_loss: 0.0874 - output_1_loss: 0.1074 - output_2_loss: 0.0920 - output_3_loss: 0.0899 - output_4_loss: 0.1022 - output_0_acc: 0.9873 - output_1_acc: 0.9765 - output_2_acc: 0.9865 - output_3_acc: 0.9850 - output_4_acc: 0.9778 - val_loss: 1.1430 - val_output_0_loss: 0.2079 - val_output_1_loss: 0.2416 - val_output_2_loss: 0.2620 - val_output_3_loss: 0.1592 - val_output_4_loss: 0.2723 - val_output_0_acc: 0.9345 - val_output_1_acc: 0.9273 - val_output_2_acc: 0.9067 - val_output_3_acc: 0.9627 - val_output_4_acc: 0.9062\n",
      "Epoch 158/200\n",
      "4000/4000 [==============================] - 1s 194us/step - loss: 0.4776 - output_0_loss: 0.0877 - output_1_loss: 0.1097 - output_2_loss: 0.0887 - output_3_loss: 0.0903 - output_4_loss: 0.1011 - output_0_acc: 0.9835 - output_1_acc: 0.9745 - output_2_acc: 0.9848 - output_3_acc: 0.9860 - output_4_acc: 0.9765 - val_loss: 0.9951 - val_output_0_loss: 0.1755 - val_output_1_loss: 0.2090 - val_output_2_loss: 0.2225 - val_output_3_loss: 0.1770 - val_output_4_loss: 0.2111 - val_output_0_acc: 0.9547 - val_output_1_acc: 0.9425 - val_output_2_acc: 0.9258 - val_output_3_acc: 0.9517 - val_output_4_acc: 0.9312\n",
      "Epoch 159/200\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.4639 - output_0_loss: 0.0872 - output_1_loss: 0.1015 - output_2_loss: 0.0870 - output_3_loss: 0.0861 - output_4_loss: 0.1021 - output_0_acc: 0.9865 - output_1_acc: 0.9795 - output_2_acc: 0.9848 - output_3_acc: 0.9850 - output_4_acc: 0.9783 - val_loss: 1.0107 - val_output_0_loss: 0.1996 - val_output_1_loss: 0.2902 - val_output_2_loss: 0.1697 - val_output_3_loss: 0.1769 - val_output_4_loss: 0.1744 - val_output_0_acc: 0.9422 - val_output_1_acc: 0.8995 - val_output_2_acc: 0.9607 - val_output_3_acc: 0.9480 - val_output_4_acc: 0.9547\n",
      "Epoch 160/200\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.4600 - output_0_loss: 0.0868 - output_1_loss: 0.1087 - output_2_loss: 0.0832 - output_3_loss: 0.0822 - output_4_loss: 0.0991 - output_0_acc: 0.9845 - output_1_acc: 0.9760 - output_2_acc: 0.9850 - output_3_acc: 0.9888 - output_4_acc: 0.9795 - val_loss: 0.9570 - val_output_0_loss: 0.1846 - val_output_1_loss: 0.1911 - val_output_2_loss: 0.2005 - val_output_3_loss: 0.1763 - val_output_4_loss: 0.2046 - val_output_0_acc: 0.9460 - val_output_1_acc: 0.9452 - val_output_2_acc: 0.9485 - val_output_3_acc: 0.9512 - val_output_4_acc: 0.9365\n",
      "Epoch 161/200\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.4636 - output_0_loss: 0.0844 - output_1_loss: 0.1019 - output_2_loss: 0.0894 - output_3_loss: 0.0893 - output_4_loss: 0.0986 - output_0_acc: 0.9875 - output_1_acc: 0.9800 - output_2_acc: 0.9843 - output_3_acc: 0.9830 - output_4_acc: 0.9772 - val_loss: 0.9398 - val_output_0_loss: 0.1867 - val_output_1_loss: 0.2238 - val_output_2_loss: 0.1626 - val_output_3_loss: 0.1560 - val_output_4_loss: 0.2106 - val_output_0_acc: 0.9442 - val_output_1_acc: 0.9262 - val_output_2_acc: 0.9547 - val_output_3_acc: 0.9593 - val_output_4_acc: 0.9362\n",
      "Epoch 162/200\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.4394 - output_0_loss: 0.0803 - output_1_loss: 0.1015 - output_2_loss: 0.0811 - output_3_loss: 0.0819 - output_4_loss: 0.0946 - output_0_acc: 0.9865 - output_1_acc: 0.9790 - output_2_acc: 0.9850 - output_3_acc: 0.9870 - output_4_acc: 0.9795 - val_loss: 0.9716 - val_output_0_loss: 0.1596 - val_output_1_loss: 0.2617 - val_output_2_loss: 0.1338 - val_output_3_loss: 0.2176 - val_output_4_loss: 0.1989 - val_output_0_acc: 0.9595 - val_output_1_acc: 0.9148 - val_output_2_acc: 0.9743 - val_output_3_acc: 0.9335 - val_output_4_acc: 0.9415\n",
      "Epoch 163/200\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.4373 - output_0_loss: 0.0804 - output_1_loss: 0.0995 - output_2_loss: 0.0803 - output_3_loss: 0.0823 - output_4_loss: 0.0947 - output_0_acc: 0.9862 - output_1_acc: 0.9783 - output_2_acc: 0.9865 - output_3_acc: 0.9845 - output_4_acc: 0.9800 - val_loss: 0.9450 - val_output_0_loss: 0.1895 - val_output_1_loss: 0.2694 - val_output_2_loss: 0.1487 - val_output_3_loss: 0.1681 - val_output_4_loss: 0.1694 - val_output_0_acc: 0.9385 - val_output_1_acc: 0.9017 - val_output_2_acc: 0.9627 - val_output_3_acc: 0.9588 - val_output_4_acc: 0.9555\n",
      "Epoch 164/200\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.4348 - output_0_loss: 0.0813 - output_1_loss: 0.1008 - output_2_loss: 0.0816 - output_3_loss: 0.0790 - output_4_loss: 0.0919 - output_0_acc: 0.9855 - output_1_acc: 0.9780 - output_2_acc: 0.9870 - output_3_acc: 0.9898 - output_4_acc: 0.9813 - val_loss: 0.9237 - val_output_0_loss: 0.1760 - val_output_1_loss: 0.2141 - val_output_2_loss: 0.1532 - val_output_3_loss: 0.1607 - val_output_4_loss: 0.2196 - val_output_0_acc: 0.9510 - val_output_1_acc: 0.9242 - val_output_2_acc: 0.9682 - val_output_3_acc: 0.9595 - val_output_4_acc: 0.9270\n",
      "Epoch 165/200\n",
      "4000/4000 [==============================] - 1s 199us/step - loss: 0.4173 - output_0_loss: 0.0781 - output_1_loss: 0.0950 - output_2_loss: 0.0782 - output_3_loss: 0.0770 - output_4_loss: 0.0890 - output_0_acc: 0.9873 - output_1_acc: 0.9785 - output_2_acc: 0.9882 - output_3_acc: 0.9880 - output_4_acc: 0.9813 - val_loss: 0.8666 - val_output_0_loss: 0.1991 - val_output_1_loss: 0.1994 - val_output_2_loss: 0.1566 - val_output_3_loss: 0.1321 - val_output_4_loss: 0.1795 - val_output_0_acc: 0.9310 - val_output_1_acc: 0.9438 - val_output_2_acc: 0.9645 - val_output_3_acc: 0.9773 - val_output_4_acc: 0.9443\n",
      "Epoch 166/200\n",
      "4000/4000 [==============================] - 1s 203us/step - loss: 0.4115 - output_0_loss: 0.0777 - output_1_loss: 0.0975 - output_2_loss: 0.0770 - output_3_loss: 0.0747 - output_4_loss: 0.0845 - output_0_acc: 0.9862 - output_1_acc: 0.9783 - output_2_acc: 0.9882 - output_3_acc: 0.9882 - output_4_acc: 0.9843 - val_loss: 0.8750 - val_output_0_loss: 0.2272 - val_output_1_loss: 0.1769 - val_output_2_loss: 0.1579 - val_output_3_loss: 0.1251 - val_output_4_loss: 0.1880 - val_output_0_acc: 0.9167 - val_output_1_acc: 0.9538 - val_output_2_acc: 0.9612 - val_output_3_acc: 0.9752 - val_output_4_acc: 0.9483\n",
      "Epoch 167/200\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.4040 - output_0_loss: 0.0732 - output_1_loss: 0.0922 - output_2_loss: 0.0751 - output_3_loss: 0.0775 - output_4_loss: 0.0860 - output_0_acc: 0.9888 - output_1_acc: 0.9822 - output_2_acc: 0.9888 - output_3_acc: 0.9895 - output_4_acc: 0.9838 - val_loss: 0.9429 - val_output_0_loss: 0.1836 - val_output_1_loss: 0.2401 - val_output_2_loss: 0.1946 - val_output_3_loss: 0.1615 - val_output_4_loss: 0.1631 - val_output_0_acc: 0.9477 - val_output_1_acc: 0.9165 - val_output_2_acc: 0.9413 - val_output_3_acc: 0.9580 - val_output_4_acc: 0.9482\n",
      "Epoch 168/200\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.3955 - output_0_loss: 0.0715 - output_1_loss: 0.0928 - output_2_loss: 0.0732 - output_3_loss: 0.0729 - output_4_loss: 0.0850 - output_0_acc: 0.9878 - output_1_acc: 0.9810 - output_2_acc: 0.9875 - output_3_acc: 0.9882 - output_4_acc: 0.9825 - val_loss: 0.8541 - val_output_0_loss: 0.1527 - val_output_1_loss: 0.1931 - val_output_2_loss: 0.1371 - val_output_3_loss: 0.1808 - val_output_4_loss: 0.1904 - val_output_0_acc: 0.9615 - val_output_1_acc: 0.9390 - val_output_2_acc: 0.9668 - val_output_3_acc: 0.9385 - val_output_4_acc: 0.9377\n",
      "Epoch 169/200\n",
      "4000/4000 [==============================] - 1s 190us/step - loss: 0.3913 - output_0_loss: 0.0731 - output_1_loss: 0.0898 - output_2_loss: 0.0718 - output_3_loss: 0.0709 - output_4_loss: 0.0858 - output_0_acc: 0.9875 - output_1_acc: 0.9840 - output_2_acc: 0.9905 - output_3_acc: 0.9912 - output_4_acc: 0.9808 - val_loss: 0.8552 - val_output_0_loss: 0.1670 - val_output_1_loss: 0.1917 - val_output_2_loss: 0.1406 - val_output_3_loss: 0.1600 - val_output_4_loss: 0.1958 - val_output_0_acc: 0.9522 - val_output_1_acc: 0.9465 - val_output_2_acc: 0.9645 - val_output_3_acc: 0.9578 - val_output_4_acc: 0.9412\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.3831 - output_0_loss: 0.0704 - output_1_loss: 0.0909 - output_2_loss: 0.0684 - output_3_loss: 0.0737 - output_4_loss: 0.0797 - output_0_acc: 0.9873 - output_1_acc: 0.9795 - output_2_acc: 0.9900 - output_3_acc: 0.9888 - output_4_acc: 0.9852 - val_loss: 0.8597 - val_output_0_loss: 0.1716 - val_output_1_loss: 0.2196 - val_output_2_loss: 0.1509 - val_output_3_loss: 0.1467 - val_output_4_loss: 0.1708 - val_output_0_acc: 0.9555 - val_output_1_acc: 0.9277 - val_output_2_acc: 0.9548 - val_output_3_acc: 0.9652 - val_output_4_acc: 0.9468\n",
      "Epoch 171/200\n",
      "4000/4000 [==============================] - 1s 176us/step - loss: 0.3833 - output_0_loss: 0.0706 - output_1_loss: 0.0871 - output_2_loss: 0.0729 - output_3_loss: 0.0690 - output_4_loss: 0.0837 - output_0_acc: 0.9862 - output_1_acc: 0.9843 - output_2_acc: 0.9865 - output_3_acc: 0.9900 - output_4_acc: 0.9798 - val_loss: 0.8132 - val_output_0_loss: 0.1346 - val_output_1_loss: 0.2269 - val_output_2_loss: 0.1526 - val_output_3_loss: 0.1426 - val_output_4_loss: 0.1564 - val_output_0_acc: 0.9618 - val_output_1_acc: 0.9237 - val_output_2_acc: 0.9543 - val_output_3_acc: 0.9633 - val_output_4_acc: 0.9562\n",
      "Epoch 172/200\n",
      "4000/4000 [==============================] - 1s 171us/step - loss: 0.3726 - output_0_loss: 0.0635 - output_1_loss: 0.0864 - output_2_loss: 0.0687 - output_3_loss: 0.0710 - output_4_loss: 0.0829 - output_0_acc: 0.9930 - output_1_acc: 0.9830 - output_2_acc: 0.9905 - output_3_acc: 0.9888 - output_4_acc: 0.9835 - val_loss: 0.8192 - val_output_0_loss: 0.1492 - val_output_1_loss: 0.2224 - val_output_2_loss: 0.1557 - val_output_3_loss: 0.1558 - val_output_4_loss: 0.1361 - val_output_0_acc: 0.9630 - val_output_1_acc: 0.9227 - val_output_2_acc: 0.9533 - val_output_3_acc: 0.9552 - val_output_4_acc: 0.9633\n",
      "Epoch 173/200\n",
      "4000/4000 [==============================] - 1s 177us/step - loss: 0.3593 - output_0_loss: 0.0652 - output_1_loss: 0.0856 - output_2_loss: 0.0661 - output_3_loss: 0.0647 - output_4_loss: 0.0777 - output_0_acc: 0.9900 - output_1_acc: 0.9835 - output_2_acc: 0.9895 - output_3_acc: 0.9922 - output_4_acc: 0.9870 - val_loss: 0.8209 - val_output_0_loss: 0.1988 - val_output_1_loss: 0.1857 - val_output_2_loss: 0.1428 - val_output_3_loss: 0.1367 - val_output_4_loss: 0.1569 - val_output_0_acc: 0.9298 - val_output_1_acc: 0.9487 - val_output_2_acc: 0.9688 - val_output_3_acc: 0.9683 - val_output_4_acc: 0.9532\n",
      "Epoch 174/200\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.3621 - output_0_loss: 0.0673 - output_1_loss: 0.0841 - output_2_loss: 0.0659 - output_3_loss: 0.0680 - output_4_loss: 0.0768 - output_0_acc: 0.9908 - output_1_acc: 0.9830 - output_2_acc: 0.9885 - output_3_acc: 0.9898 - output_4_acc: 0.9840 - val_loss: 0.8155 - val_output_0_loss: 0.1219 - val_output_1_loss: 0.2454 - val_output_2_loss: 0.1182 - val_output_3_loss: 0.1526 - val_output_4_loss: 0.1773 - val_output_0_acc: 0.9732 - val_output_1_acc: 0.9038 - val_output_2_acc: 0.9772 - val_output_3_acc: 0.9482 - val_output_4_acc: 0.9463\n",
      "Epoch 175/200\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.3523 - output_0_loss: 0.0646 - output_1_loss: 0.0838 - output_2_loss: 0.0625 - output_3_loss: 0.0657 - output_4_loss: 0.0756 - output_0_acc: 0.9903 - output_1_acc: 0.9810 - output_2_acc: 0.9908 - output_3_acc: 0.9905 - output_4_acc: 0.9843 - val_loss: 0.7948 - val_output_0_loss: 0.2032 - val_output_1_loss: 0.1800 - val_output_2_loss: 0.1297 - val_output_3_loss: 0.1255 - val_output_4_loss: 0.1564 - val_output_0_acc: 0.9350 - val_output_1_acc: 0.9495 - val_output_2_acc: 0.9697 - val_output_3_acc: 0.9763 - val_output_4_acc: 0.9505\n",
      "Epoch 176/200\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.3411 - output_0_loss: 0.0627 - output_1_loss: 0.0795 - output_2_loss: 0.0623 - output_3_loss: 0.0638 - output_4_loss: 0.0729 - output_0_acc: 0.9915 - output_1_acc: 0.9838 - output_2_acc: 0.9915 - output_3_acc: 0.9903 - output_4_acc: 0.9880 - val_loss: 0.7277 - val_output_0_loss: 0.1149 - val_output_1_loss: 0.1650 - val_output_2_loss: 0.1440 - val_output_3_loss: 0.1362 - val_output_4_loss: 0.1675 - val_output_0_acc: 0.9758 - val_output_1_acc: 0.9500 - val_output_2_acc: 0.9618 - val_output_3_acc: 0.9623 - val_output_4_acc: 0.9440\n",
      "Epoch 177/200\n",
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.3360 - output_0_loss: 0.0598 - output_1_loss: 0.0824 - output_2_loss: 0.0620 - output_3_loss: 0.0619 - output_4_loss: 0.0698 - output_0_acc: 0.9908 - output_1_acc: 0.9800 - output_2_acc: 0.9928 - output_3_acc: 0.9895 - output_4_acc: 0.9860 - val_loss: 0.8782 - val_output_0_loss: 0.1589 - val_output_1_loss: 0.1876 - val_output_2_loss: 0.1807 - val_output_3_loss: 0.1418 - val_output_4_loss: 0.2092 - val_output_0_acc: 0.9550 - val_output_1_acc: 0.9422 - val_output_2_acc: 0.9367 - val_output_3_acc: 0.9663 - val_output_4_acc: 0.9270\n",
      "Epoch 178/200\n",
      "4000/4000 [==============================] - 1s 195us/step - loss: 0.3297 - output_0_loss: 0.0615 - output_1_loss: 0.0755 - output_2_loss: 0.0603 - output_3_loss: 0.0622 - output_4_loss: 0.0702 - output_0_acc: 0.9910 - output_1_acc: 0.9860 - output_2_acc: 0.9908 - output_3_acc: 0.9930 - output_4_acc: 0.9873 - val_loss: 0.7487 - val_output_0_loss: 0.1303 - val_output_1_loss: 0.1977 - val_output_2_loss: 0.1145 - val_output_3_loss: 0.1436 - val_output_4_loss: 0.1626 - val_output_0_acc: 0.9643 - val_output_1_acc: 0.9362 - val_output_2_acc: 0.9763 - val_output_3_acc: 0.9583 - val_output_4_acc: 0.9583\n",
      "Epoch 179/200\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.3254 - output_0_loss: 0.0607 - output_1_loss: 0.0770 - output_2_loss: 0.0599 - output_3_loss: 0.0602 - output_4_loss: 0.0676 - output_0_acc: 0.9903 - output_1_acc: 0.9870 - output_2_acc: 0.9903 - output_3_acc: 0.9930 - output_4_acc: 0.9880 - val_loss: 0.8331 - val_output_0_loss: 0.1272 - val_output_1_loss: 0.1809 - val_output_2_loss: 0.1386 - val_output_3_loss: 0.1651 - val_output_4_loss: 0.2213 - val_output_0_acc: 0.9687 - val_output_1_acc: 0.9460 - val_output_2_acc: 0.9663 - val_output_3_acc: 0.9480 - val_output_4_acc: 0.9142\n",
      "Epoch 180/200\n",
      "4000/4000 [==============================] - 1s 185us/step - loss: 0.3236 - output_0_loss: 0.0589 - output_1_loss: 0.0721 - output_2_loss: 0.0643 - output_3_loss: 0.0592 - output_4_loss: 0.0690 - output_0_acc: 0.9888 - output_1_acc: 0.9868 - output_2_acc: 0.9880 - output_3_acc: 0.9920 - output_4_acc: 0.9873 - val_loss: 0.7394 - val_output_0_loss: 0.1425 - val_output_1_loss: 0.2251 - val_output_2_loss: 0.1202 - val_output_3_loss: 0.1203 - val_output_4_loss: 0.1314 - val_output_0_acc: 0.9563 - val_output_1_acc: 0.9252 - val_output_2_acc: 0.9700 - val_output_3_acc: 0.9665 - val_output_4_acc: 0.9643\n",
      "Epoch 181/200\n",
      "4000/4000 [==============================] - 1s 197us/step - loss: 0.3112 - output_0_loss: 0.0578 - output_1_loss: 0.0750 - output_2_loss: 0.0551 - output_3_loss: 0.0584 - output_4_loss: 0.0649 - output_0_acc: 0.9900 - output_1_acc: 0.9820 - output_2_acc: 0.9928 - output_3_acc: 0.9933 - output_4_acc: 0.9885 - val_loss: 0.7499 - val_output_0_loss: 0.1260 - val_output_1_loss: 0.1771 - val_output_2_loss: 0.1483 - val_output_3_loss: 0.1543 - val_output_4_loss: 0.1442 - val_output_0_acc: 0.9692 - val_output_1_acc: 0.9465 - val_output_2_acc: 0.9607 - val_output_3_acc: 0.9430 - val_output_4_acc: 0.9653\n",
      "Epoch 182/200\n",
      "4000/4000 [==============================] - 1s 193us/step - loss: 0.3033 - output_0_loss: 0.0540 - output_1_loss: 0.0708 - output_2_loss: 0.0571 - output_3_loss: 0.0558 - output_4_loss: 0.0656 - output_0_acc: 0.9920 - output_1_acc: 0.9890 - output_2_acc: 0.9888 - output_3_acc: 0.9928 - output_4_acc: 0.9870 - val_loss: 0.6842 - val_output_0_loss: 0.1481 - val_output_1_loss: 0.1837 - val_output_2_loss: 0.1071 - val_output_3_loss: 0.1154 - val_output_4_loss: 0.1300 - val_output_0_acc: 0.9558 - val_output_1_acc: 0.9428 - val_output_2_acc: 0.9760 - val_output_3_acc: 0.9738 - val_output_4_acc: 0.9647\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 188us/step - loss: 0.3028 - output_0_loss: 0.0556 - output_1_loss: 0.0713 - output_2_loss: 0.0543 - output_3_loss: 0.0565 - output_4_loss: 0.0651 - output_0_acc: 0.9925 - output_1_acc: 0.9845 - output_2_acc: 0.9942 - output_3_acc: 0.9922 - output_4_acc: 0.9868 - val_loss: 0.7205 - val_output_0_loss: 0.1465 - val_output_1_loss: 0.2323 - val_output_2_loss: 0.1048 - val_output_3_loss: 0.1148 - val_output_4_loss: 0.1220 - val_output_0_acc: 0.9550 - val_output_1_acc: 0.9142 - val_output_2_acc: 0.9778 - val_output_3_acc: 0.9732 - val_output_4_acc: 0.9708\n",
      "Epoch 184/200\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.2986 - output_0_loss: 0.0550 - output_1_loss: 0.0687 - output_2_loss: 0.0574 - output_3_loss: 0.0542 - output_4_loss: 0.0633 - output_0_acc: 0.9928 - output_1_acc: 0.9875 - output_2_acc: 0.9900 - output_3_acc: 0.9925 - output_4_acc: 0.9888 - val_loss: 0.8299 - val_output_0_loss: 0.1670 - val_output_1_loss: 0.1669 - val_output_2_loss: 0.2111 - val_output_3_loss: 0.1290 - val_output_4_loss: 0.1559 - val_output_0_acc: 0.9412 - val_output_1_acc: 0.9433 - val_output_2_acc: 0.9190 - val_output_3_acc: 0.9662 - val_output_4_acc: 0.9472\n",
      "Epoch 185/200\n",
      "4000/4000 [==============================] - 1s 187us/step - loss: 0.2945 - output_0_loss: 0.0521 - output_1_loss: 0.0715 - output_2_loss: 0.0541 - output_3_loss: 0.0529 - output_4_loss: 0.0637 - output_0_acc: 0.9925 - output_1_acc: 0.9855 - output_2_acc: 0.9912 - output_3_acc: 0.9920 - output_4_acc: 0.9875 - val_loss: 0.6525 - val_output_0_loss: 0.1203 - val_output_1_loss: 0.1340 - val_output_2_loss: 0.1009 - val_output_3_loss: 0.1586 - val_output_4_loss: 0.1387 - val_output_0_acc: 0.9683 - val_output_1_acc: 0.9655 - val_output_2_acc: 0.9800 - val_output_3_acc: 0.9452 - val_output_4_acc: 0.9603\n",
      "Epoch 186/200\n",
      "4000/4000 [==============================] - 1s 189us/step - loss: 0.2857 - output_0_loss: 0.0529 - output_1_loss: 0.0682 - output_2_loss: 0.0514 - output_3_loss: 0.0518 - output_4_loss: 0.0614 - output_0_acc: 0.9925 - output_1_acc: 0.9862 - output_2_acc: 0.9928 - output_3_acc: 0.9928 - output_4_acc: 0.9890 - val_loss: 0.7752 - val_output_0_loss: 0.1586 - val_output_1_loss: 0.2121 - val_output_2_loss: 0.1061 - val_output_3_loss: 0.1070 - val_output_4_loss: 0.1914 - val_output_0_acc: 0.9440 - val_output_1_acc: 0.9317 - val_output_2_acc: 0.9752 - val_output_3_acc: 0.9812 - val_output_4_acc: 0.9370\n",
      "Epoch 187/200\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.2789 - output_0_loss: 0.0518 - output_1_loss: 0.0663 - output_2_loss: 0.0501 - output_3_loss: 0.0505 - output_4_loss: 0.0602 - output_0_acc: 0.9915 - output_1_acc: 0.9868 - output_2_acc: 0.9925 - output_3_acc: 0.9945 - output_4_acc: 0.9888 - val_loss: 0.6074 - val_output_0_loss: 0.1296 - val_output_1_loss: 0.1460 - val_output_2_loss: 0.0999 - val_output_3_loss: 0.0960 - val_output_4_loss: 0.1358 - val_output_0_acc: 0.9660 - val_output_1_acc: 0.9590 - val_output_2_acc: 0.9790 - val_output_3_acc: 0.9837 - val_output_4_acc: 0.9620\n",
      "Epoch 188/200\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.2763 - output_0_loss: 0.0501 - output_1_loss: 0.0641 - output_2_loss: 0.0526 - output_3_loss: 0.0524 - output_4_loss: 0.0571 - output_0_acc: 0.9952 - output_1_acc: 0.9870 - output_2_acc: 0.9918 - output_3_acc: 0.9940 - output_4_acc: 0.9905 - val_loss: 0.6371 - val_output_0_loss: 0.1014 - val_output_1_loss: 0.1502 - val_output_2_loss: 0.1623 - val_output_3_loss: 0.1066 - val_output_4_loss: 0.1168 - val_output_0_acc: 0.9775 - val_output_1_acc: 0.9560 - val_output_2_acc: 0.9430 - val_output_3_acc: 0.9767 - val_output_4_acc: 0.9680\n",
      "Epoch 189/200\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 0.2717 - output_0_loss: 0.0494 - output_1_loss: 0.0633 - output_2_loss: 0.0494 - output_3_loss: 0.0506 - output_4_loss: 0.0591 - output_0_acc: 0.9922 - output_1_acc: 0.9885 - output_2_acc: 0.9922 - output_3_acc: 0.9933 - output_4_acc: 0.9890 - val_loss: 0.6604 - val_output_0_loss: 0.1281 - val_output_1_loss: 0.1261 - val_output_2_loss: 0.1311 - val_output_3_loss: 0.0881 - val_output_4_loss: 0.1870 - val_output_0_acc: 0.9660 - val_output_1_acc: 0.9697 - val_output_2_acc: 0.9665 - val_output_3_acc: 0.9833 - val_output_4_acc: 0.9375\n",
      "Epoch 190/200\n",
      "4000/4000 [==============================] - 1s 198us/step - loss: 0.2680 - output_0_loss: 0.0456 - output_1_loss: 0.0654 - output_2_loss: 0.0471 - output_3_loss: 0.0507 - output_4_loss: 0.0591 - output_0_acc: 0.9942 - output_1_acc: 0.9878 - output_2_acc: 0.9948 - output_3_acc: 0.9940 - output_4_acc: 0.9888 - val_loss: 0.7075 - val_output_0_loss: 0.1372 - val_output_1_loss: 0.1613 - val_output_2_loss: 0.1190 - val_output_3_loss: 0.1347 - val_output_4_loss: 0.1553 - val_output_0_acc: 0.9640 - val_output_1_acc: 0.9522 - val_output_2_acc: 0.9727 - val_output_3_acc: 0.9627 - val_output_4_acc: 0.9465\n",
      "Epoch 191/200\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.2562 - output_0_loss: 0.0467 - output_1_loss: 0.0594 - output_2_loss: 0.0478 - output_3_loss: 0.0482 - output_4_loss: 0.0541 - output_0_acc: 0.9942 - output_1_acc: 0.9900 - output_2_acc: 0.9925 - output_3_acc: 0.9940 - output_4_acc: 0.9908 - val_loss: 0.7061 - val_output_0_loss: 0.1100 - val_output_1_loss: 0.1768 - val_output_2_loss: 0.1552 - val_output_3_loss: 0.1131 - val_output_4_loss: 0.1510 - val_output_0_acc: 0.9705 - val_output_1_acc: 0.9372 - val_output_2_acc: 0.9530 - val_output_3_acc: 0.9737 - val_output_4_acc: 0.9558\n",
      "Epoch 192/200\n",
      "4000/4000 [==============================] - 1s 180us/step - loss: 0.2572 - output_0_loss: 0.0450 - output_1_loss: 0.0601 - output_2_loss: 0.0476 - output_3_loss: 0.0466 - output_4_loss: 0.0578 - output_0_acc: 0.9935 - output_1_acc: 0.9885 - output_2_acc: 0.9933 - output_3_acc: 0.9942 - output_4_acc: 0.9892 - val_loss: 0.7481 - val_output_0_loss: 0.1417 - val_output_1_loss: 0.1514 - val_output_2_loss: 0.1485 - val_output_3_loss: 0.1802 - val_output_4_loss: 0.1262 - val_output_0_acc: 0.9517 - val_output_1_acc: 0.9553 - val_output_2_acc: 0.9517 - val_output_3_acc: 0.9322 - val_output_4_acc: 0.9632\n",
      "Epoch 193/200\n",
      "4000/4000 [==============================] - 1s 172us/step - loss: 0.2498 - output_0_loss: 0.0449 - output_1_loss: 0.0581 - output_2_loss: 0.0453 - output_3_loss: 0.0472 - output_4_loss: 0.0543 - output_0_acc: 0.9948 - output_1_acc: 0.9895 - output_2_acc: 0.9948 - output_3_acc: 0.9928 - output_4_acc: 0.9903 - val_loss: 0.6439 - val_output_0_loss: 0.1131 - val_output_1_loss: 0.1685 - val_output_2_loss: 0.0963 - val_output_3_loss: 0.1199 - val_output_4_loss: 0.1462 - val_output_0_acc: 0.9702 - val_output_1_acc: 0.9515 - val_output_2_acc: 0.9822 - val_output_3_acc: 0.9645 - val_output_4_acc: 0.9560\n",
      "Epoch 194/200\n",
      "4000/4000 [==============================] - 1s 163us/step - loss: 0.2456 - output_0_loss: 0.0463 - output_1_loss: 0.0587 - output_2_loss: 0.0437 - output_3_loss: 0.0447 - output_4_loss: 0.0523 - output_0_acc: 0.9910 - output_1_acc: 0.9903 - output_2_acc: 0.9945 - output_3_acc: 0.9960 - output_4_acc: 0.9910 - val_loss: 0.6336 - val_output_0_loss: 0.1297 - val_output_1_loss: 0.1592 - val_output_2_loss: 0.1346 - val_output_3_loss: 0.1052 - val_output_4_loss: 0.1049 - val_output_0_acc: 0.9633 - val_output_1_acc: 0.9525 - val_output_2_acc: 0.9662 - val_output_3_acc: 0.9758 - val_output_4_acc: 0.9737\n",
      "Epoch 195/200\n",
      "4000/4000 [==============================] - 1s 165us/step - loss: 0.2374 - output_0_loss: 0.0415 - output_1_loss: 0.0562 - output_2_loss: 0.0418 - output_3_loss: 0.0448 - output_4_loss: 0.0531 - output_0_acc: 0.9945 - output_1_acc: 0.9915 - output_2_acc: 0.9950 - output_3_acc: 0.9963 - output_4_acc: 0.9905 - val_loss: 0.6546 - val_output_0_loss: 0.1222 - val_output_1_loss: 0.1862 - val_output_2_loss: 0.1263 - val_output_3_loss: 0.0925 - val_output_4_loss: 0.1274 - val_output_0_acc: 0.9670 - val_output_1_acc: 0.9288 - val_output_2_acc: 0.9637 - val_output_3_acc: 0.9827 - val_output_4_acc: 0.9613\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 170us/step - loss: 0.2370 - output_0_loss: 0.0415 - output_1_loss: 0.0590 - output_2_loss: 0.0426 - output_3_loss: 0.0455 - output_4_loss: 0.0485 - output_0_acc: 0.9933 - output_1_acc: 0.9870 - output_2_acc: 0.9945 - output_3_acc: 0.9942 - output_4_acc: 0.9925 - val_loss: 0.6560 - val_output_0_loss: 0.1080 - val_output_1_loss: 0.1326 - val_output_2_loss: 0.1175 - val_output_3_loss: 0.1313 - val_output_4_loss: 0.1665 - val_output_0_acc: 0.9735 - val_output_1_acc: 0.9612 - val_output_2_acc: 0.9715 - val_output_3_acc: 0.9627 - val_output_4_acc: 0.9392\n",
      "Epoch 197/200\n",
      "4000/4000 [==============================] - 1s 160us/step - loss: 0.2369 - output_0_loss: 0.0423 - output_1_loss: 0.0552 - output_2_loss: 0.0412 - output_3_loss: 0.0444 - output_4_loss: 0.0538 - output_0_acc: 0.9940 - output_1_acc: 0.9903 - output_2_acc: 0.9963 - output_3_acc: 0.9955 - output_4_acc: 0.9898 - val_loss: 0.5583 - val_output_0_loss: 0.0913 - val_output_1_loss: 0.1636 - val_output_2_loss: 0.0994 - val_output_3_loss: 0.1009 - val_output_4_loss: 0.1031 - val_output_0_acc: 0.9800 - val_output_1_acc: 0.9502 - val_output_2_acc: 0.9732 - val_output_3_acc: 0.9792 - val_output_4_acc: 0.9762\n",
      "Epoch 198/200\n",
      "4000/4000 [==============================] - 1s 182us/step - loss: 0.2242 - output_0_loss: 0.0396 - output_1_loss: 0.0565 - output_2_loss: 0.0398 - output_3_loss: 0.0429 - output_4_loss: 0.0453 - output_0_acc: 0.9952 - output_1_acc: 0.9882 - output_2_acc: 0.9965 - output_3_acc: 0.9948 - output_4_acc: 0.9930 - val_loss: 0.7061 - val_output_0_loss: 0.1454 - val_output_1_loss: 0.1301 - val_output_2_loss: 0.1379 - val_output_3_loss: 0.1383 - val_output_4_loss: 0.1544 - val_output_0_acc: 0.9492 - val_output_1_acc: 0.9600 - val_output_2_acc: 0.9553 - val_output_3_acc: 0.9593 - val_output_4_acc: 0.9460\n",
      "Epoch 199/200\n",
      "4000/4000 [==============================] - 1s 178us/step - loss: 0.2291 - output_0_loss: 0.0439 - output_1_loss: 0.0542 - output_2_loss: 0.0396 - output_3_loss: 0.0420 - output_4_loss: 0.0494 - output_0_acc: 0.9925 - output_1_acc: 0.9885 - output_2_acc: 0.9958 - output_3_acc: 0.9952 - output_4_acc: 0.9915 - val_loss: 0.6422 - val_output_0_loss: 0.1283 - val_output_1_loss: 0.1808 - val_output_2_loss: 0.1068 - val_output_3_loss: 0.0923 - val_output_4_loss: 0.1340 - val_output_0_acc: 0.9610 - val_output_1_acc: 0.9398 - val_output_2_acc: 0.9795 - val_output_3_acc: 0.9772 - val_output_4_acc: 0.9605\n",
      "Epoch 200/200\n",
      "4000/4000 [==============================] - 1s 179us/step - loss: 0.2206 - output_0_loss: 0.0399 - output_1_loss: 0.0515 - output_2_loss: 0.0405 - output_3_loss: 0.0398 - output_4_loss: 0.0488 - output_0_acc: 0.9940 - output_1_acc: 0.9920 - output_2_acc: 0.9940 - output_3_acc: 0.9952 - output_4_acc: 0.9905 - val_loss: 0.5999 - val_output_0_loss: 0.1317 - val_output_1_loss: 0.1252 - val_output_2_loss: 0.0995 - val_output_3_loss: 0.0779 - val_output_4_loss: 0.1657 - val_output_0_acc: 0.9613 - val_output_1_acc: 0.9623 - val_output_2_acc: 0.9785 - val_output_3_acc: 0.9857 - val_output_4_acc: 0.9405\n"
     ]
    }
   ],
   "source": [
    "history = coding_model.fit(x_train, y_train, validation_split=percentage_split, batch_size=32, epochs=nb_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values (of first char only)\n",
    "plt.plot(history.history['output_0_acc'])\n",
    "plt.plot(history.history['val_output_0_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot training & validation loss values (of first char only)\n",
    "plt.plot(history.history['output_0_loss'])\n",
    "plt.plot(history.history['val_output_0_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n",
      "100000/100000 [==============================] - 2s 20us/step\n",
      "loss : 0.608820455379486\n",
      "output_0_loss : 0.12797732916116714\n",
      "output_1_loss : 0.12703988629817964\n",
      "output_2_loss : 0.1091656908273697\n",
      "output_3_loss : 0.08084671403884888\n",
      "output_4_loss : 0.1637908337879181\n",
      "output_0_acc : 0.96503\n",
      "output_1_acc : 0.96431\n",
      "output_2_acc : 0.97602\n",
      "output_3_acc : 0.98366\n",
      "output_4_acc : 0.94185\n"
     ]
    }
   ],
   "source": [
    "nb_words_to_test = 100000\n",
    "\n",
    "x_test = create_inputs(nb_words_to_test, nb_chars, nb_letters)\n",
    "x_test_scaled  = scaler.transform(x_test)\n",
    "\n",
    "y_test_raw = encrypt(x_test, nb_words_to_test, nb_chars)\n",
    "y_test_raw_cate = keras.utils.to_categorical(y_test_raw, nb_letters)\n",
    "\n",
    "# process the y data as useful ANN multiple-outputs data\n",
    "y_test = []\n",
    "for c in range(nb_chars):\n",
    "    # extract each 'char' colomn from the global y_train0 tensor\n",
    "    # in order to have multiplue yi_train outputs tensors\n",
    "    yi_test = y_test_raw_cate[:,c,:]\n",
    "    y_test.append(yi_test)\n",
    "\n",
    "\n",
    "print('\\n# Evaluate on test data')\n",
    "results = coding_model.evaluate(x_test_scaled, y_test, batch_size=128)\n",
    "for r in range(len(results)):\n",
    "    print(coding_model.metrics_names[r],':',results[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llhak', 'zupys', 'ymymg']\n",
      "x_test=\n",
      " [[108 108 104  97 107]\n",
      " [122 117 112 121 115]\n",
      " [121 109 121 109 103]]\n",
      "x_test_scaled=\n",
      " [[-0.1944215  -0.20276551 -0.75594591 -1.67757868 -0.33833488]\n",
      " [ 1.67463093  0.99122139  0.3148938   1.53199765  0.72061624]\n",
      " [ 1.54112718 -0.0701003   1.51958848 -0.07279052 -0.86781044]]\n",
      "-->\n",
      "prediction\n",
      "['11 11 7 0 10', '25 20 15 24 18', '24 12 24 12 6']\n",
      "check prediction\n",
      "y_test=\n",
      " [[11 11  7  0 10]\n",
      " [25 20 15 24 18]\n",
      " [24 12 24 12  6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "nb_words_to_test = 3\n",
    "\n",
    "x_test = create_inputs(nb_words_to_test, nb_chars, nb_letters)\n",
    "print_readable_inputs(x_test)\n",
    "print(\"x_test=\\n\", x_test)\n",
    "\n",
    "x_test_scaled  = scaler.transform(x_test)\n",
    "print(\"x_test_scaled=\\n\", x_test_scaled)\n",
    "print('-->')\n",
    "\n",
    "prediction = coding_model.predict(x_test_scaled)\n",
    "#print(prediction)\n",
    "print('prediction')\n",
    "print_readable_outputs(prediction, nb_words_to_test, nb_chars)\n",
    "\n",
    "print('check prediction')\n",
    "y_test = encrypt(x_test, nb_words_to_test, nb_chars)\n",
    "print(\"y_test=\\n\", y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
