{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of characters in a word.\n",
    "# for instance abccba has nb_chars = 6\n",
    "nb_chars = 5\n",
    "\n",
    "# number of possible characters used during the encoding.\n",
    "# for instance abcde leads to 01234 has nb_letters = 5\n",
    "nb_letters = 26\n",
    "\n",
    "# number of words samples to be generated \n",
    "nb_words = 10000\n",
    "\n",
    "# percentage of words that will be used for validation\n",
    "percentage_split = 0.60\n",
    "\n",
    "# number of epochs for fitting the model training step\n",
    "nb_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11881376"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of combinations\n",
    "nb_letters**nb_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inputs(nb_words, nb_chars, nb_letters):\n",
    "    '''Create a numpy array of nb_words rows with nb_chars columns each element\n",
    "    being a random letter of nb_letters (a, b...)'''\n",
    "    words = np.zeros((nb_words, nb_chars), dtype=int)\n",
    "    \n",
    "    for w in range(nb_words):\n",
    "        optim_tentative = False\n",
    "        if optim_tentative == True and w%10 != 0:\n",
    "            i = random.randint(0, nb_letters-1)\n",
    "            for c in range(nb_chars):\n",
    "                words[w, c] = ord('a') + i\n",
    "        else:\n",
    "            for c in range(nb_chars):\n",
    "                i = random.randint(0, nb_letters-1)\n",
    "                words[w, c] = ord('a') + i\n",
    "                \n",
    "    return words\n",
    "\n",
    "\n",
    "def encrypt(words, nb_words, nb_chars):\n",
    "    '''Encrypt each element of a numpy array of nb_words rows with nb_chars \n",
    "    columns each item with a secret algorithm'''\n",
    "    \n",
    "    encrypted_words = words.copy()\n",
    "    encrypted_words_probs = np.zeros((nb_words, nb_chars, nb_chars))\n",
    "    \n",
    "    #val_max = -1\n",
    "    \n",
    "    for w in range(nb_words):\n",
    "        for c in range(nb_chars): # 0,1,2,3,4\n",
    "            encrypted_words[w,c] = int(words[w,c]) - 49\n",
    "            val = encrypted_words[w,c] - 48\n",
    "            \n",
    "            #if val > val_max:\n",
    "            #    val_max = val\n",
    "            \n",
    "            # add entropy (i.e. mistakes in the encryption)\n",
    "            #epsilon = random.randint(0, 100)\n",
    "            #if epsilon == 5 and val != val_max:\n",
    "            #val +=1\n",
    "            \n",
    "            #print('w:',w,', c:',c,', [wc]:', val)\n",
    "            #encrypted_words_probs[w, c, val ] = 1.0\n",
    "            encrypted_words[w,c] = val\n",
    "    return encrypted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(nb_chars, nb_letters):\n",
    "\n",
    "    # This returns a tensor\n",
    "    inputs = layers.Input(shape=(nb_chars,), dtype='float32', name='main_input')\n",
    "    #original_inputs = tf.keras.Input(shape=(original_dim,), name='encoder_input')\n",
    "\n",
    "    # a layer instance is callable on a tensor, and returns a tensor\n",
    "    x = layers.Dense(4096, activation='relu', name='hl_1')(inputs)\n",
    "    #x = layers.Dense(2048, activation='relu', name='hl_1')(inputs)\n",
    "    #x = layers.Dense(64, activation='relu', name='hl_2')(x)\n",
    "\n",
    "    outputs = []\n",
    "    losses = {}\n",
    "    for o in range(nb_chars):\n",
    "        name_i = 'output_'+str(o)\n",
    "        output_i = layers.Dense(nb_letters, activation='softmax', dtype='float32', name=name_i)(x)\n",
    "        outputs.append(output_i)\n",
    "        losses[name_i] = 'categorical_crossentropy'\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    rmsprop = tf.keras.optimizers.RMSprop(lr=0.01)\n",
    "\n",
    "    model.compile(optimizer=rmsprop,\n",
    "                         loss=losses,\n",
    "                         metrics=['accuracy'])       \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_readable_inputs(x):\n",
    "    words = []\n",
    "    for w in x:\n",
    "        word = ''\n",
    "        for c in w:\n",
    "            word += chr(c)\n",
    "        words.append(word)\n",
    "   \n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_readable_outputs_(outputs, nb_words, nb_chars):\n",
    "    \n",
    "    # outputs are listed : first, per char, second by sample, third by letter probability\n",
    "    words = [''] * nb_words\n",
    "    \n",
    "    c_i = 0\n",
    "    for char in outputs:\n",
    "\n",
    "        s_i = 0\n",
    "        for sample in char:\n",
    "\n",
    "            l_i = 0\n",
    "            best_value = -float('inf')\n",
    "            best_letter = -1\n",
    "            for letter_probs in sample:\n",
    "                if letter_probs > best_value:\n",
    "                    best_value = letter_probs\n",
    "                    best_letter = l_i\n",
    "                l_i += 1\n",
    "            words[s_i] += str(best_letter)\n",
    "            if c_i != nb_chars - 1:\n",
    "                words[s_i] += ' '\n",
    "            s_i += 1\n",
    "        c_i += 1\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_readable_outputs(outputs, nb_words, nb_chars):\n",
    "    \n",
    "    # outputs are listed : first, per char, second by sample, third by letter probability\n",
    "    words = [''] * nb_words\n",
    "    c_i = 0\n",
    "    for char in outputs:\n",
    "        s_i = 0\n",
    "        for sample in char:\n",
    "            best_letter = np.argmax(sample)\n",
    "            words[s_i] += str(best_letter)\n",
    "            if c_i != nb_chars - 1:\n",
    "                words[s_i] += ' '\n",
    "            s_i += 1\n",
    "        c_i += 1\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (as readable inputs)\n",
      "['aczcl', 'rznos', 'zpcfr', 'ltwkl']\n",
      "x (partial):\n",
      " [[ 97  99 122  99 108]\n",
      " [114 122 110 111 115]\n",
      " [122 112  99 102 114]\n",
      " [108 116 119 107 108]] out of  10000\n",
      "\n",
      "x_train:\n",
      " [[-1.67591811 -1.40066029  1.66497155 -1.38082529 -0.18851213]\n",
      " [ 0.5959696   1.69835433  0.06856563  0.20861389  0.74696563]\n",
      " [ 1.66509323  0.35095667 -1.39480646 -0.98346549  0.61332595]\n",
      " [-0.20587312  0.88991573  1.26587007 -0.32119917 -0.18851213]] out of  10000\n",
      "\n",
      "y (readable):\n",
      " [[ 0  2 25  2 11]\n",
      " [17 25 13 14 18]\n",
      " [25 15  2  5 17]\n",
      " ...\n",
      " [25 13 22 19 10]\n",
      " [18 14 11 22 20]\n",
      " [ 3  6  1  5 17]]\n",
      "\n",
      "y (less readable):\n",
      " [[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]] out of  10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = create_inputs(nb_words, nb_chars, nb_letters)\n",
    "print('x: (as readable inputs)')\n",
    "\n",
    "first_n_samples = 4\n",
    "\n",
    "print_readable_inputs(x[:first_n_samples])\n",
    "print('x (partial):\\n', x[:first_n_samples], 'out of ',len(x))\n",
    "print()\n",
    "\n",
    "# process the x data as useful ANN input data\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "x_train  = scaler.fit_transform(x)\n",
    "\n",
    "print('x_train:\\n', x_train[:first_n_samples], 'out of ',len(x_train))\n",
    "print()\n",
    "\n",
    "# create output data for training\n",
    "y = encrypt(x, nb_words, nb_chars)\n",
    "print('y (readable):\\n', y)\n",
    "print()\n",
    "\n",
    "# process the y data as useful ANN output data\n",
    "y_train0 = keras.utils.to_categorical(y, nb_letters)\n",
    "print('y (less readable):\\n', y_train0[:first_n_samples], 'out of ',len(y_train0))\n",
    "print('')\n",
    "\n",
    "# process the y data as useful ANN multiple-outputs data\n",
    "y_train = []\n",
    "for c in range(nb_chars):\n",
    "    # extract each 'char' colomn from the global y_train0 tensor\n",
    "    # in order to have multiplue yi_train outputs tensors\n",
    "    yi_train = y_train0[:,c,:]\n",
    "    y_train.append(yi_train)\n",
    "\n",
    "# Not really displayable, henced commented\n",
    "#print('y_train):')\n",
    "#print(y_train[:first_n_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hl_1 (Dense)                    (None, 4096)         24576       main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output_0 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_2 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_3 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_4 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 557,186\n",
      "Trainable params: 557,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "coding_model = build_model(nb_chars, nb_letters)\n",
    "print(coding_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 6000 samples\n",
      "Epoch 1/200\n",
      "4000/4000 [==============================] - 3s 795us/sample - loss: 12.4259 - output_0_loss: 2.4962 - output_1_loss: 2.5010 - output_2_loss: 2.4917 - output_3_loss: 2.4624 - output_4_loss: 2.4746 - output_0_accuracy: 0.1670 - output_1_accuracy: 0.1657 - output_2_accuracy: 0.1610 - output_3_accuracy: 0.1782 - output_4_accuracy: 0.1737 - val_loss: 10.5854 - val_output_0_loss: 2.1498 - val_output_1_loss: 2.1396 - val_output_2_loss: 2.0700 - val_output_3_loss: 2.1019 - val_output_4_loss: 2.1258 - val_output_0_accuracy: 0.2168 - val_output_1_accuracy: 0.2273 - val_output_2_accuracy: 0.2450 - val_output_3_accuracy: 0.2208 - val_output_4_accuracy: 0.2243\n",
      "Epoch 2/200\n",
      "4000/4000 [==============================] - 1s 324us/sample - loss: 9.1913 - output_0_loss: 1.8639 - output_1_loss: 1.8375 - output_2_loss: 1.8418 - output_3_loss: 1.8165 - output_4_loss: 1.8316 - output_0_accuracy: 0.2957 - output_1_accuracy: 0.2957 - output_2_accuracy: 0.2940 - output_3_accuracy: 0.3115 - output_4_accuracy: 0.2977 - val_loss: 8.5550 - val_output_0_loss: 1.7295 - val_output_1_loss: 1.6768 - val_output_2_loss: 1.7188 - val_output_3_loss: 1.7340 - val_output_4_loss: 1.6962 - val_output_0_accuracy: 0.3103 - val_output_1_accuracy: 0.3328 - val_output_2_accuracy: 0.3528 - val_output_3_accuracy: 0.3327 - val_output_4_accuracy: 0.3413\n",
      "Epoch 3/200\n",
      "4000/4000 [==============================] - 1s 315us/sample - loss: 7.8026 - output_0_loss: 1.5698 - output_1_loss: 1.5661 - output_2_loss: 1.5656 - output_3_loss: 1.5513 - output_4_loss: 1.5498 - output_0_accuracy: 0.3772 - output_1_accuracy: 0.3905 - output_2_accuracy: 0.3697 - output_3_accuracy: 0.3862 - output_4_accuracy: 0.3820 - val_loss: 7.6455 - val_output_0_loss: 1.5781 - val_output_1_loss: 1.5031 - val_output_2_loss: 1.4990 - val_output_3_loss: 1.6106 - val_output_4_loss: 1.4541 - val_output_0_accuracy: 0.3567 - val_output_1_accuracy: 0.3898 - val_output_2_accuracy: 0.3712 - val_output_3_accuracy: 0.3802 - val_output_4_accuracy: 0.4132\n",
      "Epoch 4/200\n",
      "4000/4000 [==============================] - 1s 311us/sample - loss: 6.9360 - output_0_loss: 1.3818 - output_1_loss: 1.4009 - output_2_loss: 1.4089 - output_3_loss: 1.3806 - output_4_loss: 1.3638 - output_0_accuracy: 0.4535 - output_1_accuracy: 0.4372 - output_2_accuracy: 0.4408 - output_3_accuracy: 0.4375 - output_4_accuracy: 0.4498 - val_loss: 6.7876 - val_output_0_loss: 1.3753 - val_output_1_loss: 1.2814 - val_output_2_loss: 1.4070 - val_output_3_loss: 1.3743 - val_output_4_loss: 1.3508 - val_output_0_accuracy: 0.4285 - val_output_1_accuracy: 0.4635 - val_output_2_accuracy: 0.4138 - val_output_3_accuracy: 0.4247 - val_output_4_accuracy: 0.4357\n",
      "Epoch 5/200\n",
      "4000/4000 [==============================] - 2s 477us/sample - loss: 6.2853 - output_0_loss: 1.2563 - output_1_loss: 1.2529 - output_2_loss: 1.2591 - output_3_loss: 1.2654 - output_4_loss: 1.2515 - output_0_accuracy: 0.4950 - output_1_accuracy: 0.4908 - output_2_accuracy: 0.4877 - output_3_accuracy: 0.4852 - output_4_accuracy: 0.4800 - val_loss: 6.1823 - val_output_0_loss: 1.2249 - val_output_1_loss: 1.2785 - val_output_2_loss: 1.1554 - val_output_3_loss: 1.2294 - val_output_4_loss: 1.2946 - val_output_0_accuracy: 0.4897 - val_output_1_accuracy: 0.4702 - val_output_2_accuracy: 0.5322 - val_output_3_accuracy: 0.4973 - val_output_4_accuracy: 0.4895\n",
      "Epoch 6/200\n",
      "4000/4000 [==============================] - 2s 557us/sample - loss: 5.7938 - output_0_loss: 1.1641 - output_1_loss: 1.1544 - output_2_loss: 1.1612 - output_3_loss: 1.1664 - output_4_loss: 1.1476 - output_0_accuracy: 0.5195 - output_1_accuracy: 0.5320 - output_2_accuracy: 0.5225 - output_3_accuracy: 0.5092 - output_4_accuracy: 0.5310 - val_loss: 5.8680 - val_output_0_loss: 1.2227 - val_output_1_loss: 1.1348 - val_output_2_loss: 1.1864 - val_output_3_loss: 1.1327 - val_output_4_loss: 1.1927 - val_output_0_accuracy: 0.4957 - val_output_1_accuracy: 0.5130 - val_output_2_accuracy: 0.4963 - val_output_3_accuracy: 0.5203 - val_output_4_accuracy: 0.5168\n",
      "Epoch 7/200\n",
      "4000/4000 [==============================] - 2s 494us/sample - loss: 5.3268 - output_0_loss: 1.0811 - output_1_loss: 1.0575 - output_2_loss: 1.0743 - output_3_loss: 1.0618 - output_4_loss: 1.0521 - output_0_accuracy: 0.5567 - output_1_accuracy: 0.5717 - output_2_accuracy: 0.5605 - output_3_accuracy: 0.5605 - output_4_accuracy: 0.5620 - val_loss: 5.3498 - val_output_0_loss: 1.1113 - val_output_1_loss: 1.0245 - val_output_2_loss: 1.0556 - val_output_3_loss: 1.1184 - val_output_4_loss: 1.0412 - val_output_0_accuracy: 0.5310 - val_output_1_accuracy: 0.5783 - val_output_2_accuracy: 0.5543 - val_output_3_accuracy: 0.5260 - val_output_4_accuracy: 0.5668\n",
      "Epoch 8/200\n",
      "4000/4000 [==============================] - 1s 321us/sample - loss: 4.9813 - output_0_loss: 0.9894 - output_1_loss: 0.9955 - output_2_loss: 0.9903 - output_3_loss: 1.0075 - output_4_loss: 0.9985 - output_0_accuracy: 0.5903 - output_1_accuracy: 0.5922 - output_2_accuracy: 0.6018 - output_3_accuracy: 0.5813 - output_4_accuracy: 0.5875 - val_loss: 5.1007 - val_output_0_loss: 1.0389 - val_output_1_loss: 1.0430 - val_output_2_loss: 0.9837 - val_output_3_loss: 1.0324 - val_output_4_loss: 1.0044 - val_output_0_accuracy: 0.5607 - val_output_1_accuracy: 0.5568 - val_output_2_accuracy: 0.5867 - val_output_3_accuracy: 0.5778 - val_output_4_accuracy: 0.5725\n",
      "Epoch 9/200\n",
      "4000/4000 [==============================] - 1s 308us/sample - loss: 4.6605 - output_0_loss: 0.9330 - output_1_loss: 0.9157 - output_2_loss: 0.9245 - output_3_loss: 0.9379 - output_4_loss: 0.9494 - output_0_accuracy: 0.6205 - output_1_accuracy: 0.6227 - output_2_accuracy: 0.6275 - output_3_accuracy: 0.6168 - output_4_accuracy: 0.6085 - val_loss: 4.9009 - val_output_0_loss: 1.0082 - val_output_1_loss: 0.9194 - val_output_2_loss: 0.9433 - val_output_3_loss: 1.0083 - val_output_4_loss: 1.0230 - val_output_0_accuracy: 0.5938 - val_output_1_accuracy: 0.6527 - val_output_2_accuracy: 0.5935 - val_output_3_accuracy: 0.5727 - val_output_4_accuracy: 0.5747\n",
      "Epoch 10/200\n",
      "4000/4000 [==============================] - 1s 301us/sample - loss: 4.3729 - output_0_loss: 0.8749 - output_1_loss: 0.8512 - output_2_loss: 0.8912 - output_3_loss: 0.8698 - output_4_loss: 0.8856 - output_0_accuracy: 0.6413 - output_1_accuracy: 0.6550 - output_2_accuracy: 0.6308 - output_3_accuracy: 0.6465 - output_4_accuracy: 0.6388 - val_loss: 4.4847 - val_output_0_loss: 0.9175 - val_output_1_loss: 0.9057 - val_output_2_loss: 0.8747 - val_output_3_loss: 0.9762 - val_output_4_loss: 0.8102 - val_output_0_accuracy: 0.6343 - val_output_1_accuracy: 0.6147 - val_output_2_accuracy: 0.6498 - val_output_3_accuracy: 0.5902 - val_output_4_accuracy: 0.6673\n",
      "Epoch 11/200\n",
      "4000/4000 [==============================] - 1s 302us/sample - loss: 4.0963 - output_0_loss: 0.8115 - output_1_loss: 0.7958 - output_2_loss: 0.8243 - output_3_loss: 0.8411 - output_4_loss: 0.8236 - output_0_accuracy: 0.6773 - output_1_accuracy: 0.6837 - output_2_accuracy: 0.6630 - output_3_accuracy: 0.6605 - output_4_accuracy: 0.6662 - val_loss: 4.4940 - val_output_0_loss: 0.8676 - val_output_1_loss: 0.8563 - val_output_2_loss: 0.8440 - val_output_3_loss: 0.8884 - val_output_4_loss: 1.0390 - val_output_0_accuracy: 0.6435 - val_output_1_accuracy: 0.6470 - val_output_2_accuracy: 0.6505 - val_output_3_accuracy: 0.6402 - val_output_4_accuracy: 0.5685\n",
      "Epoch 12/200\n",
      "4000/4000 [==============================] - 1s 325us/sample - loss: 3.8858 - output_0_loss: 0.7763 - output_1_loss: 0.7707 - output_2_loss: 0.7785 - output_3_loss: 0.7878 - output_4_loss: 0.7724 - output_0_accuracy: 0.6850 - output_1_accuracy: 0.6892 - output_2_accuracy: 0.6860 - output_3_accuracy: 0.6817 - output_4_accuracy: 0.6837 - val_loss: 4.3233 - val_output_0_loss: 0.9015 - val_output_1_loss: 0.7425 - val_output_2_loss: 0.8823 - val_output_3_loss: 0.9404 - val_output_4_loss: 0.8582 - val_output_0_accuracy: 0.6363 - val_output_1_accuracy: 0.7043 - val_output_2_accuracy: 0.6502 - val_output_3_accuracy: 0.6050 - val_output_4_accuracy: 0.6363\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 2s 415us/sample - loss: 3.6664 - output_0_loss: 0.7432 - output_1_loss: 0.7248 - output_2_loss: 0.7285 - output_3_loss: 0.7314 - output_4_loss: 0.7385 - output_0_accuracy: 0.6988 - output_1_accuracy: 0.7157 - output_2_accuracy: 0.7125 - output_3_accuracy: 0.7057 - output_4_accuracy: 0.7063 - val_loss: 3.8964 - val_output_0_loss: 0.7415 - val_output_1_loss: 0.7711 - val_output_2_loss: 0.7299 - val_output_3_loss: 0.8783 - val_output_4_loss: 0.7766 - val_output_0_accuracy: 0.7043 - val_output_1_accuracy: 0.6865 - val_output_2_accuracy: 0.7162 - val_output_3_accuracy: 0.6305 - val_output_4_accuracy: 0.6937\n",
      "Epoch 14/200\n",
      "4000/4000 [==============================] - 2s 423us/sample - loss: 3.4509 - output_0_loss: 0.7011 - output_1_loss: 0.6761 - output_2_loss: 0.6881 - output_3_loss: 0.6864 - output_4_loss: 0.6993 - output_0_accuracy: 0.7235 - output_1_accuracy: 0.7390 - output_2_accuracy: 0.7225 - output_3_accuracy: 0.7318 - output_4_accuracy: 0.7185 - val_loss: 3.7731 - val_output_0_loss: 0.7534 - val_output_1_loss: 0.6964 - val_output_2_loss: 0.7832 - val_output_3_loss: 0.7990 - val_output_4_loss: 0.7437 - val_output_0_accuracy: 0.6982 - val_output_1_accuracy: 0.7202 - val_output_2_accuracy: 0.6865 - val_output_3_accuracy: 0.6667 - val_output_4_accuracy: 0.7273\n",
      "Epoch 15/200\n",
      "4000/4000 [==============================] - 1s 340us/sample - loss: 3.2328 - output_0_loss: 0.6470 - output_1_loss: 0.6344 - output_2_loss: 0.6329 - output_3_loss: 0.6587 - output_4_loss: 0.6598 - output_0_accuracy: 0.7452 - output_1_accuracy: 0.7448 - output_2_accuracy: 0.7498 - output_3_accuracy: 0.7347 - output_4_accuracy: 0.7398 - val_loss: 3.7333 - val_output_0_loss: 0.7247 - val_output_1_loss: 0.8492 - val_output_2_loss: 0.7564 - val_output_3_loss: 0.7228 - val_output_4_loss: 0.6790 - val_output_0_accuracy: 0.7075 - val_output_1_accuracy: 0.6612 - val_output_2_accuracy: 0.6927 - val_output_3_accuracy: 0.7078 - val_output_4_accuracy: 0.7402\n",
      "Epoch 16/200\n",
      "4000/4000 [==============================] - 3s 630us/sample - loss: 3.0572 - output_0_loss: 0.6031 - output_1_loss: 0.5955 - output_2_loss: 0.6117 - output_3_loss: 0.6213 - output_4_loss: 0.6256 - output_0_accuracy: 0.7602 - output_1_accuracy: 0.7642 - output_2_accuracy: 0.7555 - output_3_accuracy: 0.7573 - output_4_accuracy: 0.7600 - val_loss: 3.6334 - val_output_0_loss: 0.7044 - val_output_1_loss: 0.7441 - val_output_2_loss: 0.7761 - val_output_3_loss: 0.6904 - val_output_4_loss: 0.7198 - val_output_0_accuracy: 0.7342 - val_output_1_accuracy: 0.6718 - val_output_2_accuracy: 0.6870 - val_output_3_accuracy: 0.7435 - val_output_4_accuracy: 0.7167\n",
      "Epoch 17/200\n",
      "4000/4000 [==============================] - 2s 507us/sample - loss: 2.8669 - output_0_loss: 0.5770 - output_1_loss: 0.5650 - output_2_loss: 0.5709 - output_3_loss: 0.5865 - output_4_loss: 0.5674 - output_0_accuracy: 0.7810 - output_1_accuracy: 0.7922 - output_2_accuracy: 0.7825 - output_3_accuracy: 0.7665 - output_4_accuracy: 0.7775 - val_loss: 3.0934 - val_output_0_loss: 0.6438 - val_output_1_loss: 0.5453 - val_output_2_loss: 0.6044 - val_output_3_loss: 0.6889 - val_output_4_loss: 0.6125 - val_output_0_accuracy: 0.7397 - val_output_1_accuracy: 0.8103 - val_output_2_accuracy: 0.7705 - val_output_3_accuracy: 0.7288 - val_output_4_accuracy: 0.7715\n",
      "Epoch 18/200\n",
      "4000/4000 [==============================] - 3s 628us/sample - loss: 2.7325 - output_0_loss: 0.5436 - output_1_loss: 0.5379 - output_2_loss: 0.5408 - output_3_loss: 0.5596 - output_4_loss: 0.5506 - output_0_accuracy: 0.7908 - output_1_accuracy: 0.7952 - output_2_accuracy: 0.7903 - output_3_accuracy: 0.7830 - output_4_accuracy: 0.7890 - val_loss: 3.1242 - val_output_0_loss: 0.6127 - val_output_1_loss: 0.6114 - val_output_2_loss: 0.6751 - val_output_3_loss: 0.6377 - val_output_4_loss: 0.5867 - val_output_0_accuracy: 0.7602 - val_output_1_accuracy: 0.7700 - val_output_2_accuracy: 0.7278 - val_output_3_accuracy: 0.7378 - val_output_4_accuracy: 0.7695\n",
      "Epoch 19/200\n",
      "4000/4000 [==============================] - 1s 315us/sample - loss: 2.5810 - output_0_loss: 0.5131 - output_1_loss: 0.5009 - output_2_loss: 0.5164 - output_3_loss: 0.5263 - output_4_loss: 0.5244 - output_0_accuracy: 0.8108 - output_1_accuracy: 0.8163 - output_2_accuracy: 0.8050 - output_3_accuracy: 0.8037 - output_4_accuracy: 0.8033 - val_loss: 3.2898 - val_output_0_loss: 0.5289 - val_output_1_loss: 0.7429 - val_output_2_loss: 0.7566 - val_output_3_loss: 0.6765 - val_output_4_loss: 0.5860 - val_output_0_accuracy: 0.7993 - val_output_1_accuracy: 0.7215 - val_output_2_accuracy: 0.6995 - val_output_3_accuracy: 0.7515 - val_output_4_accuracy: 0.7820\n",
      "Epoch 20/200\n",
      "4000/4000 [==============================] - 1s 320us/sample - loss: 2.4363 - output_0_loss: 0.4832 - output_1_loss: 0.4744 - output_2_loss: 0.4847 - output_3_loss: 0.5018 - output_4_loss: 0.4922 - output_0_accuracy: 0.8115 - output_1_accuracy: 0.8270 - output_2_accuracy: 0.8253 - output_3_accuracy: 0.8125 - output_4_accuracy: 0.8177 - val_loss: 3.0230 - val_output_0_loss: 0.5870 - val_output_1_loss: 0.5328 - val_output_2_loss: 0.5315 - val_output_3_loss: 0.6521 - val_output_4_loss: 0.7197 - val_output_0_accuracy: 0.8040 - val_output_1_accuracy: 0.7947 - val_output_2_accuracy: 0.8012 - val_output_3_accuracy: 0.7377 - val_output_4_accuracy: 0.7470\n",
      "Epoch 21/200\n",
      "4000/4000 [==============================] - 1s 324us/sample - loss: 2.3004 - output_0_loss: 0.4433 - output_1_loss: 0.4620 - output_2_loss: 0.4534 - output_3_loss: 0.4778 - output_4_loss: 0.4638 - output_0_accuracy: 0.8390 - output_1_accuracy: 0.8310 - output_2_accuracy: 0.8445 - output_3_accuracy: 0.8248 - output_4_accuracy: 0.8347 - val_loss: 2.7311 - val_output_0_loss: 0.6055 - val_output_1_loss: 0.5261 - val_output_2_loss: 0.5400 - val_output_3_loss: 0.5898 - val_output_4_loss: 0.4702 - val_output_0_accuracy: 0.7772 - val_output_1_accuracy: 0.7930 - val_output_2_accuracy: 0.7982 - val_output_3_accuracy: 0.7692 - val_output_4_accuracy: 0.8445\n",
      "Epoch 22/200\n",
      "4000/4000 [==============================] - 1s 308us/sample - loss: 2.2000 - output_0_loss: 0.4297 - output_1_loss: 0.4402 - output_2_loss: 0.4367 - output_3_loss: 0.4478 - output_4_loss: 0.4456 - output_0_accuracy: 0.8360 - output_1_accuracy: 0.8355 - output_2_accuracy: 0.8413 - output_3_accuracy: 0.8357 - output_4_accuracy: 0.8340 - val_loss: 2.7672 - val_output_0_loss: 0.4555 - val_output_1_loss: 0.5432 - val_output_2_loss: 0.8023 - val_output_3_loss: 0.4939 - val_output_4_loss: 0.4741 - val_output_0_accuracy: 0.8332 - val_output_1_accuracy: 0.8035 - val_output_2_accuracy: 0.7240 - val_output_3_accuracy: 0.8102 - val_output_4_accuracy: 0.8267\n",
      "Epoch 23/200\n",
      "4000/4000 [==============================] - 1s 305us/sample - loss: 2.0520 - output_0_loss: 0.3908 - output_1_loss: 0.4188 - output_2_loss: 0.4134 - output_3_loss: 0.4165 - output_4_loss: 0.4125 - output_0_accuracy: 0.8568 - output_1_accuracy: 0.8522 - output_2_accuracy: 0.8413 - output_3_accuracy: 0.8432 - output_4_accuracy: 0.8468 - val_loss: 2.5516 - val_output_0_loss: 0.6490 - val_output_1_loss: 0.4850 - val_output_2_loss: 0.4330 - val_output_3_loss: 0.5726 - val_output_4_loss: 0.4117 - val_output_0_accuracy: 0.7498 - val_output_1_accuracy: 0.8268 - val_output_2_accuracy: 0.8457 - val_output_3_accuracy: 0.7735 - val_output_4_accuracy: 0.8532\n",
      "Epoch 24/200\n",
      "4000/4000 [==============================] - 1s 290us/sample - loss: 1.9320 - output_0_loss: 0.3831 - output_1_loss: 0.3745 - output_2_loss: 0.3904 - output_3_loss: 0.3923 - output_4_loss: 0.3917 - output_0_accuracy: 0.8620 - output_1_accuracy: 0.8675 - output_2_accuracy: 0.8612 - output_3_accuracy: 0.8615 - output_4_accuracy: 0.8570 - val_loss: 2.7173 - val_output_0_loss: 0.5594 - val_output_1_loss: 0.5386 - val_output_2_loss: 0.5758 - val_output_3_loss: 0.5716 - val_output_4_loss: 0.4723 - val_output_0_accuracy: 0.8100 - val_output_1_accuracy: 0.8080 - val_output_2_accuracy: 0.7885 - val_output_3_accuracy: 0.7882 - val_output_4_accuracy: 0.8215\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 291us/sample - loss: 1.8553 - output_0_loss: 0.3649 - output_1_loss: 0.3666 - output_2_loss: 0.3601 - output_3_loss: 0.3851 - output_4_loss: 0.3785 - output_0_accuracy: 0.8700 - output_1_accuracy: 0.8700 - output_2_accuracy: 0.8723 - output_3_accuracy: 0.8605 - output_4_accuracy: 0.8608 - val_loss: 2.1822 - val_output_0_loss: 0.4864 - val_output_1_loss: 0.3797 - val_output_2_loss: 0.4432 - val_output_3_loss: 0.4051 - val_output_4_loss: 0.4668 - val_output_0_accuracy: 0.8108 - val_output_1_accuracy: 0.8645 - val_output_2_accuracy: 0.8262 - val_output_3_accuracy: 0.8607 - val_output_4_accuracy: 0.8233\n",
      "Epoch 26/200\n",
      "4000/4000 [==============================] - 1s 316us/sample - loss: 1.7265 - output_0_loss: 0.3288 - output_1_loss: 0.3447 - output_2_loss: 0.3394 - output_3_loss: 0.3637 - output_4_loss: 0.3499 - output_0_accuracy: 0.8870 - output_1_accuracy: 0.8823 - output_2_accuracy: 0.8775 - output_3_accuracy: 0.8683 - output_4_accuracy: 0.8750 - val_loss: 2.1978 - val_output_0_loss: 0.4820 - val_output_1_loss: 0.4166 - val_output_2_loss: 0.5530 - val_output_3_loss: 0.3648 - val_output_4_loss: 0.3826 - val_output_0_accuracy: 0.8287 - val_output_1_accuracy: 0.8500 - val_output_2_accuracy: 0.7750 - val_output_3_accuracy: 0.8740 - val_output_4_accuracy: 0.8638\n",
      "Epoch 27/200\n",
      "4000/4000 [==============================] - 1s 318us/sample - loss: 1.6549 - output_0_loss: 0.3195 - output_1_loss: 0.3298 - output_2_loss: 0.3326 - output_3_loss: 0.3297 - output_4_loss: 0.3434 - output_0_accuracy: 0.8830 - output_1_accuracy: 0.8857 - output_2_accuracy: 0.8815 - output_3_accuracy: 0.8875 - output_4_accuracy: 0.8775 - val_loss: 1.8908 - val_output_0_loss: 0.3453 - val_output_1_loss: 0.3250 - val_output_2_loss: 0.3154 - val_output_3_loss: 0.5323 - val_output_4_loss: 0.3736 - val_output_0_accuracy: 0.8890 - val_output_1_accuracy: 0.8855 - val_output_2_accuracy: 0.8943 - val_output_3_accuracy: 0.7942 - val_output_4_accuracy: 0.8605\n",
      "Epoch 28/200\n",
      "4000/4000 [==============================] - 2s 445us/sample - loss: 1.5560 - output_0_loss: 0.2982 - output_1_loss: 0.3051 - output_2_loss: 0.3174 - output_3_loss: 0.3180 - output_4_loss: 0.3173 - output_0_accuracy: 0.8960 - output_1_accuracy: 0.8982 - output_2_accuracy: 0.8913 - output_3_accuracy: 0.8895 - output_4_accuracy: 0.8920 - val_loss: 2.4129 - val_output_0_loss: 0.4547 - val_output_1_loss: 0.6146 - val_output_2_loss: 0.4597 - val_output_3_loss: 0.5087 - val_output_4_loss: 0.3763 - val_output_0_accuracy: 0.8477 - val_output_1_accuracy: 0.7830 - val_output_2_accuracy: 0.8528 - val_output_3_accuracy: 0.8180 - val_output_4_accuracy: 0.8738\n",
      "Epoch 29/200\n",
      "4000/4000 [==============================] - 3s 688us/sample - loss: 1.4684 - output_0_loss: 0.2861 - output_1_loss: 0.2852 - output_2_loss: 0.2986 - output_3_loss: 0.3100 - output_4_loss: 0.2885 - output_0_accuracy: 0.9010 - output_1_accuracy: 0.9047 - output_2_accuracy: 0.8995 - output_3_accuracy: 0.8950 - output_4_accuracy: 0.8982 - val_loss: 1.6340 - val_output_0_loss: 0.2969 - val_output_1_loss: 0.3226 - val_output_2_loss: 0.3336 - val_output_3_loss: 0.4349 - val_output_4_loss: 0.2458 - val_output_0_accuracy: 0.9095 - val_output_1_accuracy: 0.8870 - val_output_2_accuracy: 0.8837 - val_output_3_accuracy: 0.8492 - val_output_4_accuracy: 0.9235\n",
      "Epoch 30/200\n",
      "4000/4000 [==============================] - 2s 441us/sample - loss: 1.4333 - output_0_loss: 0.2871 - output_1_loss: 0.2783 - output_2_loss: 0.2865 - output_3_loss: 0.3004 - output_4_loss: 0.2811 - output_0_accuracy: 0.8995 - output_1_accuracy: 0.9040 - output_2_accuracy: 0.9022 - output_3_accuracy: 0.8950 - output_4_accuracy: 0.9085 - val_loss: 1.8496 - val_output_0_loss: 0.3593 - val_output_1_loss: 0.3920 - val_output_2_loss: 0.2927 - val_output_3_loss: 0.3624 - val_output_4_loss: 0.4416 - val_output_0_accuracy: 0.8763 - val_output_1_accuracy: 0.8660 - val_output_2_accuracy: 0.8927 - val_output_3_accuracy: 0.8810 - val_output_4_accuracy: 0.8312\n",
      "Epoch 31/200\n",
      "4000/4000 [==============================] - 2s 553us/sample - loss: 1.3603 - output_0_loss: 0.2647 - output_1_loss: 0.2715 - output_2_loss: 0.2805 - output_3_loss: 0.2792 - output_4_loss: 0.2644 - output_0_accuracy: 0.9093 - output_1_accuracy: 0.9030 - output_2_accuracy: 0.9038 - output_3_accuracy: 0.9060 - output_4_accuracy: 0.9097 - val_loss: 1.5717 - val_output_0_loss: 0.3609 - val_output_1_loss: 0.2466 - val_output_2_loss: 0.3404 - val_output_3_loss: 0.2661 - val_output_4_loss: 0.3591 - val_output_0_accuracy: 0.8765 - val_output_1_accuracy: 0.9193 - val_output_2_accuracy: 0.8828 - val_output_3_accuracy: 0.9098 - val_output_4_accuracy: 0.8600\n",
      "Epoch 32/200\n",
      "4000/4000 [==============================] - 2s 425us/sample - loss: 1.2933 - output_0_loss: 0.2527 - output_1_loss: 0.2552 - output_2_loss: 0.2460 - output_3_loss: 0.2775 - output_4_loss: 0.2619 - output_0_accuracy: 0.9178 - output_1_accuracy: 0.9103 - output_2_accuracy: 0.9155 - output_3_accuracy: 0.9035 - output_4_accuracy: 0.9145 - val_loss: 1.9354 - val_output_0_loss: 0.4241 - val_output_1_loss: 0.2609 - val_output_2_loss: 0.4218 - val_output_3_loss: 0.4669 - val_output_4_loss: 0.3621 - val_output_0_accuracy: 0.8508 - val_output_1_accuracy: 0.9043 - val_output_2_accuracy: 0.8613 - val_output_3_accuracy: 0.8317 - val_output_4_accuracy: 0.8497\n",
      "Epoch 33/200\n",
      "4000/4000 [==============================] - 2s 511us/sample - loss: 1.2435 - output_0_loss: 0.2559 - output_1_loss: 0.2475 - output_2_loss: 0.2340 - output_3_loss: 0.2704 - output_4_loss: 0.2358 - output_0_accuracy: 0.9143 - output_1_accuracy: 0.9162 - output_2_accuracy: 0.9170 - output_3_accuracy: 0.9103 - output_4_accuracy: 0.9187 - val_loss: 1.7913 - val_output_0_loss: 0.3438 - val_output_1_loss: 0.3444 - val_output_2_loss: 0.3516 - val_output_3_loss: 0.4862 - val_output_4_loss: 0.2659 - val_output_0_accuracy: 0.8767 - val_output_1_accuracy: 0.9007 - val_output_2_accuracy: 0.8752 - val_output_3_accuracy: 0.8240 - val_output_4_accuracy: 0.9130\n",
      "Epoch 34/200\n",
      "4000/4000 [==============================] - 1s 361us/sample - loss: 1.1932 - output_0_loss: 0.2453 - output_1_loss: 0.2429 - output_2_loss: 0.2338 - output_3_loss: 0.2353 - output_4_loss: 0.2359 - output_0_accuracy: 0.9208 - output_1_accuracy: 0.9145 - output_2_accuracy: 0.9212 - output_3_accuracy: 0.9172 - output_4_accuracy: 0.9237 - val_loss: 1.6299 - val_output_0_loss: 0.2402 - val_output_1_loss: 0.2476 - val_output_2_loss: 0.3603 - val_output_3_loss: 0.4439 - val_output_4_loss: 0.3396 - val_output_0_accuracy: 0.9097 - val_output_1_accuracy: 0.9160 - val_output_2_accuracy: 0.8535 - val_output_3_accuracy: 0.8397 - val_output_4_accuracy: 0.8842\n",
      "Epoch 35/200\n",
      "4000/4000 [==============================] - 3s 729us/sample - loss: 1.1239 - output_0_loss: 0.2101 - output_1_loss: 0.2221 - output_2_loss: 0.2323 - output_3_loss: 0.2364 - output_4_loss: 0.2231 - output_0_accuracy: 0.9293 - output_1_accuracy: 0.9258 - output_2_accuracy: 0.9218 - output_3_accuracy: 0.9220 - output_4_accuracy: 0.9260 - val_loss: 1.4079 - val_output_0_loss: 0.2205 - val_output_1_loss: 0.2784 - val_output_2_loss: 0.2621 - val_output_3_loss: 0.3027 - val_output_4_loss: 0.3445 - val_output_0_accuracy: 0.9295 - val_output_1_accuracy: 0.9058 - val_output_2_accuracy: 0.9097 - val_output_3_accuracy: 0.8913 - val_output_4_accuracy: 0.8710\n",
      "Epoch 36/200\n",
      "4000/4000 [==============================] - 2s 461us/sample - loss: 1.0682 - output_0_loss: 0.2119 - output_1_loss: 0.2094 - output_2_loss: 0.2127 - output_3_loss: 0.2256 - output_4_loss: 0.2086 - output_0_accuracy: 0.9298 - output_1_accuracy: 0.9273 - output_2_accuracy: 0.9293 - output_3_accuracy: 0.9275 - output_4_accuracy: 0.9325 - val_loss: 1.7277 - val_output_0_loss: 0.3749 - val_output_1_loss: 0.3135 - val_output_2_loss: 0.2787 - val_output_3_loss: 0.4212 - val_output_4_loss: 0.3410 - val_output_0_accuracy: 0.8775 - val_output_1_accuracy: 0.8910 - val_output_2_accuracy: 0.8967 - val_output_3_accuracy: 0.8572 - val_output_4_accuracy: 0.8817\n",
      "Epoch 37/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 361us/sample - loss: 1.0572 - output_0_loss: 0.2089 - output_1_loss: 0.2065 - output_2_loss: 0.2002 - output_3_loss: 0.2258 - output_4_loss: 0.2157 - output_0_accuracy: 0.9283 - output_1_accuracy: 0.9317 - output_2_accuracy: 0.9293 - output_3_accuracy: 0.9295 - output_4_accuracy: 0.9270 - val_loss: 1.1823 - val_output_0_loss: 0.2400 - val_output_1_loss: 0.2204 - val_output_2_loss: 0.2223 - val_output_3_loss: 0.3163 - val_output_4_loss: 0.1837 - val_output_0_accuracy: 0.9180 - val_output_1_accuracy: 0.9290 - val_output_2_accuracy: 0.9230 - val_output_3_accuracy: 0.8822 - val_output_4_accuracy: 0.9413\n",
      "Epoch 38/200\n",
      "4000/4000 [==============================] - 2s 526us/sample - loss: 0.9826 - output_0_loss: 0.1878 - output_1_loss: 0.2103 - output_2_loss: 0.1913 - output_3_loss: 0.1969 - output_4_loss: 0.1963 - output_0_accuracy: 0.9365 - output_1_accuracy: 0.9277 - output_2_accuracy: 0.9400 - output_3_accuracy: 0.9320 - output_4_accuracy: 0.9367 - val_loss: 1.7593 - val_output_0_loss: 0.3953 - val_output_1_loss: 0.5184 - val_output_2_loss: 0.3093 - val_output_3_loss: 0.3009 - val_output_4_loss: 0.2352 - val_output_0_accuracy: 0.8785 - val_output_1_accuracy: 0.8495 - val_output_2_accuracy: 0.9037 - val_output_3_accuracy: 0.8965 - val_output_4_accuracy: 0.9167\n",
      "Epoch 39/200\n",
      "4000/4000 [==============================] - 2s 384us/sample - loss: 0.9422 - output_0_loss: 0.1848 - output_1_loss: 0.1915 - output_2_loss: 0.1865 - output_3_loss: 0.1965 - output_4_loss: 0.1830 - output_0_accuracy: 0.9415 - output_1_accuracy: 0.9365 - output_2_accuracy: 0.9377 - output_3_accuracy: 0.9348 - output_4_accuracy: 0.9417 - val_loss: 1.3962 - val_output_0_loss: 0.3035 - val_output_1_loss: 0.2678 - val_output_2_loss: 0.3439 - val_output_3_loss: 0.2904 - val_output_4_loss: 0.1900 - val_output_0_accuracy: 0.9008 - val_output_1_accuracy: 0.9027 - val_output_2_accuracy: 0.8847 - val_output_3_accuracy: 0.9108 - val_output_4_accuracy: 0.9392\n",
      "Epoch 40/200\n",
      "4000/4000 [==============================] - 1s 314us/sample - loss: 0.8927 - output_0_loss: 0.1743 - output_1_loss: 0.1866 - output_2_loss: 0.1776 - output_3_loss: 0.1926 - output_4_loss: 0.1616 - output_0_accuracy: 0.9467 - output_1_accuracy: 0.9370 - output_2_accuracy: 0.9398 - output_3_accuracy: 0.9367 - output_4_accuracy: 0.9503 - val_loss: 1.4534 - val_output_0_loss: 0.3546 - val_output_1_loss: 0.3731 - val_output_2_loss: 0.1716 - val_output_3_loss: 0.1737 - val_output_4_loss: 0.3808 - val_output_0_accuracy: 0.8792 - val_output_1_accuracy: 0.8910 - val_output_2_accuracy: 0.9435 - val_output_3_accuracy: 0.9442 - val_output_4_accuracy: 0.8687\n",
      "Epoch 41/200\n",
      "4000/4000 [==============================] - 1s 302us/sample - loss: 0.8957 - output_0_loss: 0.1796 - output_1_loss: 0.1728 - output_2_loss: 0.1754 - output_3_loss: 0.1815 - output_4_loss: 0.1864 - output_0_accuracy: 0.9415 - output_1_accuracy: 0.9420 - output_2_accuracy: 0.9452 - output_3_accuracy: 0.9405 - output_4_accuracy: 0.9415 - val_loss: 0.9438 - val_output_0_loss: 0.1826 - val_output_1_loss: 0.1679 - val_output_2_loss: 0.1834 - val_output_3_loss: 0.2311 - val_output_4_loss: 0.1790 - val_output_0_accuracy: 0.9378 - val_output_1_accuracy: 0.9480 - val_output_2_accuracy: 0.9353 - val_output_3_accuracy: 0.9337 - val_output_4_accuracy: 0.9440\n",
      "Epoch 42/200\n",
      "4000/4000 [==============================] - 1s 308us/sample - loss: 0.8111 - output_0_loss: 0.1495 - output_1_loss: 0.1700 - output_2_loss: 0.1626 - output_3_loss: 0.1732 - output_4_loss: 0.1557 - output_0_accuracy: 0.9532 - output_1_accuracy: 0.9465 - output_2_accuracy: 0.9457 - output_3_accuracy: 0.9448 - output_4_accuracy: 0.9492 - val_loss: 0.9161 - val_output_0_loss: 0.1444 - val_output_1_loss: 0.2231 - val_output_2_loss: 0.1596 - val_output_3_loss: 0.1643 - val_output_4_loss: 0.2244 - val_output_0_accuracy: 0.9588 - val_output_1_accuracy: 0.9260 - val_output_2_accuracy: 0.9507 - val_output_3_accuracy: 0.9473 - val_output_4_accuracy: 0.9128\n",
      "Epoch 43/200\n",
      "4000/4000 [==============================] - 1s 325us/sample - loss: 0.8068 - output_0_loss: 0.1580 - output_1_loss: 0.1651 - output_2_loss: 0.1597 - output_3_loss: 0.1696 - output_4_loss: 0.1545 - output_0_accuracy: 0.9475 - output_1_accuracy: 0.9463 - output_2_accuracy: 0.9475 - output_3_accuracy: 0.9413 - output_4_accuracy: 0.9513 - val_loss: 1.1021 - val_output_0_loss: 0.2336 - val_output_1_loss: 0.1831 - val_output_2_loss: 0.1944 - val_output_3_loss: 0.3305 - val_output_4_loss: 0.1602 - val_output_0_accuracy: 0.9200 - val_output_1_accuracy: 0.9393 - val_output_2_accuracy: 0.9362 - val_output_3_accuracy: 0.8953 - val_output_4_accuracy: 0.9452\n",
      "Epoch 44/200\n",
      "4000/4000 [==============================] - 1s 319us/sample - loss: 0.7595 - output_0_loss: 0.1494 - output_1_loss: 0.1497 - output_2_loss: 0.1535 - output_3_loss: 0.1567 - output_4_loss: 0.1501 - output_0_accuracy: 0.9513 - output_1_accuracy: 0.9498 - output_2_accuracy: 0.9498 - output_3_accuracy: 0.9517 - output_4_accuracy: 0.9520 - val_loss: 1.2933 - val_output_0_loss: 0.2559 - val_output_1_loss: 0.2961 - val_output_2_loss: 0.1751 - val_output_3_loss: 0.1903 - val_output_4_loss: 0.3769 - val_output_0_accuracy: 0.9198 - val_output_1_accuracy: 0.9143 - val_output_2_accuracy: 0.9483 - val_output_3_accuracy: 0.9347 - val_output_4_accuracy: 0.8770\n",
      "Epoch 45/200\n",
      "4000/4000 [==============================] - 1s 315us/sample - loss: 0.7392 - output_0_loss: 0.1412 - output_1_loss: 0.1585 - output_2_loss: 0.1469 - output_3_loss: 0.1495 - output_4_loss: 0.1431 - output_0_accuracy: 0.9585 - output_1_accuracy: 0.9515 - output_2_accuracy: 0.9523 - output_3_accuracy: 0.9467 - output_4_accuracy: 0.9517 - val_loss: 1.1782 - val_output_0_loss: 0.2748 - val_output_1_loss: 0.2524 - val_output_2_loss: 0.2368 - val_output_3_loss: 0.2610 - val_output_4_loss: 0.1539 - val_output_0_accuracy: 0.9130 - val_output_1_accuracy: 0.9160 - val_output_2_accuracy: 0.9170 - val_output_3_accuracy: 0.9122 - val_output_4_accuracy: 0.9502\n",
      "Epoch 46/200\n",
      "4000/4000 [==============================] - 1s 304us/sample - loss: 0.7186 - output_0_loss: 0.1309 - output_1_loss: 0.1424 - output_2_loss: 0.1461 - output_3_loss: 0.1536 - output_4_loss: 0.1457 - output_0_accuracy: 0.9563 - output_1_accuracy: 0.9535 - output_2_accuracy: 0.9542 - output_3_accuracy: 0.9455 - output_4_accuracy: 0.9515 - val_loss: 0.9513 - val_output_0_loss: 0.1285 - val_output_1_loss: 0.2081 - val_output_2_loss: 0.2419 - val_output_3_loss: 0.1200 - val_output_4_loss: 0.2523 - val_output_0_accuracy: 0.9595 - val_output_1_accuracy: 0.9238 - val_output_2_accuracy: 0.9302 - val_output_3_accuracy: 0.9623 - val_output_4_accuracy: 0.9153\n",
      "Epoch 47/200\n",
      "4000/4000 [==============================] - 1s 318us/sample - loss: 0.6987 - output_0_loss: 0.1353 - output_1_loss: 0.1352 - output_2_loss: 0.1365 - output_3_loss: 0.1479 - output_4_loss: 0.1438 - output_0_accuracy: 0.9565 - output_1_accuracy: 0.9548 - output_2_accuracy: 0.9567 - output_3_accuracy: 0.9538 - output_4_accuracy: 0.9548 - val_loss: 1.0295 - val_output_0_loss: 0.1427 - val_output_1_loss: 0.2882 - val_output_2_loss: 0.1798 - val_output_3_loss: 0.1938 - val_output_4_loss: 0.2242 - val_output_0_accuracy: 0.9530 - val_output_1_accuracy: 0.9048 - val_output_2_accuracy: 0.9478 - val_output_3_accuracy: 0.9322 - val_output_4_accuracy: 0.9273\n",
      "Epoch 48/200\n",
      "4000/4000 [==============================] - 1s 306us/sample - loss: 0.6734 - output_0_loss: 0.1267 - output_1_loss: 0.1485 - output_2_loss: 0.1405 - output_3_loss: 0.1328 - output_4_loss: 0.1249 - output_0_accuracy: 0.9625 - output_1_accuracy: 0.9507 - output_2_accuracy: 0.9578 - output_3_accuracy: 0.9555 - output_4_accuracy: 0.9592 - val_loss: 1.1397 - val_output_0_loss: 0.1999 - val_output_1_loss: 0.1869 - val_output_2_loss: 0.2008 - val_output_3_loss: 0.3866 - val_output_4_loss: 0.1658 - val_output_0_accuracy: 0.9425 - val_output_1_accuracy: 0.9362 - val_output_2_accuracy: 0.9438 - val_output_3_accuracy: 0.8702 - val_output_4_accuracy: 0.9443\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 305us/sample - loss: 0.6705 - output_0_loss: 0.1367 - output_1_loss: 0.1327 - output_2_loss: 0.1358 - output_3_loss: 0.1397 - output_4_loss: 0.1257 - output_0_accuracy: 0.9592 - output_1_accuracy: 0.9603 - output_2_accuracy: 0.9563 - output_3_accuracy: 0.9563 - output_4_accuracy: 0.9607 - val_loss: 0.7556 - val_output_0_loss: 0.1400 - val_output_1_loss: 0.1747 - val_output_2_loss: 0.0967 - val_output_3_loss: 0.2286 - val_output_4_loss: 0.1163 - val_output_0_accuracy: 0.9507 - val_output_1_accuracy: 0.9412 - val_output_2_accuracy: 0.9715 - val_output_3_accuracy: 0.9240 - val_output_4_accuracy: 0.9635\n",
      "Epoch 50/200\n",
      "4000/4000 [==============================] - 1s 307us/sample - loss: 0.6092 - output_0_loss: 0.1095 - output_1_loss: 0.1266 - output_2_loss: 0.1230 - output_3_loss: 0.1307 - output_4_loss: 0.1194 - output_0_accuracy: 0.9638 - output_1_accuracy: 0.9590 - output_2_accuracy: 0.9607 - output_3_accuracy: 0.9555 - output_4_accuracy: 0.9635 - val_loss: 1.0713 - val_output_0_loss: 0.1921 - val_output_1_loss: 0.2539 - val_output_2_loss: 0.2068 - val_output_3_loss: 0.2555 - val_output_4_loss: 0.1618 - val_output_0_accuracy: 0.9317 - val_output_1_accuracy: 0.9157 - val_output_2_accuracy: 0.9360 - val_output_3_accuracy: 0.9132 - val_output_4_accuracy: 0.9490\n",
      "Epoch 51/200\n",
      "4000/4000 [==============================] - 2s 485us/sample - loss: 0.6507 - output_0_loss: 0.1402 - output_1_loss: 0.1265 - output_2_loss: 0.1282 - output_3_loss: 0.1434 - output_4_loss: 0.1123 - output_0_accuracy: 0.9550 - output_1_accuracy: 0.9607 - output_2_accuracy: 0.9617 - output_3_accuracy: 0.9565 - output_4_accuracy: 0.9670 - val_loss: 0.7487 - val_output_0_loss: 0.1972 - val_output_1_loss: 0.1375 - val_output_2_loss: 0.1376 - val_output_3_loss: 0.1385 - val_output_4_loss: 0.1372 - val_output_0_accuracy: 0.9373 - val_output_1_accuracy: 0.9528 - val_output_2_accuracy: 0.9592 - val_output_3_accuracy: 0.9575 - val_output_4_accuracy: 0.9585\n",
      "Epoch 52/200\n",
      "4000/4000 [==============================] - 1s 312us/sample - loss: 0.6186 - output_0_loss: 0.1234 - output_1_loss: 0.1290 - output_2_loss: 0.1183 - output_3_loss: 0.1165 - output_4_loss: 0.1314 - output_0_accuracy: 0.9617 - output_1_accuracy: 0.9582 - output_2_accuracy: 0.9655 - output_3_accuracy: 0.9622 - output_4_accuracy: 0.9595 - val_loss: 0.9395 - val_output_0_loss: 0.1829 - val_output_1_loss: 0.1358 - val_output_2_loss: 0.3610 - val_output_3_loss: 0.1530 - val_output_4_loss: 0.1068 - val_output_0_accuracy: 0.9338 - val_output_1_accuracy: 0.9507 - val_output_2_accuracy: 0.8700 - val_output_3_accuracy: 0.9473 - val_output_4_accuracy: 0.9665\n",
      "Epoch 53/200\n",
      "4000/4000 [==============================] - 1s 323us/sample - loss: 0.5806 - output_0_loss: 0.1128 - output_1_loss: 0.1107 - output_2_loss: 0.1191 - output_3_loss: 0.1271 - output_4_loss: 0.1109 - output_0_accuracy: 0.9635 - output_1_accuracy: 0.9672 - output_2_accuracy: 0.9632 - output_3_accuracy: 0.9620 - output_4_accuracy: 0.9653 - val_loss: 1.0057 - val_output_0_loss: 0.1612 - val_output_1_loss: 0.3237 - val_output_2_loss: 0.2050 - val_output_3_loss: 0.2056 - val_output_4_loss: 0.1109 - val_output_0_accuracy: 0.9488 - val_output_1_accuracy: 0.8948 - val_output_2_accuracy: 0.9358 - val_output_3_accuracy: 0.9307 - val_output_4_accuracy: 0.9673\n",
      "Epoch 54/200\n",
      "4000/4000 [==============================] - 1s 331us/sample - loss: 0.6002 - output_0_loss: 0.1251 - output_1_loss: 0.1209 - output_2_loss: 0.1150 - output_3_loss: 0.1294 - output_4_loss: 0.1098 - output_0_accuracy: 0.9615 - output_1_accuracy: 0.9615 - output_2_accuracy: 0.9653 - output_3_accuracy: 0.9603 - output_4_accuracy: 0.9657 - val_loss: 0.6965 - val_output_0_loss: 0.1736 - val_output_1_loss: 0.0824 - val_output_2_loss: 0.1011 - val_output_3_loss: 0.1262 - val_output_4_loss: 0.2140 - val_output_0_accuracy: 0.9392 - val_output_1_accuracy: 0.9770 - val_output_2_accuracy: 0.9715 - val_output_3_accuracy: 0.9632 - val_output_4_accuracy: 0.9323\n",
      "Epoch 55/200\n",
      "4000/4000 [==============================] - 1s 323us/sample - loss: 0.5628 - output_0_loss: 0.1094 - output_1_loss: 0.1130 - output_2_loss: 0.1205 - output_3_loss: 0.1026 - output_4_loss: 0.1173 - output_0_accuracy: 0.9682 - output_1_accuracy: 0.9640 - output_2_accuracy: 0.9630 - output_3_accuracy: 0.9663 - output_4_accuracy: 0.9615 - val_loss: 0.7685 - val_output_0_loss: 0.1340 - val_output_1_loss: 0.1427 - val_output_2_loss: 0.2210 - val_output_3_loss: 0.1861 - val_output_4_loss: 0.0846 - val_output_0_accuracy: 0.9565 - val_output_1_accuracy: 0.9498 - val_output_2_accuracy: 0.9183 - val_output_3_accuracy: 0.9375 - val_output_4_accuracy: 0.9750\n",
      "Epoch 56/200\n",
      "4000/4000 [==============================] - 1s 327us/sample - loss: 0.5297 - output_0_loss: 0.1067 - output_1_loss: 0.1068 - output_2_loss: 0.1130 - output_3_loss: 0.1047 - output_4_loss: 0.0985 - output_0_accuracy: 0.9682 - output_1_accuracy: 0.9655 - output_2_accuracy: 0.9628 - output_3_accuracy: 0.9635 - output_4_accuracy: 0.9680 - val_loss: 0.8020 - val_output_0_loss: 0.2073 - val_output_1_loss: 0.1241 - val_output_2_loss: 0.1568 - val_output_3_loss: 0.2224 - val_output_4_loss: 0.0923 - val_output_0_accuracy: 0.9278 - val_output_1_accuracy: 0.9590 - val_output_2_accuracy: 0.9462 - val_output_3_accuracy: 0.9217 - val_output_4_accuracy: 0.9693\n",
      "Epoch 57/200\n",
      "4000/4000 [==============================] - 2s 392us/sample - loss: 0.5454 - output_0_loss: 0.1112 - output_1_loss: 0.0977 - output_2_loss: 0.1157 - output_3_loss: 0.1061 - output_4_loss: 0.1147 - output_0_accuracy: 0.9665 - output_1_accuracy: 0.9685 - output_2_accuracy: 0.9630 - output_3_accuracy: 0.9678 - output_4_accuracy: 0.9647 - val_loss: 1.0801 - val_output_0_loss: 0.3391 - val_output_1_loss: 0.1486 - val_output_2_loss: 0.1907 - val_output_3_loss: 0.2446 - val_output_4_loss: 0.1568 - val_output_0_accuracy: 0.8905 - val_output_1_accuracy: 0.9545 - val_output_2_accuracy: 0.9360 - val_output_3_accuracy: 0.9130 - val_output_4_accuracy: 0.9373\n",
      "Epoch 58/200\n",
      "4000/4000 [==============================] - 2s 492us/sample - loss: 0.5218 - output_0_loss: 0.0959 - output_1_loss: 0.1219 - output_2_loss: 0.1010 - output_3_loss: 0.1002 - output_4_loss: 0.1029 - output_0_accuracy: 0.9693 - output_1_accuracy: 0.9588 - output_2_accuracy: 0.9690 - output_3_accuracy: 0.9685 - output_4_accuracy: 0.9693 - val_loss: 0.7889 - val_output_0_loss: 0.2679 - val_output_1_loss: 0.1881 - val_output_2_loss: 0.1271 - val_output_3_loss: 0.1204 - val_output_4_loss: 0.0858 - val_output_0_accuracy: 0.9062 - val_output_1_accuracy: 0.9375 - val_output_2_accuracy: 0.9602 - val_output_3_accuracy: 0.9623 - val_output_4_accuracy: 0.9732\n",
      "Epoch 59/200\n",
      "4000/4000 [==============================] - 2s 393us/sample - loss: 0.5305 - output_0_loss: 0.1132 - output_1_loss: 0.1094 - output_2_loss: 0.1198 - output_3_loss: 0.0933 - output_4_loss: 0.0948 - output_0_accuracy: 0.9663 - output_1_accuracy: 0.9620 - output_2_accuracy: 0.9638 - output_3_accuracy: 0.9725 - output_4_accuracy: 0.9703 - val_loss: 0.9656 - val_output_0_loss: 0.2107 - val_output_1_loss: 0.1168 - val_output_2_loss: 0.1985 - val_output_3_loss: 0.3081 - val_output_4_loss: 0.1313 - val_output_0_accuracy: 0.9330 - val_output_1_accuracy: 0.9642 - val_output_2_accuracy: 0.9303 - val_output_3_accuracy: 0.8973 - val_output_4_accuracy: 0.9560\n",
      "Epoch 60/200\n",
      "4000/4000 [==============================] - 2s 410us/sample - loss: 0.4640 - output_0_loss: 0.0866 - output_1_loss: 0.0937 - output_2_loss: 0.0827 - output_3_loss: 0.1052 - output_4_loss: 0.0957 - output_0_accuracy: 0.9725 - output_1_accuracy: 0.9675 - output_2_accuracy: 0.9740 - output_3_accuracy: 0.9672 - output_4_accuracy: 0.9740 - val_loss: 0.7123 - val_output_0_loss: 0.1100 - val_output_1_loss: 0.0968 - val_output_2_loss: 0.2689 - val_output_3_loss: 0.1089 - val_output_4_loss: 0.1277 - val_output_0_accuracy: 0.9628 - val_output_1_accuracy: 0.9675 - val_output_2_accuracy: 0.9187 - val_output_3_accuracy: 0.9638 - val_output_4_accuracy: 0.9583\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 2s 393us/sample - loss: 0.5187 - output_0_loss: 0.0955 - output_1_loss: 0.1021 - output_2_loss: 0.1045 - output_3_loss: 0.1096 - output_4_loss: 0.1070 - output_0_accuracy: 0.9712 - output_1_accuracy: 0.9705 - output_2_accuracy: 0.9695 - output_3_accuracy: 0.9643 - output_4_accuracy: 0.9665 - val_loss: 0.7788 - val_output_0_loss: 0.1521 - val_output_1_loss: 0.1378 - val_output_2_loss: 0.2026 - val_output_3_loss: 0.1747 - val_output_4_loss: 0.1109 - val_output_0_accuracy: 0.9432 - val_output_1_accuracy: 0.9513 - val_output_2_accuracy: 0.9428 - val_output_3_accuracy: 0.9407 - val_output_4_accuracy: 0.9697\n",
      "Epoch 62/200\n",
      "4000/4000 [==============================] - 1s 301us/sample - loss: 0.4719 - output_0_loss: 0.0912 - output_1_loss: 0.0896 - output_2_loss: 0.0916 - output_3_loss: 0.1025 - output_4_loss: 0.0970 - output_0_accuracy: 0.9685 - output_1_accuracy: 0.9750 - output_2_accuracy: 0.9715 - output_3_accuracy: 0.9705 - output_4_accuracy: 0.9688 - val_loss: 0.5221 - val_output_0_loss: 0.0658 - val_output_1_loss: 0.1729 - val_output_2_loss: 0.0411 - val_output_3_loss: 0.1127 - val_output_4_loss: 0.1296 - val_output_0_accuracy: 0.9798 - val_output_1_accuracy: 0.9455 - val_output_2_accuracy: 0.9910 - val_output_3_accuracy: 0.9648 - val_output_4_accuracy: 0.9588\n",
      "Epoch 63/200\n",
      "4000/4000 [==============================] - 1s 312us/sample - loss: 0.4612 - output_0_loss: 0.0885 - output_1_loss: 0.0832 - output_2_loss: 0.1034 - output_3_loss: 0.0936 - output_4_loss: 0.0925 - output_0_accuracy: 0.9712 - output_1_accuracy: 0.9758 - output_2_accuracy: 0.9690 - output_3_accuracy: 0.9678 - output_4_accuracy: 0.9725 - val_loss: 0.7564 - val_output_0_loss: 0.2049 - val_output_1_loss: 0.2025 - val_output_2_loss: 0.0939 - val_output_3_loss: 0.1582 - val_output_4_loss: 0.0969 - val_output_0_accuracy: 0.9330 - val_output_1_accuracy: 0.9380 - val_output_2_accuracy: 0.9670 - val_output_3_accuracy: 0.9482 - val_output_4_accuracy: 0.9675\n",
      "Epoch 64/200\n",
      "4000/4000 [==============================] - 1s 329us/sample - loss: 0.4681 - output_0_loss: 0.0952 - output_1_loss: 0.0985 - output_2_loss: 0.0828 - output_3_loss: 0.0949 - output_4_loss: 0.0967 - output_0_accuracy: 0.9690 - output_1_accuracy: 0.9690 - output_2_accuracy: 0.9753 - output_3_accuracy: 0.9680 - output_4_accuracy: 0.9705 - val_loss: 0.6797 - val_output_0_loss: 0.0584 - val_output_1_loss: 0.2191 - val_output_2_loss: 0.1072 - val_output_3_loss: 0.0874 - val_output_4_loss: 0.2081 - val_output_0_accuracy: 0.9835 - val_output_1_accuracy: 0.9255 - val_output_2_accuracy: 0.9678 - val_output_3_accuracy: 0.9732 - val_output_4_accuracy: 0.9317\n",
      "Epoch 65/200\n",
      "4000/4000 [==============================] - 1s 348us/sample - loss: 0.4362 - output_0_loss: 0.0768 - output_1_loss: 0.0856 - output_2_loss: 0.0760 - output_3_loss: 0.1011 - output_4_loss: 0.0968 - output_0_accuracy: 0.9762 - output_1_accuracy: 0.9722 - output_2_accuracy: 0.9747 - output_3_accuracy: 0.9670 - output_4_accuracy: 0.9678 - val_loss: 0.9688 - val_output_0_loss: 0.1369 - val_output_1_loss: 0.1308 - val_output_2_loss: 0.1186 - val_output_3_loss: 0.3914 - val_output_4_loss: 0.1899 - val_output_0_accuracy: 0.9562 - val_output_1_accuracy: 0.9588 - val_output_2_accuracy: 0.9663 - val_output_3_accuracy: 0.8920 - val_output_4_accuracy: 0.9348\n",
      "Epoch 66/200\n",
      "4000/4000 [==============================] - 1s 344us/sample - loss: 0.4578 - output_0_loss: 0.0779 - output_1_loss: 0.0953 - output_2_loss: 0.0883 - output_3_loss: 0.1029 - output_4_loss: 0.0933 - output_0_accuracy: 0.9755 - output_1_accuracy: 0.9725 - output_2_accuracy: 0.9735 - output_3_accuracy: 0.9690 - output_4_accuracy: 0.9730 - val_loss: 0.5077 - val_output_0_loss: 0.0544 - val_output_1_loss: 0.1066 - val_output_2_loss: 0.0877 - val_output_3_loss: 0.1166 - val_output_4_loss: 0.1418 - val_output_0_accuracy: 0.9853 - val_output_1_accuracy: 0.9643 - val_output_2_accuracy: 0.9708 - val_output_3_accuracy: 0.9598 - val_output_4_accuracy: 0.9578\n",
      "Epoch 67/200\n",
      "4000/4000 [==============================] - 1s 315us/sample - loss: 0.4061 - output_0_loss: 0.0770 - output_1_loss: 0.0787 - output_2_loss: 0.0752 - output_3_loss: 0.0889 - output_4_loss: 0.0863 - output_0_accuracy: 0.9783 - output_1_accuracy: 0.9758 - output_2_accuracy: 0.9743 - output_3_accuracy: 0.9722 - output_4_accuracy: 0.9735 - val_loss: 1.1006 - val_output_0_loss: 0.2326 - val_output_1_loss: 0.1406 - val_output_2_loss: 0.1736 - val_output_3_loss: 0.3903 - val_output_4_loss: 0.1636 - val_output_0_accuracy: 0.9268 - val_output_1_accuracy: 0.9513 - val_output_2_accuracy: 0.9475 - val_output_3_accuracy: 0.8930 - val_output_4_accuracy: 0.9422\n",
      "Epoch 68/200\n",
      "4000/4000 [==============================] - 1s 314us/sample - loss: 0.4450 - output_0_loss: 0.0898 - output_1_loss: 0.0859 - output_2_loss: 0.0801 - output_3_loss: 0.0909 - output_4_loss: 0.0983 - output_0_accuracy: 0.9707 - output_1_accuracy: 0.9715 - output_2_accuracy: 0.9760 - output_3_accuracy: 0.9718 - output_4_accuracy: 0.9712 - val_loss: 0.4061 - val_output_0_loss: 0.0707 - val_output_1_loss: 0.0694 - val_output_2_loss: 0.0655 - val_output_3_loss: 0.1243 - val_output_4_loss: 0.0774 - val_output_0_accuracy: 0.9770 - val_output_1_accuracy: 0.9793 - val_output_2_accuracy: 0.9810 - val_output_3_accuracy: 0.9563 - val_output_4_accuracy: 0.9758\n",
      "Epoch 69/200\n",
      "4000/4000 [==============================] - 1s 323us/sample - loss: 0.4137 - output_0_loss: 0.0711 - output_1_loss: 0.0898 - output_2_loss: 0.0954 - output_3_loss: 0.0775 - output_4_loss: 0.0799 - output_0_accuracy: 0.9810 - output_1_accuracy: 0.9747 - output_2_accuracy: 0.9715 - output_3_accuracy: 0.9755 - output_4_accuracy: 0.9762 - val_loss: 0.4966 - val_output_0_loss: 0.0842 - val_output_1_loss: 0.1208 - val_output_2_loss: 0.1133 - val_output_3_loss: 0.1124 - val_output_4_loss: 0.0661 - val_output_0_accuracy: 0.9715 - val_output_1_accuracy: 0.9588 - val_output_2_accuracy: 0.9622 - val_output_3_accuracy: 0.9618 - val_output_4_accuracy: 0.9797\n",
      "Epoch 70/200\n",
      "4000/4000 [==============================] - 1s 340us/sample - loss: 0.4103 - output_0_loss: 0.0830 - output_1_loss: 0.0863 - output_2_loss: 0.0912 - output_3_loss: 0.0766 - output_4_loss: 0.0732 - output_0_accuracy: 0.9720 - output_1_accuracy: 0.9750 - output_2_accuracy: 0.9715 - output_3_accuracy: 0.9740 - output_4_accuracy: 0.9762 - val_loss: 0.5164 - val_output_0_loss: 0.1057 - val_output_1_loss: 0.2027 - val_output_2_loss: 0.0573 - val_output_3_loss: 0.0656 - val_output_4_loss: 0.0845 - val_output_0_accuracy: 0.9623 - val_output_1_accuracy: 0.9368 - val_output_2_accuracy: 0.9842 - val_output_3_accuracy: 0.9820 - val_output_4_accuracy: 0.9700\n",
      "Epoch 71/200\n",
      "4000/4000 [==============================] - 1s 307us/sample - loss: 0.3887 - output_0_loss: 0.0759 - output_1_loss: 0.0788 - output_2_loss: 0.0725 - output_3_loss: 0.0808 - output_4_loss: 0.0808 - output_0_accuracy: 0.9755 - output_1_accuracy: 0.9737 - output_2_accuracy: 0.9768 - output_3_accuracy: 0.9745 - output_4_accuracy: 0.9760 - val_loss: 0.9888 - val_output_0_loss: 0.1904 - val_output_1_loss: 0.1289 - val_output_2_loss: 0.1600 - val_output_3_loss: 0.2287 - val_output_4_loss: 0.2792 - val_output_0_accuracy: 0.9400 - val_output_1_accuracy: 0.9600 - val_output_2_accuracy: 0.9512 - val_output_3_accuracy: 0.9312 - val_output_4_accuracy: 0.9137\n",
      "Epoch 72/200\n",
      "4000/4000 [==============================] - 1s 318us/sample - loss: 0.3836 - output_0_loss: 0.0722 - output_1_loss: 0.0803 - output_2_loss: 0.0700 - output_3_loss: 0.0816 - output_4_loss: 0.0794 - output_0_accuracy: 0.9770 - output_1_accuracy: 0.9778 - output_2_accuracy: 0.9762 - output_3_accuracy: 0.9743 - output_4_accuracy: 0.9732 - val_loss: 0.5125 - val_output_0_loss: 0.0650 - val_output_1_loss: 0.1319 - val_output_2_loss: 0.1043 - val_output_3_loss: 0.1583 - val_output_4_loss: 0.0527 - val_output_0_accuracy: 0.9807 - val_output_1_accuracy: 0.9552 - val_output_2_accuracy: 0.9655 - val_output_3_accuracy: 0.9682 - val_output_4_accuracy: 0.9857\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 288us/sample - loss: 0.3946 - output_0_loss: 0.0766 - output_1_loss: 0.0750 - output_2_loss: 0.0744 - output_3_loss: 0.0917 - output_4_loss: 0.0769 - output_0_accuracy: 0.9768 - output_1_accuracy: 0.9740 - output_2_accuracy: 0.9772 - output_3_accuracy: 0.9715 - output_4_accuracy: 0.9758 - val_loss: 0.6476 - val_output_0_loss: 0.1865 - val_output_1_loss: 0.0974 - val_output_2_loss: 0.1180 - val_output_3_loss: 0.1111 - val_output_4_loss: 0.1361 - val_output_0_accuracy: 0.9365 - val_output_1_accuracy: 0.9692 - val_output_2_accuracy: 0.9587 - val_output_3_accuracy: 0.9688 - val_output_4_accuracy: 0.9553\n",
      "Epoch 74/200\n",
      "4000/4000 [==============================] - 1s 287us/sample - loss: 0.3520 - output_0_loss: 0.0667 - output_1_loss: 0.0618 - output_2_loss: 0.0712 - output_3_loss: 0.0821 - output_4_loss: 0.0701 - output_0_accuracy: 0.9793 - output_1_accuracy: 0.9785 - output_2_accuracy: 0.9772 - output_3_accuracy: 0.9747 - output_4_accuracy: 0.9785 - val_loss: 0.4013 - val_output_0_loss: 0.0855 - val_output_1_loss: 0.1503 - val_output_2_loss: 0.0481 - val_output_3_loss: 0.0567 - val_output_4_loss: 0.0603 - val_output_0_accuracy: 0.9735 - val_output_1_accuracy: 0.9495 - val_output_2_accuracy: 0.9878 - val_output_3_accuracy: 0.9827 - val_output_4_accuracy: 0.9822\n",
      "Epoch 75/200\n",
      "4000/4000 [==============================] - 1s 296us/sample - loss: 0.3494 - output_0_loss: 0.0684 - output_1_loss: 0.0709 - output_2_loss: 0.0715 - output_3_loss: 0.0674 - output_4_loss: 0.0714 - output_0_accuracy: 0.9778 - output_1_accuracy: 0.9768 - output_2_accuracy: 0.9795 - output_3_accuracy: 0.9790 - output_4_accuracy: 0.9800 - val_loss: 0.6328 - val_output_0_loss: 0.1970 - val_output_1_loss: 0.0458 - val_output_2_loss: 0.2218 - val_output_3_loss: 0.0903 - val_output_4_loss: 0.0777 - val_output_0_accuracy: 0.9428 - val_output_1_accuracy: 0.9865 - val_output_2_accuracy: 0.9352 - val_output_3_accuracy: 0.9695 - val_output_4_accuracy: 0.9752\n",
      "Epoch 76/200\n",
      "4000/4000 [==============================] - 1s 299us/sample - loss: 0.3668 - output_0_loss: 0.0695 - output_1_loss: 0.0901 - output_2_loss: 0.0642 - output_3_loss: 0.0740 - output_4_loss: 0.0688 - output_0_accuracy: 0.9772 - output_1_accuracy: 0.9725 - output_2_accuracy: 0.9790 - output_3_accuracy: 0.9775 - output_4_accuracy: 0.9795 - val_loss: 0.5128 - val_output_0_loss: 0.1475 - val_output_1_loss: 0.0749 - val_output_2_loss: 0.0952 - val_output_3_loss: 0.1129 - val_output_4_loss: 0.0813 - val_output_0_accuracy: 0.9523 - val_output_1_accuracy: 0.9783 - val_output_2_accuracy: 0.9688 - val_output_3_accuracy: 0.9667 - val_output_4_accuracy: 0.9737\n",
      "Epoch 77/200\n",
      "4000/4000 [==============================] - 1s 319us/sample - loss: 0.3587 - output_0_loss: 0.0675 - output_1_loss: 0.0755 - output_2_loss: 0.0702 - output_3_loss: 0.0736 - output_4_loss: 0.0719 - output_0_accuracy: 0.9780 - output_1_accuracy: 0.9785 - output_2_accuracy: 0.9785 - output_3_accuracy: 0.9775 - output_4_accuracy: 0.9785 - val_loss: 0.3959 - val_output_0_loss: 0.1214 - val_output_1_loss: 0.0294 - val_output_2_loss: 0.0537 - val_output_3_loss: 0.1119 - val_output_4_loss: 0.0793 - val_output_0_accuracy: 0.9667 - val_output_1_accuracy: 0.9935 - val_output_2_accuracy: 0.9865 - val_output_3_accuracy: 0.9625 - val_output_4_accuracy: 0.9723\n",
      "Epoch 78/200\n",
      "4000/4000 [==============================] - 1s 335us/sample - loss: 0.3385 - output_0_loss: 0.0632 - output_1_loss: 0.0737 - output_2_loss: 0.0617 - output_3_loss: 0.0805 - output_4_loss: 0.0594 - output_0_accuracy: 0.9795 - output_1_accuracy: 0.9795 - output_2_accuracy: 0.9800 - output_3_accuracy: 0.9762 - output_4_accuracy: 0.9803 - val_loss: 0.5232 - val_output_0_loss: 0.0944 - val_output_1_loss: 0.1693 - val_output_2_loss: 0.1423 - val_output_3_loss: 0.0511 - val_output_4_loss: 0.0673 - val_output_0_accuracy: 0.9698 - val_output_1_accuracy: 0.9530 - val_output_2_accuracy: 0.9567 - val_output_3_accuracy: 0.9843 - val_output_4_accuracy: 0.9810\n",
      "Epoch 79/200\n",
      "4000/4000 [==============================] - 1s 319us/sample - loss: 0.3492 - output_0_loss: 0.0706 - output_1_loss: 0.0700 - output_2_loss: 0.0714 - output_3_loss: 0.0784 - output_4_loss: 0.0588 - output_0_accuracy: 0.9772 - output_1_accuracy: 0.9772 - output_2_accuracy: 0.9778 - output_3_accuracy: 0.9750 - output_4_accuracy: 0.9820 - val_loss: 0.2908 - val_output_0_loss: 0.0425 - val_output_1_loss: 0.0718 - val_output_2_loss: 0.0486 - val_output_3_loss: 0.0564 - val_output_4_loss: 0.0711 - val_output_0_accuracy: 0.9870 - val_output_1_accuracy: 0.9782 - val_output_2_accuracy: 0.9857 - val_output_3_accuracy: 0.9832 - val_output_4_accuracy: 0.9773\n",
      "Epoch 80/200\n",
      "4000/4000 [==============================] - 1s 311us/sample - loss: 0.3341 - output_0_loss: 0.0701 - output_1_loss: 0.0575 - output_2_loss: 0.0675 - output_3_loss: 0.0653 - output_4_loss: 0.0738 - output_0_accuracy: 0.9768 - output_1_accuracy: 0.9825 - output_2_accuracy: 0.9778 - output_3_accuracy: 0.9803 - output_4_accuracy: 0.9765 - val_loss: 0.3039 - val_output_0_loss: 0.0667 - val_output_1_loss: 0.0721 - val_output_2_loss: 0.0333 - val_output_3_loss: 0.0668 - val_output_4_loss: 0.0648 - val_output_0_accuracy: 0.9798 - val_output_1_accuracy: 0.9757 - val_output_2_accuracy: 0.9915 - val_output_3_accuracy: 0.9767 - val_output_4_accuracy: 0.9795\n",
      "Epoch 81/200\n",
      "4000/4000 [==============================] - 1s 298us/sample - loss: 0.3496 - output_0_loss: 0.0725 - output_1_loss: 0.0657 - output_2_loss: 0.0826 - output_3_loss: 0.0638 - output_4_loss: 0.0649 - output_0_accuracy: 0.9787 - output_1_accuracy: 0.9803 - output_2_accuracy: 0.9755 - output_3_accuracy: 0.9812 - output_4_accuracy: 0.9787 - val_loss: 0.5411 - val_output_0_loss: 0.1742 - val_output_1_loss: 0.0931 - val_output_2_loss: 0.0380 - val_output_3_loss: 0.1270 - val_output_4_loss: 0.1094 - val_output_0_accuracy: 0.9487 - val_output_1_accuracy: 0.9663 - val_output_2_accuracy: 0.9900 - val_output_3_accuracy: 0.9623 - val_output_4_accuracy: 0.9618\n",
      "Epoch 82/200\n",
      "4000/4000 [==============================] - 1s 316us/sample - loss: 0.3340 - output_0_loss: 0.0637 - output_1_loss: 0.0627 - output_2_loss: 0.0526 - output_3_loss: 0.0826 - output_4_loss: 0.0724 - output_0_accuracy: 0.9793 - output_1_accuracy: 0.9818 - output_2_accuracy: 0.9852 - output_3_accuracy: 0.9758 - output_4_accuracy: 0.9760 - val_loss: 0.4919 - val_output_0_loss: 0.0806 - val_output_1_loss: 0.1344 - val_output_2_loss: 0.1404 - val_output_3_loss: 0.1014 - val_output_4_loss: 0.0349 - val_output_0_accuracy: 0.9740 - val_output_1_accuracy: 0.9562 - val_output_2_accuracy: 0.9538 - val_output_3_accuracy: 0.9672 - val_output_4_accuracy: 0.9918\n",
      "Epoch 83/200\n",
      "4000/4000 [==============================] - 1s 316us/sample - loss: 0.3153 - output_0_loss: 0.0672 - output_1_loss: 0.0609 - output_2_loss: 0.0717 - output_3_loss: 0.0543 - output_4_loss: 0.0611 - output_0_accuracy: 0.9795 - output_1_accuracy: 0.9810 - output_2_accuracy: 0.9815 - output_3_accuracy: 0.9852 - output_4_accuracy: 0.9820 - val_loss: 0.5299 - val_output_0_loss: 0.1298 - val_output_1_loss: 0.1056 - val_output_2_loss: 0.0771 - val_output_3_loss: 0.1650 - val_output_4_loss: 0.0530 - val_output_0_accuracy: 0.9560 - val_output_1_accuracy: 0.9652 - val_output_2_accuracy: 0.9740 - val_output_3_accuracy: 0.9510 - val_output_4_accuracy: 0.9833\n",
      "Epoch 84/200\n",
      "4000/4000 [==============================] - 1s 346us/sample - loss: 0.3303 - output_0_loss: 0.0662 - output_1_loss: 0.0739 - output_2_loss: 0.0701 - output_3_loss: 0.0641 - output_4_loss: 0.0559 - output_0_accuracy: 0.9783 - output_1_accuracy: 0.9770 - output_2_accuracy: 0.9772 - output_3_accuracy: 0.9820 - output_4_accuracy: 0.9820 - val_loss: 0.3976 - val_output_0_loss: 0.0709 - val_output_1_loss: 0.0497 - val_output_2_loss: 0.0840 - val_output_3_loss: 0.1271 - val_output_4_loss: 0.0652 - val_output_0_accuracy: 0.9758 - val_output_1_accuracy: 0.9838 - val_output_2_accuracy: 0.9713 - val_output_3_accuracy: 0.9602 - val_output_4_accuracy: 0.9802\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 325us/sample - loss: 0.3395 - output_0_loss: 0.0614 - output_1_loss: 0.0677 - output_2_loss: 0.0706 - output_3_loss: 0.0614 - output_4_loss: 0.0784 - output_0_accuracy: 0.9815 - output_1_accuracy: 0.9805 - output_2_accuracy: 0.9772 - output_3_accuracy: 0.9810 - output_4_accuracy: 0.9768 - val_loss: 0.4422 - val_output_0_loss: 0.0631 - val_output_1_loss: 0.1320 - val_output_2_loss: 0.0766 - val_output_3_loss: 0.0599 - val_output_4_loss: 0.1104 - val_output_0_accuracy: 0.9802 - val_output_1_accuracy: 0.9587 - val_output_2_accuracy: 0.9743 - val_output_3_accuracy: 0.9815 - val_output_4_accuracy: 0.9672\n",
      "Epoch 86/200\n",
      "4000/4000 [==============================] - 1s 326us/sample - loss: 0.3071 - output_0_loss: 0.0655 - output_1_loss: 0.0634 - output_2_loss: 0.0569 - output_3_loss: 0.0643 - output_4_loss: 0.0570 - output_0_accuracy: 0.9772 - output_1_accuracy: 0.9785 - output_2_accuracy: 0.9852 - output_3_accuracy: 0.9772 - output_4_accuracy: 0.9812 - val_loss: 0.4075 - val_output_0_loss: 0.1107 - val_output_1_loss: 0.0221 - val_output_2_loss: 0.0623 - val_output_3_loss: 0.1290 - val_output_4_loss: 0.0834 - val_output_0_accuracy: 0.9625 - val_output_1_accuracy: 0.9943 - val_output_2_accuracy: 0.9835 - val_output_3_accuracy: 0.9560 - val_output_4_accuracy: 0.9727\n",
      "Epoch 87/200\n",
      "4000/4000 [==============================] - 1s 315us/sample - loss: 0.3247 - output_0_loss: 0.0693 - output_1_loss: 0.0598 - output_2_loss: 0.0683 - output_3_loss: 0.0648 - output_4_loss: 0.0626 - output_0_accuracy: 0.9793 - output_1_accuracy: 0.9805 - output_2_accuracy: 0.9795 - output_3_accuracy: 0.9793 - output_4_accuracy: 0.9780 - val_loss: 0.3664 - val_output_0_loss: 0.1433 - val_output_1_loss: 0.0983 - val_output_2_loss: 0.0205 - val_output_3_loss: 0.0821 - val_output_4_loss: 0.0221 - val_output_0_accuracy: 0.9600 - val_output_1_accuracy: 0.9698 - val_output_2_accuracy: 0.9957 - val_output_3_accuracy: 0.9732 - val_output_4_accuracy: 0.9950\n",
      "Epoch 88/200\n",
      "4000/4000 [==============================] - 1s 324us/sample - loss: 0.3239 - output_0_loss: 0.0676 - output_1_loss: 0.0752 - output_2_loss: 0.0651 - output_3_loss: 0.0545 - output_4_loss: 0.0616 - output_0_accuracy: 0.9793 - output_1_accuracy: 0.9785 - output_2_accuracy: 0.9770 - output_3_accuracy: 0.9827 - output_4_accuracy: 0.9815 - val_loss: 0.3942 - val_output_0_loss: 0.1145 - val_output_1_loss: 0.0800 - val_output_2_loss: 0.0724 - val_output_3_loss: 0.0728 - val_output_4_loss: 0.0544 - val_output_0_accuracy: 0.9597 - val_output_1_accuracy: 0.9702 - val_output_2_accuracy: 0.9777 - val_output_3_accuracy: 0.9743 - val_output_4_accuracy: 0.9862\n",
      "Epoch 89/200\n",
      "4000/4000 [==============================] - 1s 315us/sample - loss: 0.2892 - output_0_loss: 0.0497 - output_1_loss: 0.0518 - output_2_loss: 0.0584 - output_3_loss: 0.0600 - output_4_loss: 0.0694 - output_0_accuracy: 0.9845 - output_1_accuracy: 0.9830 - output_2_accuracy: 0.9845 - output_3_accuracy: 0.9800 - output_4_accuracy: 0.9787 - val_loss: 0.7038 - val_output_0_loss: 0.1969 - val_output_1_loss: 0.0625 - val_output_2_loss: 0.2093 - val_output_3_loss: 0.1001 - val_output_4_loss: 0.1344 - val_output_0_accuracy: 0.9470 - val_output_1_accuracy: 0.9810 - val_output_2_accuracy: 0.9333 - val_output_3_accuracy: 0.9680 - val_output_4_accuracy: 0.9637\n",
      "Epoch 90/200\n",
      "4000/4000 [==============================] - 1s 304us/sample - loss: 0.3037 - output_0_loss: 0.0628 - output_1_loss: 0.0607 - output_2_loss: 0.0639 - output_3_loss: 0.0670 - output_4_loss: 0.0493 - output_0_accuracy: 0.9815 - output_1_accuracy: 0.9805 - output_2_accuracy: 0.9805 - output_3_accuracy: 0.9778 - output_4_accuracy: 0.9872 - val_loss: 0.5440 - val_output_0_loss: 0.0968 - val_output_1_loss: 0.1561 - val_output_2_loss: 0.0927 - val_output_3_loss: 0.0644 - val_output_4_loss: 0.1335 - val_output_0_accuracy: 0.9680 - val_output_1_accuracy: 0.9553 - val_output_2_accuracy: 0.9705 - val_output_3_accuracy: 0.9807 - val_output_4_accuracy: 0.9555\n",
      "Epoch 91/200\n",
      "4000/4000 [==============================] - 1s 308us/sample - loss: 0.2782 - output_0_loss: 0.0559 - output_1_loss: 0.0533 - output_2_loss: 0.0498 - output_3_loss: 0.0540 - output_4_loss: 0.0653 - output_0_accuracy: 0.9818 - output_1_accuracy: 0.9825 - output_2_accuracy: 0.9858 - output_3_accuracy: 0.9820 - output_4_accuracy: 0.9805 - val_loss: 0.3739 - val_output_0_loss: 0.1006 - val_output_1_loss: 0.0856 - val_output_2_loss: 0.0911 - val_output_3_loss: 0.0541 - val_output_4_loss: 0.0428 - val_output_0_accuracy: 0.9727 - val_output_1_accuracy: 0.9720 - val_output_2_accuracy: 0.9717 - val_output_3_accuracy: 0.9853 - val_output_4_accuracy: 0.9870\n",
      "Epoch 92/200\n",
      "4000/4000 [==============================] - 1s 368us/sample - loss: 0.2995 - output_0_loss: 0.0612 - output_1_loss: 0.0582 - output_2_loss: 0.0564 - output_3_loss: 0.0584 - output_4_loss: 0.0653 - output_0_accuracy: 0.9805 - output_1_accuracy: 0.9833 - output_2_accuracy: 0.9815 - output_3_accuracy: 0.9845 - output_4_accuracy: 0.9800 - val_loss: 0.4019 - val_output_0_loss: 0.1515 - val_output_1_loss: 0.0275 - val_output_2_loss: 0.1200 - val_output_3_loss: 0.0569 - val_output_4_loss: 0.0455 - val_output_0_accuracy: 0.9588 - val_output_1_accuracy: 0.9923 - val_output_2_accuracy: 0.9680 - val_output_3_accuracy: 0.9838 - val_output_4_accuracy: 0.9865\n",
      "Epoch 93/200\n",
      "4000/4000 [==============================] - 1s 365us/sample - loss: 0.3000 - output_0_loss: 0.0618 - output_1_loss: 0.0625 - output_2_loss: 0.0654 - output_3_loss: 0.0597 - output_4_loss: 0.0507 - output_0_accuracy: 0.9810 - output_1_accuracy: 0.9803 - output_2_accuracy: 0.9795 - output_3_accuracy: 0.9810 - output_4_accuracy: 0.9827 - val_loss: 0.5724 - val_output_0_loss: 0.1020 - val_output_1_loss: 0.1129 - val_output_2_loss: 0.0528 - val_output_3_loss: 0.1461 - val_output_4_loss: 0.1592 - val_output_0_accuracy: 0.9653 - val_output_1_accuracy: 0.9648 - val_output_2_accuracy: 0.9838 - val_output_3_accuracy: 0.9540 - val_output_4_accuracy: 0.9498\n",
      "Epoch 94/200\n",
      "4000/4000 [==============================] - 2s 451us/sample - loss: 0.2912 - output_0_loss: 0.0582 - output_1_loss: 0.0662 - output_2_loss: 0.0514 - output_3_loss: 0.0607 - output_4_loss: 0.0548 - output_0_accuracy: 0.9837 - output_1_accuracy: 0.9797 - output_2_accuracy: 0.9815 - output_3_accuracy: 0.9815 - output_4_accuracy: 0.9830 - val_loss: 0.3599 - val_output_0_loss: 0.1259 - val_output_1_loss: 0.0518 - val_output_2_loss: 0.1056 - val_output_3_loss: 0.0463 - val_output_4_loss: 0.0298 - val_output_0_accuracy: 0.9657 - val_output_1_accuracy: 0.9838 - val_output_2_accuracy: 0.9667 - val_output_3_accuracy: 0.9852 - val_output_4_accuracy: 0.9922\n",
      "Epoch 95/200\n",
      "4000/4000 [==============================] - 1s 374us/sample - loss: 0.2767 - output_0_loss: 0.0529 - output_1_loss: 0.0569 - output_2_loss: 0.0588 - output_3_loss: 0.0550 - output_4_loss: 0.0530 - output_0_accuracy: 0.9837 - output_1_accuracy: 0.9833 - output_2_accuracy: 0.9815 - output_3_accuracy: 0.9840 - output_4_accuracy: 0.9833 - val_loss: 0.2950 - val_output_0_loss: 0.1117 - val_output_1_loss: 0.0758 - val_output_2_loss: 0.0594 - val_output_3_loss: 0.0366 - val_output_4_loss: 0.0127 - val_output_0_accuracy: 0.9638 - val_output_1_accuracy: 0.9722 - val_output_2_accuracy: 0.9808 - val_output_3_accuracy: 0.9890 - val_output_4_accuracy: 0.9970\n",
      "Epoch 96/200\n",
      "4000/4000 [==============================] - 1s 375us/sample - loss: 0.2657 - output_0_loss: 0.0599 - output_1_loss: 0.0481 - output_2_loss: 0.0481 - output_3_loss: 0.0481 - output_4_loss: 0.0615 - output_0_accuracy: 0.9843 - output_1_accuracy: 0.9850 - output_2_accuracy: 0.9847 - output_3_accuracy: 0.9870 - output_4_accuracy: 0.9812 - val_loss: 0.4365 - val_output_0_loss: 0.0668 - val_output_1_loss: 0.1611 - val_output_2_loss: 0.0529 - val_output_3_loss: 0.1013 - val_output_4_loss: 0.0545 - val_output_0_accuracy: 0.9773 - val_output_1_accuracy: 0.9467 - val_output_2_accuracy: 0.9823 - val_output_3_accuracy: 0.9707 - val_output_4_accuracy: 0.9853\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 370us/sample - loss: 0.2841 - output_0_loss: 0.0520 - output_1_loss: 0.0532 - output_2_loss: 0.0668 - output_3_loss: 0.0587 - output_4_loss: 0.0535 - output_0_accuracy: 0.9810 - output_1_accuracy: 0.9810 - output_2_accuracy: 0.9793 - output_3_accuracy: 0.9805 - output_4_accuracy: 0.9827 - val_loss: 0.4489 - val_output_0_loss: 0.1580 - val_output_1_loss: 0.0863 - val_output_2_loss: 0.0706 - val_output_3_loss: 0.0799 - val_output_4_loss: 0.0532 - val_output_0_accuracy: 0.9502 - val_output_1_accuracy: 0.9688 - val_output_2_accuracy: 0.9767 - val_output_3_accuracy: 0.9728 - val_output_4_accuracy: 0.9832\n",
      "Epoch 98/200\n",
      "4000/4000 [==============================] - 1s 352us/sample - loss: 0.2643 - output_0_loss: 0.0555 - output_1_loss: 0.0485 - output_2_loss: 0.0454 - output_3_loss: 0.0583 - output_4_loss: 0.0566 - output_0_accuracy: 0.9822 - output_1_accuracy: 0.9845 - output_2_accuracy: 0.9847 - output_3_accuracy: 0.9818 - output_4_accuracy: 0.9830 - val_loss: 0.3484 - val_output_0_loss: 0.1306 - val_output_1_loss: 0.0500 - val_output_2_loss: 0.0494 - val_output_3_loss: 0.0660 - val_output_4_loss: 0.0524 - val_output_0_accuracy: 0.9620 - val_output_1_accuracy: 0.9817 - val_output_2_accuracy: 0.9858 - val_output_3_accuracy: 0.9797 - val_output_4_accuracy: 0.9832\n",
      "Epoch 99/200\n",
      "4000/4000 [==============================] - 2s 386us/sample - loss: 0.2450 - output_0_loss: 0.0519 - output_1_loss: 0.0487 - output_2_loss: 0.0411 - output_3_loss: 0.0562 - output_4_loss: 0.0470 - output_0_accuracy: 0.9815 - output_1_accuracy: 0.9845 - output_2_accuracy: 0.9908 - output_3_accuracy: 0.9830 - output_4_accuracy: 0.9847 - val_loss: 0.3428 - val_output_0_loss: 0.0988 - val_output_1_loss: 0.0512 - val_output_2_loss: 0.0478 - val_output_3_loss: 0.0766 - val_output_4_loss: 0.0685 - val_output_0_accuracy: 0.9695 - val_output_1_accuracy: 0.9827 - val_output_2_accuracy: 0.9855 - val_output_3_accuracy: 0.9740 - val_output_4_accuracy: 0.9767\n",
      "Epoch 100/200\n",
      "4000/4000 [==============================] - 1s 349us/sample - loss: 0.2756 - output_0_loss: 0.0507 - output_1_loss: 0.0645 - output_2_loss: 0.0506 - output_3_loss: 0.0568 - output_4_loss: 0.0529 - output_0_accuracy: 0.9843 - output_1_accuracy: 0.9808 - output_2_accuracy: 0.9833 - output_3_accuracy: 0.9830 - output_4_accuracy: 0.9825 - val_loss: 0.6445 - val_output_0_loss: 0.0596 - val_output_1_loss: 0.1861 - val_output_2_loss: 0.1053 - val_output_3_loss: 0.2023 - val_output_4_loss: 0.0918 - val_output_0_accuracy: 0.9805 - val_output_1_accuracy: 0.9453 - val_output_2_accuracy: 0.9613 - val_output_3_accuracy: 0.9408 - val_output_4_accuracy: 0.9748\n",
      "Epoch 101/200\n",
      "4000/4000 [==============================] - 1s 361us/sample - loss: 0.2516 - output_0_loss: 0.0418 - output_1_loss: 0.0471 - output_2_loss: 0.0510 - output_3_loss: 0.0546 - output_4_loss: 0.0571 - output_0_accuracy: 0.9883 - output_1_accuracy: 0.9865 - output_2_accuracy: 0.9840 - output_3_accuracy: 0.9808 - output_4_accuracy: 0.9847 - val_loss: 0.3343 - val_output_0_loss: 0.0533 - val_output_1_loss: 0.0900 - val_output_2_loss: 0.0647 - val_output_3_loss: 0.1027 - val_output_4_loss: 0.0234 - val_output_0_accuracy: 0.9852 - val_output_1_accuracy: 0.9695 - val_output_2_accuracy: 0.9835 - val_output_3_accuracy: 0.9707 - val_output_4_accuracy: 0.9937\n",
      "Epoch 102/200\n",
      "4000/4000 [==============================] - 1s 354us/sample - loss: 0.2731 - output_0_loss: 0.0604 - output_1_loss: 0.0506 - output_2_loss: 0.0442 - output_3_loss: 0.0618 - output_4_loss: 0.0562 - output_0_accuracy: 0.9793 - output_1_accuracy: 0.9827 - output_2_accuracy: 0.9880 - output_3_accuracy: 0.9787 - output_4_accuracy: 0.9825 - val_loss: 0.4436 - val_output_0_loss: 0.0860 - val_output_1_loss: 0.0722 - val_output_2_loss: 0.0725 - val_output_3_loss: 0.1253 - val_output_4_loss: 0.0868 - val_output_0_accuracy: 0.9732 - val_output_1_accuracy: 0.9740 - val_output_2_accuracy: 0.9762 - val_output_3_accuracy: 0.9622 - val_output_4_accuracy: 0.9712\n",
      "Epoch 103/200\n",
      "4000/4000 [==============================] - 1s 372us/sample - loss: 0.2510 - output_0_loss: 0.0414 - output_1_loss: 0.0515 - output_2_loss: 0.0563 - output_3_loss: 0.0440 - output_4_loss: 0.0579 - output_0_accuracy: 0.9870 - output_1_accuracy: 0.9825 - output_2_accuracy: 0.9840 - output_3_accuracy: 0.9850 - output_4_accuracy: 0.9815 - val_loss: 0.6504 - val_output_0_loss: 0.0800 - val_output_1_loss: 0.0750 - val_output_2_loss: 0.0799 - val_output_3_loss: 0.2195 - val_output_4_loss: 0.1962 - val_output_0_accuracy: 0.9748 - val_output_1_accuracy: 0.9778 - val_output_2_accuracy: 0.9738 - val_output_3_accuracy: 0.9307 - val_output_4_accuracy: 0.9438\n",
      "Epoch 104/200\n",
      "4000/4000 [==============================] - 1s 369us/sample - loss: 0.2545 - output_0_loss: 0.0584 - output_1_loss: 0.0443 - output_2_loss: 0.0487 - output_3_loss: 0.0579 - output_4_loss: 0.0452 - output_0_accuracy: 0.9818 - output_1_accuracy: 0.9870 - output_2_accuracy: 0.9862 - output_3_accuracy: 0.9827 - output_4_accuracy: 0.9865 - val_loss: 0.2374 - val_output_0_loss: 0.0949 - val_output_1_loss: 0.0218 - val_output_2_loss: 0.0278 - val_output_3_loss: 0.0297 - val_output_4_loss: 0.0648 - val_output_0_accuracy: 0.9707 - val_output_1_accuracy: 0.9943 - val_output_2_accuracy: 0.9922 - val_output_3_accuracy: 0.9912 - val_output_4_accuracy: 0.9817\n",
      "Epoch 105/200\n",
      "4000/4000 [==============================] - 1s 357us/sample - loss: 0.2566 - output_0_loss: 0.0454 - output_1_loss: 0.0497 - output_2_loss: 0.0514 - output_3_loss: 0.0502 - output_4_loss: 0.0600 - output_0_accuracy: 0.9843 - output_1_accuracy: 0.9845 - output_2_accuracy: 0.9855 - output_3_accuracy: 0.9837 - output_4_accuracy: 0.9827 - val_loss: 0.4594 - val_output_0_loss: 0.1139 - val_output_1_loss: 0.0508 - val_output_2_loss: 0.1265 - val_output_3_loss: 0.0915 - val_output_4_loss: 0.0772 - val_output_0_accuracy: 0.9612 - val_output_1_accuracy: 0.9807 - val_output_2_accuracy: 0.9570 - val_output_3_accuracy: 0.9705 - val_output_4_accuracy: 0.9740\n",
      "Epoch 106/200\n",
      "4000/4000 [==============================] - 2s 382us/sample - loss: 0.2306 - output_0_loss: 0.0449 - output_1_loss: 0.0449 - output_2_loss: 0.0460 - output_3_loss: 0.0514 - output_4_loss: 0.0433 - output_0_accuracy: 0.9858 - output_1_accuracy: 0.9880 - output_2_accuracy: 0.9890 - output_3_accuracy: 0.9827 - output_4_accuracy: 0.9862 - val_loss: 0.3440 - val_output_0_loss: 0.0780 - val_output_1_loss: 0.0855 - val_output_2_loss: 0.0739 - val_output_3_loss: 0.0278 - val_output_4_loss: 0.0792 - val_output_0_accuracy: 0.9757 - val_output_1_accuracy: 0.9753 - val_output_2_accuracy: 0.9812 - val_output_3_accuracy: 0.9937 - val_output_4_accuracy: 0.9748\n",
      "Epoch 107/200\n",
      "4000/4000 [==============================] - 1s 340us/sample - loss: 0.2426 - output_0_loss: 0.0491 - output_1_loss: 0.0536 - output_2_loss: 0.0435 - output_3_loss: 0.0470 - output_4_loss: 0.0493 - output_0_accuracy: 0.9835 - output_1_accuracy: 0.9865 - output_2_accuracy: 0.9847 - output_3_accuracy: 0.9870 - output_4_accuracy: 0.9837 - val_loss: 0.4096 - val_output_0_loss: 0.0652 - val_output_1_loss: 0.0394 - val_output_2_loss: 0.1322 - val_output_3_loss: 0.1154 - val_output_4_loss: 0.0567 - val_output_0_accuracy: 0.9800 - val_output_1_accuracy: 0.9887 - val_output_2_accuracy: 0.9552 - val_output_3_accuracy: 0.9632 - val_output_4_accuracy: 0.9815\n",
      "Epoch 108/200\n",
      "4000/4000 [==============================] - 1s 338us/sample - loss: 0.2552 - output_0_loss: 0.0564 - output_1_loss: 0.0411 - output_2_loss: 0.0550 - output_3_loss: 0.0508 - output_4_loss: 0.0518 - output_0_accuracy: 0.9827 - output_1_accuracy: 0.9868 - output_2_accuracy: 0.9852 - output_3_accuracy: 0.9825 - output_4_accuracy: 0.9825 - val_loss: 0.4714 - val_output_0_loss: 0.1051 - val_output_1_loss: 0.1235 - val_output_2_loss: 0.1185 - val_output_3_loss: 0.0634 - val_output_4_loss: 0.0602 - val_output_0_accuracy: 0.9645 - val_output_1_accuracy: 0.9580 - val_output_2_accuracy: 0.9618 - val_output_3_accuracy: 0.9792 - val_output_4_accuracy: 0.9825\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 355us/sample - loss: 0.2280 - output_0_loss: 0.0427 - output_1_loss: 0.0460 - output_2_loss: 0.0390 - output_3_loss: 0.0551 - output_4_loss: 0.0452 - output_0_accuracy: 0.9868 - output_1_accuracy: 0.9843 - output_2_accuracy: 0.9902 - output_3_accuracy: 0.9845 - output_4_accuracy: 0.9858 - val_loss: 0.5053 - val_output_0_loss: 0.1282 - val_output_1_loss: 0.1226 - val_output_2_loss: 0.0874 - val_output_3_loss: 0.0411 - val_output_4_loss: 0.1265 - val_output_0_accuracy: 0.9602 - val_output_1_accuracy: 0.9615 - val_output_2_accuracy: 0.9718 - val_output_3_accuracy: 0.9888 - val_output_4_accuracy: 0.9573\n",
      "Epoch 110/200\n",
      "4000/4000 [==============================] - 2s 423us/sample - loss: 0.2381 - output_0_loss: 0.0446 - output_1_loss: 0.0508 - output_2_loss: 0.0542 - output_3_loss: 0.0478 - output_4_loss: 0.0406 - output_0_accuracy: 0.9870 - output_1_accuracy: 0.9850 - output_2_accuracy: 0.9803 - output_3_accuracy: 0.9835 - output_4_accuracy: 0.9893 - val_loss: 0.4208 - val_output_0_loss: 0.0902 - val_output_1_loss: 0.0640 - val_output_2_loss: 0.1360 - val_output_3_loss: 0.0720 - val_output_4_loss: 0.0602 - val_output_0_accuracy: 0.9713 - val_output_1_accuracy: 0.9805 - val_output_2_accuracy: 0.9628 - val_output_3_accuracy: 0.9750 - val_output_4_accuracy: 0.9808\n",
      "Epoch 111/200\n",
      "4000/4000 [==============================] - 2s 381us/sample - loss: 0.2531 - output_0_loss: 0.0573 - output_1_loss: 0.0521 - output_2_loss: 0.0405 - output_3_loss: 0.0492 - output_4_loss: 0.0540 - output_0_accuracy: 0.9847 - output_1_accuracy: 0.9852 - output_2_accuracy: 0.9887 - output_3_accuracy: 0.9877 - output_4_accuracy: 0.9847 - val_loss: 0.3446 - val_output_0_loss: 0.0539 - val_output_1_loss: 0.1593 - val_output_2_loss: 0.0438 - val_output_3_loss: 0.0588 - val_output_4_loss: 0.0290 - val_output_0_accuracy: 0.9817 - val_output_1_accuracy: 0.9597 - val_output_2_accuracy: 0.9863 - val_output_3_accuracy: 0.9818 - val_output_4_accuracy: 0.9912\n",
      "Epoch 112/200\n",
      "4000/4000 [==============================] - 2s 395us/sample - loss: 0.2500 - output_0_loss: 0.0415 - output_1_loss: 0.0560 - output_2_loss: 0.0454 - output_3_loss: 0.0518 - output_4_loss: 0.0554 - output_0_accuracy: 0.9868 - output_1_accuracy: 0.9810 - output_2_accuracy: 0.9843 - output_3_accuracy: 0.9852 - output_4_accuracy: 0.9837 - val_loss: 0.3164 - val_output_0_loss: 0.0341 - val_output_1_loss: 0.0477 - val_output_2_loss: 0.0496 - val_output_3_loss: 0.1307 - val_output_4_loss: 0.0536 - val_output_0_accuracy: 0.9900 - val_output_1_accuracy: 0.9832 - val_output_2_accuracy: 0.9847 - val_output_3_accuracy: 0.9582 - val_output_4_accuracy: 0.9813\n",
      "Epoch 113/200\n",
      "4000/4000 [==============================] - 1s 364us/sample - loss: 0.2153 - output_0_loss: 0.0382 - output_1_loss: 0.0434 - output_2_loss: 0.0467 - output_3_loss: 0.0423 - output_4_loss: 0.0448 - output_0_accuracy: 0.9862 - output_1_accuracy: 0.9865 - output_2_accuracy: 0.9868 - output_3_accuracy: 0.9868 - output_4_accuracy: 0.9855 - val_loss: 0.3085 - val_output_0_loss: 0.0875 - val_output_1_loss: 0.0609 - val_output_2_loss: 0.0388 - val_output_3_loss: 0.0585 - val_output_4_loss: 0.0623 - val_output_0_accuracy: 0.9693 - val_output_1_accuracy: 0.9790 - val_output_2_accuracy: 0.9892 - val_output_3_accuracy: 0.9813 - val_output_4_accuracy: 0.9800\n",
      "Epoch 114/200\n",
      "4000/4000 [==============================] - 1s 365us/sample - loss: 0.2469 - output_0_loss: 0.0410 - output_1_loss: 0.0667 - output_2_loss: 0.0444 - output_3_loss: 0.0464 - output_4_loss: 0.0485 - output_0_accuracy: 0.9885 - output_1_accuracy: 0.9810 - output_2_accuracy: 0.9852 - output_3_accuracy: 0.9872 - output_4_accuracy: 0.9855 - val_loss: 0.3024 - val_output_0_loss: 0.0616 - val_output_1_loss: 0.1105 - val_output_2_loss: 0.0311 - val_output_3_loss: 0.0724 - val_output_4_loss: 0.0263 - val_output_0_accuracy: 0.9777 - val_output_1_accuracy: 0.9658 - val_output_2_accuracy: 0.9912 - val_output_3_accuracy: 0.9783 - val_output_4_accuracy: 0.9933\n",
      "Epoch 115/200\n",
      "4000/4000 [==============================] - 1s 374us/sample - loss: 0.2178 - output_0_loss: 0.0506 - output_1_loss: 0.0415 - output_2_loss: 0.0402 - output_3_loss: 0.0445 - output_4_loss: 0.0410 - output_0_accuracy: 0.9850 - output_1_accuracy: 0.9862 - output_2_accuracy: 0.9872 - output_3_accuracy: 0.9860 - output_4_accuracy: 0.9880 - val_loss: 0.4688 - val_output_0_loss: 0.1409 - val_output_1_loss: 0.0709 - val_output_2_loss: 0.0276 - val_output_3_loss: 0.1756 - val_output_4_loss: 0.0537 - val_output_0_accuracy: 0.9670 - val_output_1_accuracy: 0.9757 - val_output_2_accuracy: 0.9908 - val_output_3_accuracy: 0.9430 - val_output_4_accuracy: 0.9832\n",
      "Epoch 116/200\n",
      "4000/4000 [==============================] - 2s 387us/sample - loss: 0.2153 - output_0_loss: 0.0417 - output_1_loss: 0.0406 - output_2_loss: 0.0470 - output_3_loss: 0.0438 - output_4_loss: 0.0422 - output_0_accuracy: 0.9880 - output_1_accuracy: 0.9885 - output_2_accuracy: 0.9868 - output_3_accuracy: 0.9868 - output_4_accuracy: 0.9872 - val_loss: 0.3060 - val_output_0_loss: 0.0724 - val_output_1_loss: 0.0299 - val_output_2_loss: 0.0410 - val_output_3_loss: 0.1023 - val_output_4_loss: 0.0612 - val_output_0_accuracy: 0.9747 - val_output_1_accuracy: 0.9913 - val_output_2_accuracy: 0.9848 - val_output_3_accuracy: 0.9703 - val_output_4_accuracy: 0.9793\n",
      "Epoch 117/200\n",
      "4000/4000 [==============================] - 3s 645us/sample - loss: 0.2339 - output_0_loss: 0.0415 - output_1_loss: 0.0564 - output_2_loss: 0.0448 - output_3_loss: 0.0499 - output_4_loss: 0.0413 - output_0_accuracy: 0.9880 - output_1_accuracy: 0.9818 - output_2_accuracy: 0.9862 - output_3_accuracy: 0.9843 - output_4_accuracy: 0.9865 - val_loss: 0.2774 - val_output_0_loss: 0.0627 - val_output_1_loss: 0.0545 - val_output_2_loss: 0.0498 - val_output_3_loss: 0.0516 - val_output_4_loss: 0.0583 - val_output_0_accuracy: 0.9808 - val_output_1_accuracy: 0.9833 - val_output_2_accuracy: 0.9845 - val_output_3_accuracy: 0.9833 - val_output_4_accuracy: 0.9787\n",
      "Epoch 118/200\n",
      "4000/4000 [==============================] - 2s 384us/sample - loss: 0.2390 - output_0_loss: 0.0601 - output_1_loss: 0.0352 - output_2_loss: 0.0494 - output_3_loss: 0.0480 - output_4_loss: 0.0463 - output_0_accuracy: 0.9815 - output_1_accuracy: 0.9893 - output_2_accuracy: 0.9852 - output_3_accuracy: 0.9837 - output_4_accuracy: 0.9858 - val_loss: 0.3428 - val_output_0_loss: 0.0531 - val_output_1_loss: 0.0594 - val_output_2_loss: 0.0824 - val_output_3_loss: 0.1133 - val_output_4_loss: 0.0349 - val_output_0_accuracy: 0.9838 - val_output_1_accuracy: 0.9788 - val_output_2_accuracy: 0.9737 - val_output_3_accuracy: 0.9635 - val_output_4_accuracy: 0.9908\n",
      "Epoch 119/200\n",
      "4000/4000 [==============================] - 2s 464us/sample - loss: 0.2090 - output_0_loss: 0.0400 - output_1_loss: 0.0448 - output_2_loss: 0.0362 - output_3_loss: 0.0437 - output_4_loss: 0.0443 - output_0_accuracy: 0.9870 - output_1_accuracy: 0.9860 - output_2_accuracy: 0.9895 - output_3_accuracy: 0.9880 - output_4_accuracy: 0.9870 - val_loss: 0.3792 - val_output_0_loss: 0.1087 - val_output_1_loss: 0.1045 - val_output_2_loss: 0.0539 - val_output_3_loss: 0.0391 - val_output_4_loss: 0.0726 - val_output_0_accuracy: 0.9665 - val_output_1_accuracy: 0.9685 - val_output_2_accuracy: 0.9810 - val_output_3_accuracy: 0.9878 - val_output_4_accuracy: 0.9765\n",
      "Epoch 120/200\n",
      "4000/4000 [==============================] - 2s 573us/sample - loss: 0.2165 - output_0_loss: 0.0395 - output_1_loss: 0.0415 - output_2_loss: 0.0371 - output_3_loss: 0.0520 - output_4_loss: 0.0464 - output_0_accuracy: 0.9877 - output_1_accuracy: 0.9890 - output_2_accuracy: 0.9900 - output_3_accuracy: 0.9852 - output_4_accuracy: 0.9860 - val_loss: 0.2938 - val_output_0_loss: 0.0723 - val_output_1_loss: 0.0373 - val_output_2_loss: 0.0404 - val_output_3_loss: 0.0907 - val_output_4_loss: 0.0527 - val_output_0_accuracy: 0.9765 - val_output_1_accuracy: 0.9877 - val_output_2_accuracy: 0.9878 - val_output_3_accuracy: 0.9747 - val_output_4_accuracy: 0.9825\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 343us/sample - loss: 0.2431 - output_0_loss: 0.0610 - output_1_loss: 0.0443 - output_2_loss: 0.0463 - output_3_loss: 0.0488 - output_4_loss: 0.0426 - output_0_accuracy: 0.9795 - output_1_accuracy: 0.9883 - output_2_accuracy: 0.9865 - output_3_accuracy: 0.9865 - output_4_accuracy: 0.9872 - val_loss: 0.5025 - val_output_0_loss: 0.1104 - val_output_1_loss: 0.1263 - val_output_2_loss: 0.0972 - val_output_3_loss: 0.0568 - val_output_4_loss: 0.1113 - val_output_0_accuracy: 0.9657 - val_output_1_accuracy: 0.9557 - val_output_2_accuracy: 0.9648 - val_output_3_accuracy: 0.9823 - val_output_4_accuracy: 0.9622\n",
      "Epoch 122/200\n",
      "4000/4000 [==============================] - 2s 488us/sample - loss: 0.2317 - output_0_loss: 0.0450 - output_1_loss: 0.0479 - output_2_loss: 0.0460 - output_3_loss: 0.0430 - output_4_loss: 0.0498 - output_0_accuracy: 0.9847 - output_1_accuracy: 0.9845 - output_2_accuracy: 0.9870 - output_3_accuracy: 0.9872 - output_4_accuracy: 0.9858 - val_loss: 0.6427 - val_output_0_loss: 0.1633 - val_output_1_loss: 0.0868 - val_output_2_loss: 0.0637 - val_output_3_loss: 0.2367 - val_output_4_loss: 0.0914 - val_output_0_accuracy: 0.9482 - val_output_1_accuracy: 0.9737 - val_output_2_accuracy: 0.9852 - val_output_3_accuracy: 0.9360 - val_output_4_accuracy: 0.9735\n",
      "Epoch 123/200\n",
      "4000/4000 [==============================] - 2s 614us/sample - loss: 0.2201 - output_0_loss: 0.0544 - output_1_loss: 0.0412 - output_2_loss: 0.0384 - output_3_loss: 0.0476 - output_4_loss: 0.0384 - output_0_accuracy: 0.9830 - output_1_accuracy: 0.9898 - output_2_accuracy: 0.9877 - output_3_accuracy: 0.9875 - output_4_accuracy: 0.9875 - val_loss: 0.5004 - val_output_0_loss: 0.1947 - val_output_1_loss: 0.1689 - val_output_2_loss: 0.0357 - val_output_3_loss: 0.0250 - val_output_4_loss: 0.0767 - val_output_0_accuracy: 0.9358 - val_output_1_accuracy: 0.9490 - val_output_2_accuracy: 0.9907 - val_output_3_accuracy: 0.9928 - val_output_4_accuracy: 0.9753\n",
      "Epoch 124/200\n",
      "4000/4000 [==============================] - 2s 441us/sample - loss: 0.2355 - output_0_loss: 0.0426 - output_1_loss: 0.0507 - output_2_loss: 0.0480 - output_3_loss: 0.0446 - output_4_loss: 0.0496 - output_0_accuracy: 0.9862 - output_1_accuracy: 0.9850 - output_2_accuracy: 0.9843 - output_3_accuracy: 0.9855 - output_4_accuracy: 0.9843 - val_loss: 0.3253 - val_output_0_loss: 0.0563 - val_output_1_loss: 0.0369 - val_output_2_loss: 0.0501 - val_output_3_loss: 0.0761 - val_output_4_loss: 0.1054 - val_output_0_accuracy: 0.9830 - val_output_1_accuracy: 0.9885 - val_output_2_accuracy: 0.9848 - val_output_3_accuracy: 0.9740 - val_output_4_accuracy: 0.9653\n",
      "Epoch 125/200\n",
      "4000/4000 [==============================] - 1s 328us/sample - loss: 0.1843 - output_0_loss: 0.0287 - output_1_loss: 0.0472 - output_2_loss: 0.0299 - output_3_loss: 0.0380 - output_4_loss: 0.0403 - output_0_accuracy: 0.9910 - output_1_accuracy: 0.9870 - output_2_accuracy: 0.9918 - output_3_accuracy: 0.9885 - output_4_accuracy: 0.9862 - val_loss: 0.3731 - val_output_0_loss: 0.0287 - val_output_1_loss: 0.1281 - val_output_2_loss: 0.0476 - val_output_3_loss: 0.0606 - val_output_4_loss: 0.1072 - val_output_0_accuracy: 0.9910 - val_output_1_accuracy: 0.9643 - val_output_2_accuracy: 0.9858 - val_output_3_accuracy: 0.9802 - val_output_4_accuracy: 0.9610\n",
      "Epoch 126/200\n",
      "4000/4000 [==============================] - 1s 301us/sample - loss: 0.2100 - output_0_loss: 0.0425 - output_1_loss: 0.0305 - output_2_loss: 0.0424 - output_3_loss: 0.0469 - output_4_loss: 0.0477 - output_0_accuracy: 0.9855 - output_1_accuracy: 0.9910 - output_2_accuracy: 0.9872 - output_3_accuracy: 0.9847 - output_4_accuracy: 0.9870 - val_loss: 0.4257 - val_output_0_loss: 0.1625 - val_output_1_loss: 0.1111 - val_output_2_loss: 0.0324 - val_output_3_loss: 0.0480 - val_output_4_loss: 0.0736 - val_output_0_accuracy: 0.9567 - val_output_1_accuracy: 0.9620 - val_output_2_accuracy: 0.9910 - val_output_3_accuracy: 0.9865 - val_output_4_accuracy: 0.9802\n",
      "Epoch 127/200\n",
      "4000/4000 [==============================] - 1s 328us/sample - loss: 0.1915 - output_0_loss: 0.0454 - output_1_loss: 0.0428 - output_2_loss: 0.0355 - output_3_loss: 0.0312 - output_4_loss: 0.0365 - output_0_accuracy: 0.9872 - output_1_accuracy: 0.9860 - output_2_accuracy: 0.9883 - output_3_accuracy: 0.9900 - output_4_accuracy: 0.9883 - val_loss: 0.3235 - val_output_0_loss: 0.0763 - val_output_1_loss: 0.0608 - val_output_2_loss: 0.0329 - val_output_3_loss: 0.1150 - val_output_4_loss: 0.0385 - val_output_0_accuracy: 0.9743 - val_output_1_accuracy: 0.9808 - val_output_2_accuracy: 0.9897 - val_output_3_accuracy: 0.9683 - val_output_4_accuracy: 0.9880\n",
      "Epoch 128/200\n",
      "4000/4000 [==============================] - 1s 312us/sample - loss: 0.2063 - output_0_loss: 0.0396 - output_1_loss: 0.0421 - output_2_loss: 0.0441 - output_3_loss: 0.0441 - output_4_loss: 0.0363 - output_0_accuracy: 0.9885 - output_1_accuracy: 0.9865 - output_2_accuracy: 0.9862 - output_3_accuracy: 0.9887 - output_4_accuracy: 0.9893 - val_loss: 0.4603 - val_output_0_loss: 0.1243 - val_output_1_loss: 0.0579 - val_output_2_loss: 0.0628 - val_output_3_loss: 0.1435 - val_output_4_loss: 0.0722 - val_output_0_accuracy: 0.9607 - val_output_1_accuracy: 0.9808 - val_output_2_accuracy: 0.9745 - val_output_3_accuracy: 0.9622 - val_output_4_accuracy: 0.9792\n",
      "Epoch 129/200\n",
      "4000/4000 [==============================] - 1s 291us/sample - loss: 0.2097 - output_0_loss: 0.0433 - output_1_loss: 0.0464 - output_2_loss: 0.0379 - output_3_loss: 0.0424 - output_4_loss: 0.0397 - output_0_accuracy: 0.9890 - output_1_accuracy: 0.9868 - output_2_accuracy: 0.9875 - output_3_accuracy: 0.9862 - output_4_accuracy: 0.9898 - val_loss: 0.4475 - val_output_0_loss: 0.0554 - val_output_1_loss: 0.0694 - val_output_2_loss: 0.0527 - val_output_3_loss: 0.1838 - val_output_4_loss: 0.0854 - val_output_0_accuracy: 0.9833 - val_output_1_accuracy: 0.9797 - val_output_2_accuracy: 0.9825 - val_output_3_accuracy: 0.9483 - val_output_4_accuracy: 0.9708\n",
      "Epoch 130/200\n",
      "4000/4000 [==============================] - 1s 289us/sample - loss: 0.2071 - output_0_loss: 0.0422 - output_1_loss: 0.0353 - output_2_loss: 0.0395 - output_3_loss: 0.0523 - output_4_loss: 0.0379 - output_0_accuracy: 0.9870 - output_1_accuracy: 0.9885 - output_2_accuracy: 0.9877 - output_3_accuracy: 0.9840 - output_4_accuracy: 0.9898 - val_loss: 0.3928 - val_output_0_loss: 0.0600 - val_output_1_loss: 0.0304 - val_output_2_loss: 0.1008 - val_output_3_loss: 0.1197 - val_output_4_loss: 0.0820 - val_output_0_accuracy: 0.9812 - val_output_1_accuracy: 0.9917 - val_output_2_accuracy: 0.9658 - val_output_3_accuracy: 0.9642 - val_output_4_accuracy: 0.9733\n",
      "Epoch 131/200\n",
      "4000/4000 [==============================] - 1s 287us/sample - loss: 0.1814 - output_0_loss: 0.0273 - output_1_loss: 0.0441 - output_2_loss: 0.0324 - output_3_loss: 0.0418 - output_4_loss: 0.0358 - output_0_accuracy: 0.9910 - output_1_accuracy: 0.9865 - output_2_accuracy: 0.9885 - output_3_accuracy: 0.9862 - output_4_accuracy: 0.9893 - val_loss: 0.3250 - val_output_0_loss: 0.0896 - val_output_1_loss: 0.0320 - val_output_2_loss: 0.0493 - val_output_3_loss: 0.0763 - val_output_4_loss: 0.0775 - val_output_0_accuracy: 0.9777 - val_output_1_accuracy: 0.9902 - val_output_2_accuracy: 0.9840 - val_output_3_accuracy: 0.9772 - val_output_4_accuracy: 0.9712\n",
      "Epoch 132/200\n",
      "4000/4000 [==============================] - 1s 288us/sample - loss: 0.1958 - output_0_loss: 0.0429 - output_1_loss: 0.0324 - output_2_loss: 0.0327 - output_3_loss: 0.0531 - output_4_loss: 0.0347 - output_0_accuracy: 0.9862 - output_1_accuracy: 0.9905 - output_2_accuracy: 0.9910 - output_3_accuracy: 0.9843 - output_4_accuracy: 0.9887 - val_loss: 0.2641 - val_output_0_loss: 0.0801 - val_output_1_loss: 0.0376 - val_output_2_loss: 0.0840 - val_output_3_loss: 0.0380 - val_output_4_loss: 0.0241 - val_output_0_accuracy: 0.9728 - val_output_1_accuracy: 0.9868 - val_output_2_accuracy: 0.9820 - val_output_3_accuracy: 0.9877 - val_output_4_accuracy: 0.9918\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 287us/sample - loss: 0.1975 - output_0_loss: 0.0361 - output_1_loss: 0.0413 - output_2_loss: 0.0369 - output_3_loss: 0.0425 - output_4_loss: 0.0407 - output_0_accuracy: 0.9898 - output_1_accuracy: 0.9862 - output_2_accuracy: 0.9883 - output_3_accuracy: 0.9883 - output_4_accuracy: 0.9865 - val_loss: 0.3368 - val_output_0_loss: 0.1422 - val_output_1_loss: 0.0358 - val_output_2_loss: 0.0606 - val_output_3_loss: 0.0677 - val_output_4_loss: 0.0298 - val_output_0_accuracy: 0.9583 - val_output_1_accuracy: 0.9895 - val_output_2_accuracy: 0.9810 - val_output_3_accuracy: 0.9778 - val_output_4_accuracy: 0.9920\n",
      "Epoch 134/200\n",
      "4000/4000 [==============================] - 3s 644us/sample - loss: 0.1999 - output_0_loss: 0.0335 - output_1_loss: 0.0445 - output_2_loss: 0.0440 - output_3_loss: 0.0381 - output_4_loss: 0.0399 - output_0_accuracy: 0.9902 - output_1_accuracy: 0.9875 - output_2_accuracy: 0.9868 - output_3_accuracy: 0.9883 - output_4_accuracy: 0.9875 - val_loss: 0.3450 - val_output_0_loss: 0.0889 - val_output_1_loss: 0.0351 - val_output_2_loss: 0.1034 - val_output_3_loss: 0.0525 - val_output_4_loss: 0.0648 - val_output_0_accuracy: 0.9742 - val_output_1_accuracy: 0.9873 - val_output_2_accuracy: 0.9705 - val_output_3_accuracy: 0.9847 - val_output_4_accuracy: 0.9783\n",
      "Epoch 135/200\n",
      "4000/4000 [==============================] - 3s 708us/sample - loss: 0.2042 - output_0_loss: 0.0351 - output_1_loss: 0.0393 - output_2_loss: 0.0389 - output_3_loss: 0.0501 - output_4_loss: 0.0408 - output_0_accuracy: 0.9890 - output_1_accuracy: 0.9870 - output_2_accuracy: 0.9883 - output_3_accuracy: 0.9868 - output_4_accuracy: 0.9877 - val_loss: 0.4014 - val_output_0_loss: 0.1163 - val_output_1_loss: 0.1192 - val_output_2_loss: 0.0307 - val_output_3_loss: 0.1107 - val_output_4_loss: 0.0246 - val_output_0_accuracy: 0.9672 - val_output_1_accuracy: 0.9597 - val_output_2_accuracy: 0.9903 - val_output_3_accuracy: 0.9692 - val_output_4_accuracy: 0.9928\n",
      "Epoch 136/200\n",
      "4000/4000 [==============================] - 3s 656us/sample - loss: 0.1789 - output_0_loss: 0.0380 - output_1_loss: 0.0318 - output_2_loss: 0.0364 - output_3_loss: 0.0427 - output_4_loss: 0.0300 - output_0_accuracy: 0.9902 - output_1_accuracy: 0.9890 - output_2_accuracy: 0.9895 - output_3_accuracy: 0.9870 - output_4_accuracy: 0.9890 - val_loss: 0.5022 - val_output_0_loss: 0.0497 - val_output_1_loss: 0.0667 - val_output_2_loss: 0.1456 - val_output_3_loss: 0.1600 - val_output_4_loss: 0.0797 - val_output_0_accuracy: 0.9857 - val_output_1_accuracy: 0.9810 - val_output_2_accuracy: 0.9625 - val_output_3_accuracy: 0.9490 - val_output_4_accuracy: 0.9765\n",
      "Epoch 137/200\n",
      "4000/4000 [==============================] - 2s 546us/sample - loss: 0.2208 - output_0_loss: 0.0464 - output_1_loss: 0.0414 - output_2_loss: 0.0462 - output_3_loss: 0.0468 - output_4_loss: 0.0398 - output_0_accuracy: 0.9875 - output_1_accuracy: 0.9865 - output_2_accuracy: 0.9835 - output_3_accuracy: 0.9827 - output_4_accuracy: 0.9855 - val_loss: 0.3316 - val_output_0_loss: 0.0477 - val_output_1_loss: 0.0514 - val_output_2_loss: 0.0769 - val_output_3_loss: 0.0888 - val_output_4_loss: 0.0667 - val_output_0_accuracy: 0.9855 - val_output_1_accuracy: 0.9830 - val_output_2_accuracy: 0.9757 - val_output_3_accuracy: 0.9732 - val_output_4_accuracy: 0.9782\n",
      "Epoch 138/200\n",
      "4000/4000 [==============================] - 2s 511us/sample - loss: 0.1888 - output_0_loss: 0.0351 - output_1_loss: 0.0350 - output_2_loss: 0.0340 - output_3_loss: 0.0430 - output_4_loss: 0.0418 - output_0_accuracy: 0.9883 - output_1_accuracy: 0.9890 - output_2_accuracy: 0.9883 - output_3_accuracy: 0.9860 - output_4_accuracy: 0.9883 - val_loss: 0.2709 - val_output_0_loss: 0.0417 - val_output_1_loss: 0.0450 - val_output_2_loss: 0.0540 - val_output_3_loss: 0.0757 - val_output_4_loss: 0.0549 - val_output_0_accuracy: 0.9878 - val_output_1_accuracy: 0.9855 - val_output_2_accuracy: 0.9815 - val_output_3_accuracy: 0.9785 - val_output_4_accuracy: 0.9830\n",
      "Epoch 139/200\n",
      "4000/4000 [==============================] - 1s 315us/sample - loss: 0.1898 - output_0_loss: 0.0387 - output_1_loss: 0.0358 - output_2_loss: 0.0371 - output_3_loss: 0.0380 - output_4_loss: 0.0402 - output_0_accuracy: 0.9875 - output_1_accuracy: 0.9895 - output_2_accuracy: 0.9895 - output_3_accuracy: 0.9893 - output_4_accuracy: 0.9880 - val_loss: 0.3904 - val_output_0_loss: 0.1578 - val_output_1_loss: 0.0525 - val_output_2_loss: 0.0611 - val_output_3_loss: 0.0730 - val_output_4_loss: 0.0480 - val_output_0_accuracy: 0.9528 - val_output_1_accuracy: 0.9820 - val_output_2_accuracy: 0.9838 - val_output_3_accuracy: 0.9738 - val_output_4_accuracy: 0.9848\n",
      "Epoch 140/200\n",
      "4000/4000 [==============================] - 1s 309us/sample - loss: 0.1809 - output_0_loss: 0.0301 - output_1_loss: 0.0330 - output_2_loss: 0.0393 - output_3_loss: 0.0410 - output_4_loss: 0.0374 - output_0_accuracy: 0.9905 - output_1_accuracy: 0.9893 - output_2_accuracy: 0.9877 - output_3_accuracy: 0.9865 - output_4_accuracy: 0.9877 - val_loss: 0.5478 - val_output_0_loss: 0.0940 - val_output_1_loss: 0.0397 - val_output_2_loss: 0.0881 - val_output_3_loss: 0.2088 - val_output_4_loss: 0.1163 - val_output_0_accuracy: 0.9770 - val_output_1_accuracy: 0.9868 - val_output_2_accuracy: 0.9728 - val_output_3_accuracy: 0.9463 - val_output_4_accuracy: 0.9662\n",
      "Epoch 141/200\n",
      "4000/4000 [==============================] - 1s 310us/sample - loss: 0.1934 - output_0_loss: 0.0343 - output_1_loss: 0.0322 - output_2_loss: 0.0390 - output_3_loss: 0.0485 - output_4_loss: 0.0394 - output_0_accuracy: 0.9887 - output_1_accuracy: 0.9887 - output_2_accuracy: 0.9877 - output_3_accuracy: 0.9860 - output_4_accuracy: 0.9860 - val_loss: 0.5671 - val_output_0_loss: 0.2103 - val_output_1_loss: 0.0687 - val_output_2_loss: 0.0543 - val_output_3_loss: 0.0980 - val_output_4_loss: 0.1370 - val_output_0_accuracy: 0.9477 - val_output_1_accuracy: 0.9765 - val_output_2_accuracy: 0.9820 - val_output_3_accuracy: 0.9657 - val_output_4_accuracy: 0.9535\n",
      "Epoch 142/200\n",
      "4000/4000 [==============================] - 1s 306us/sample - loss: 0.1762 - output_0_loss: 0.0363 - output_1_loss: 0.0362 - output_2_loss: 0.0304 - output_3_loss: 0.0352 - output_4_loss: 0.0381 - output_0_accuracy: 0.9887 - output_1_accuracy: 0.9868 - output_2_accuracy: 0.9902 - output_3_accuracy: 0.9877 - output_4_accuracy: 0.9898 - val_loss: 0.6102 - val_output_0_loss: 0.1391 - val_output_1_loss: 0.0542 - val_output_2_loss: 0.1648 - val_output_3_loss: 0.0570 - val_output_4_loss: 0.1946 - val_output_0_accuracy: 0.9593 - val_output_1_accuracy: 0.9827 - val_output_2_accuracy: 0.9558 - val_output_3_accuracy: 0.9820 - val_output_4_accuracy: 0.9452\n",
      "Epoch 143/200\n",
      "4000/4000 [==============================] - 1s 306us/sample - loss: 0.1913 - output_0_loss: 0.0386 - output_1_loss: 0.0273 - output_2_loss: 0.0447 - output_3_loss: 0.0450 - output_4_loss: 0.0357 - output_0_accuracy: 0.9887 - output_1_accuracy: 0.9915 - output_2_accuracy: 0.9862 - output_3_accuracy: 0.9860 - output_4_accuracy: 0.9883 - val_loss: 0.3060 - val_output_0_loss: 0.0567 - val_output_1_loss: 0.0506 - val_output_2_loss: 0.0394 - val_output_3_loss: 0.0855 - val_output_4_loss: 0.0734 - val_output_0_accuracy: 0.9788 - val_output_1_accuracy: 0.9830 - val_output_2_accuracy: 0.9877 - val_output_3_accuracy: 0.9755 - val_output_4_accuracy: 0.9750\n",
      "Epoch 144/200\n",
      "4000/4000 [==============================] - 1s 308us/sample - loss: 0.1817 - output_0_loss: 0.0356 - output_1_loss: 0.0335 - output_2_loss: 0.0387 - output_3_loss: 0.0419 - output_4_loss: 0.0321 - output_0_accuracy: 0.9895 - output_1_accuracy: 0.9900 - output_2_accuracy: 0.9885 - output_3_accuracy: 0.9870 - output_4_accuracy: 0.9912 - val_loss: 0.3129 - val_output_0_loss: 0.0463 - val_output_1_loss: 0.0778 - val_output_2_loss: 0.0427 - val_output_3_loss: 0.0800 - val_output_4_loss: 0.0656 - val_output_0_accuracy: 0.9848 - val_output_1_accuracy: 0.9733 - val_output_2_accuracy: 0.9857 - val_output_3_accuracy: 0.9768 - val_output_4_accuracy: 0.9817\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 307us/sample - loss: 0.1807 - output_0_loss: 0.0351 - output_1_loss: 0.0307 - output_2_loss: 0.0413 - output_3_loss: 0.0339 - output_4_loss: 0.0398 - output_0_accuracy: 0.9885 - output_1_accuracy: 0.9912 - output_2_accuracy: 0.9883 - output_3_accuracy: 0.9883 - output_4_accuracy: 0.9880 - val_loss: 0.1888 - val_output_0_loss: 0.0296 - val_output_1_loss: 0.0733 - val_output_2_loss: 0.0288 - val_output_3_loss: 0.0283 - val_output_4_loss: 0.0288 - val_output_0_accuracy: 0.9908 - val_output_1_accuracy: 0.9743 - val_output_2_accuracy: 0.9917 - val_output_3_accuracy: 0.9902 - val_output_4_accuracy: 0.9910\n",
      "Epoch 146/200\n",
      "4000/4000 [==============================] - 1s 323us/sample - loss: 0.1924 - output_0_loss: 0.0449 - output_1_loss: 0.0395 - output_2_loss: 0.0342 - output_3_loss: 0.0457 - output_4_loss: 0.0281 - output_0_accuracy: 0.9850 - output_1_accuracy: 0.9862 - output_2_accuracy: 0.9902 - output_3_accuracy: 0.9887 - output_4_accuracy: 0.9895 - val_loss: 0.2377 - val_output_0_loss: 0.0465 - val_output_1_loss: 0.0649 - val_output_2_loss: 0.0603 - val_output_3_loss: 0.0424 - val_output_4_loss: 0.0233 - val_output_0_accuracy: 0.9865 - val_output_1_accuracy: 0.9777 - val_output_2_accuracy: 0.9812 - val_output_3_accuracy: 0.9837 - val_output_4_accuracy: 0.9927\n",
      "Epoch 147/200\n",
      "4000/4000 [==============================] - 1s 333us/sample - loss: 0.1652 - output_0_loss: 0.0326 - output_1_loss: 0.0243 - output_2_loss: 0.0365 - output_3_loss: 0.0349 - output_4_loss: 0.0369 - output_0_accuracy: 0.9910 - output_1_accuracy: 0.9927 - output_2_accuracy: 0.9868 - output_3_accuracy: 0.9890 - output_4_accuracy: 0.9875 - val_loss: 0.3091 - val_output_0_loss: 0.0567 - val_output_1_loss: 0.0328 - val_output_2_loss: 0.0655 - val_output_3_loss: 0.0669 - val_output_4_loss: 0.0886 - val_output_0_accuracy: 0.9820 - val_output_1_accuracy: 0.9890 - val_output_2_accuracy: 0.9753 - val_output_3_accuracy: 0.9788 - val_output_4_accuracy: 0.9685\n",
      "Epoch 148/200\n",
      "4000/4000 [==============================] - 1s 329us/sample - loss: 0.1971 - output_0_loss: 0.0389 - output_1_loss: 0.0401 - output_2_loss: 0.0440 - output_3_loss: 0.0402 - output_4_loss: 0.0338 - output_0_accuracy: 0.9872 - output_1_accuracy: 0.9855 - output_2_accuracy: 0.9862 - output_3_accuracy: 0.9865 - output_4_accuracy: 0.9908 - val_loss: 0.2458 - val_output_0_loss: 0.0600 - val_output_1_loss: 0.0333 - val_output_2_loss: 0.0468 - val_output_3_loss: 0.0390 - val_output_4_loss: 0.0669 - val_output_0_accuracy: 0.9793 - val_output_1_accuracy: 0.9882 - val_output_2_accuracy: 0.9878 - val_output_3_accuracy: 0.9887 - val_output_4_accuracy: 0.9763\n",
      "Epoch 149/200\n",
      "4000/4000 [==============================] - 1s 341us/sample - loss: 0.1812 - output_0_loss: 0.0349 - output_1_loss: 0.0361 - output_2_loss: 0.0291 - output_3_loss: 0.0402 - output_4_loss: 0.0408 - output_0_accuracy: 0.9898 - output_1_accuracy: 0.9895 - output_2_accuracy: 0.9912 - output_3_accuracy: 0.9868 - output_4_accuracy: 0.9908 - val_loss: 0.2598 - val_output_0_loss: 0.0500 - val_output_1_loss: 0.0229 - val_output_2_loss: 0.0662 - val_output_3_loss: 0.0620 - val_output_4_loss: 0.0583 - val_output_0_accuracy: 0.9845 - val_output_1_accuracy: 0.9917 - val_output_2_accuracy: 0.9790 - val_output_3_accuracy: 0.9825 - val_output_4_accuracy: 0.9817\n",
      "Epoch 150/200\n",
      "4000/4000 [==============================] - 1s 319us/sample - loss: 0.2039 - output_0_loss: 0.0343 - output_1_loss: 0.0370 - output_2_loss: 0.0512 - output_3_loss: 0.0382 - output_4_loss: 0.0431 - output_0_accuracy: 0.9895 - output_1_accuracy: 0.9895 - output_2_accuracy: 0.9840 - output_3_accuracy: 0.9885 - output_4_accuracy: 0.9875 - val_loss: 0.3901 - val_output_0_loss: 0.0668 - val_output_1_loss: 0.0373 - val_output_2_loss: 0.1206 - val_output_3_loss: 0.1095 - val_output_4_loss: 0.0554 - val_output_0_accuracy: 0.9808 - val_output_1_accuracy: 0.9887 - val_output_2_accuracy: 0.9615 - val_output_3_accuracy: 0.9655 - val_output_4_accuracy: 0.9830\n",
      "Epoch 151/200\n",
      "4000/4000 [==============================] - 1s 349us/sample - loss: 0.1965 - output_0_loss: 0.0473 - output_1_loss: 0.0269 - output_2_loss: 0.0404 - output_3_loss: 0.0377 - output_4_loss: 0.0443 - output_0_accuracy: 0.9868 - output_1_accuracy: 0.9910 - output_2_accuracy: 0.9885 - output_3_accuracy: 0.9880 - output_4_accuracy: 0.9890 - val_loss: 0.6154 - val_output_0_loss: 0.1694 - val_output_1_loss: 0.1470 - val_output_2_loss: 0.0944 - val_output_3_loss: 0.1127 - val_output_4_loss: 0.0936 - val_output_0_accuracy: 0.9558 - val_output_1_accuracy: 0.9478 - val_output_2_accuracy: 0.9707 - val_output_3_accuracy: 0.9613 - val_output_4_accuracy: 0.9698\n",
      "Epoch 152/200\n",
      "4000/4000 [==============================] - 2s 406us/sample - loss: 0.1778 - output_0_loss: 0.0384 - output_1_loss: 0.0355 - output_2_loss: 0.0336 - output_3_loss: 0.0296 - output_4_loss: 0.0407 - output_0_accuracy: 0.9880 - output_1_accuracy: 0.9895 - output_2_accuracy: 0.9898 - output_3_accuracy: 0.9895 - output_4_accuracy: 0.9885 - val_loss: 0.3354 - val_output_0_loss: 0.0989 - val_output_1_loss: 0.0501 - val_output_2_loss: 0.0346 - val_output_3_loss: 0.0668 - val_output_4_loss: 0.0844 - val_output_0_accuracy: 0.9717 - val_output_1_accuracy: 0.9823 - val_output_2_accuracy: 0.9892 - val_output_3_accuracy: 0.9777 - val_output_4_accuracy: 0.9753\n",
      "Epoch 153/200\n",
      "4000/4000 [==============================] - 2s 598us/sample - loss: 0.1858 - output_0_loss: 0.0447 - output_1_loss: 0.0327 - output_2_loss: 0.0403 - output_3_loss: 0.0330 - output_4_loss: 0.0351 - output_0_accuracy: 0.9875 - output_1_accuracy: 0.9902 - output_2_accuracy: 0.9887 - output_3_accuracy: 0.9908 - output_4_accuracy: 0.9883 - val_loss: 0.4136 - val_output_0_loss: 0.0455 - val_output_1_loss: 0.0892 - val_output_2_loss: 0.0679 - val_output_3_loss: 0.1215 - val_output_4_loss: 0.0889 - val_output_0_accuracy: 0.9847 - val_output_1_accuracy: 0.9773 - val_output_2_accuracy: 0.9797 - val_output_3_accuracy: 0.9675 - val_output_4_accuracy: 0.9723\n",
      "Epoch 154/200\n",
      "4000/4000 [==============================] - 2s 495us/sample - loss: 0.1743 - output_0_loss: 0.0379 - output_1_loss: 0.0292 - output_2_loss: 0.0309 - output_3_loss: 0.0383 - output_4_loss: 0.0379 - output_0_accuracy: 0.9898 - output_1_accuracy: 0.9930 - output_2_accuracy: 0.9900 - output_3_accuracy: 0.9875 - output_4_accuracy: 0.9883 - val_loss: 0.2469 - val_output_0_loss: 0.0750 - val_output_1_loss: 0.0193 - val_output_2_loss: 0.0444 - val_output_3_loss: 0.0514 - val_output_4_loss: 0.0571 - val_output_0_accuracy: 0.9775 - val_output_1_accuracy: 0.9943 - val_output_2_accuracy: 0.9852 - val_output_3_accuracy: 0.9848 - val_output_4_accuracy: 0.9817\n",
      "Epoch 155/200\n",
      "4000/4000 [==============================] - 2s 493us/sample - loss: 0.1671 - output_0_loss: 0.0394 - output_1_loss: 0.0313 - output_2_loss: 0.0253 - output_3_loss: 0.0312 - output_4_loss: 0.0398 - output_0_accuracy: 0.9877 - output_1_accuracy: 0.9895 - output_2_accuracy: 0.9912 - output_3_accuracy: 0.9890 - output_4_accuracy: 0.9870 - val_loss: 0.2654 - val_output_0_loss: 0.0484 - val_output_1_loss: 0.0446 - val_output_2_loss: 0.0631 - val_output_3_loss: 0.0378 - val_output_4_loss: 0.0709 - val_output_0_accuracy: 0.9857 - val_output_1_accuracy: 0.9863 - val_output_2_accuracy: 0.9772 - val_output_3_accuracy: 0.9895 - val_output_4_accuracy: 0.9767\n",
      "Epoch 156/200\n",
      "4000/4000 [==============================] - 2s 550us/sample - loss: 0.1774 - output_0_loss: 0.0358 - output_1_loss: 0.0298 - output_2_loss: 0.0334 - output_3_loss: 0.0405 - output_4_loss: 0.0379 - output_0_accuracy: 0.9900 - output_1_accuracy: 0.9910 - output_2_accuracy: 0.9885 - output_3_accuracy: 0.9902 - output_4_accuracy: 0.9887 - val_loss: 0.4011 - val_output_0_loss: 0.0656 - val_output_1_loss: 0.1255 - val_output_2_loss: 0.0485 - val_output_3_loss: 0.0685 - val_output_4_loss: 0.0971 - val_output_0_accuracy: 0.9795 - val_output_1_accuracy: 0.9637 - val_output_2_accuracy: 0.9863 - val_output_3_accuracy: 0.9800 - val_output_4_accuracy: 0.9670\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 322us/sample - loss: 0.1854 - output_0_loss: 0.0318 - output_1_loss: 0.0349 - output_2_loss: 0.0309 - output_3_loss: 0.0422 - output_4_loss: 0.0456 - output_0_accuracy: 0.9902 - output_1_accuracy: 0.9893 - output_2_accuracy: 0.9905 - output_3_accuracy: 0.9877 - output_4_accuracy: 0.9880 - val_loss: 0.1741 - val_output_0_loss: 0.0222 - val_output_1_loss: 0.0357 - val_output_2_loss: 0.0441 - val_output_3_loss: 0.0296 - val_output_4_loss: 0.0420 - val_output_0_accuracy: 0.9937 - val_output_1_accuracy: 0.9875 - val_output_2_accuracy: 0.9850 - val_output_3_accuracy: 0.9910 - val_output_4_accuracy: 0.9873\n",
      "Epoch 158/200\n",
      "4000/4000 [==============================] - 2s 417us/sample - loss: 0.1856 - output_0_loss: 0.0436 - output_1_loss: 0.0455 - output_2_loss: 0.0445 - output_3_loss: 0.0236 - output_4_loss: 0.0283 - output_0_accuracy: 0.9860 - output_1_accuracy: 0.9850 - output_2_accuracy: 0.9858 - output_3_accuracy: 0.9923 - output_4_accuracy: 0.9925 - val_loss: 0.3428 - val_output_0_loss: 0.0424 - val_output_1_loss: 0.0749 - val_output_2_loss: 0.0178 - val_output_3_loss: 0.1394 - val_output_4_loss: 0.0683 - val_output_0_accuracy: 0.9852 - val_output_1_accuracy: 0.9808 - val_output_2_accuracy: 0.9947 - val_output_3_accuracy: 0.9590 - val_output_4_accuracy: 0.9798\n",
      "Epoch 159/200\n",
      "4000/4000 [==============================] - 1s 371us/sample - loss: 0.1657 - output_0_loss: 0.0300 - output_1_loss: 0.0251 - output_2_loss: 0.0296 - output_3_loss: 0.0455 - output_4_loss: 0.0354 - output_0_accuracy: 0.9898 - output_1_accuracy: 0.9930 - output_2_accuracy: 0.9910 - output_3_accuracy: 0.9862 - output_4_accuracy: 0.9902 - val_loss: 0.2189 - val_output_0_loss: 0.0316 - val_output_1_loss: 0.0460 - val_output_2_loss: 0.0517 - val_output_3_loss: 0.0219 - val_output_4_loss: 0.0674 - val_output_0_accuracy: 0.9917 - val_output_1_accuracy: 0.9863 - val_output_2_accuracy: 0.9830 - val_output_3_accuracy: 0.9942 - val_output_4_accuracy: 0.9758\n",
      "Epoch 160/200\n",
      "4000/4000 [==============================] - 1s 361us/sample - loss: 0.1610 - output_0_loss: 0.0336 - output_1_loss: 0.0336 - output_2_loss: 0.0281 - output_3_loss: 0.0315 - output_4_loss: 0.0342 - output_0_accuracy: 0.9885 - output_1_accuracy: 0.9900 - output_2_accuracy: 0.9927 - output_3_accuracy: 0.9893 - output_4_accuracy: 0.9880 - val_loss: 0.3784 - val_output_0_loss: 0.0610 - val_output_1_loss: 0.0636 - val_output_2_loss: 0.1126 - val_output_3_loss: 0.1115 - val_output_4_loss: 0.0292 - val_output_0_accuracy: 0.9800 - val_output_1_accuracy: 0.9798 - val_output_2_accuracy: 0.9685 - val_output_3_accuracy: 0.9712 - val_output_4_accuracy: 0.9902\n",
      "Epoch 161/200\n",
      "4000/4000 [==============================] - 2s 382us/sample - loss: 0.1725 - output_0_loss: 0.0393 - output_1_loss: 0.0281 - output_2_loss: 0.0384 - output_3_loss: 0.0324 - output_4_loss: 0.0343 - output_0_accuracy: 0.9870 - output_1_accuracy: 0.9900 - output_2_accuracy: 0.9870 - output_3_accuracy: 0.9893 - output_4_accuracy: 0.9883 - val_loss: 0.5013 - val_output_0_loss: 0.1460 - val_output_1_loss: 0.0184 - val_output_2_loss: 0.0596 - val_output_3_loss: 0.1610 - val_output_4_loss: 0.1160 - val_output_0_accuracy: 0.9537 - val_output_1_accuracy: 0.9948 - val_output_2_accuracy: 0.9812 - val_output_3_accuracy: 0.9557 - val_output_4_accuracy: 0.9585\n",
      "Epoch 162/200\n",
      "4000/4000 [==============================] - 2s 554us/sample - loss: 0.1851 - output_0_loss: 0.0300 - output_1_loss: 0.0399 - output_2_loss: 0.0379 - output_3_loss: 0.0431 - output_4_loss: 0.0342 - output_0_accuracy: 0.9893 - output_1_accuracy: 0.9870 - output_2_accuracy: 0.9877 - output_3_accuracy: 0.9883 - output_4_accuracy: 0.9895 - val_loss: 0.2783 - val_output_0_loss: 0.0544 - val_output_1_loss: 0.0472 - val_output_2_loss: 0.0729 - val_output_3_loss: 0.0767 - val_output_4_loss: 0.0266 - val_output_0_accuracy: 0.9832 - val_output_1_accuracy: 0.9857 - val_output_2_accuracy: 0.9773 - val_output_3_accuracy: 0.9768 - val_output_4_accuracy: 0.9917\n",
      "Epoch 163/200\n",
      "4000/4000 [==============================] - 2s 506us/sample - loss: 0.1600 - output_0_loss: 0.0368 - output_1_loss: 0.0308 - output_2_loss: 0.0319 - output_3_loss: 0.0298 - output_4_loss: 0.0308 - output_0_accuracy: 0.9902 - output_1_accuracy: 0.9925 - output_2_accuracy: 0.9920 - output_3_accuracy: 0.9885 - output_4_accuracy: 0.9898 - val_loss: 0.3220 - val_output_0_loss: 0.0211 - val_output_1_loss: 0.0267 - val_output_2_loss: 0.0467 - val_output_3_loss: 0.1979 - val_output_4_loss: 0.0291 - val_output_0_accuracy: 0.9940 - val_output_1_accuracy: 0.9917 - val_output_2_accuracy: 0.9845 - val_output_3_accuracy: 0.9482 - val_output_4_accuracy: 0.9905\n",
      "Epoch 164/200\n",
      "4000/4000 [==============================] - 2s 521us/sample - loss: 0.1805 - output_0_loss: 0.0322 - output_1_loss: 0.0429 - output_2_loss: 0.0384 - output_3_loss: 0.0257 - output_4_loss: 0.0413 - output_0_accuracy: 0.9895 - output_1_accuracy: 0.9880 - output_2_accuracy: 0.9880 - output_3_accuracy: 0.9912 - output_4_accuracy: 0.9875 - val_loss: 0.3179 - val_output_0_loss: 0.0706 - val_output_1_loss: 0.0787 - val_output_2_loss: 0.0937 - val_output_3_loss: 0.0416 - val_output_4_loss: 0.0331 - val_output_0_accuracy: 0.9803 - val_output_1_accuracy: 0.9752 - val_output_2_accuracy: 0.9695 - val_output_3_accuracy: 0.9872 - val_output_4_accuracy: 0.9890\n",
      "Epoch 165/200\n",
      "4000/4000 [==============================] - 2s 537us/sample - loss: 0.1682 - output_0_loss: 0.0402 - output_1_loss: 0.0353 - output_2_loss: 0.0339 - output_3_loss: 0.0323 - output_4_loss: 0.0265 - output_0_accuracy: 0.9898 - output_1_accuracy: 0.9898 - output_2_accuracy: 0.9908 - output_3_accuracy: 0.9908 - output_4_accuracy: 0.9908 - val_loss: 0.2884 - val_output_0_loss: 0.0534 - val_output_1_loss: 0.0360 - val_output_2_loss: 0.1089 - val_output_3_loss: 0.0712 - val_output_4_loss: 0.0184 - val_output_0_accuracy: 0.9845 - val_output_1_accuracy: 0.9883 - val_output_2_accuracy: 0.9655 - val_output_3_accuracy: 0.9755 - val_output_4_accuracy: 0.9943\n",
      "Epoch 166/200\n",
      "4000/4000 [==============================] - 3s 781us/sample - loss: 0.1799 - output_0_loss: 0.0281 - output_1_loss: 0.0378 - output_2_loss: 0.0392 - output_3_loss: 0.0380 - output_4_loss: 0.0368 - output_0_accuracy: 0.9905 - output_1_accuracy: 0.9887 - output_2_accuracy: 0.9895 - output_3_accuracy: 0.9870 - output_4_accuracy: 0.9885 - val_loss: 0.2083 - val_output_0_loss: 0.0490 - val_output_1_loss: 0.0443 - val_output_2_loss: 0.0433 - val_output_3_loss: 0.0582 - val_output_4_loss: 0.0135 - val_output_0_accuracy: 0.9855 - val_output_1_accuracy: 0.9860 - val_output_2_accuracy: 0.9860 - val_output_3_accuracy: 0.9840 - val_output_4_accuracy: 0.9957\n",
      "Epoch 167/200\n",
      "4000/4000 [==============================] - 2s 431us/sample - loss: 0.1602 - output_0_loss: 0.0363 - output_1_loss: 0.0384 - output_2_loss: 0.0271 - output_3_loss: 0.0339 - output_4_loss: 0.0246 - output_0_accuracy: 0.9887 - output_1_accuracy: 0.9872 - output_2_accuracy: 0.9920 - output_3_accuracy: 0.9883 - output_4_accuracy: 0.9920 - val_loss: 0.2402 - val_output_0_loss: 0.0404 - val_output_1_loss: 0.0400 - val_output_2_loss: 0.0600 - val_output_3_loss: 0.0831 - val_output_4_loss: 0.0168 - val_output_0_accuracy: 0.9875 - val_output_1_accuracy: 0.9853 - val_output_2_accuracy: 0.9780 - val_output_3_accuracy: 0.9760 - val_output_4_accuracy: 0.9953\n",
      "Epoch 168/200\n",
      "4000/4000 [==============================] - 3s 755us/sample - loss: 0.1534 - output_0_loss: 0.0312 - output_1_loss: 0.0325 - output_2_loss: 0.0320 - output_3_loss: 0.0310 - output_4_loss: 0.0267 - output_0_accuracy: 0.9908 - output_1_accuracy: 0.9912 - output_2_accuracy: 0.9880 - output_3_accuracy: 0.9920 - output_4_accuracy: 0.9915 - val_loss: 0.2592 - val_output_0_loss: 0.0971 - val_output_1_loss: 0.0388 - val_output_2_loss: 0.0180 - val_output_3_loss: 0.0818 - val_output_4_loss: 0.0238 - val_output_0_accuracy: 0.9675 - val_output_1_accuracy: 0.9873 - val_output_2_accuracy: 0.9943 - val_output_3_accuracy: 0.9742 - val_output_4_accuracy: 0.9937\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 2s 499us/sample - loss: 0.1981 - output_0_loss: 0.0411 - output_1_loss: 0.0333 - output_2_loss: 0.0513 - output_3_loss: 0.0421 - output_4_loss: 0.0304 - output_0_accuracy: 0.9875 - output_1_accuracy: 0.9898 - output_2_accuracy: 0.9862 - output_3_accuracy: 0.9865 - output_4_accuracy: 0.9910 - val_loss: 0.2923 - val_output_0_loss: 0.0549 - val_output_1_loss: 0.0342 - val_output_2_loss: 0.0680 - val_output_3_loss: 0.0751 - val_output_4_loss: 0.0600 - val_output_0_accuracy: 0.9842 - val_output_1_accuracy: 0.9903 - val_output_2_accuracy: 0.9853 - val_output_3_accuracy: 0.9773 - val_output_4_accuracy: 0.9817\n",
      "Epoch 170/200\n",
      "4000/4000 [==============================] - 2s 445us/sample - loss: 0.1488 - output_0_loss: 0.0328 - output_1_loss: 0.0241 - output_2_loss: 0.0255 - output_3_loss: 0.0353 - output_4_loss: 0.0312 - output_0_accuracy: 0.9902 - output_1_accuracy: 0.9927 - output_2_accuracy: 0.9927 - output_3_accuracy: 0.9890 - output_4_accuracy: 0.9895 - val_loss: 0.2453 - val_output_0_loss: 0.0453 - val_output_1_loss: 0.0518 - val_output_2_loss: 0.0206 - val_output_3_loss: 0.0474 - val_output_4_loss: 0.0796 - val_output_0_accuracy: 0.9867 - val_output_1_accuracy: 0.9860 - val_output_2_accuracy: 0.9938 - val_output_3_accuracy: 0.9883 - val_output_4_accuracy: 0.9780\n",
      "Epoch 171/200\n",
      "4000/4000 [==============================] - 2s 543us/sample - loss: 0.1780 - output_0_loss: 0.0425 - output_1_loss: 0.0356 - output_2_loss: 0.0315 - output_3_loss: 0.0311 - output_4_loss: 0.0373 - output_0_accuracy: 0.9877 - output_1_accuracy: 0.9890 - output_2_accuracy: 0.9898 - output_3_accuracy: 0.9895 - output_4_accuracy: 0.9887 - val_loss: 0.3127 - val_output_0_loss: 0.1035 - val_output_1_loss: 0.0339 - val_output_2_loss: 0.0363 - val_output_3_loss: 0.0624 - val_output_4_loss: 0.0764 - val_output_0_accuracy: 0.9690 - val_output_1_accuracy: 0.9893 - val_output_2_accuracy: 0.9890 - val_output_3_accuracy: 0.9807 - val_output_4_accuracy: 0.9770\n",
      "Epoch 172/200\n",
      "4000/4000 [==============================] - 1s 311us/sample - loss: 0.1433 - output_0_loss: 0.0317 - output_1_loss: 0.0277 - output_2_loss: 0.0258 - output_3_loss: 0.0333 - output_4_loss: 0.0247 - output_0_accuracy: 0.9902 - output_1_accuracy: 0.9930 - output_2_accuracy: 0.9923 - output_3_accuracy: 0.9908 - output_4_accuracy: 0.9923 - val_loss: 0.3252 - val_output_0_loss: 0.1043 - val_output_1_loss: 0.0569 - val_output_2_loss: 0.0368 - val_output_3_loss: 0.0213 - val_output_4_loss: 0.1057 - val_output_0_accuracy: 0.9692 - val_output_1_accuracy: 0.9818 - val_output_2_accuracy: 0.9883 - val_output_3_accuracy: 0.9943 - val_output_4_accuracy: 0.9733\n",
      "Epoch 173/200\n",
      "4000/4000 [==============================] - 1s 316us/sample - loss: 0.1812 - output_0_loss: 0.0380 - output_1_loss: 0.0334 - output_2_loss: 0.0265 - output_3_loss: 0.0425 - output_4_loss: 0.0409 - output_0_accuracy: 0.9885 - output_1_accuracy: 0.9885 - output_2_accuracy: 0.9910 - output_3_accuracy: 0.9860 - output_4_accuracy: 0.9872 - val_loss: 0.3972 - val_output_0_loss: 0.0998 - val_output_1_loss: 0.0621 - val_output_2_loss: 0.0368 - val_output_3_loss: 0.1728 - val_output_4_loss: 0.0273 - val_output_0_accuracy: 0.9757 - val_output_1_accuracy: 0.9825 - val_output_2_accuracy: 0.9895 - val_output_3_accuracy: 0.9543 - val_output_4_accuracy: 0.9917\n",
      "Epoch 174/200\n",
      "4000/4000 [==============================] - 1s 336us/sample - loss: 0.1602 - output_0_loss: 0.0332 - output_1_loss: 0.0309 - output_2_loss: 0.0347 - output_3_loss: 0.0335 - output_4_loss: 0.0279 - output_0_accuracy: 0.9905 - output_1_accuracy: 0.9923 - output_2_accuracy: 0.9902 - output_3_accuracy: 0.9887 - output_4_accuracy: 0.9918 - val_loss: 0.4770 - val_output_0_loss: 0.1092 - val_output_1_loss: 0.0324 - val_output_2_loss: 0.0773 - val_output_3_loss: 0.1346 - val_output_4_loss: 0.1234 - val_output_0_accuracy: 0.9670 - val_output_1_accuracy: 0.9887 - val_output_2_accuracy: 0.9745 - val_output_3_accuracy: 0.9597 - val_output_4_accuracy: 0.9632\n",
      "Epoch 175/200\n",
      "4000/4000 [==============================] - 1s 341us/sample - loss: 0.1579 - output_0_loss: 0.0386 - output_1_loss: 0.0281 - output_2_loss: 0.0247 - output_3_loss: 0.0350 - output_4_loss: 0.0316 - output_0_accuracy: 0.9875 - output_1_accuracy: 0.9920 - output_2_accuracy: 0.9918 - output_3_accuracy: 0.9887 - output_4_accuracy: 0.9890 - val_loss: 0.5005 - val_output_0_loss: 0.0674 - val_output_1_loss: 0.2083 - val_output_2_loss: 0.0441 - val_output_3_loss: 0.0808 - val_output_4_loss: 0.0987 - val_output_0_accuracy: 0.9763 - val_output_1_accuracy: 0.9502 - val_output_2_accuracy: 0.9868 - val_output_3_accuracy: 0.9713 - val_output_4_accuracy: 0.9703\n",
      "Epoch 176/200\n",
      "4000/4000 [==============================] - 1s 330us/sample - loss: 0.1679 - output_0_loss: 0.0296 - output_1_loss: 0.0354 - output_2_loss: 0.0302 - output_3_loss: 0.0379 - output_4_loss: 0.0348 - output_0_accuracy: 0.9925 - output_1_accuracy: 0.9895 - output_2_accuracy: 0.9895 - output_3_accuracy: 0.9900 - output_4_accuracy: 0.9890 - val_loss: 0.1890 - val_output_0_loss: 0.0792 - val_output_1_loss: 0.0134 - val_output_2_loss: 0.0303 - val_output_3_loss: 0.0491 - val_output_4_loss: 0.0165 - val_output_0_accuracy: 0.9808 - val_output_1_accuracy: 0.9965 - val_output_2_accuracy: 0.9910 - val_output_3_accuracy: 0.9850 - val_output_4_accuracy: 0.9957\n",
      "Epoch 177/200\n",
      "4000/4000 [==============================] - 1s 323us/sample - loss: 0.1268 - output_0_loss: 0.0290 - output_1_loss: 0.0241 - output_2_loss: 0.0185 - output_3_loss: 0.0277 - output_4_loss: 0.0275 - output_0_accuracy: 0.9902 - output_1_accuracy: 0.9923 - output_2_accuracy: 0.9948 - output_3_accuracy: 0.9893 - output_4_accuracy: 0.9915 - val_loss: 0.2381 - val_output_0_loss: 0.0547 - val_output_1_loss: 0.0278 - val_output_2_loss: 0.0748 - val_output_3_loss: 0.0528 - val_output_4_loss: 0.0275 - val_output_0_accuracy: 0.9833 - val_output_1_accuracy: 0.9910 - val_output_2_accuracy: 0.9785 - val_output_3_accuracy: 0.9815 - val_output_4_accuracy: 0.9913\n",
      "Epoch 178/200\n",
      "4000/4000 [==============================] - 1s 337us/sample - loss: 0.1608 - output_0_loss: 0.0335 - output_1_loss: 0.0343 - output_2_loss: 0.0317 - output_3_loss: 0.0301 - output_4_loss: 0.0311 - output_0_accuracy: 0.9880 - output_1_accuracy: 0.9902 - output_2_accuracy: 0.9900 - output_3_accuracy: 0.9912 - output_4_accuracy: 0.9887 - val_loss: 0.3905 - val_output_0_loss: 0.0791 - val_output_1_loss: 0.0965 - val_output_2_loss: 0.0968 - val_output_3_loss: 0.0645 - val_output_4_loss: 0.0545 - val_output_0_accuracy: 0.9763 - val_output_1_accuracy: 0.9742 - val_output_2_accuracy: 0.9680 - val_output_3_accuracy: 0.9787 - val_output_4_accuracy: 0.9803\n",
      "Epoch 179/200\n",
      "4000/4000 [==============================] - 2s 592us/sample - loss: 0.1440 - output_0_loss: 0.0260 - output_1_loss: 0.0267 - output_2_loss: 0.0242 - output_3_loss: 0.0352 - output_4_loss: 0.0319 - output_0_accuracy: 0.9925 - output_1_accuracy: 0.9898 - output_2_accuracy: 0.9927 - output_3_accuracy: 0.9880 - output_4_accuracy: 0.9895 - val_loss: 0.2623 - val_output_0_loss: 0.0342 - val_output_1_loss: 0.0637 - val_output_2_loss: 0.0318 - val_output_3_loss: 0.0885 - val_output_4_loss: 0.0434 - val_output_0_accuracy: 0.9892 - val_output_1_accuracy: 0.9810 - val_output_2_accuracy: 0.9900 - val_output_3_accuracy: 0.9732 - val_output_4_accuracy: 0.9860\n",
      "Epoch 180/200\n",
      "4000/4000 [==============================] - 3s 732us/sample - loss: 0.1707 - output_0_loss: 0.0332 - output_1_loss: 0.0300 - output_2_loss: 0.0274 - output_3_loss: 0.0464 - output_4_loss: 0.0336 - output_0_accuracy: 0.9890 - output_1_accuracy: 0.9912 - output_2_accuracy: 0.9902 - output_3_accuracy: 0.9880 - output_4_accuracy: 0.9900 - val_loss: 0.2145 - val_output_0_loss: 0.0497 - val_output_1_loss: 0.0353 - val_output_2_loss: 0.0306 - val_output_3_loss: 0.0474 - val_output_4_loss: 0.0510 - val_output_0_accuracy: 0.9858 - val_output_1_accuracy: 0.9893 - val_output_2_accuracy: 0.9897 - val_output_3_accuracy: 0.9848 - val_output_4_accuracy: 0.9842\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 2s 615us/sample - loss: 0.1636 - output_0_loss: 0.0391 - output_1_loss: 0.0290 - output_2_loss: 0.0319 - output_3_loss: 0.0272 - output_4_loss: 0.0365 - output_0_accuracy: 0.9862 - output_1_accuracy: 0.9908 - output_2_accuracy: 0.9915 - output_3_accuracy: 0.9930 - output_4_accuracy: 0.9895 - val_loss: 0.3165 - val_output_0_loss: 0.0487 - val_output_1_loss: 0.0656 - val_output_2_loss: 0.0774 - val_output_3_loss: 0.0671 - val_output_4_loss: 0.0579 - val_output_0_accuracy: 0.9832 - val_output_1_accuracy: 0.9778 - val_output_2_accuracy: 0.9772 - val_output_3_accuracy: 0.9797 - val_output_4_accuracy: 0.9815\n",
      "Epoch 182/200\n",
      "4000/4000 [==============================] - 1s 330us/sample - loss: 0.1519 - output_0_loss: 0.0323 - output_1_loss: 0.0390 - output_2_loss: 0.0226 - output_3_loss: 0.0308 - output_4_loss: 0.0272 - output_0_accuracy: 0.9900 - output_1_accuracy: 0.9868 - output_2_accuracy: 0.9930 - output_3_accuracy: 0.9925 - output_4_accuracy: 0.9912 - val_loss: 0.3814 - val_output_0_loss: 0.0684 - val_output_1_loss: 0.0633 - val_output_2_loss: 0.1060 - val_output_3_loss: 0.0605 - val_output_4_loss: 0.0825 - val_output_0_accuracy: 0.9778 - val_output_1_accuracy: 0.9812 - val_output_2_accuracy: 0.9733 - val_output_3_accuracy: 0.9842 - val_output_4_accuracy: 0.9732\n",
      "Epoch 183/200\n",
      "4000/4000 [==============================] - 1s 317us/sample - loss: 0.1536 - output_0_loss: 0.0242 - output_1_loss: 0.0275 - output_2_loss: 0.0331 - output_3_loss: 0.0391 - output_4_loss: 0.0296 - output_0_accuracy: 0.9925 - output_1_accuracy: 0.9918 - output_2_accuracy: 0.9905 - output_3_accuracy: 0.9883 - output_4_accuracy: 0.9912 - val_loss: 0.3183 - val_output_0_loss: 0.0793 - val_output_1_loss: 0.0983 - val_output_2_loss: 0.0440 - val_output_3_loss: 0.0524 - val_output_4_loss: 0.0437 - val_output_0_accuracy: 0.9737 - val_output_1_accuracy: 0.9700 - val_output_2_accuracy: 0.9847 - val_output_3_accuracy: 0.9828 - val_output_4_accuracy: 0.9845\n",
      "Epoch 184/200\n",
      "4000/4000 [==============================] - 1s 323us/sample - loss: 0.1469 - output_0_loss: 0.0277 - output_1_loss: 0.0288 - output_2_loss: 0.0314 - output_3_loss: 0.0331 - output_4_loss: 0.0260 - output_0_accuracy: 0.9927 - output_1_accuracy: 0.9915 - output_2_accuracy: 0.9890 - output_3_accuracy: 0.9875 - output_4_accuracy: 0.9920 - val_loss: 0.2646 - val_output_0_loss: 0.0735 - val_output_1_loss: 0.0374 - val_output_2_loss: 0.0635 - val_output_3_loss: 0.0446 - val_output_4_loss: 0.0453 - val_output_0_accuracy: 0.9783 - val_output_1_accuracy: 0.9893 - val_output_2_accuracy: 0.9823 - val_output_3_accuracy: 0.9880 - val_output_4_accuracy: 0.9857\n",
      "Epoch 185/200\n",
      "4000/4000 [==============================] - 1s 322us/sample - loss: 0.1907 - output_0_loss: 0.0420 - output_1_loss: 0.0333 - output_2_loss: 0.0366 - output_3_loss: 0.0367 - output_4_loss: 0.0421 - output_0_accuracy: 0.9858 - output_1_accuracy: 0.9902 - output_2_accuracy: 0.9887 - output_3_accuracy: 0.9868 - output_4_accuracy: 0.9865 - val_loss: 0.2035 - val_output_0_loss: 0.0370 - val_output_1_loss: 0.0232 - val_output_2_loss: 0.0429 - val_output_3_loss: 0.0725 - val_output_4_loss: 0.0277 - val_output_0_accuracy: 0.9877 - val_output_1_accuracy: 0.9923 - val_output_2_accuracy: 0.9857 - val_output_3_accuracy: 0.9812 - val_output_4_accuracy: 0.9912\n",
      "Epoch 186/200\n",
      "4000/4000 [==============================] - 1s 357us/sample - loss: 0.1324 - output_0_loss: 0.0206 - output_1_loss: 0.0240 - output_2_loss: 0.0218 - output_3_loss: 0.0385 - output_4_loss: 0.0276 - output_0_accuracy: 0.9930 - output_1_accuracy: 0.9915 - output_2_accuracy: 0.9923 - output_3_accuracy: 0.9902 - output_4_accuracy: 0.9910 - val_loss: 0.1852 - val_output_0_loss: 0.0244 - val_output_1_loss: 0.0356 - val_output_2_loss: 0.0133 - val_output_3_loss: 0.0294 - val_output_4_loss: 0.0826 - val_output_0_accuracy: 0.9927 - val_output_1_accuracy: 0.9883 - val_output_2_accuracy: 0.9957 - val_output_3_accuracy: 0.9912 - val_output_4_accuracy: 0.9792\n",
      "Epoch 187/200\n",
      "4000/4000 [==============================] - 1s 360us/sample - loss: 0.1554 - output_0_loss: 0.0369 - output_1_loss: 0.0263 - output_2_loss: 0.0340 - output_3_loss: 0.0247 - output_4_loss: 0.0335 - output_0_accuracy: 0.9890 - output_1_accuracy: 0.9908 - output_2_accuracy: 0.9890 - output_3_accuracy: 0.9920 - output_4_accuracy: 0.9912 - val_loss: 0.2102 - val_output_0_loss: 0.0566 - val_output_1_loss: 0.0198 - val_output_2_loss: 0.0784 - val_output_3_loss: 0.0302 - val_output_4_loss: 0.0251 - val_output_0_accuracy: 0.9818 - val_output_1_accuracy: 0.9942 - val_output_2_accuracy: 0.9723 - val_output_3_accuracy: 0.9918 - val_output_4_accuracy: 0.9937\n",
      "Epoch 188/200\n",
      "4000/4000 [==============================] - 1s 349us/sample - loss: 0.1474 - output_0_loss: 0.0311 - output_1_loss: 0.0258 - output_2_loss: 0.0288 - output_3_loss: 0.0363 - output_4_loss: 0.0254 - output_0_accuracy: 0.9908 - output_1_accuracy: 0.9908 - output_2_accuracy: 0.9898 - output_3_accuracy: 0.9880 - output_4_accuracy: 0.9915 - val_loss: 0.5355 - val_output_0_loss: 0.1041 - val_output_1_loss: 0.0790 - val_output_2_loss: 0.1281 - val_output_3_loss: 0.1537 - val_output_4_loss: 0.0696 - val_output_0_accuracy: 0.9738 - val_output_1_accuracy: 0.9755 - val_output_2_accuracy: 0.9635 - val_output_3_accuracy: 0.9495 - val_output_4_accuracy: 0.9792\n",
      "Epoch 189/200\n",
      "4000/4000 [==============================] - 1s 339us/sample - loss: 0.1767 - output_0_loss: 0.0262 - output_1_loss: 0.0392 - output_2_loss: 0.0316 - output_3_loss: 0.0436 - output_4_loss: 0.0361 - output_0_accuracy: 0.9905 - output_1_accuracy: 0.9895 - output_2_accuracy: 0.9893 - output_3_accuracy: 0.9855 - output_4_accuracy: 0.9890 - val_loss: 0.2890 - val_output_0_loss: 0.0912 - val_output_1_loss: 0.0508 - val_output_2_loss: 0.0546 - val_output_3_loss: 0.0501 - val_output_4_loss: 0.0422 - val_output_0_accuracy: 0.9730 - val_output_1_accuracy: 0.9850 - val_output_2_accuracy: 0.9830 - val_output_3_accuracy: 0.9862 - val_output_4_accuracy: 0.9863\n",
      "Epoch 190/200\n",
      "4000/4000 [==============================] - 1s 353us/sample - loss: 0.1638 - output_0_loss: 0.0411 - output_1_loss: 0.0390 - output_2_loss: 0.0286 - output_3_loss: 0.0276 - output_4_loss: 0.0277 - output_0_accuracy: 0.9893 - output_1_accuracy: 0.9870 - output_2_accuracy: 0.9925 - output_3_accuracy: 0.9927 - output_4_accuracy: 0.9912 - val_loss: 0.2391 - val_output_0_loss: 0.0379 - val_output_1_loss: 0.0176 - val_output_2_loss: 0.0889 - val_output_3_loss: 0.0674 - val_output_4_loss: 0.0270 - val_output_0_accuracy: 0.9882 - val_output_1_accuracy: 0.9942 - val_output_2_accuracy: 0.9767 - val_output_3_accuracy: 0.9802 - val_output_4_accuracy: 0.9918\n",
      "Epoch 191/200\n",
      "4000/4000 [==============================] - 1s 336us/sample - loss: 0.1623 - output_0_loss: 0.0265 - output_1_loss: 0.0355 - output_2_loss: 0.0271 - output_3_loss: 0.0370 - output_4_loss: 0.0362 - output_0_accuracy: 0.9910 - output_1_accuracy: 0.9877 - output_2_accuracy: 0.9912 - output_3_accuracy: 0.9905 - output_4_accuracy: 0.9877 - val_loss: 0.4166 - val_output_0_loss: 0.1128 - val_output_1_loss: 0.0787 - val_output_2_loss: 0.0936 - val_output_3_loss: 0.0976 - val_output_4_loss: 0.0337 - val_output_0_accuracy: 0.9650 - val_output_1_accuracy: 0.9765 - val_output_2_accuracy: 0.9717 - val_output_3_accuracy: 0.9718 - val_output_4_accuracy: 0.9898\n",
      "Epoch 192/200\n",
      "4000/4000 [==============================] - 1s 314us/sample - loss: 0.1319 - output_0_loss: 0.0278 - output_1_loss: 0.0234 - output_2_loss: 0.0262 - output_3_loss: 0.0277 - output_4_loss: 0.0268 - output_0_accuracy: 0.9908 - output_1_accuracy: 0.9918 - output_2_accuracy: 0.9920 - output_3_accuracy: 0.9912 - output_4_accuracy: 0.9920 - val_loss: 0.1741 - val_output_0_loss: 0.0579 - val_output_1_loss: 0.0226 - val_output_2_loss: 0.0338 - val_output_3_loss: 0.0452 - val_output_4_loss: 0.0144 - val_output_0_accuracy: 0.9818 - val_output_1_accuracy: 0.9947 - val_output_2_accuracy: 0.9897 - val_output_3_accuracy: 0.9863 - val_output_4_accuracy: 0.9963\n",
      "Epoch 193/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 340us/sample - loss: 0.1546 - output_0_loss: 0.0294 - output_1_loss: 0.0313 - output_2_loss: 0.0311 - output_3_loss: 0.0284 - output_4_loss: 0.0343 - output_0_accuracy: 0.9908 - output_1_accuracy: 0.9902 - output_2_accuracy: 0.9912 - output_3_accuracy: 0.9912 - output_4_accuracy: 0.9905 - val_loss: 0.3091 - val_output_0_loss: 0.0401 - val_output_1_loss: 0.0497 - val_output_2_loss: 0.0544 - val_output_3_loss: 0.0608 - val_output_4_loss: 0.1040 - val_output_0_accuracy: 0.9877 - val_output_1_accuracy: 0.9852 - val_output_2_accuracy: 0.9823 - val_output_3_accuracy: 0.9825 - val_output_4_accuracy: 0.9643\n",
      "Epoch 194/200\n",
      "4000/4000 [==============================] - 1s 323us/sample - loss: 0.1272 - output_0_loss: 0.0232 - output_1_loss: 0.0192 - output_2_loss: 0.0231 - output_3_loss: 0.0305 - output_4_loss: 0.0311 - output_0_accuracy: 0.9940 - output_1_accuracy: 0.9940 - output_2_accuracy: 0.9923 - output_3_accuracy: 0.9898 - output_4_accuracy: 0.9908 - val_loss: 0.2395 - val_output_0_loss: 0.0526 - val_output_1_loss: 0.0259 - val_output_2_loss: 0.0402 - val_output_3_loss: 0.0979 - val_output_4_loss: 0.0226 - val_output_0_accuracy: 0.9842 - val_output_1_accuracy: 0.9913 - val_output_2_accuracy: 0.9890 - val_output_3_accuracy: 0.9713 - val_output_4_accuracy: 0.9927\n",
      "Epoch 195/200\n",
      "4000/4000 [==============================] - 1s 330us/sample - loss: 0.1562 - output_0_loss: 0.0277 - output_1_loss: 0.0360 - output_2_loss: 0.0285 - output_3_loss: 0.0256 - output_4_loss: 0.0383 - output_0_accuracy: 0.9905 - output_1_accuracy: 0.9893 - output_2_accuracy: 0.9910 - output_3_accuracy: 0.9918 - output_4_accuracy: 0.9875 - val_loss: 0.2556 - val_output_0_loss: 0.0383 - val_output_1_loss: 0.0528 - val_output_2_loss: 0.0399 - val_output_3_loss: 0.0467 - val_output_4_loss: 0.0773 - val_output_0_accuracy: 0.9890 - val_output_1_accuracy: 0.9808 - val_output_2_accuracy: 0.9880 - val_output_3_accuracy: 0.9845 - val_output_4_accuracy: 0.9732\n",
      "Epoch 196/200\n",
      "4000/4000 [==============================] - 1s 326us/sample - loss: 0.1563 - output_0_loss: 0.0314 - output_1_loss: 0.0311 - output_2_loss: 0.0335 - output_3_loss: 0.0346 - output_4_loss: 0.0257 - output_0_accuracy: 0.9900 - output_1_accuracy: 0.9908 - output_2_accuracy: 0.9920 - output_3_accuracy: 0.9885 - output_4_accuracy: 0.9910 - val_loss: 0.1846 - val_output_0_loss: 0.0537 - val_output_1_loss: 0.0406 - val_output_2_loss: 0.0276 - val_output_3_loss: 0.0308 - val_output_4_loss: 0.0319 - val_output_0_accuracy: 0.9815 - val_output_1_accuracy: 0.9872 - val_output_2_accuracy: 0.9918 - val_output_3_accuracy: 0.9907 - val_output_4_accuracy: 0.9885\n",
      "Epoch 197/200\n",
      "4000/4000 [==============================] - 1s 333us/sample - loss: 0.1357 - output_0_loss: 0.0340 - output_1_loss: 0.0217 - output_2_loss: 0.0238 - output_3_loss: 0.0252 - output_4_loss: 0.0309 - output_0_accuracy: 0.9883 - output_1_accuracy: 0.9942 - output_2_accuracy: 0.9927 - output_3_accuracy: 0.9925 - output_4_accuracy: 0.9885 - val_loss: 0.8060 - val_output_0_loss: 0.1472 - val_output_1_loss: 0.0923 - val_output_2_loss: 0.3500 - val_output_3_loss: 0.1122 - val_output_4_loss: 0.1024 - val_output_0_accuracy: 0.9542 - val_output_1_accuracy: 0.9717 - val_output_2_accuracy: 0.9093 - val_output_3_accuracy: 0.9697 - val_output_4_accuracy: 0.9733\n",
      "Epoch 198/200\n",
      "4000/4000 [==============================] - 1s 330us/sample - loss: 0.1557 - output_0_loss: 0.0378 - output_1_loss: 0.0251 - output_2_loss: 0.0360 - output_3_loss: 0.0281 - output_4_loss: 0.0287 - output_0_accuracy: 0.9895 - output_1_accuracy: 0.9912 - output_2_accuracy: 0.9898 - output_3_accuracy: 0.9912 - output_4_accuracy: 0.9910 - val_loss: 0.2429 - val_output_0_loss: 0.0468 - val_output_1_loss: 0.0168 - val_output_2_loss: 0.0402 - val_output_3_loss: 0.1100 - val_output_4_loss: 0.0290 - val_output_0_accuracy: 0.9868 - val_output_1_accuracy: 0.9948 - val_output_2_accuracy: 0.9870 - val_output_3_accuracy: 0.9712 - val_output_4_accuracy: 0.9922\n",
      "Epoch 199/200\n",
      "4000/4000 [==============================] - 1s 362us/sample - loss: 0.1292 - output_0_loss: 0.0208 - output_1_loss: 0.0321 - output_2_loss: 0.0218 - output_3_loss: 0.0326 - output_4_loss: 0.0218 - output_0_accuracy: 0.9918 - output_1_accuracy: 0.9900 - output_2_accuracy: 0.9930 - output_3_accuracy: 0.9908 - output_4_accuracy: 0.9940 - val_loss: 0.3075 - val_output_0_loss: 0.0958 - val_output_1_loss: 0.0521 - val_output_2_loss: 0.0633 - val_output_3_loss: 0.0435 - val_output_4_loss: 0.0529 - val_output_0_accuracy: 0.9692 - val_output_1_accuracy: 0.9818 - val_output_2_accuracy: 0.9805 - val_output_3_accuracy: 0.9877 - val_output_4_accuracy: 0.9825\n",
      "Epoch 200/200\n",
      "4000/4000 [==============================] - 1s 335us/sample - loss: 0.1375 - output_0_loss: 0.0259 - output_1_loss: 0.0319 - output_2_loss: 0.0237 - output_3_loss: 0.0300 - output_4_loss: 0.0261 - output_0_accuracy: 0.9887 - output_1_accuracy: 0.9885 - output_2_accuracy: 0.9923 - output_3_accuracy: 0.9915 - output_4_accuracy: 0.9890 - val_loss: 0.2283 - val_output_0_loss: 0.0316 - val_output_1_loss: 0.0941 - val_output_2_loss: 0.0264 - val_output_3_loss: 0.0564 - val_output_4_loss: 0.0198 - val_output_0_accuracy: 0.9902 - val_output_1_accuracy: 0.9783 - val_output_2_accuracy: 0.9912 - val_output_3_accuracy: 0.9830 - val_output_4_accuracy: 0.9938\n"
     ]
    }
   ],
   "source": [
    "history = coding_model.fit(x_train, y_train, validation_split=percentage_split, batch_size=32, epochs=nb_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'output_0_loss', 'output_1_loss', 'output_2_loss', 'output_3_loss', 'output_4_loss', 'output_0_accuracy', 'output_1_accuracy', 'output_2_accuracy', 'output_3_accuracy', 'output_4_accuracy', 'val_loss', 'val_output_0_loss', 'val_output_1_loss', 'val_output_2_loss', 'val_output_3_loss', 'val_output_4_loss', 'val_output_0_accuracy', 'val_output_1_accuracy', 'val_output_2_accuracy', 'val_output_3_accuracy', 'val_output_4_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values (of first char only)\n",
    "plt.plot(history.history['val_output_0_accuracy'])\n",
    "plt.plot(history.history['val_output_0_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot training & validation loss values (of first char only)\n",
    "plt.plot(history.history['output_0_loss'])\n",
    "plt.plot(history.history['val_output_0_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.232115676817894\n",
      "output_0_loss : 0.031012308\n",
      "output_1_loss : 0.0938223\n",
      "output_2_loss : 0.033841055\n",
      "output_3_loss : 0.052941248\n",
      "output_4_loss : 0.020443635\n",
      "output_0_accuracy : 0.98962\n",
      "output_1_accuracy : 0.97646\n",
      "output_2_accuracy : 0.99047\n",
      "output_3_accuracy : 0.98321\n",
      "output_4_accuracy : 0.99341\n"
     ]
    }
   ],
   "source": [
    "nb_words_to_test = 100000\n",
    "\n",
    "x_test = create_inputs(nb_words_to_test, nb_chars, nb_letters)\n",
    "x_test_scaled  = scaler.transform(x_test)\n",
    "\n",
    "y_test_raw = encrypt(x_test, nb_words_to_test, nb_chars)\n",
    "y_test_raw_cate = keras.utils.to_categorical(y_test_raw, nb_letters)\n",
    "\n",
    "# process the y data as useful ANN multiple-outputs data\n",
    "y_test = []\n",
    "for c in range(nb_chars):\n",
    "    # extract each 'char' colomn from the global y_train0 tensor\n",
    "    # in order to have multiplue yi_train outputs tensors\n",
    "    yi_test = y_test_raw_cate[:,c,:]\n",
    "    y_test.append(yi_test)\n",
    "\n",
    "\n",
    "print('\\n# Evaluate on test data')\n",
    "results = coding_model.evaluate(x_test_scaled, y_test, batch_size=128)\n",
    "for r in range(len(results)):\n",
    "    print(coding_model.metrics_names[r],':',results[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ylddr', 'tylva', 'ifuon']\n",
      "x_test=\n",
      " [[121 108 100 100 114]\n",
      " [116 121 108 118  97]\n",
      " [105 102 117 111 110]]\n",
      "x_test_scaled=\n",
      " [[ 1.53145278 -0.1880024  -1.26177263 -1.24837202  0.61332595]\n",
      " [ 0.86325051  1.56361456 -0.19750202  1.13578675 -1.65854862]\n",
      " [-0.60679448 -0.99644099  0.99980242  0.20861389  0.07876723]]\n",
      "-->\n",
      "prediction\n",
      "['24 11 3 3 17', '19 24 11 21 0', '8 5 20 14 13']\n",
      "check prediction\n",
      "y_test=\n",
      " [[24 11  3  3 17]\n",
      " [19 24 11 21  0]\n",
      " [ 8  5 20 14 13]]\n"
     ]
    }
   ],
   "source": [
    "nb_words_to_test = 3\n",
    "\n",
    "x_test = create_inputs(nb_words_to_test, nb_chars, nb_letters)\n",
    "print_readable_inputs(x_test)\n",
    "print(\"x_test=\\n\", x_test)\n",
    "\n",
    "x_test_scaled  = scaler.transform(x_test)\n",
    "print(\"x_test_scaled=\\n\", x_test_scaled)\n",
    "print('-->')\n",
    "\n",
    "prediction = coding_model.predict(x_test_scaled)\n",
    "#print(prediction)\n",
    "print('prediction')\n",
    "print_readable_outputs(prediction, nb_words_to_test, nb_chars)\n",
    "\n",
    "print('check prediction')\n",
    "y_test = encrypt(x_test, nb_words_to_test, nb_chars)\n",
    "print(\"y_test=\\n\", y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
