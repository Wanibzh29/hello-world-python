{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of characters in a word.\n",
    "# for instance abccba has nb_chars = 6\n",
    "nb_chars = 4\n",
    "\n",
    "# number of possible characters used during the encoding.\n",
    "# for instance abcde leads to 01234 has nb_letters = 5\n",
    "nb_letters = 26\n",
    "\n",
    "# number of words samples to be generated \n",
    "nb_words = 30000\n",
    "\n",
    "# percentage of words that will be used for validation\n",
    "percentage_split = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456976"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of combinations\n",
    "nb_letters**nb_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inputs(nb_words, nb_chars, nb_letters):\n",
    "    '''Create a numpy array of nb_words rows with nb_chars columns each element\n",
    "    being a random letter of nb_letters (a, b...)'''\n",
    "    words = np.zeros((nb_words, nb_chars), dtype=int)\n",
    "    \n",
    "    for w in range(nb_words):\n",
    "        optim_tentative = False\n",
    "        if optim_tentative == True and w%10 != 0:\n",
    "            i = random.randint(0, nb_letters-1)\n",
    "            for c in range(nb_chars):\n",
    "                words[w, c] = ord('a') + i\n",
    "        else:\n",
    "            for c in range(nb_chars):\n",
    "                i = random.randint(0, nb_letters-1)\n",
    "                words[w, c] = ord('a') + i\n",
    "                \n",
    "    return words\n",
    "\n",
    "\n",
    "def encrypt(words, nb_words, nb_chars):\n",
    "    '''Encrypt each element of a numpy array of nb_words rows with nb_chars \n",
    "    columns each item with a secret algorithm'''\n",
    "    \n",
    "    encrypted_words = words.copy()\n",
    "    encrypted_words_probs = np.zeros((nb_words, nb_chars, nb_chars))\n",
    "    \n",
    "    #val_max = -1\n",
    "    \n",
    "    for w in range(nb_words):\n",
    "        for c in range(nb_chars): # 0,1,2,3,4\n",
    "            encrypted_words[w,c] = int(words[w,c]) - 49\n",
    "            val = encrypted_words[w,c] - 48\n",
    "            \n",
    "            #if val > val_max:\n",
    "            #    val_max = val\n",
    "            \n",
    "            # add entropy (i.e. mistakes in the encryption)\n",
    "            #epsilon = random.randint(0, 100)\n",
    "            #if epsilon == 5 and val != val_max:\n",
    "            #val +=1\n",
    "            \n",
    "            #print('w:',w,', c:',c,', [wc]:', val)\n",
    "            #encrypted_words_probs[w, c, val ] = 1.0\n",
    "            encrypted_words[w,c] = val\n",
    "    return encrypted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_features = nb_chars\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = layers.Input(shape=(nb_chars,), dtype='float32', name='main_input')\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = layers.Dense(4096, activation='relu', name='hl_1')(inputs)\n",
    "#x = layers.Dense(2048, activation='relu', name='hl_1')(inputs)\n",
    "#x = layers.Dense(64, activation='relu', name='hl_2')(x)\n",
    "\n",
    "outputs = []\n",
    "losses = {}\n",
    "for o in range(nb_chars):\n",
    "    name_i = 'output_'+str(o)\n",
    "    output_i = layers.Dense(nb_letters, activation='softmax', dtype='float32', name=name_i)(x)\n",
    "    outputs.append(output_i)\n",
    "    losses[name_i] = 'categorical_crossentropy'\n",
    "\n",
    "coding_model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "coding_model.compile(optimizer='rmsprop',\n",
    "                     loss=losses,\n",
    "                     metrics=['accuracy'])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hl_1 (Dense)                    (None, 4096)         20480       main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output_0 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_2 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_3 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 446,568\n",
      "Trainable params: 446,568\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(coding_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_readable_inputs(x):\n",
    "    words = []\n",
    "    for w in x:\n",
    "        word = ''\n",
    "        for c in w:\n",
    "            word += chr(c)\n",
    "        words.append(word)\n",
    "   \n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_readable_outputs(outputs, nb_words):\n",
    "    \n",
    "    # outputs are listed : first, per char, second by sample, third by letter probability\n",
    "    words = [''] * nb_words\n",
    "    \n",
    "    c_i = 0\n",
    "    for char in outputs:\n",
    "\n",
    "        s_i = 0\n",
    "        for sample in char:\n",
    "\n",
    "            l_i = 0\n",
    "            best_value = -float('inf')\n",
    "            best_letter = -1\n",
    "            for letter_probs in sample:\n",
    "                if letter_probs > best_value:\n",
    "                    best_value = letter_probs\n",
    "                    best_letter = l_i\n",
    "                l_i += 1\n",
    "            words[s_i] += str(best_letter)\n",
    "            words[s_i] += '-'\n",
    "            s_i += 1\n",
    "        c_i += 1\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (as readable inputs)\n",
      "['gtvu', 'ulru', 'wvzs']\n",
      "x:\n",
      " [[103 116 118 117]\n",
      " [117 108 114 117]\n",
      " [119 118 122 115]] out of  30000\n",
      "\n",
      "x_train:\n",
      " [[-0.86578526  0.87178929  1.13625801  1.00472895]\n",
      " [ 1.00044727 -0.19507639  0.6046691   1.00472895]\n",
      " [ 1.26705191  1.13850571  1.66784693  0.7377895 ]] out of  30000\n",
      "\n",
      "y:\n",
      " [[ 6 19 21 20]\n",
      " [20 11 17 20]\n",
      " [22 21 25 18]\n",
      " ...\n",
      " [ 0  9  8 16]\n",
      " [14 18  9 10]\n",
      " [18 10 22  4]]\n",
      "\n",
      "y_train:\n",
      " [[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "   0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "   0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]] out of  30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "x = create_inputs(nb_words, nb_chars, nb_letters)\n",
    "print('x: (as readable inputs)')\n",
    "print_readable_inputs(x[:3])\n",
    "print('x:\\n', x[:3], 'out of ',len(x))\n",
    "print()\n",
    "\n",
    "# process the x data as useful ANN input data\n",
    "scaler = StandardScaler()\n",
    "x_train  = scaler.fit_transform(x)\n",
    "\n",
    "print('x_train:\\n', x_train[:3], 'out of ',len(x_train))\n",
    "print()\n",
    "\n",
    "# create output data for training\n",
    "y = encrypt(x, nb_words, nb_chars)\n",
    "print('y:\\n', y)\n",
    "print()\n",
    "# process the y data as useful ANN output data\n",
    "y_train = keras.utils.to_categorical(y, nb_letters)\n",
    "print('y_train:\\n', y_train[:3], 'out of ',len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_sub_set(y, c_ref, nb_chars):\n",
    "    '''Retrieve the probalities of the i-th char'''\n",
    "    nb_samples = len(y)\n",
    "    \n",
    "    yi = np.zeros((nb_samples, nb_letters), dtype=int)\n",
    "    \n",
    "    for s in range(nb_samples):\n",
    "        for c in range(nb_chars):\n",
    "            #print('ysl:',y[s][0][l_i])\n",
    "            if c == c_ref:\n",
    "                yi[s] = y[s, c]\n",
    "                \n",
    "    return yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = []\n",
    "for c in range(nb_chars):\n",
    "    yi_train = get_sub_sub_set(y_train, c, nb_chars)\n",
    "    y_train2.append(yi_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2999 samples, validate on 27001 samples\n",
      "Epoch 1/200\n",
      "2999/2999 [==============================] - 2s 639us/step - loss: 10.6856 - output_0_loss: 2.6729 - output_1_loss: 2.6718 - output_2_loss: 2.6686 - output_3_loss: 2.6722 - output_0_acc: 0.1344 - output_1_acc: 0.1387 - output_2_acc: 0.1374 - output_3_acc: 0.1297 - val_loss: 9.5143 - val_output_0_loss: 2.3803 - val_output_1_loss: 2.3941 - val_output_2_loss: 2.3576 - val_output_3_loss: 2.3824 - val_output_0_acc: 0.1839 - val_output_1_acc: 0.1808 - val_output_2_acc: 0.1753 - val_output_3_acc: 0.1880\n",
      "Epoch 2/200\n",
      "2999/2999 [==============================] - 1s 481us/step - loss: 8.9485 - output_0_loss: 2.2361 - output_1_loss: 2.2400 - output_2_loss: 2.2351 - output_3_loss: 2.2373 - output_0_acc: 0.2171 - output_1_acc: 0.2001 - output_2_acc: 0.2064 - output_3_acc: 0.2077 - val_loss: 8.6106 - val_output_0_loss: 2.1387 - val_output_1_loss: 2.1568 - val_output_2_loss: 2.1490 - val_output_3_loss: 2.1661 - val_output_0_acc: 0.2328 - val_output_1_acc: 0.2085 - val_output_2_acc: 0.2262 - val_output_3_acc: 0.2232\n",
      "Epoch 3/200\n",
      "2999/2999 [==============================] - 1s 479us/step - loss: 8.1866 - output_0_loss: 2.0397 - output_1_loss: 2.0570 - output_2_loss: 2.0534 - output_3_loss: 2.0364 - output_0_acc: 0.2561 - output_1_acc: 0.2301 - output_2_acc: 0.2457 - output_3_acc: 0.2544 - val_loss: 8.0632 - val_output_0_loss: 2.0763 - val_output_1_loss: 1.9863 - val_output_2_loss: 1.9877 - val_output_3_loss: 2.0129 - val_output_0_acc: 0.2376 - val_output_1_acc: 0.2562 - val_output_2_acc: 0.2417 - val_output_3_acc: 0.2541\n",
      "Epoch 4/200\n",
      "2999/2999 [==============================] - 1s 472us/step - loss: 7.6282 - output_0_loss: 1.9050 - output_1_loss: 1.9037 - output_2_loss: 1.9080 - output_3_loss: 1.9115 - output_0_acc: 0.2934 - output_1_acc: 0.2748 - output_2_acc: 0.2798 - output_3_acc: 0.2891 - val_loss: 7.8095 - val_output_0_loss: 2.0208 - val_output_1_loss: 1.9704 - val_output_2_loss: 1.9092 - val_output_3_loss: 1.9090 - val_output_0_acc: 0.2264 - val_output_1_acc: 0.2461 - val_output_2_acc: 0.2431 - val_output_3_acc: 0.2618\n",
      "Epoch 5/200\n",
      "2999/2999 [==============================] - 1s 476us/step - loss: 7.2197 - output_0_loss: 1.7966 - output_1_loss: 1.8070 - output_2_loss: 1.8035 - output_3_loss: 1.8125 - output_0_acc: 0.3248 - output_1_acc: 0.3174 - output_2_acc: 0.3158 - output_3_acc: 0.3074 - val_loss: 7.4386 - val_output_0_loss: 1.9245 - val_output_1_loss: 1.8483 - val_output_2_loss: 1.8684 - val_output_3_loss: 1.7974 - val_output_0_acc: 0.2669 - val_output_1_acc: 0.2921 - val_output_2_acc: 0.2947 - val_output_3_acc: 0.3108\n",
      "Epoch 6/200\n",
      "2999/2999 [==============================] - 1s 471us/step - loss: 6.8678 - output_0_loss: 1.7118 - output_1_loss: 1.7220 - output_2_loss: 1.7217 - output_3_loss: 1.7123 - output_0_acc: 0.3474 - output_1_acc: 0.3318 - output_2_acc: 0.3334 - output_3_acc: 0.3388 - val_loss: 6.9848 - val_output_0_loss: 1.7468 - val_output_1_loss: 1.6958 - val_output_2_loss: 1.7751 - val_output_3_loss: 1.7671 - val_output_0_acc: 0.2998 - val_output_1_acc: 0.3353 - val_output_2_acc: 0.2885 - val_output_3_acc: 0.3187\n",
      "Epoch 7/200\n",
      "2999/2999 [==============================] - 1s 430us/step - loss: 6.5416 - output_0_loss: 1.6360 - output_1_loss: 1.6311 - output_2_loss: 1.6351 - output_3_loss: 1.6395 - output_0_acc: 0.3675 - output_1_acc: 0.3701 - output_2_acc: 0.3525 - output_3_acc: 0.3558 - val_loss: 6.8374 - val_output_0_loss: 1.7684 - val_output_1_loss: 1.7291 - val_output_2_loss: 1.6321 - val_output_3_loss: 1.7078 - val_output_0_acc: 0.3366 - val_output_1_acc: 0.2835 - val_output_2_acc: 0.3557 - val_output_3_acc: 0.3155\n",
      "Epoch 8/200\n",
      "2999/2999 [==============================] - 1s 430us/step - loss: 6.2877 - output_0_loss: 1.5719 - output_1_loss: 1.5792 - output_2_loss: 1.5684 - output_3_loss: 1.5682 - output_0_acc: 0.3871 - output_1_acc: 0.3635 - output_2_acc: 0.3835 - output_3_acc: 0.3908 - val_loss: 6.4795 - val_output_0_loss: 1.6505 - val_output_1_loss: 1.6145 - val_output_2_loss: 1.5922 - val_output_3_loss: 1.6223 - val_output_0_acc: 0.3160 - val_output_1_acc: 0.3549 - val_output_2_acc: 0.3067 - val_output_3_acc: 0.3574\n",
      "Epoch 9/200\n",
      "2999/2999 [==============================] - 1s 410us/step - loss: 6.0448 - output_0_loss: 1.5042 - output_1_loss: 1.5115 - output_2_loss: 1.5154 - output_3_loss: 1.5136 - output_0_acc: 0.4078 - output_1_acc: 0.4028 - output_2_acc: 0.3941 - output_3_acc: 0.3905 - val_loss: 6.3237 - val_output_0_loss: 1.6009 - val_output_1_loss: 1.6132 - val_output_2_loss: 1.5121 - val_output_3_loss: 1.5976 - val_output_0_acc: 0.3571 - val_output_1_acc: 0.3448 - val_output_2_acc: 0.4057 - val_output_3_acc: 0.3781\n",
      "Epoch 10/200\n",
      "2999/2999 [==============================] - 1s 444us/step - loss: 5.8241 - output_0_loss: 1.4489 - output_1_loss: 1.4606 - output_2_loss: 1.4544 - output_3_loss: 1.4602 - output_0_acc: 0.4351 - output_1_acc: 0.4075 - output_2_acc: 0.4165 - output_3_acc: 0.4231 - val_loss: 6.0702 - val_output_0_loss: 1.4819 - val_output_1_loss: 1.5278 - val_output_2_loss: 1.5051 - val_output_3_loss: 1.5554 - val_output_0_acc: 0.4217 - val_output_1_acc: 0.3845 - val_output_2_acc: 0.3730 - val_output_3_acc: 0.3508\n",
      "Epoch 11/200\n",
      "2999/2999 [==============================] - 1s 463us/step - loss: 5.5999 - output_0_loss: 1.4018 - output_1_loss: 1.4007 - output_2_loss: 1.4036 - output_3_loss: 1.3938 - output_0_acc: 0.4435 - output_1_acc: 0.4415 - output_2_acc: 0.4275 - output_3_acc: 0.4525 - val_loss: 5.8951 - val_output_0_loss: 1.5261 - val_output_1_loss: 1.4197 - val_output_2_loss: 1.3811 - val_output_3_loss: 1.5681 - val_output_0_acc: 0.4191 - val_output_1_acc: 0.4463 - val_output_2_acc: 0.4492 - val_output_3_acc: 0.4027\n",
      "Epoch 12/200\n",
      "2999/2999 [==============================] - 1s 468us/step - loss: 5.4110 - output_0_loss: 1.3590 - output_1_loss: 1.3529 - output_2_loss: 1.3476 - output_3_loss: 1.3515 - output_0_acc: 0.4568 - output_1_acc: 0.4558 - output_2_acc: 0.4565 - output_3_acc: 0.4588 - val_loss: 5.7967 - val_output_0_loss: 1.4895 - val_output_1_loss: 1.4235 - val_output_2_loss: 1.4427 - val_output_3_loss: 1.4410 - val_output_0_acc: 0.3931 - val_output_1_acc: 0.4701 - val_output_2_acc: 0.4288 - val_output_3_acc: 0.4144\n",
      "Epoch 13/200\n",
      "2999/2999 [==============================] - 1s 460us/step - loss: 5.2303 - output_0_loss: 1.3124 - output_1_loss: 1.3056 - output_2_loss: 1.3066 - output_3_loss: 1.3058 - output_0_acc: 0.4712 - output_1_acc: 0.4852 - output_2_acc: 0.4858 - output_3_acc: 0.4815 - val_loss: 5.4681 - val_output_0_loss: 1.3849 - val_output_1_loss: 1.3324 - val_output_2_loss: 1.3969 - val_output_3_loss: 1.3540 - val_output_0_acc: 0.4157 - val_output_1_acc: 0.4649 - val_output_2_acc: 0.4452 - val_output_3_acc: 0.4658\n",
      "Epoch 14/200\n",
      "2999/2999 [==============================] - 1s 453us/step - loss: 5.0837 - output_0_loss: 1.2755 - output_1_loss: 1.2666 - output_2_loss: 1.2710 - output_3_loss: 1.2705 - output_0_acc: 0.4955 - output_1_acc: 0.4922 - output_2_acc: 0.4798 - output_3_acc: 0.4808 - val_loss: 5.3425 - val_output_0_loss: 1.3406 - val_output_1_loss: 1.3397 - val_output_2_loss: 1.3168 - val_output_3_loss: 1.3454 - val_output_0_acc: 0.4514 - val_output_1_acc: 0.4319 - val_output_2_acc: 0.4832 - val_output_3_acc: 0.4392\n",
      "Epoch 15/200\n",
      "2999/2999 [==============================] - 1s 469us/step - loss: 4.9228 - output_0_loss: 1.2266 - output_1_loss: 1.2272 - output_2_loss: 1.2365 - output_3_loss: 1.2324 - output_0_acc: 0.5068 - output_1_acc: 0.5082 - output_2_acc: 0.5075 - output_3_acc: 0.5015 - val_loss: 5.2970 - val_output_0_loss: 1.3513 - val_output_1_loss: 1.3097 - val_output_2_loss: 1.3129 - val_output_3_loss: 1.3231 - val_output_0_acc: 0.4105 - val_output_1_acc: 0.4667 - val_output_2_acc: 0.4361 - val_output_3_acc: 0.4538\n",
      "Epoch 16/200\n",
      "2999/2999 [==============================] - 1s 484us/step - loss: 4.7610 - output_0_loss: 1.1987 - output_1_loss: 1.1925 - output_2_loss: 1.1874 - output_3_loss: 1.1824 - output_0_acc: 0.5188 - output_1_acc: 0.5208 - output_2_acc: 0.5235 - output_3_acc: 0.5292 - val_loss: 5.0790 - val_output_0_loss: 1.2805 - val_output_1_loss: 1.2756 - val_output_2_loss: 1.2024 - val_output_3_loss: 1.3205 - val_output_0_acc: 0.4656 - val_output_1_acc: 0.4769 - val_output_2_acc: 0.5193 - val_output_3_acc: 0.4173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "2999/2999 [==============================] - 1s 460us/step - loss: 4.6341 - output_0_loss: 1.1578 - output_1_loss: 1.1691 - output_2_loss: 1.1493 - output_3_loss: 1.1580 - output_0_acc: 0.5405 - output_1_acc: 0.5385 - output_2_acc: 0.5472 - output_3_acc: 0.5372 - val_loss: 5.0767 - val_output_0_loss: 1.2514 - val_output_1_loss: 1.2168 - val_output_2_loss: 1.3238 - val_output_3_loss: 1.2847 - val_output_0_acc: 0.4951 - val_output_1_acc: 0.4942 - val_output_2_acc: 0.4310 - val_output_3_acc: 0.4709\n",
      "Epoch 18/200\n",
      "2999/2999 [==============================] - 1s 457us/step - loss: 4.5140 - output_0_loss: 1.1307 - output_1_loss: 1.1271 - output_2_loss: 1.1221 - output_3_loss: 1.1341 - output_0_acc: 0.5388 - output_1_acc: 0.5552 - output_2_acc: 0.5552 - output_3_acc: 0.5408 - val_loss: 4.8213 - val_output_0_loss: 1.1916 - val_output_1_loss: 1.1624 - val_output_2_loss: 1.1884 - val_output_3_loss: 1.2788 - val_output_0_acc: 0.5110 - val_output_1_acc: 0.4973 - val_output_2_acc: 0.4720 - val_output_3_acc: 0.4609\n",
      "Epoch 19/200\n",
      "2999/2999 [==============================] - 1s 424us/step - loss: 4.3824 - output_0_loss: 1.0981 - output_1_loss: 1.0938 - output_2_loss: 1.0959 - output_3_loss: 1.0946 - output_0_acc: 0.5645 - output_1_acc: 0.5622 - output_2_acc: 0.5625 - output_3_acc: 0.5622 - val_loss: 4.8106 - val_output_0_loss: 1.2825 - val_output_1_loss: 1.1854 - val_output_2_loss: 1.1497 - val_output_3_loss: 1.1929 - val_output_0_acc: 0.4299 - val_output_1_acc: 0.4934 - val_output_2_acc: 0.5365 - val_output_3_acc: 0.5308\n",
      "Epoch 20/200\n",
      "2999/2999 [==============================] - 1s 443us/step - loss: 4.2401 - output_0_loss: 1.0716 - output_1_loss: 1.0615 - output_2_loss: 1.0523 - output_3_loss: 1.0546 - output_0_acc: 0.5835 - output_1_acc: 0.5819 - output_2_acc: 0.5869 - output_3_acc: 0.5879 - val_loss: 4.6177 - val_output_0_loss: 1.2190 - val_output_1_loss: 1.1234 - val_output_2_loss: 1.1170 - val_output_3_loss: 1.1583 - val_output_0_acc: 0.4866 - val_output_1_acc: 0.5361 - val_output_2_acc: 0.5510 - val_output_3_acc: 0.5386\n",
      "Epoch 21/200\n",
      "2999/2999 [==============================] - 1s 457us/step - loss: 4.1583 - output_0_loss: 1.0474 - output_1_loss: 1.0485 - output_2_loss: 1.0307 - output_3_loss: 1.0317 - output_0_acc: 0.5845 - output_1_acc: 0.5805 - output_2_acc: 0.5869 - output_3_acc: 0.5855 - val_loss: 4.5542 - val_output_0_loss: 1.1305 - val_output_1_loss: 1.1732 - val_output_2_loss: 1.1760 - val_output_3_loss: 1.0745 - val_output_0_acc: 0.5229 - val_output_1_acc: 0.5221 - val_output_2_acc: 0.4657 - val_output_3_acc: 0.5757\n",
      "Epoch 22/200\n",
      "2999/2999 [==============================] - 1s 448us/step - loss: 4.0186 - output_0_loss: 1.0109 - output_1_loss: 1.0104 - output_2_loss: 0.9926 - output_3_loss: 1.0047 - output_0_acc: 0.5885 - output_1_acc: 0.6025 - output_2_acc: 0.6025 - output_3_acc: 0.5969 - val_loss: 4.6176 - val_output_0_loss: 1.1115 - val_output_1_loss: 1.1336 - val_output_2_loss: 1.2330 - val_output_3_loss: 1.1395 - val_output_0_acc: 0.5442 - val_output_1_acc: 0.5157 - val_output_2_acc: 0.4870 - val_output_3_acc: 0.5254\n",
      "Epoch 23/200\n",
      "2999/2999 [==============================] - 1s 432us/step - loss: 3.9525 - output_0_loss: 0.9932 - output_1_loss: 0.9919 - output_2_loss: 0.9853 - output_3_loss: 0.9821 - output_0_acc: 0.6005 - output_1_acc: 0.5962 - output_2_acc: 0.6032 - output_3_acc: 0.6065 - val_loss: 4.4718 - val_output_0_loss: 1.1391 - val_output_1_loss: 1.1065 - val_output_2_loss: 1.0876 - val_output_3_loss: 1.1385 - val_output_0_acc: 0.5432 - val_output_1_acc: 0.5391 - val_output_2_acc: 0.5461 - val_output_3_acc: 0.5245\n",
      "Epoch 24/200\n",
      "2999/2999 [==============================] - 1s 421us/step - loss: 3.8438 - output_0_loss: 0.9658 - output_1_loss: 0.9663 - output_2_loss: 0.9556 - output_3_loss: 0.9561 - output_0_acc: 0.6219 - output_1_acc: 0.6165 - output_2_acc: 0.6089 - output_3_acc: 0.6299 - val_loss: 4.1971 - val_output_0_loss: 1.0851 - val_output_1_loss: 1.0872 - val_output_2_loss: 0.9891 - val_output_3_loss: 1.0358 - val_output_0_acc: 0.5351 - val_output_1_acc: 0.5743 - val_output_2_acc: 0.5727 - val_output_3_acc: 0.5770\n",
      "Epoch 25/200\n",
      "2999/2999 [==============================] - 1s 442us/step - loss: 3.7496 - output_0_loss: 0.9391 - output_1_loss: 0.9463 - output_2_loss: 0.9282 - output_3_loss: 0.9360 - output_0_acc: 0.6275 - output_1_acc: 0.6259 - output_2_acc: 0.6272 - output_3_acc: 0.6362 - val_loss: 4.2463 - val_output_0_loss: 1.1328 - val_output_1_loss: 1.0468 - val_output_2_loss: 1.0451 - val_output_3_loss: 1.0217 - val_output_0_acc: 0.5402 - val_output_1_acc: 0.5838 - val_output_2_acc: 0.5640 - val_output_3_acc: 0.5828\n",
      "Epoch 26/200\n",
      "2999/2999 [==============================] - 1s 436us/step - loss: 3.6687 - output_0_loss: 0.9140 - output_1_loss: 0.9241 - output_2_loss: 0.9226 - output_3_loss: 0.9080 - output_0_acc: 0.6349 - output_1_acc: 0.6329 - output_2_acc: 0.6242 - output_3_acc: 0.6469 - val_loss: 4.1107 - val_output_0_loss: 1.0212 - val_output_1_loss: 0.9802 - val_output_2_loss: 0.9675 - val_output_3_loss: 1.1418 - val_output_0_acc: 0.5967 - val_output_1_acc: 0.6021 - val_output_2_acc: 0.5893 - val_output_3_acc: 0.5169\n",
      "Epoch 27/200\n",
      "2999/2999 [==============================] - 1s 428us/step - loss: 3.5762 - output_0_loss: 0.9020 - output_1_loss: 0.8923 - output_2_loss: 0.8835 - output_3_loss: 0.8984 - output_0_acc: 0.6395 - output_1_acc: 0.6419 - output_2_acc: 0.6529 - output_3_acc: 0.6445 - val_loss: 4.1597 - val_output_0_loss: 0.9627 - val_output_1_loss: 1.0157 - val_output_2_loss: 1.1454 - val_output_3_loss: 1.0360 - val_output_0_acc: 0.6304 - val_output_1_acc: 0.5949 - val_output_2_acc: 0.4908 - val_output_3_acc: 0.5965\n",
      "Epoch 28/200\n",
      "2999/2999 [==============================] - 1s 395us/step - loss: 3.5064 - output_0_loss: 0.8834 - output_1_loss: 0.8788 - output_2_loss: 0.8736 - output_3_loss: 0.8706 - output_0_acc: 0.6495 - output_1_acc: 0.6516 - output_2_acc: 0.6532 - output_3_acc: 0.6559 - val_loss: 3.8780 - val_output_0_loss: 0.9467 - val_output_1_loss: 0.9530 - val_output_2_loss: 0.9915 - val_output_3_loss: 0.9868 - val_output_0_acc: 0.6227 - val_output_1_acc: 0.6173 - val_output_2_acc: 0.5506 - val_output_3_acc: 0.5665\n",
      "Epoch 29/200\n",
      "2999/2999 [==============================] - 1s 427us/step - loss: 3.4055 - output_0_loss: 0.8613 - output_1_loss: 0.8509 - output_2_loss: 0.8467 - output_3_loss: 0.8466 - output_0_acc: 0.6666 - output_1_acc: 0.6719 - output_2_acc: 0.6719 - output_3_acc: 0.6699 - val_loss: 3.8051 - val_output_0_loss: 0.9771 - val_output_1_loss: 0.9315 - val_output_2_loss: 1.0274 - val_output_3_loss: 0.8691 - val_output_0_acc: 0.5903 - val_output_1_acc: 0.6062 - val_output_2_acc: 0.5746 - val_output_3_acc: 0.6535\n",
      "Epoch 30/200\n",
      "2999/2999 [==============================] - 1s 426us/step - loss: 3.3185 - output_0_loss: 0.8302 - output_1_loss: 0.8355 - output_2_loss: 0.8254 - output_3_loss: 0.8273 - output_0_acc: 0.6842 - output_1_acc: 0.6742 - output_2_acc: 0.6832 - output_3_acc: 0.6759 - val_loss: 3.4945 - val_output_0_loss: 0.8856 - val_output_1_loss: 0.9038 - val_output_2_loss: 0.8230 - val_output_3_loss: 0.8822 - val_output_0_acc: 0.6483 - val_output_1_acc: 0.6072 - val_output_2_acc: 0.7125 - val_output_3_acc: 0.6530\n",
      "Epoch 31/200\n",
      "2999/2999 [==============================] - 1s 439us/step - loss: 3.2674 - output_0_loss: 0.8243 - output_1_loss: 0.8183 - output_2_loss: 0.8060 - output_3_loss: 0.8189 - output_0_acc: 0.6816 - output_1_acc: 0.6812 - output_2_acc: 0.6902 - output_3_acc: 0.6852 - val_loss: 3.6036 - val_output_0_loss: 0.9785 - val_output_1_loss: 0.8653 - val_output_2_loss: 0.9015 - val_output_3_loss: 0.8583 - val_output_0_acc: 0.5759 - val_output_1_acc: 0.6493 - val_output_2_acc: 0.6270 - val_output_3_acc: 0.6447\n",
      "Epoch 32/200\n",
      "2999/2999 [==============================] - 1s 409us/step - loss: 3.1903 - output_0_loss: 0.8089 - output_1_loss: 0.7971 - output_2_loss: 0.7928 - output_3_loss: 0.7915 - output_0_acc: 0.6882 - output_1_acc: 0.6849 - output_2_acc: 0.6972 - output_3_acc: 0.6946 - val_loss: 3.6554 - val_output_0_loss: 0.9071 - val_output_1_loss: 0.8925 - val_output_2_loss: 0.8716 - val_output_3_loss: 0.9843 - val_output_0_acc: 0.6654 - val_output_1_acc: 0.5886 - val_output_2_acc: 0.6591 - val_output_3_acc: 0.5494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "2999/2999 [==============================] - 1s 394us/step - loss: 3.1138 - output_0_loss: 0.7905 - output_1_loss: 0.7742 - output_2_loss: 0.7768 - output_3_loss: 0.7722 - output_0_acc: 0.7002 - output_1_acc: 0.7099 - output_2_acc: 0.7036 - output_3_acc: 0.7039 - val_loss: 3.4972 - val_output_0_loss: 0.9167 - val_output_1_loss: 0.8833 - val_output_2_loss: 0.8318 - val_output_3_loss: 0.8654 - val_output_0_acc: 0.6206 - val_output_1_acc: 0.6158 - val_output_2_acc: 0.6789 - val_output_3_acc: 0.6255\n",
      "Epoch 34/200\n",
      "2999/2999 [==============================] - 1s 405us/step - loss: 3.0404 - output_0_loss: 0.7672 - output_1_loss: 0.7601 - output_2_loss: 0.7540 - output_3_loss: 0.7591 - output_0_acc: 0.7152 - output_1_acc: 0.7089 - output_2_acc: 0.7119 - output_3_acc: 0.7139 - val_loss: 3.3391 - val_output_0_loss: 0.8708 - val_output_1_loss: 0.8320 - val_output_2_loss: 0.8526 - val_output_3_loss: 0.7837 - val_output_0_acc: 0.6441 - val_output_1_acc: 0.6497 - val_output_2_acc: 0.6376 - val_output_3_acc: 0.7084\n",
      "Epoch 35/200\n",
      "2999/2999 [==============================] - 1s 413us/step - loss: 2.9790 - output_0_loss: 0.7596 - output_1_loss: 0.7387 - output_2_loss: 0.7297 - output_3_loss: 0.7510 - output_0_acc: 0.7092 - output_1_acc: 0.7229 - output_2_acc: 0.7289 - output_3_acc: 0.7106 - val_loss: 3.3034 - val_output_0_loss: 0.8362 - val_output_1_loss: 0.8489 - val_output_2_loss: 0.8185 - val_output_3_loss: 0.7999 - val_output_0_acc: 0.6637 - val_output_1_acc: 0.6089 - val_output_2_acc: 0.6978 - val_output_3_acc: 0.6897\n",
      "Epoch 36/200\n",
      "2999/2999 [==============================] - 1s 409us/step - loss: 2.9042 - output_0_loss: 0.7408 - output_1_loss: 0.7268 - output_2_loss: 0.7153 - output_3_loss: 0.7212 - output_0_acc: 0.7116 - output_1_acc: 0.7332 - output_2_acc: 0.7359 - output_3_acc: 0.7289 - val_loss: 3.3158 - val_output_0_loss: 0.8540 - val_output_1_loss: 0.8153 - val_output_2_loss: 0.8139 - val_output_3_loss: 0.8326 - val_output_0_acc: 0.6739 - val_output_1_acc: 0.6842 - val_output_2_acc: 0.6424 - val_output_3_acc: 0.6505\n",
      "Epoch 37/200\n",
      "2999/2999 [==============================] - 1s 428us/step - loss: 2.8379 - output_0_loss: 0.7211 - output_1_loss: 0.7029 - output_2_loss: 0.7014 - output_3_loss: 0.7125 - output_0_acc: 0.7316 - output_1_acc: 0.7376 - output_2_acc: 0.7446 - output_3_acc: 0.7339 - val_loss: 3.3857 - val_output_0_loss: 0.8272 - val_output_1_loss: 0.8129 - val_output_2_loss: 0.8965 - val_output_3_loss: 0.8491 - val_output_0_acc: 0.6946 - val_output_1_acc: 0.6748 - val_output_2_acc: 0.6085 - val_output_3_acc: 0.6848\n",
      "Epoch 38/200\n",
      "2999/2999 [==============================] - 1s 425us/step - loss: 2.7814 - output_0_loss: 0.7116 - output_1_loss: 0.6981 - output_2_loss: 0.6841 - output_3_loss: 0.6876 - output_0_acc: 0.7332 - output_1_acc: 0.7406 - output_2_acc: 0.7469 - output_3_acc: 0.7496 - val_loss: 3.2128 - val_output_0_loss: 0.8835 - val_output_1_loss: 0.7801 - val_output_2_loss: 0.7826 - val_output_3_loss: 0.7666 - val_output_0_acc: 0.5968 - val_output_1_acc: 0.6921 - val_output_2_acc: 0.6839 - val_output_3_acc: 0.7026\n",
      "Epoch 39/200\n",
      "2999/2999 [==============================] - 1s 418us/step - loss: 2.7215 - output_0_loss: 0.7011 - output_1_loss: 0.6755 - output_2_loss: 0.6653 - output_3_loss: 0.6796 - output_0_acc: 0.7366 - output_1_acc: 0.7586 - output_2_acc: 0.7506 - output_3_acc: 0.7479 - val_loss: 3.2092 - val_output_0_loss: 0.8050 - val_output_1_loss: 0.8177 - val_output_2_loss: 0.7891 - val_output_3_loss: 0.7974 - val_output_0_acc: 0.6784 - val_output_1_acc: 0.6252 - val_output_2_acc: 0.6901 - val_output_3_acc: 0.6811\n",
      "Epoch 40/200\n",
      "2999/2999 [==============================] - 1s 438us/step - loss: 2.6689 - output_0_loss: 0.6748 - output_1_loss: 0.6686 - output_2_loss: 0.6697 - output_3_loss: 0.6558 - output_0_acc: 0.7456 - output_1_acc: 0.7526 - output_2_acc: 0.7549 - output_3_acc: 0.7536 - val_loss: 3.0168 - val_output_0_loss: 0.7854 - val_output_1_loss: 0.7350 - val_output_2_loss: 0.7603 - val_output_3_loss: 0.7360 - val_output_0_acc: 0.6850 - val_output_1_acc: 0.7075 - val_output_2_acc: 0.6925 - val_output_3_acc: 0.7324\n",
      "Epoch 41/200\n",
      "2999/2999 [==============================] - 1s 392us/step - loss: 2.6201 - output_0_loss: 0.6711 - output_1_loss: 0.6499 - output_2_loss: 0.6505 - output_3_loss: 0.6487 - output_0_acc: 0.7503 - output_1_acc: 0.7703 - output_2_acc: 0.7676 - output_3_acc: 0.7696 - val_loss: 3.0231 - val_output_0_loss: 0.7945 - val_output_1_loss: 0.7548 - val_output_2_loss: 0.7172 - val_output_3_loss: 0.7565 - val_output_0_acc: 0.6603 - val_output_1_acc: 0.6999 - val_output_2_acc: 0.7141 - val_output_3_acc: 0.7084\n",
      "Epoch 42/200\n",
      "2999/2999 [==============================] - 1s 386us/step - loss: 2.5378 - output_0_loss: 0.6514 - output_1_loss: 0.6286 - output_2_loss: 0.6263 - output_3_loss: 0.6315 - output_0_acc: 0.7649 - output_1_acc: 0.7739 - output_2_acc: 0.7739 - output_3_acc: 0.7769 - val_loss: 2.9824 - val_output_0_loss: 0.7603 - val_output_1_loss: 0.7568 - val_output_2_loss: 0.7057 - val_output_3_loss: 0.7596 - val_output_0_acc: 0.7050 - val_output_1_acc: 0.6814 - val_output_2_acc: 0.7106 - val_output_3_acc: 0.6700\n",
      "Epoch 43/200\n",
      "2999/2999 [==============================] - 1s 413us/step - loss: 2.4923 - output_0_loss: 0.6298 - output_1_loss: 0.6240 - output_2_loss: 0.6124 - output_3_loss: 0.6261 - output_0_acc: 0.7753 - output_1_acc: 0.7746 - output_2_acc: 0.7806 - output_3_acc: 0.7759 - val_loss: 2.9665 - val_output_0_loss: 0.7602 - val_output_1_loss: 0.7485 - val_output_2_loss: 0.7427 - val_output_3_loss: 0.7152 - val_output_0_acc: 0.6956 - val_output_1_acc: 0.6716 - val_output_2_acc: 0.6682 - val_output_3_acc: 0.6947\n",
      "Epoch 44/200\n",
      "2999/2999 [==============================] - 1s 451us/step - loss: 2.4622 - output_0_loss: 0.6264 - output_1_loss: 0.6137 - output_2_loss: 0.6084 - output_3_loss: 0.6137 - output_0_acc: 0.7743 - output_1_acc: 0.7833 - output_2_acc: 0.7793 - output_3_acc: 0.7843 - val_loss: 2.9963 - val_output_0_loss: 0.7810 - val_output_1_loss: 0.8146 - val_output_2_loss: 0.6730 - val_output_3_loss: 0.7277 - val_output_0_acc: 0.6870 - val_output_1_acc: 0.6369 - val_output_2_acc: 0.7468 - val_output_3_acc: 0.7136\n",
      "Epoch 45/200\n",
      "2999/2999 [==============================] - 1s 439us/step - loss: 2.3997 - output_0_loss: 0.6165 - output_1_loss: 0.6030 - output_2_loss: 0.5862 - output_3_loss: 0.5940 - output_0_acc: 0.7736 - output_1_acc: 0.7979 - output_2_acc: 0.8036 - output_3_acc: 0.7933 - val_loss: 2.7738 - val_output_0_loss: 0.6912 - val_output_1_loss: 0.6307 - val_output_2_loss: 0.7431 - val_output_3_loss: 0.7088 - val_output_0_acc: 0.7418 - val_output_1_acc: 0.7756 - val_output_2_acc: 0.6550 - val_output_3_acc: 0.7231\n",
      "Epoch 46/200\n",
      "2999/2999 [==============================] - 1s 458us/step - loss: 2.3421 - output_0_loss: 0.6010 - output_1_loss: 0.5833 - output_2_loss: 0.5764 - output_3_loss: 0.5814 - output_0_acc: 0.7913 - output_1_acc: 0.7949 - output_2_acc: 0.7946 - output_3_acc: 0.8036 - val_loss: 2.9185 - val_output_0_loss: 0.7896 - val_output_1_loss: 0.7107 - val_output_2_loss: 0.7152 - val_output_3_loss: 0.7030 - val_output_0_acc: 0.6383 - val_output_1_acc: 0.7230 - val_output_2_acc: 0.6600 - val_output_3_acc: 0.7403\n",
      "Epoch 47/200\n",
      "2999/2999 [==============================] - 1s 448us/step - loss: 2.3072 - output_0_loss: 0.5863 - output_1_loss: 0.5758 - output_2_loss: 0.5716 - output_3_loss: 0.5734 - output_0_acc: 0.7959 - output_1_acc: 0.7953 - output_2_acc: 0.8069 - output_3_acc: 0.8109 - val_loss: 2.7262 - val_output_0_loss: 0.7577 - val_output_1_loss: 0.6891 - val_output_2_loss: 0.6508 - val_output_3_loss: 0.6286 - val_output_0_acc: 0.6946 - val_output_1_acc: 0.7150 - val_output_2_acc: 0.7517 - val_output_3_acc: 0.7618\n",
      "Epoch 48/200\n",
      "2999/2999 [==============================] - 1s 416us/step - loss: 2.2610 - output_0_loss: 0.5827 - output_1_loss: 0.5582 - output_2_loss: 0.5537 - output_3_loss: 0.5663 - output_0_acc: 0.7936 - output_1_acc: 0.8113 - output_2_acc: 0.8183 - output_3_acc: 0.8089 - val_loss: 2.6831 - val_output_0_loss: 0.6520 - val_output_1_loss: 0.7408 - val_output_2_loss: 0.6265 - val_output_3_loss: 0.6640 - val_output_0_acc: 0.7758 - val_output_1_acc: 0.6466 - val_output_2_acc: 0.7405 - val_output_3_acc: 0.7268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "2999/2999 [==============================] - 1s 433us/step - loss: 2.2084 - output_0_loss: 0.5608 - output_1_loss: 0.5611 - output_2_loss: 0.5421 - output_3_loss: 0.5444 - output_0_acc: 0.8089 - output_1_acc: 0.8163 - output_2_acc: 0.8246 - output_3_acc: 0.8206 - val_loss: 2.6729 - val_output_0_loss: 0.6936 - val_output_1_loss: 0.6630 - val_output_2_loss: 0.6104 - val_output_3_loss: 0.7060 - val_output_0_acc: 0.7278 - val_output_1_acc: 0.7247 - val_output_2_acc: 0.7726 - val_output_3_acc: 0.7348\n",
      "Epoch 50/200\n",
      "2999/2999 [==============================] - 1s 403us/step - loss: 2.1410 - output_0_loss: 0.5529 - output_1_loss: 0.5378 - output_2_loss: 0.5271 - output_3_loss: 0.5231 - output_0_acc: 0.8076 - output_1_acc: 0.8229 - output_2_acc: 0.8343 - output_3_acc: 0.8289 - val_loss: 2.7782 - val_output_0_loss: 0.7138 - val_output_1_loss: 0.7998 - val_output_2_loss: 0.6284 - val_output_3_loss: 0.6363 - val_output_0_acc: 0.6984 - val_output_1_acc: 0.6216 - val_output_2_acc: 0.7733 - val_output_3_acc: 0.7454\n",
      "Epoch 51/200\n",
      "2999/2999 [==============================] - 1s 408us/step - loss: 2.1053 - output_0_loss: 0.5459 - output_1_loss: 0.5258 - output_2_loss: 0.5098 - output_3_loss: 0.5237 - output_0_acc: 0.8173 - output_1_acc: 0.8309 - output_2_acc: 0.8333 - output_3_acc: 0.8316 - val_loss: 2.4352 - val_output_0_loss: 0.6574 - val_output_1_loss: 0.5750 - val_output_2_loss: 0.5505 - val_output_3_loss: 0.6523 - val_output_0_acc: 0.7542 - val_output_1_acc: 0.8030 - val_output_2_acc: 0.8067 - val_output_3_acc: 0.7315\n",
      "Epoch 52/200\n",
      "2999/2999 [==============================] - 1s 406us/step - loss: 2.0745 - output_0_loss: 0.5386 - output_1_loss: 0.5119 - output_2_loss: 0.5071 - output_3_loss: 0.5168 - output_0_acc: 0.8173 - output_1_acc: 0.8359 - output_2_acc: 0.8419 - output_3_acc: 0.8323 - val_loss: 2.6561 - val_output_0_loss: 0.6767 - val_output_1_loss: 0.6735 - val_output_2_loss: 0.6868 - val_output_3_loss: 0.6190 - val_output_0_acc: 0.7516 - val_output_1_acc: 0.7272 - val_output_2_acc: 0.7043 - val_output_3_acc: 0.7549\n",
      "Epoch 53/200\n",
      "2999/2999 [==============================] - 1s 429us/step - loss: 2.0195 - output_0_loss: 0.5213 - output_1_loss: 0.5028 - output_2_loss: 0.4949 - output_3_loss: 0.5005 - output_0_acc: 0.8206 - output_1_acc: 0.8363 - output_2_acc: 0.8409 - output_3_acc: 0.8333 - val_loss: 2.4792 - val_output_0_loss: 0.6505 - val_output_1_loss: 0.5764 - val_output_2_loss: 0.6456 - val_output_3_loss: 0.6067 - val_output_0_acc: 0.7083 - val_output_1_acc: 0.7830 - val_output_2_acc: 0.7089 - val_output_3_acc: 0.7634\n",
      "Epoch 54/200\n",
      "2999/2999 [==============================] - 1s 466us/step - loss: 1.9766 - output_0_loss: 0.5086 - output_1_loss: 0.4880 - output_2_loss: 0.4958 - output_3_loss: 0.4842 - output_0_acc: 0.8333 - output_1_acc: 0.8523 - output_2_acc: 0.8476 - output_3_acc: 0.8493 - val_loss: 2.4851 - val_output_0_loss: 0.5954 - val_output_1_loss: 0.6534 - val_output_2_loss: 0.5873 - val_output_3_loss: 0.6490 - val_output_0_acc: 0.8029 - val_output_1_acc: 0.7490 - val_output_2_acc: 0.8043 - val_output_3_acc: 0.7562\n",
      "Epoch 55/200\n",
      "2999/2999 [==============================] - 1s 442us/step - loss: 1.9412 - output_0_loss: 0.4985 - output_1_loss: 0.4907 - output_2_loss: 0.4771 - output_3_loss: 0.4750 - output_0_acc: 0.8346 - output_1_acc: 0.8453 - output_2_acc: 0.8560 - output_3_acc: 0.8603 - val_loss: 2.3583 - val_output_0_loss: 0.5935 - val_output_1_loss: 0.5719 - val_output_2_loss: 0.5462 - val_output_3_loss: 0.6466 - val_output_0_acc: 0.7934 - val_output_1_acc: 0.7869 - val_output_2_acc: 0.8106 - val_output_3_acc: 0.7165\n",
      "Epoch 56/200\n",
      "2999/2999 [==============================] - 1s 436us/step - loss: 1.8789 - output_0_loss: 0.4879 - output_1_loss: 0.4661 - output_2_loss: 0.4570 - output_3_loss: 0.4679 - output_0_acc: 0.8476 - output_1_acc: 0.8556 - output_2_acc: 0.8666 - output_3_acc: 0.8666 - val_loss: 2.4451 - val_output_0_loss: 0.6689 - val_output_1_loss: 0.5867 - val_output_2_loss: 0.6284 - val_output_3_loss: 0.5611 - val_output_0_acc: 0.7243 - val_output_1_acc: 0.7598 - val_output_2_acc: 0.7367 - val_output_3_acc: 0.7916\n",
      "Epoch 57/200\n",
      "2999/2999 [==============================] - 1s 431us/step - loss: 1.8587 - output_0_loss: 0.4794 - output_1_loss: 0.4597 - output_2_loss: 0.4615 - output_3_loss: 0.4580 - output_0_acc: 0.8413 - output_1_acc: 0.8583 - output_2_acc: 0.8540 - output_3_acc: 0.8616 - val_loss: 2.3474 - val_output_0_loss: 0.6820 - val_output_1_loss: 0.5708 - val_output_2_loss: 0.5335 - val_output_3_loss: 0.5612 - val_output_0_acc: 0.6886 - val_output_1_acc: 0.7947 - val_output_2_acc: 0.8141 - val_output_3_acc: 0.7969\n",
      "Epoch 58/200\n",
      "2999/2999 [==============================] - 1s 430us/step - loss: 1.8130 - output_0_loss: 0.4708 - output_1_loss: 0.4465 - output_2_loss: 0.4411 - output_3_loss: 0.4546 - output_0_acc: 0.8443 - output_1_acc: 0.8596 - output_2_acc: 0.8703 - output_3_acc: 0.8633 - val_loss: 2.2285 - val_output_0_loss: 0.6168 - val_output_1_loss: 0.5677 - val_output_2_loss: 0.5130 - val_output_3_loss: 0.5310 - val_output_0_acc: 0.7590 - val_output_1_acc: 0.7751 - val_output_2_acc: 0.8326 - val_output_3_acc: 0.8079\n",
      "Epoch 59/200\n",
      "2999/2999 [==============================] - 1s 428us/step - loss: 1.7638 - output_0_loss: 0.4623 - output_1_loss: 0.4355 - output_2_loss: 0.4299 - output_3_loss: 0.4362 - output_0_acc: 0.8603 - output_1_acc: 0.8670 - output_2_acc: 0.8696 - output_3_acc: 0.8733 - val_loss: 2.1579 - val_output_0_loss: 0.5801 - val_output_1_loss: 0.5710 - val_output_2_loss: 0.4866 - val_output_3_loss: 0.5202 - val_output_0_acc: 0.7699 - val_output_1_acc: 0.7872 - val_output_2_acc: 0.8498 - val_output_3_acc: 0.8378\n",
      "Epoch 60/200\n",
      "2999/2999 [==============================] - 1s 442us/step - loss: 1.7403 - output_0_loss: 0.4465 - output_1_loss: 0.4357 - output_2_loss: 0.4286 - output_3_loss: 0.4295 - output_0_acc: 0.8683 - output_1_acc: 0.8760 - output_2_acc: 0.8813 - output_3_acc: 0.8806 - val_loss: 2.2031 - val_output_0_loss: 0.5818 - val_output_1_loss: 0.5254 - val_output_2_loss: 0.5008 - val_output_3_loss: 0.5952 - val_output_0_acc: 0.7724 - val_output_1_acc: 0.8106 - val_output_2_acc: 0.8346 - val_output_3_acc: 0.7617\n",
      "Epoch 61/200\n",
      "2999/2999 [==============================] - 1s 443us/step - loss: 1.6933 - output_0_loss: 0.4460 - output_1_loss: 0.4233 - output_2_loss: 0.4104 - output_3_loss: 0.4137 - output_0_acc: 0.8550 - output_1_acc: 0.8793 - output_2_acc: 0.8853 - output_3_acc: 0.8820 - val_loss: 2.1479 - val_output_0_loss: 0.5886 - val_output_1_loss: 0.5163 - val_output_2_loss: 0.4977 - val_output_3_loss: 0.5453 - val_output_0_acc: 0.7642 - val_output_1_acc: 0.8221 - val_output_2_acc: 0.8220 - val_output_3_acc: 0.7799\n",
      "Epoch 62/200\n",
      "2999/2999 [==============================] - 1s 434us/step - loss: 1.6553 - output_0_loss: 0.4318 - output_1_loss: 0.4118 - output_2_loss: 0.4008 - output_3_loss: 0.4109 - output_0_acc: 0.8693 - output_1_acc: 0.8786 - output_2_acc: 0.8873 - output_3_acc: 0.8840 - val_loss: 2.0396 - val_output_0_loss: 0.6483 - val_output_1_loss: 0.4470 - val_output_2_loss: 0.4724 - val_output_3_loss: 0.4719 - val_output_0_acc: 0.7148 - val_output_1_acc: 0.8884 - val_output_2_acc: 0.8491 - val_output_3_acc: 0.8560\n",
      "Epoch 63/200\n",
      "2999/2999 [==============================] - 1s 420us/step - loss: 1.6296 - output_0_loss: 0.4179 - output_1_loss: 0.4101 - output_2_loss: 0.3992 - output_3_loss: 0.4023 - output_0_acc: 0.8783 - output_1_acc: 0.8860 - output_2_acc: 0.8940 - output_3_acc: 0.8920 - val_loss: 2.1235 - val_output_0_loss: 0.5191 - val_output_1_loss: 0.5306 - val_output_2_loss: 0.4989 - val_output_3_loss: 0.5749 - val_output_0_acc: 0.8122 - val_output_1_acc: 0.7956 - val_output_2_acc: 0.8164 - val_output_3_acc: 0.7485\n",
      "Epoch 64/200\n",
      "2999/2999 [==============================] - 1s 420us/step - loss: 1.5849 - output_0_loss: 0.4133 - output_1_loss: 0.3975 - output_2_loss: 0.3785 - output_3_loss: 0.3956 - output_0_acc: 0.8733 - output_1_acc: 0.8860 - output_2_acc: 0.9000 - output_3_acc: 0.8966 - val_loss: 1.9857 - val_output_0_loss: 0.4886 - val_output_1_loss: 0.5588 - val_output_2_loss: 0.4790 - val_output_3_loss: 0.4594 - val_output_0_acc: 0.8374 - val_output_1_acc: 0.7870 - val_output_2_acc: 0.8399 - val_output_3_acc: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200\n",
      "2999/2999 [==============================] - 1s 436us/step - loss: 1.5610 - output_0_loss: 0.4124 - output_1_loss: 0.3891 - output_2_loss: 0.3781 - output_3_loss: 0.3813 - output_0_acc: 0.8776 - output_1_acc: 0.8920 - output_2_acc: 0.8960 - output_3_acc: 0.9006 - val_loss: 1.9816 - val_output_0_loss: 0.5295 - val_output_1_loss: 0.4782 - val_output_2_loss: 0.4450 - val_output_3_loss: 0.5288 - val_output_0_acc: 0.8046 - val_output_1_acc: 0.8399 - val_output_2_acc: 0.8531 - val_output_3_acc: 0.7769\n",
      "Epoch 66/200\n",
      "2999/2999 [==============================] - 1s 442us/step - loss: 1.5370 - output_0_loss: 0.4015 - output_1_loss: 0.3876 - output_2_loss: 0.3742 - output_3_loss: 0.3737 - output_0_acc: 0.8870 - output_1_acc: 0.8866 - output_2_acc: 0.9013 - output_3_acc: 0.9006 - val_loss: 1.8029 - val_output_0_loss: 0.4798 - val_output_1_loss: 0.4415 - val_output_2_loss: 0.3887 - val_output_3_loss: 0.4928 - val_output_0_acc: 0.8475 - val_output_1_acc: 0.8651 - val_output_2_acc: 0.9123 - val_output_3_acc: 0.8204\n",
      "Epoch 67/200\n",
      "2999/2999 [==============================] - 1s 460us/step - loss: 1.4862 - output_0_loss: 0.3936 - output_1_loss: 0.3726 - output_2_loss: 0.3515 - output_3_loss: 0.3685 - output_0_acc: 0.8866 - output_1_acc: 0.9026 - output_2_acc: 0.9076 - output_3_acc: 0.9020 - val_loss: 1.9004 - val_output_0_loss: 0.5228 - val_output_1_loss: 0.4871 - val_output_2_loss: 0.4686 - val_output_3_loss: 0.4220 - val_output_0_acc: 0.7940 - val_output_1_acc: 0.8179 - val_output_2_acc: 0.8166 - val_output_3_acc: 0.8807\n",
      "Epoch 68/200\n",
      "2999/2999 [==============================] - 1s 428us/step - loss: 1.4380 - output_0_loss: 0.3791 - output_1_loss: 0.3553 - output_2_loss: 0.3478 - output_3_loss: 0.3558 - output_0_acc: 0.9013 - output_1_acc: 0.9106 - output_2_acc: 0.9143 - output_3_acc: 0.9176 - val_loss: 1.9108 - val_output_0_loss: 0.5710 - val_output_1_loss: 0.4347 - val_output_2_loss: 0.4216 - val_output_3_loss: 0.4835 - val_output_0_acc: 0.7556 - val_output_1_acc: 0.8700 - val_output_2_acc: 0.8694 - val_output_3_acc: 0.8279\n",
      "Epoch 69/200\n",
      "2999/2999 [==============================] - 1s 409us/step - loss: 1.4297 - output_0_loss: 0.3792 - output_1_loss: 0.3515 - output_2_loss: 0.3507 - output_3_loss: 0.3482 - output_0_acc: 0.8940 - output_1_acc: 0.9096 - output_2_acc: 0.9106 - output_3_acc: 0.9173 - val_loss: 1.6949 - val_output_0_loss: 0.4259 - val_output_1_loss: 0.4084 - val_output_2_loss: 0.4231 - val_output_3_loss: 0.4375 - val_output_0_acc: 0.8843 - val_output_1_acc: 0.8876 - val_output_2_acc: 0.8481 - val_output_3_acc: 0.8487\n",
      "Epoch 70/200\n",
      "2999/2999 [==============================] - 1s 415us/step - loss: 1.3939 - output_0_loss: 0.3603 - output_1_loss: 0.3503 - output_2_loss: 0.3345 - output_3_loss: 0.3488 - output_0_acc: 0.9016 - output_1_acc: 0.9056 - output_2_acc: 0.9236 - output_3_acc: 0.9156 - val_loss: 1.8494 - val_output_0_loss: 0.4609 - val_output_1_loss: 0.4194 - val_output_2_loss: 0.5437 - val_output_3_loss: 0.4254 - val_output_0_acc: 0.8429 - val_output_1_acc: 0.8729 - val_output_2_acc: 0.7545 - val_output_3_acc: 0.8703\n",
      "Epoch 71/200\n",
      "2999/2999 [==============================] - 1s 407us/step - loss: 1.3584 - output_0_loss: 0.3587 - output_1_loss: 0.3445 - output_2_loss: 0.3251 - output_3_loss: 0.3301 - output_0_acc: 0.9000 - output_1_acc: 0.9096 - output_2_acc: 0.9196 - output_3_acc: 0.9223 - val_loss: 1.7028 - val_output_0_loss: 0.4697 - val_output_1_loss: 0.4418 - val_output_2_loss: 0.3682 - val_output_3_loss: 0.4232 - val_output_0_acc: 0.8203 - val_output_1_acc: 0.8454 - val_output_2_acc: 0.9043 - val_output_3_acc: 0.8432\n",
      "Epoch 72/200\n",
      "2999/2999 [==============================] - 1s 392us/step - loss: 1.3314 - output_0_loss: 0.3531 - output_1_loss: 0.3260 - output_2_loss: 0.3231 - output_3_loss: 0.3291 - output_0_acc: 0.9033 - output_1_acc: 0.9173 - output_2_acc: 0.9223 - output_3_acc: 0.9203 - val_loss: 1.7375 - val_output_0_loss: 0.5020 - val_output_1_loss: 0.4287 - val_output_2_loss: 0.4075 - val_output_3_loss: 0.3994 - val_output_0_acc: 0.8237 - val_output_1_acc: 0.8582 - val_output_2_acc: 0.8766 - val_output_3_acc: 0.8854\n",
      "Epoch 73/200\n",
      "2999/2999 [==============================] - 1s 406us/step - loss: 1.3052 - output_0_loss: 0.3426 - output_1_loss: 0.3216 - output_2_loss: 0.3168 - output_3_loss: 0.3242 - output_0_acc: 0.9113 - output_1_acc: 0.9183 - output_2_acc: 0.9210 - output_3_acc: 0.9243 - val_loss: 1.6683 - val_output_0_loss: 0.4795 - val_output_1_loss: 0.4538 - val_output_2_loss: 0.3560 - val_output_3_loss: 0.3788 - val_output_0_acc: 0.8154 - val_output_1_acc: 0.8359 - val_output_2_acc: 0.9115 - val_output_3_acc: 0.9017\n",
      "Epoch 74/200\n",
      "2999/2999 [==============================] - 1s 430us/step - loss: 1.2614 - output_0_loss: 0.3425 - output_1_loss: 0.3122 - output_2_loss: 0.2976 - output_3_loss: 0.3090 - output_0_acc: 0.9100 - output_1_acc: 0.9263 - output_2_acc: 0.9356 - output_3_acc: 0.9283 - val_loss: 1.4871 - val_output_0_loss: 0.3865 - val_output_1_loss: 0.4086 - val_output_2_loss: 0.3701 - val_output_3_loss: 0.3219 - val_output_0_acc: 0.8915 - val_output_1_acc: 0.8756 - val_output_2_acc: 0.8963 - val_output_3_acc: 0.9434\n",
      "Epoch 75/200\n",
      "2999/2999 [==============================] - 1s 395us/step - loss: 1.2267 - output_0_loss: 0.3131 - output_1_loss: 0.3089 - output_2_loss: 0.2962 - output_3_loss: 0.3086 - output_0_acc: 0.9276 - output_1_acc: 0.9283 - output_2_acc: 0.9373 - output_3_acc: 0.9326 - val_loss: 1.7369 - val_output_0_loss: 0.5102 - val_output_1_loss: 0.4309 - val_output_2_loss: 0.4456 - val_output_3_loss: 0.3502 - val_output_0_acc: 0.8056 - val_output_1_acc: 0.8733 - val_output_2_acc: 0.8257 - val_output_3_acc: 0.9214\n",
      "Epoch 76/200\n",
      "2999/2999 [==============================] - 1s 426us/step - loss: 1.2198 - output_0_loss: 0.3217 - output_1_loss: 0.3084 - output_2_loss: 0.2928 - output_3_loss: 0.2969 - output_0_acc: 0.9200 - output_1_acc: 0.9300 - output_2_acc: 0.9336 - output_3_acc: 0.9376 - val_loss: 1.5024 - val_output_0_loss: 0.4231 - val_output_1_loss: 0.3876 - val_output_2_loss: 0.3349 - val_output_3_loss: 0.3568 - val_output_0_acc: 0.8551 - val_output_1_acc: 0.8925 - val_output_2_acc: 0.9114 - val_output_3_acc: 0.9127\n",
      "Epoch 77/200\n",
      "2999/2999 [==============================] - 1s 401us/step - loss: 1.1781 - output_0_loss: 0.3129 - output_1_loss: 0.2931 - output_2_loss: 0.2842 - output_3_loss: 0.2878 - output_0_acc: 0.9253 - output_1_acc: 0.9350 - output_2_acc: 0.9386 - output_3_acc: 0.9360 - val_loss: 1.4721 - val_output_0_loss: 0.4091 - val_output_1_loss: 0.4165 - val_output_2_loss: 0.2968 - val_output_3_loss: 0.3497 - val_output_0_acc: 0.8955 - val_output_1_acc: 0.8606 - val_output_2_acc: 0.9546 - val_output_3_acc: 0.9047\n",
      "Epoch 78/200\n",
      "2999/2999 [==============================] - 1s 420us/step - loss: 1.1603 - output_0_loss: 0.3078 - output_1_loss: 0.2884 - output_2_loss: 0.2774 - output_3_loss: 0.2867 - output_0_acc: 0.9213 - output_1_acc: 0.9333 - output_2_acc: 0.9380 - output_3_acc: 0.9390 - val_loss: 1.5314 - val_output_0_loss: 0.3619 - val_output_1_loss: 0.4735 - val_output_2_loss: 0.3499 - val_output_3_loss: 0.3462 - val_output_0_acc: 0.9014 - val_output_1_acc: 0.8291 - val_output_2_acc: 0.8846 - val_output_3_acc: 0.9194\n",
      "Epoch 79/200\n",
      "2999/2999 [==============================] - 1s 414us/step - loss: 1.1331 - output_0_loss: 0.2979 - output_1_loss: 0.2894 - output_2_loss: 0.2713 - output_3_loss: 0.2745 - output_0_acc: 0.9283 - output_1_acc: 0.9343 - output_2_acc: 0.9430 - output_3_acc: 0.9473 - val_loss: 1.4808 - val_output_0_loss: 0.3492 - val_output_1_loss: 0.4197 - val_output_2_loss: 0.3487 - val_output_3_loss: 0.3633 - val_output_0_acc: 0.9173 - val_output_1_acc: 0.8483 - val_output_2_acc: 0.9153 - val_output_3_acc: 0.8860\n",
      "Epoch 80/200\n",
      "2999/2999 [==============================] - 1s 432us/step - loss: 1.1066 - output_0_loss: 0.2951 - output_1_loss: 0.2782 - output_2_loss: 0.2628 - output_3_loss: 0.2704 - output_0_acc: 0.9316 - output_1_acc: 0.9406 - output_2_acc: 0.9423 - output_3_acc: 0.9410 - val_loss: 1.4877 - val_output_0_loss: 0.3394 - val_output_1_loss: 0.3692 - val_output_2_loss: 0.3770 - val_output_3_loss: 0.4021 - val_output_0_acc: 0.9192 - val_output_1_acc: 0.8882 - val_output_2_acc: 0.8759 - val_output_3_acc: 0.8510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "2999/2999 [==============================] - 1s 451us/step - loss: 1.0806 - output_0_loss: 0.2916 - output_1_loss: 0.2677 - output_2_loss: 0.2577 - output_3_loss: 0.2636 - output_0_acc: 0.9313 - output_1_acc: 0.9433 - output_2_acc: 0.9466 - output_3_acc: 0.9416 - val_loss: 1.3430 - val_output_0_loss: 0.3596 - val_output_1_loss: 0.3111 - val_output_2_loss: 0.3521 - val_output_3_loss: 0.3202 - val_output_0_acc: 0.8890 - val_output_1_acc: 0.9337 - val_output_2_acc: 0.8859 - val_output_3_acc: 0.9240\n",
      "Epoch 82/200\n",
      "2999/2999 [==============================] - 1s 420us/step - loss: 1.0448 - output_0_loss: 0.2783 - output_1_loss: 0.2638 - output_2_loss: 0.2516 - output_3_loss: 0.2511 - output_0_acc: 0.9376 - output_1_acc: 0.9483 - output_2_acc: 0.9460 - output_3_acc: 0.9527 - val_loss: 1.5429 - val_output_0_loss: 0.3978 - val_output_1_loss: 0.4241 - val_output_2_loss: 0.3815 - val_output_3_loss: 0.3395 - val_output_0_acc: 0.8579 - val_output_1_acc: 0.8318 - val_output_2_acc: 0.8697 - val_output_3_acc: 0.9102\n",
      "Epoch 83/200\n",
      "2999/2999 [==============================] - 1s 416us/step - loss: 1.0302 - output_0_loss: 0.2722 - output_1_loss: 0.2580 - output_2_loss: 0.2470 - output_3_loss: 0.2530 - output_0_acc: 0.9376 - output_1_acc: 0.9446 - output_2_acc: 0.9456 - output_3_acc: 0.9483 - val_loss: 1.3676 - val_output_0_loss: 0.3956 - val_output_1_loss: 0.3473 - val_output_2_loss: 0.2941 - val_output_3_loss: 0.3306 - val_output_0_acc: 0.8692 - val_output_1_acc: 0.8972 - val_output_2_acc: 0.9103 - val_output_3_acc: 0.9004\n",
      "Epoch 84/200\n",
      "2999/2999 [==============================] - 1s 409us/step - loss: 1.0059 - output_0_loss: 0.2672 - output_1_loss: 0.2545 - output_2_loss: 0.2396 - output_3_loss: 0.2447 - output_0_acc: 0.9416 - output_1_acc: 0.9423 - output_2_acc: 0.9530 - output_3_acc: 0.9520 - val_loss: 1.3519 - val_output_0_loss: 0.3249 - val_output_1_loss: 0.3752 - val_output_2_loss: 0.3504 - val_output_3_loss: 0.3014 - val_output_0_acc: 0.9206 - val_output_1_acc: 0.8700 - val_output_2_acc: 0.8803 - val_output_3_acc: 0.9323\n",
      "Epoch 85/200\n",
      "2999/2999 [==============================] - 1s 427us/step - loss: 0.9830 - output_0_loss: 0.2630 - output_1_loss: 0.2522 - output_2_loss: 0.2328 - output_3_loss: 0.2351 - output_0_acc: 0.9416 - output_1_acc: 0.9406 - output_2_acc: 0.9597 - output_3_acc: 0.9573 - val_loss: 1.4198 - val_output_0_loss: 0.4247 - val_output_1_loss: 0.2873 - val_output_2_loss: 0.3809 - val_output_3_loss: 0.3269 - val_output_0_acc: 0.8408 - val_output_1_acc: 0.9366 - val_output_2_acc: 0.8650 - val_output_3_acc: 0.9107\n",
      "Epoch 86/200\n",
      "2999/2999 [==============================] - 1s 424us/step - loss: 0.9557 - output_0_loss: 0.2534 - output_1_loss: 0.2377 - output_2_loss: 0.2298 - output_3_loss: 0.2348 - output_0_acc: 0.9473 - output_1_acc: 0.9523 - output_2_acc: 0.9583 - output_3_acc: 0.9550 - val_loss: 1.2982 - val_output_0_loss: 0.3289 - val_output_1_loss: 0.3342 - val_output_2_loss: 0.2806 - val_output_3_loss: 0.3546 - val_output_0_acc: 0.9111 - val_output_1_acc: 0.9014 - val_output_2_acc: 0.9377 - val_output_3_acc: 0.8806\n",
      "Epoch 87/200\n",
      "2999/2999 [==============================] - 1s 458us/step - loss: 0.9249 - output_0_loss: 0.2473 - output_1_loss: 0.2283 - output_2_loss: 0.2177 - output_3_loss: 0.2316 - output_0_acc: 0.9496 - output_1_acc: 0.9547 - output_2_acc: 0.9647 - output_3_acc: 0.9597 - val_loss: 1.2556 - val_output_0_loss: 0.3595 - val_output_1_loss: 0.3732 - val_output_2_loss: 0.2600 - val_output_3_loss: 0.2628 - val_output_0_acc: 0.8779 - val_output_1_acc: 0.8714 - val_output_2_acc: 0.9549 - val_output_3_acc: 0.9494\n",
      "Epoch 88/200\n",
      "2999/2999 [==============================] - 1s 426us/step - loss: 0.9120 - output_0_loss: 0.2422 - output_1_loss: 0.2285 - output_2_loss: 0.2190 - output_3_loss: 0.2223 - output_0_acc: 0.9500 - output_1_acc: 0.9573 - output_2_acc: 0.9550 - output_3_acc: 0.9607 - val_loss: 1.2062 - val_output_0_loss: 0.2991 - val_output_1_loss: 0.3368 - val_output_2_loss: 0.2835 - val_output_3_loss: 0.2868 - val_output_0_acc: 0.9359 - val_output_1_acc: 0.8894 - val_output_2_acc: 0.9194 - val_output_3_acc: 0.9376\n",
      "Epoch 89/200\n",
      "2999/2999 [==============================] - 1s 443us/step - loss: 0.8878 - output_0_loss: 0.2390 - output_1_loss: 0.2279 - output_2_loss: 0.2134 - output_3_loss: 0.2074 - output_0_acc: 0.9486 - output_1_acc: 0.9530 - output_2_acc: 0.9603 - output_3_acc: 0.9670 - val_loss: 1.4526 - val_output_0_loss: 0.4663 - val_output_1_loss: 0.3204 - val_output_2_loss: 0.3164 - val_output_3_loss: 0.3494 - val_output_0_acc: 0.8089 - val_output_1_acc: 0.8902 - val_output_2_acc: 0.8896 - val_output_3_acc: 0.8814\n",
      "Epoch 90/200\n",
      "2999/2999 [==============================] - 1s 458us/step - loss: 0.8718 - output_0_loss: 0.2379 - output_1_loss: 0.2133 - output_2_loss: 0.2031 - output_3_loss: 0.2174 - output_0_acc: 0.9537 - output_1_acc: 0.9573 - output_2_acc: 0.9647 - output_3_acc: 0.9613 - val_loss: 1.1563 - val_output_0_loss: 0.3316 - val_output_1_loss: 0.2896 - val_output_2_loss: 0.2283 - val_output_3_loss: 0.3068 - val_output_0_acc: 0.9039 - val_output_1_acc: 0.9301 - val_output_2_acc: 0.9607 - val_output_3_acc: 0.9171\n",
      "Epoch 91/200\n",
      "2999/2999 [==============================] - 1s 440us/step - loss: 0.8395 - output_0_loss: 0.2262 - output_1_loss: 0.2095 - output_2_loss: 0.2004 - output_3_loss: 0.2033 - output_0_acc: 0.9553 - output_1_acc: 0.9627 - output_2_acc: 0.9653 - output_3_acc: 0.9690 - val_loss: 1.3866 - val_output_0_loss: 0.3006 - val_output_1_loss: 0.4813 - val_output_2_loss: 0.2863 - val_output_3_loss: 0.3185 - val_output_0_acc: 0.9193 - val_output_1_acc: 0.7772 - val_output_2_acc: 0.9200 - val_output_3_acc: 0.8952\n",
      "Epoch 92/200\n",
      "2999/2999 [==============================] - 1s 457us/step - loss: 0.8301 - output_0_loss: 0.2212 - output_1_loss: 0.2090 - output_2_loss: 0.1975 - output_3_loss: 0.2024 - output_0_acc: 0.9547 - output_1_acc: 0.9607 - output_2_acc: 0.9700 - output_3_acc: 0.9633 - val_loss: 1.1438 - val_output_0_loss: 0.3342 - val_output_1_loss: 0.2602 - val_output_2_loss: 0.2026 - val_output_3_loss: 0.3469 - val_output_0_acc: 0.9019 - val_output_1_acc: 0.9417 - val_output_2_acc: 0.9694 - val_output_3_acc: 0.8702\n",
      "Epoch 93/200\n",
      "2999/2999 [==============================] - 1s 431us/step - loss: 0.8095 - output_0_loss: 0.2209 - output_1_loss: 0.2056 - output_2_loss: 0.1853 - output_3_loss: 0.1977 - output_0_acc: 0.9570 - output_1_acc: 0.9600 - output_2_acc: 0.9670 - output_3_acc: 0.9663 - val_loss: 1.1286 - val_output_0_loss: 0.3511 - val_output_1_loss: 0.2755 - val_output_2_loss: 0.2674 - val_output_3_loss: 0.2347 - val_output_0_acc: 0.8740 - val_output_1_acc: 0.9354 - val_output_2_acc: 0.9204 - val_output_3_acc: 0.9490\n",
      "Epoch 94/200\n",
      "2999/2999 [==============================] - 1s 428us/step - loss: 0.7859 - output_0_loss: 0.2125 - output_1_loss: 0.1954 - output_2_loss: 0.1859 - output_3_loss: 0.1920 - output_0_acc: 0.9610 - output_1_acc: 0.9640 - output_2_acc: 0.9693 - output_3_acc: 0.9703 - val_loss: 1.2316 - val_output_0_loss: 0.3538 - val_output_1_loss: 0.3139 - val_output_2_loss: 0.2756 - val_output_3_loss: 0.2882 - val_output_0_acc: 0.8660 - val_output_1_acc: 0.9132 - val_output_2_acc: 0.9123 - val_output_3_acc: 0.9189\n",
      "Epoch 95/200\n",
      "2999/2999 [==============================] - 1s 429us/step - loss: 0.7922 - output_0_loss: 0.2116 - output_1_loss: 0.1981 - output_2_loss: 0.1859 - output_3_loss: 0.1966 - output_0_acc: 0.9573 - output_1_acc: 0.9653 - output_2_acc: 0.9717 - output_3_acc: 0.9667 - val_loss: 0.9864 - val_output_0_loss: 0.2694 - val_output_1_loss: 0.2539 - val_output_2_loss: 0.2009 - val_output_3_loss: 0.2622 - val_output_0_acc: 0.9477 - val_output_1_acc: 0.9476 - val_output_2_acc: 0.9698 - val_output_3_acc: 0.9233\n",
      "Epoch 96/200\n",
      "2999/2999 [==============================] - 1s 454us/step - loss: 0.7467 - output_0_loss: 0.2046 - output_1_loss: 0.1883 - output_2_loss: 0.1704 - output_3_loss: 0.1834 - output_0_acc: 0.9620 - output_1_acc: 0.9690 - output_2_acc: 0.9770 - output_3_acc: 0.9677 - val_loss: 1.0932 - val_output_0_loss: 0.2865 - val_output_1_loss: 0.3270 - val_output_2_loss: 0.2665 - val_output_3_loss: 0.2132 - val_output_0_acc: 0.9294 - val_output_1_acc: 0.8852 - val_output_2_acc: 0.9258 - val_output_3_acc: 0.9590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "2999/2999 [==============================] - 1s 479us/step - loss: 0.7341 - output_0_loss: 0.1974 - output_1_loss: 0.1880 - output_2_loss: 0.1727 - output_3_loss: 0.1760 - output_0_acc: 0.9663 - output_1_acc: 0.9677 - output_2_acc: 0.9733 - output_3_acc: 0.9760 - val_loss: 1.0564 - val_output_0_loss: 0.2900 - val_output_1_loss: 0.2776 - val_output_2_loss: 0.2148 - val_output_3_loss: 0.2740 - val_output_0_acc: 0.9216 - val_output_1_acc: 0.9239 - val_output_2_acc: 0.9551 - val_output_3_acc: 0.9302\n",
      "Epoch 98/200\n",
      "2999/2999 [==============================] - 1s 446us/step - loss: 0.7171 - output_0_loss: 0.1922 - output_1_loss: 0.1810 - output_2_loss: 0.1696 - output_3_loss: 0.1743 - output_0_acc: 0.9657 - output_1_acc: 0.9703 - output_2_acc: 0.9733 - output_3_acc: 0.9777 - val_loss: 1.2449 - val_output_0_loss: 0.5077 - val_output_1_loss: 0.2329 - val_output_2_loss: 0.2243 - val_output_3_loss: 0.2800 - val_output_0_acc: 0.7679 - val_output_1_acc: 0.9468 - val_output_2_acc: 0.9579 - val_output_3_acc: 0.9261\n",
      "Epoch 99/200\n",
      "2999/2999 [==============================] - 1s 419us/step - loss: 0.6998 - output_0_loss: 0.1933 - output_1_loss: 0.1778 - output_2_loss: 0.1613 - output_3_loss: 0.1674 - output_0_acc: 0.9600 - output_1_acc: 0.9687 - output_2_acc: 0.9733 - output_3_acc: 0.9747 - val_loss: 0.9934 - val_output_0_loss: 0.2747 - val_output_1_loss: 0.2947 - val_output_2_loss: 0.2076 - val_output_3_loss: 0.2164 - val_output_0_acc: 0.9238 - val_output_1_acc: 0.9048 - val_output_2_acc: 0.9626 - val_output_3_acc: 0.9501\n",
      "Epoch 100/200\n",
      "2999/2999 [==============================] - 1s 429us/step - loss: 0.6735 - output_0_loss: 0.1820 - output_1_loss: 0.1704 - output_2_loss: 0.1566 - output_3_loss: 0.1645 - output_0_acc: 0.9727 - output_1_acc: 0.9680 - output_2_acc: 0.9797 - output_3_acc: 0.9783 - val_loss: 1.0023 - val_output_0_loss: 0.2913 - val_output_1_loss: 0.2399 - val_output_2_loss: 0.2577 - val_output_3_loss: 0.2134 - val_output_0_acc: 0.8990 - val_output_1_acc: 0.9464 - val_output_2_acc: 0.9183 - val_output_3_acc: 0.9645\n",
      "Epoch 101/200\n",
      "2999/2999 [==============================] - 1s 430us/step - loss: 0.6536 - output_0_loss: 0.1776 - output_1_loss: 0.1660 - output_2_loss: 0.1509 - output_3_loss: 0.1590 - output_0_acc: 0.9667 - output_1_acc: 0.9760 - output_2_acc: 0.9797 - output_3_acc: 0.9790 - val_loss: 0.9462 - val_output_0_loss: 0.3043 - val_output_1_loss: 0.2335 - val_output_2_loss: 0.1848 - val_output_3_loss: 0.2236 - val_output_0_acc: 0.9027 - val_output_1_acc: 0.9329 - val_output_2_acc: 0.9683 - val_output_3_acc: 0.9473\n",
      "Epoch 102/200\n",
      "2999/2999 [==============================] - 1s 444us/step - loss: 0.6528 - output_0_loss: 0.1755 - output_1_loss: 0.1621 - output_2_loss: 0.1498 - output_3_loss: 0.1655 - output_0_acc: 0.9693 - output_1_acc: 0.9750 - output_2_acc: 0.9777 - output_3_acc: 0.9707 - val_loss: 0.9414 - val_output_0_loss: 0.2611 - val_output_1_loss: 0.2030 - val_output_2_loss: 0.2696 - val_output_3_loss: 0.2078 - val_output_0_acc: 0.9284 - val_output_1_acc: 0.9601 - val_output_2_acc: 0.9144 - val_output_3_acc: 0.9590\n",
      "Epoch 103/200\n",
      "2999/2999 [==============================] - 1s 427us/step - loss: 0.6410 - output_0_loss: 0.1748 - output_1_loss: 0.1597 - output_2_loss: 0.1505 - output_3_loss: 0.1561 - output_0_acc: 0.9703 - output_1_acc: 0.9760 - output_2_acc: 0.9767 - output_3_acc: 0.9787 - val_loss: 1.0688 - val_output_0_loss: 0.2034 - val_output_1_loss: 0.1947 - val_output_2_loss: 0.3067 - val_output_3_loss: 0.3640 - val_output_0_acc: 0.9737 - val_output_1_acc: 0.9616 - val_output_2_acc: 0.8851 - val_output_3_acc: 0.8800\n",
      "Epoch 104/200\n",
      "2999/2999 [==============================] - 1s 456us/step - loss: 0.6110 - output_0_loss: 0.1680 - output_1_loss: 0.1518 - output_2_loss: 0.1419 - output_3_loss: 0.1493 - output_0_acc: 0.9707 - output_1_acc: 0.9760 - output_2_acc: 0.9787 - output_3_acc: 0.9810 - val_loss: 0.9443 - val_output_0_loss: 0.2257 - val_output_1_loss: 0.2781 - val_output_2_loss: 0.2058 - val_output_3_loss: 0.2347 - val_output_0_acc: 0.9494 - val_output_1_acc: 0.8927 - val_output_2_acc: 0.9552 - val_output_3_acc: 0.9350\n",
      "Epoch 105/200\n",
      "2999/2999 [==============================] - 1s 444us/step - loss: 0.6021 - output_0_loss: 0.1585 - output_1_loss: 0.1566 - output_2_loss: 0.1405 - output_3_loss: 0.1465 - output_0_acc: 0.9753 - output_1_acc: 0.9737 - output_2_acc: 0.9800 - output_3_acc: 0.9790 - val_loss: 0.8541 - val_output_0_loss: 0.2403 - val_output_1_loss: 0.2041 - val_output_2_loss: 0.2176 - val_output_3_loss: 0.1921 - val_output_0_acc: 0.9508 - val_output_1_acc: 0.9532 - val_output_2_acc: 0.9327 - val_output_3_acc: 0.9709\n",
      "Epoch 106/200\n",
      "2999/2999 [==============================] - 1s 423us/step - loss: 0.5789 - output_0_loss: 0.1600 - output_1_loss: 0.1445 - output_2_loss: 0.1329 - output_3_loss: 0.1414 - output_0_acc: 0.9727 - output_1_acc: 0.9803 - output_2_acc: 0.9840 - output_3_acc: 0.9843 - val_loss: 0.8866 - val_output_0_loss: 0.3176 - val_output_1_loss: 0.2294 - val_output_2_loss: 0.1658 - val_output_3_loss: 0.1737 - val_output_0_acc: 0.8869 - val_output_1_acc: 0.9349 - val_output_2_acc: 0.9670 - val_output_3_acc: 0.9712\n",
      "Epoch 107/200\n",
      "2999/2999 [==============================] - 1s 450us/step - loss: 0.5755 - output_0_loss: 0.1554 - output_1_loss: 0.1489 - output_2_loss: 0.1325 - output_3_loss: 0.1387 - output_0_acc: 0.9733 - output_1_acc: 0.9753 - output_2_acc: 0.9807 - output_3_acc: 0.9820 - val_loss: 0.7253 - val_output_0_loss: 0.1921 - val_output_1_loss: 0.1849 - val_output_2_loss: 0.1523 - val_output_3_loss: 0.1961 - val_output_0_acc: 0.9634 - val_output_1_acc: 0.9621 - val_output_2_acc: 0.9716 - val_output_3_acc: 0.9527\n",
      "Epoch 108/200\n",
      "2999/2999 [==============================] - 1s 427us/step - loss: 0.5578 - output_0_loss: 0.1513 - output_1_loss: 0.1436 - output_2_loss: 0.1269 - output_3_loss: 0.1360 - output_0_acc: 0.9783 - output_1_acc: 0.9800 - output_2_acc: 0.9853 - output_3_acc: 0.9833 - val_loss: 0.9910 - val_output_0_loss: 0.3239 - val_output_1_loss: 0.2705 - val_output_2_loss: 0.1907 - val_output_3_loss: 0.2059 - val_output_0_acc: 0.8545 - val_output_1_acc: 0.8916 - val_output_2_acc: 0.9605 - val_output_3_acc: 0.9488\n",
      "Epoch 109/200\n",
      "2999/2999 [==============================] - 1s 389us/step - loss: 0.5355 - output_0_loss: 0.1476 - output_1_loss: 0.1345 - output_2_loss: 0.1225 - output_3_loss: 0.1309 - output_0_acc: 0.9800 - output_1_acc: 0.9800 - output_2_acc: 0.9870 - output_3_acc: 0.9873 - val_loss: 0.8140 - val_output_0_loss: 0.2619 - val_output_1_loss: 0.1964 - val_output_2_loss: 0.1448 - val_output_3_loss: 0.2108 - val_output_0_acc: 0.9160 - val_output_1_acc: 0.9601 - val_output_2_acc: 0.9745 - val_output_3_acc: 0.9490\n",
      "Epoch 110/200\n",
      "2999/2999 [==============================] - 1s 433us/step - loss: 0.5276 - output_0_loss: 0.1407 - output_1_loss: 0.1341 - output_2_loss: 0.1239 - output_3_loss: 0.1288 - output_0_acc: 0.9780 - output_1_acc: 0.9810 - output_2_acc: 0.9857 - output_3_acc: 0.9833 - val_loss: 0.6961 - val_output_0_loss: 0.1907 - val_output_1_loss: 0.1917 - val_output_2_loss: 0.1462 - val_output_3_loss: 0.1675 - val_output_0_acc: 0.9589 - val_output_1_acc: 0.9591 - val_output_2_acc: 0.9785 - val_output_3_acc: 0.9673\n",
      "Epoch 111/200\n",
      "2999/2999 [==============================] - 1s 434us/step - loss: 0.5107 - output_0_loss: 0.1407 - output_1_loss: 0.1298 - output_2_loss: 0.1179 - output_3_loss: 0.1224 - output_0_acc: 0.9780 - output_1_acc: 0.9830 - output_2_acc: 0.9847 - output_3_acc: 0.9850 - val_loss: 0.8914 - val_output_0_loss: 0.3187 - val_output_1_loss: 0.1655 - val_output_2_loss: 0.1988 - val_output_3_loss: 0.2085 - val_output_0_acc: 0.8679 - val_output_1_acc: 0.9760 - val_output_2_acc: 0.9463 - val_output_3_acc: 0.9470\n",
      "Epoch 112/200\n",
      "2999/2999 [==============================] - 1s 418us/step - loss: 0.4995 - output_0_loss: 0.1355 - output_1_loss: 0.1280 - output_2_loss: 0.1142 - output_3_loss: 0.1217 - output_0_acc: 0.9833 - output_1_acc: 0.9827 - output_2_acc: 0.9853 - output_3_acc: 0.9847 - val_loss: 0.7325 - val_output_0_loss: 0.1970 - val_output_1_loss: 0.1681 - val_output_2_loss: 0.1669 - val_output_3_loss: 0.2006 - val_output_0_acc: 0.9603 - val_output_1_acc: 0.9739 - val_output_2_acc: 0.9579 - val_output_3_acc: 0.9481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/200\n",
      "2999/2999 [==============================] - 1s 425us/step - loss: 0.4968 - output_0_loss: 0.1378 - output_1_loss: 0.1288 - output_2_loss: 0.1076 - output_3_loss: 0.1225 - output_0_acc: 0.9773 - output_1_acc: 0.9807 - output_2_acc: 0.9900 - output_3_acc: 0.9860 - val_loss: 0.7812 - val_output_0_loss: 0.1989 - val_output_1_loss: 0.2370 - val_output_2_loss: 0.1691 - val_output_3_loss: 0.1762 - val_output_0_acc: 0.9503 - val_output_1_acc: 0.9150 - val_output_2_acc: 0.9606 - val_output_3_acc: 0.9766\n",
      "Epoch 114/200\n",
      "2999/2999 [==============================] - 1s 395us/step - loss: 0.4728 - output_0_loss: 0.1264 - output_1_loss: 0.1211 - output_2_loss: 0.1128 - output_3_loss: 0.1125 - output_0_acc: 0.9843 - output_1_acc: 0.9840 - output_2_acc: 0.9843 - output_3_acc: 0.9887 - val_loss: 0.6974 - val_output_0_loss: 0.2163 - val_output_1_loss: 0.1665 - val_output_2_loss: 0.1496 - val_output_3_loss: 0.1650 - val_output_0_acc: 0.9333 - val_output_1_acc: 0.9711 - val_output_2_acc: 0.9741 - val_output_3_acc: 0.9661\n",
      "Epoch 115/200\n",
      "2999/2999 [==============================] - 1s 427us/step - loss: 0.4526 - output_0_loss: 0.1246 - output_1_loss: 0.1146 - output_2_loss: 0.1034 - output_3_loss: 0.1100 - output_0_acc: 0.9810 - output_1_acc: 0.9863 - output_2_acc: 0.9897 - output_3_acc: 0.9897 - val_loss: 0.6650 - val_output_0_loss: 0.1936 - val_output_1_loss: 0.1589 - val_output_2_loss: 0.1732 - val_output_3_loss: 0.1394 - val_output_0_acc: 0.9529 - val_output_1_acc: 0.9766 - val_output_2_acc: 0.9619 - val_output_3_acc: 0.9856\n",
      "Epoch 116/200\n",
      "2999/2999 [==============================] - 1s 419us/step - loss: 0.4573 - output_0_loss: 0.1262 - output_1_loss: 0.1178 - output_2_loss: 0.1043 - output_3_loss: 0.1090 - output_0_acc: 0.9817 - output_1_acc: 0.9807 - output_2_acc: 0.9850 - output_3_acc: 0.9880 - val_loss: 0.8596 - val_output_0_loss: 0.2183 - val_output_1_loss: 0.2385 - val_output_2_loss: 0.1780 - val_output_3_loss: 0.2249 - val_output_0_acc: 0.9327 - val_output_1_acc: 0.9360 - val_output_2_acc: 0.9458 - val_output_3_acc: 0.9333\n",
      "Epoch 117/200\n",
      "2999/2999 [==============================] - 1s 422us/step - loss: 0.4337 - output_0_loss: 0.1230 - output_1_loss: 0.1063 - output_2_loss: 0.0968 - output_3_loss: 0.1076 - output_0_acc: 0.9827 - output_1_acc: 0.9887 - output_2_acc: 0.9910 - output_3_acc: 0.9883 - val_loss: 0.7248 - val_output_0_loss: 0.1807 - val_output_1_loss: 0.2080 - val_output_2_loss: 0.1644 - val_output_3_loss: 0.1717 - val_output_0_acc: 0.9511 - val_output_1_acc: 0.9462 - val_output_2_acc: 0.9604 - val_output_3_acc: 0.9632\n",
      "Epoch 118/200\n",
      "2999/2999 [==============================] - 1s 409us/step - loss: 0.4280 - output_0_loss: 0.1181 - output_1_loss: 0.1085 - output_2_loss: 0.0964 - output_3_loss: 0.1051 - output_0_acc: 0.9863 - output_1_acc: 0.9850 - output_2_acc: 0.9903 - output_3_acc: 0.9900 - val_loss: 0.5839 - val_output_0_loss: 0.1974 - val_output_1_loss: 0.1402 - val_output_2_loss: 0.1280 - val_output_3_loss: 0.1184 - val_output_0_acc: 0.9394 - val_output_1_acc: 0.9761 - val_output_2_acc: 0.9842 - val_output_3_acc: 0.9930\n",
      "Epoch 119/200\n",
      "2999/2999 [==============================] - 1s 432us/step - loss: 0.4116 - output_0_loss: 0.1126 - output_1_loss: 0.1056 - output_2_loss: 0.0898 - output_3_loss: 0.1035 - output_0_acc: 0.9880 - output_1_acc: 0.9850 - output_2_acc: 0.9903 - output_3_acc: 0.9887 - val_loss: 0.5633 - val_output_0_loss: 0.1862 - val_output_1_loss: 0.1235 - val_output_2_loss: 0.1085 - val_output_3_loss: 0.1451 - val_output_0_acc: 0.9596 - val_output_1_acc: 0.9817 - val_output_2_acc: 0.9926 - val_output_3_acc: 0.9806\n",
      "Epoch 120/200\n",
      "2999/2999 [==============================] - 1s 435us/step - loss: 0.4089 - output_0_loss: 0.1107 - output_1_loss: 0.1064 - output_2_loss: 0.0942 - output_3_loss: 0.0976 - output_0_acc: 0.9877 - output_1_acc: 0.9843 - output_2_acc: 0.9913 - output_3_acc: 0.9887 - val_loss: 0.6499 - val_output_0_loss: 0.2110 - val_output_1_loss: 0.2043 - val_output_2_loss: 0.0908 - val_output_3_loss: 0.1438 - val_output_0_acc: 0.9439 - val_output_1_acc: 0.9436 - val_output_2_acc: 0.9938 - val_output_3_acc: 0.9742\n",
      "Epoch 121/200\n",
      "2999/2999 [==============================] - 1s 452us/step - loss: 0.3923 - output_0_loss: 0.1088 - output_1_loss: 0.1027 - output_2_loss: 0.0859 - output_3_loss: 0.0948 - output_0_acc: 0.9870 - output_1_acc: 0.9870 - output_2_acc: 0.9943 - output_3_acc: 0.9910 - val_loss: 0.5751 - val_output_0_loss: 0.1489 - val_output_1_loss: 0.1224 - val_output_2_loss: 0.1288 - val_output_3_loss: 0.1750 - val_output_0_acc: 0.9761 - val_output_1_acc: 0.9868 - val_output_2_acc: 0.9789 - val_output_3_acc: 0.9399\n",
      "Epoch 122/200\n",
      "2999/2999 [==============================] - 1s 465us/step - loss: 0.3871 - output_0_loss: 0.1084 - output_1_loss: 0.0977 - output_2_loss: 0.0899 - output_3_loss: 0.0911 - output_0_acc: 0.9850 - output_1_acc: 0.9880 - output_2_acc: 0.9917 - output_3_acc: 0.9907 - val_loss: 0.5247 - val_output_0_loss: 0.1506 - val_output_1_loss: 0.1305 - val_output_2_loss: 0.0882 - val_output_3_loss: 0.1554 - val_output_0_acc: 0.9762 - val_output_1_acc: 0.9749 - val_output_2_acc: 0.9957 - val_output_3_acc: 0.9706\n",
      "Epoch 123/200\n",
      "2999/2999 [==============================] - 1s 454us/step - loss: 0.3717 - output_0_loss: 0.1062 - output_1_loss: 0.0914 - output_2_loss: 0.0859 - output_3_loss: 0.0882 - output_0_acc: 0.9867 - output_1_acc: 0.9923 - output_2_acc: 0.9900 - output_3_acc: 0.9940 - val_loss: 0.6457 - val_output_0_loss: 0.2021 - val_output_1_loss: 0.1820 - val_output_2_loss: 0.1215 - val_output_3_loss: 0.1401 - val_output_0_acc: 0.9350 - val_output_1_acc: 0.9447 - val_output_2_acc: 0.9793 - val_output_3_acc: 0.9724\n",
      "Epoch 124/200\n",
      "2999/2999 [==============================] - 1s 425us/step - loss: 0.3654 - output_0_loss: 0.0987 - output_1_loss: 0.0958 - output_2_loss: 0.0832 - output_3_loss: 0.0877 - output_0_acc: 0.9877 - output_1_acc: 0.9873 - output_2_acc: 0.9903 - output_3_acc: 0.9903 - val_loss: 0.5700 - val_output_0_loss: 0.1596 - val_output_1_loss: 0.1818 - val_output_2_loss: 0.1255 - val_output_3_loss: 0.1030 - val_output_0_acc: 0.9603 - val_output_1_acc: 0.9535 - val_output_2_acc: 0.9757 - val_output_3_acc: 0.9916\n",
      "Epoch 125/200\n",
      "2999/2999 [==============================] - 1s 441us/step - loss: 0.3542 - output_0_loss: 0.0941 - output_1_loss: 0.0922 - output_2_loss: 0.0776 - output_3_loss: 0.0903 - output_0_acc: 0.9893 - output_1_acc: 0.9883 - output_2_acc: 0.9937 - output_3_acc: 0.9890 - val_loss: 0.5236 - val_output_0_loss: 0.1434 - val_output_1_loss: 0.1318 - val_output_2_loss: 0.1102 - val_output_3_loss: 0.1382 - val_output_0_acc: 0.9722 - val_output_1_acc: 0.9781 - val_output_2_acc: 0.9889 - val_output_3_acc: 0.9760\n",
      "Epoch 126/200\n",
      "2999/2999 [==============================] - 1s 439us/step - loss: 0.3490 - output_0_loss: 0.0953 - output_1_loss: 0.0900 - output_2_loss: 0.0781 - output_3_loss: 0.0856 - output_0_acc: 0.9880 - output_1_acc: 0.9893 - output_2_acc: 0.9930 - output_3_acc: 0.9917 - val_loss: 0.4825 - val_output_0_loss: 0.1523 - val_output_1_loss: 0.1186 - val_output_2_loss: 0.1088 - val_output_3_loss: 0.1029 - val_output_0_acc: 0.9750 - val_output_1_acc: 0.9801 - val_output_2_acc: 0.9890 - val_output_3_acc: 0.9854\n",
      "Epoch 127/200\n",
      "2999/2999 [==============================] - 1s 439us/step - loss: 0.3403 - output_0_loss: 0.0929 - output_1_loss: 0.0895 - output_2_loss: 0.0757 - output_3_loss: 0.0822 - output_0_acc: 0.9890 - output_1_acc: 0.9883 - output_2_acc: 0.9933 - output_3_acc: 0.9933 - val_loss: 0.5328 - val_output_0_loss: 0.1827 - val_output_1_loss: 0.1362 - val_output_2_loss: 0.1091 - val_output_3_loss: 0.1048 - val_output_0_acc: 0.9340 - val_output_1_acc: 0.9781 - val_output_2_acc: 0.9842 - val_output_3_acc: 0.9890\n",
      "Epoch 128/200\n",
      "2999/2999 [==============================] - 1s 434us/step - loss: 0.3290 - output_0_loss: 0.0905 - output_1_loss: 0.0845 - output_2_loss: 0.0728 - output_3_loss: 0.0813 - output_0_acc: 0.9883 - output_1_acc: 0.9903 - output_2_acc: 0.9923 - output_3_acc: 0.9923 - val_loss: 0.4374 - val_output_0_loss: 0.1382 - val_output_1_loss: 0.1327 - val_output_2_loss: 0.0882 - val_output_3_loss: 0.0783 - val_output_0_acc: 0.9736 - val_output_1_acc: 0.9731 - val_output_2_acc: 0.9920 - val_output_3_acc: 0.9966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/200\n",
      "2999/2999 [==============================] - 1s 433us/step - loss: 0.3120 - output_0_loss: 0.0839 - output_1_loss: 0.0817 - output_2_loss: 0.0714 - output_3_loss: 0.0749 - output_0_acc: 0.9923 - output_1_acc: 0.9917 - output_2_acc: 0.9920 - output_3_acc: 0.9947 - val_loss: 0.5064 - val_output_0_loss: 0.1723 - val_output_1_loss: 0.1021 - val_output_2_loss: 0.0964 - val_output_3_loss: 0.1356 - val_output_0_acc: 0.9514 - val_output_1_acc: 0.9851 - val_output_2_acc: 0.9864 - val_output_3_acc: 0.9700\n",
      "Epoch 130/200\n",
      "2999/2999 [==============================] - 1s 434us/step - loss: 0.3135 - output_0_loss: 0.0848 - output_1_loss: 0.0812 - output_2_loss: 0.0715 - output_3_loss: 0.0760 - output_0_acc: 0.9907 - output_1_acc: 0.9897 - output_2_acc: 0.9923 - output_3_acc: 0.9910 - val_loss: 0.5676 - val_output_0_loss: 0.1913 - val_output_1_loss: 0.1302 - val_output_2_loss: 0.1355 - val_output_3_loss: 0.1107 - val_output_0_acc: 0.9472 - val_output_1_acc: 0.9776 - val_output_2_acc: 0.9688 - val_output_3_acc: 0.9872\n",
      "Epoch 131/200\n",
      "2999/2999 [==============================] - 1s 424us/step - loss: 0.3040 - output_0_loss: 0.0843 - output_1_loss: 0.0776 - output_2_loss: 0.0687 - output_3_loss: 0.0734 - output_0_acc: 0.9890 - output_1_acc: 0.9900 - output_2_acc: 0.9950 - output_3_acc: 0.9927 - val_loss: 0.4738 - val_output_0_loss: 0.1055 - val_output_1_loss: 0.1135 - val_output_2_loss: 0.1314 - val_output_3_loss: 0.1234 - val_output_0_acc: 0.9856 - val_output_1_acc: 0.9853 - val_output_2_acc: 0.9733 - val_output_3_acc: 0.9799\n",
      "Epoch 132/200\n",
      "2999/2999 [==============================] - 1s 430us/step - loss: 0.2956 - output_0_loss: 0.0832 - output_1_loss: 0.0709 - output_2_loss: 0.0694 - output_3_loss: 0.0722 - output_0_acc: 0.9917 - output_1_acc: 0.9937 - output_2_acc: 0.9920 - output_3_acc: 0.9927 - val_loss: 0.4469 - val_output_0_loss: 0.1140 - val_output_1_loss: 0.1184 - val_output_2_loss: 0.1029 - val_output_3_loss: 0.1116 - val_output_0_acc: 0.9816 - val_output_1_acc: 0.9804 - val_output_2_acc: 0.9882 - val_output_3_acc: 0.9855\n",
      "Epoch 133/200\n",
      "2999/2999 [==============================] - 1s 419us/step - loss: 0.2906 - output_0_loss: 0.0802 - output_1_loss: 0.0745 - output_2_loss: 0.0651 - output_3_loss: 0.0708 - output_0_acc: 0.9917 - output_1_acc: 0.9913 - output_2_acc: 0.9953 - output_3_acc: 0.9950 - val_loss: 0.4535 - val_output_0_loss: 0.1296 - val_output_1_loss: 0.1292 - val_output_2_loss: 0.1009 - val_output_3_loss: 0.0938 - val_output_0_acc: 0.9789 - val_output_1_acc: 0.9762 - val_output_2_acc: 0.9819 - val_output_3_acc: 0.9893\n",
      "Epoch 134/200\n",
      "2999/2999 [==============================] - 1s 439us/step - loss: 0.2801 - output_0_loss: 0.0760 - output_1_loss: 0.0717 - output_2_loss: 0.0635 - output_3_loss: 0.0689 - output_0_acc: 0.9910 - output_1_acc: 0.9943 - output_2_acc: 0.9933 - output_3_acc: 0.9940 - val_loss: 0.3806 - val_output_0_loss: 0.1154 - val_output_1_loss: 0.0812 - val_output_2_loss: 0.0778 - val_output_3_loss: 0.1062 - val_output_0_acc: 0.9810 - val_output_1_acc: 0.9945 - val_output_2_acc: 0.9932 - val_output_3_acc: 0.9860\n",
      "Epoch 135/200\n",
      "2999/2999 [==============================] - 1s 422us/step - loss: 0.2636 - output_0_loss: 0.0743 - output_1_loss: 0.0682 - output_2_loss: 0.0563 - output_3_loss: 0.0648 - output_0_acc: 0.9923 - output_1_acc: 0.9960 - output_2_acc: 0.9983 - output_3_acc: 0.9957 - val_loss: 0.3854 - val_output_0_loss: 0.1192 - val_output_1_loss: 0.0820 - val_output_2_loss: 0.0750 - val_output_3_loss: 0.1093 - val_output_0_acc: 0.9751 - val_output_1_acc: 0.9924 - val_output_2_acc: 0.9964 - val_output_3_acc: 0.9754\n",
      "Epoch 136/200\n",
      "2999/2999 [==============================] - 1s 416us/step - loss: 0.2741 - output_0_loss: 0.0747 - output_1_loss: 0.0705 - output_2_loss: 0.0622 - output_3_loss: 0.0667 - output_0_acc: 0.9913 - output_1_acc: 0.9920 - output_2_acc: 0.9933 - output_3_acc: 0.9937 - val_loss: 0.3948 - val_output_0_loss: 0.1124 - val_output_1_loss: 0.0749 - val_output_2_loss: 0.0741 - val_output_3_loss: 0.1334 - val_output_0_acc: 0.9823 - val_output_1_acc: 0.9933 - val_output_2_acc: 0.9922 - val_output_3_acc: 0.9632\n",
      "Epoch 137/200\n",
      "2999/2999 [==============================] - 1s 431us/step - loss: 0.2566 - output_0_loss: 0.0682 - output_1_loss: 0.0677 - output_2_loss: 0.0559 - output_3_loss: 0.0648 - output_0_acc: 0.9930 - output_1_acc: 0.9937 - output_2_acc: 0.9960 - output_3_acc: 0.9950 - val_loss: 0.4625 - val_output_0_loss: 0.1556 - val_output_1_loss: 0.1124 - val_output_2_loss: 0.0779 - val_output_3_loss: 0.1166 - val_output_0_acc: 0.9587 - val_output_1_acc: 0.9768 - val_output_2_acc: 0.9908 - val_output_3_acc: 0.9799\n",
      "Epoch 138/200\n",
      "2999/2999 [==============================] - 1s 459us/step - loss: 0.2610 - output_0_loss: 0.0718 - output_1_loss: 0.0666 - output_2_loss: 0.0588 - output_3_loss: 0.0638 - output_0_acc: 0.9927 - output_1_acc: 0.9923 - output_2_acc: 0.9937 - output_3_acc: 0.9933 - val_loss: 0.4908 - val_output_0_loss: 0.1509 - val_output_1_loss: 0.1701 - val_output_2_loss: 0.0805 - val_output_3_loss: 0.0893 - val_output_0_acc: 0.9602 - val_output_1_acc: 0.9333 - val_output_2_acc: 0.9940 - val_output_3_acc: 0.9906\n",
      "Epoch 139/200\n",
      "2999/2999 [==============================] - 1s 429us/step - loss: 0.2443 - output_0_loss: 0.0656 - output_1_loss: 0.0640 - output_2_loss: 0.0552 - output_3_loss: 0.0596 - output_0_acc: 0.9940 - output_1_acc: 0.9930 - output_2_acc: 0.9950 - output_3_acc: 0.9967 - val_loss: 0.4730 - val_output_0_loss: 0.1555 - val_output_1_loss: 0.1408 - val_output_2_loss: 0.0904 - val_output_3_loss: 0.0864 - val_output_0_acc: 0.9561 - val_output_1_acc: 0.9634 - val_output_2_acc: 0.9880 - val_output_3_acc: 0.9851\n",
      "Epoch 140/200\n",
      "2999/2999 [==============================] - 1s 401us/step - loss: 0.2415 - output_0_loss: 0.0644 - output_1_loss: 0.0635 - output_2_loss: 0.0554 - output_3_loss: 0.0582 - output_0_acc: 0.9947 - output_1_acc: 0.9930 - output_2_acc: 0.9933 - output_3_acc: 0.9940 - val_loss: 0.3748 - val_output_0_loss: 0.1007 - val_output_1_loss: 0.0868 - val_output_2_loss: 0.0883 - val_output_3_loss: 0.0989 - val_output_0_acc: 0.9843 - val_output_1_acc: 0.9926 - val_output_2_acc: 0.9859 - val_output_3_acc: 0.9869\n",
      "Epoch 141/200\n",
      "2999/2999 [==============================] - 1s 446us/step - loss: 0.2317 - output_0_loss: 0.0624 - output_1_loss: 0.0596 - output_2_loss: 0.0510 - output_3_loss: 0.0587 - output_0_acc: 0.9937 - output_1_acc: 0.9953 - output_2_acc: 0.9953 - output_3_acc: 0.9933 - val_loss: 0.5764 - val_output_0_loss: 0.1123 - val_output_1_loss: 0.1550 - val_output_2_loss: 0.1573 - val_output_3_loss: 0.1519 - val_output_0_acc: 0.9763 - val_output_1_acc: 0.9521 - val_output_2_acc: 0.9429 - val_output_3_acc: 0.9594\n",
      "Epoch 142/200\n",
      "2999/2999 [==============================] - 1s 445us/step - loss: 0.2333 - output_0_loss: 0.0661 - output_1_loss: 0.0586 - output_2_loss: 0.0513 - output_3_loss: 0.0574 - output_0_acc: 0.9910 - output_1_acc: 0.9940 - output_2_acc: 0.9937 - output_3_acc: 0.9950 - val_loss: 0.3708 - val_output_0_loss: 0.1052 - val_output_1_loss: 0.0852 - val_output_2_loss: 0.0891 - val_output_3_loss: 0.0912 - val_output_0_acc: 0.9817 - val_output_1_acc: 0.9847 - val_output_2_acc: 0.9833 - val_output_3_acc: 0.9863\n",
      "Epoch 143/200\n",
      "2999/2999 [==============================] - 1s 418us/step - loss: 0.2304 - output_0_loss: 0.0625 - output_1_loss: 0.0606 - output_2_loss: 0.0514 - output_3_loss: 0.0559 - output_0_acc: 0.9923 - output_1_acc: 0.9923 - output_2_acc: 0.9943 - output_3_acc: 0.9977 - val_loss: 0.4197 - val_output_0_loss: 0.0950 - val_output_1_loss: 0.1264 - val_output_2_loss: 0.1032 - val_output_3_loss: 0.0950 - val_output_0_acc: 0.9870 - val_output_1_acc: 0.9713 - val_output_2_acc: 0.9753 - val_output_3_acc: 0.9814\n",
      "Epoch 144/200\n",
      "2999/2999 [==============================] - 1s 417us/step - loss: 0.2165 - output_0_loss: 0.0598 - output_1_loss: 0.0556 - output_2_loss: 0.0489 - output_3_loss: 0.0522 - output_0_acc: 0.9930 - output_1_acc: 0.9950 - output_2_acc: 0.9970 - output_3_acc: 0.9943 - val_loss: 0.3305 - val_output_0_loss: 0.0991 - val_output_1_loss: 0.0604 - val_output_2_loss: 0.0789 - val_output_3_loss: 0.0920 - val_output_0_acc: 0.9772 - val_output_1_acc: 0.9971 - val_output_2_acc: 0.9860 - val_output_3_acc: 0.9893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "2999/2999 [==============================] - 1s 424us/step - loss: 0.2093 - output_0_loss: 0.0587 - output_1_loss: 0.0542 - output_2_loss: 0.0465 - output_3_loss: 0.0499 - output_0_acc: 0.9957 - output_1_acc: 0.9950 - output_2_acc: 0.9953 - output_3_acc: 0.9970 - val_loss: 0.3389 - val_output_0_loss: 0.0813 - val_output_1_loss: 0.0759 - val_output_2_loss: 0.0775 - val_output_3_loss: 0.1042 - val_output_0_acc: 0.9884 - val_output_1_acc: 0.9914 - val_output_2_acc: 0.9883 - val_output_3_acc: 0.9781\n",
      "Epoch 146/200\n",
      "2999/2999 [==============================] - 1s 455us/step - loss: 0.2081 - output_0_loss: 0.0556 - output_1_loss: 0.0559 - output_2_loss: 0.0457 - output_3_loss: 0.0510 - output_0_acc: 0.9953 - output_1_acc: 0.9923 - output_2_acc: 0.9950 - output_3_acc: 0.9950 - val_loss: 0.3022 - val_output_0_loss: 0.0859 - val_output_1_loss: 0.0665 - val_output_2_loss: 0.0373 - val_output_3_loss: 0.1126 - val_output_0_acc: 0.9871 - val_output_1_acc: 0.9961 - val_output_2_acc: 0.9991 - val_output_3_acc: 0.9590\n",
      "Epoch 147/200\n",
      "2999/2999 [==============================] - 1s 474us/step - loss: 0.2012 - output_0_loss: 0.0555 - output_1_loss: 0.0530 - output_2_loss: 0.0427 - output_3_loss: 0.0499 - output_0_acc: 0.9933 - output_1_acc: 0.9947 - output_2_acc: 0.9960 - output_3_acc: 0.9953 - val_loss: 0.4978 - val_output_0_loss: 0.0814 - val_output_1_loss: 0.1236 - val_output_2_loss: 0.1485 - val_output_3_loss: 0.1444 - val_output_0_acc: 0.9825 - val_output_1_acc: 0.9624 - val_output_2_acc: 0.9517 - val_output_3_acc: 0.9484\n",
      "Epoch 148/200\n",
      "2999/2999 [==============================] - 1s 420us/step - loss: 0.1988 - output_0_loss: 0.0523 - output_1_loss: 0.0500 - output_2_loss: 0.0468 - output_3_loss: 0.0497 - output_0_acc: 0.9950 - output_1_acc: 0.9943 - output_2_acc: 0.9940 - output_3_acc: 0.9947 - val_loss: 0.2611 - val_output_0_loss: 0.0756 - val_output_1_loss: 0.0668 - val_output_2_loss: 0.0617 - val_output_3_loss: 0.0570 - val_output_0_acc: 0.9903 - val_output_1_acc: 0.9910 - val_output_2_acc: 0.9958 - val_output_3_acc: 0.9975\n",
      "Epoch 149/200\n",
      "2999/2999 [==============================] - 1s 422us/step - loss: 0.1922 - output_0_loss: 0.0526 - output_1_loss: 0.0502 - output_2_loss: 0.0419 - output_3_loss: 0.0475 - output_0_acc: 0.9947 - output_1_acc: 0.9960 - output_2_acc: 0.9967 - output_3_acc: 0.9967 - val_loss: 0.3098 - val_output_0_loss: 0.1111 - val_output_1_loss: 0.0834 - val_output_2_loss: 0.0598 - val_output_3_loss: 0.0556 - val_output_0_acc: 0.9749 - val_output_1_acc: 0.9887 - val_output_2_acc: 0.9937 - val_output_3_acc: 0.9945\n",
      "Epoch 150/200\n",
      "2999/2999 [==============================] - 1s 426us/step - loss: 0.1905 - output_0_loss: 0.0499 - output_1_loss: 0.0499 - output_2_loss: 0.0412 - output_3_loss: 0.0494 - output_0_acc: 0.9950 - output_1_acc: 0.9957 - output_2_acc: 0.9973 - output_3_acc: 0.9950 - val_loss: 0.2904 - val_output_0_loss: 0.0801 - val_output_1_loss: 0.1019 - val_output_2_loss: 0.0623 - val_output_3_loss: 0.0461 - val_output_0_acc: 0.9905 - val_output_1_acc: 0.9724 - val_output_2_acc: 0.9942 - val_output_3_acc: 0.9973\n",
      "Epoch 151/200\n",
      "2999/2999 [==============================] - 1s 486us/step - loss: 0.1853 - output_0_loss: 0.0501 - output_1_loss: 0.0512 - output_2_loss: 0.0414 - output_3_loss: 0.0426 - output_0_acc: 0.9940 - output_1_acc: 0.9970 - output_2_acc: 0.9963 - output_3_acc: 0.9970 - val_loss: 0.3258 - val_output_0_loss: 0.0985 - val_output_1_loss: 0.0801 - val_output_2_loss: 0.0799 - val_output_3_loss: 0.0673 - val_output_0_acc: 0.9689 - val_output_1_acc: 0.9918 - val_output_2_acc: 0.9869 - val_output_3_acc: 0.9924\n",
      "Epoch 152/200\n",
      "2999/2999 [==============================] - 1s 475us/step - loss: 0.1788 - output_0_loss: 0.0471 - output_1_loss: 0.0470 - output_2_loss: 0.0412 - output_3_loss: 0.0435 - output_0_acc: 0.9957 - output_1_acc: 0.9947 - output_2_acc: 0.9957 - output_3_acc: 0.9963 - val_loss: 0.2319 - val_output_0_loss: 0.0659 - val_output_1_loss: 0.0557 - val_output_2_loss: 0.0511 - val_output_3_loss: 0.0592 - val_output_0_acc: 0.9933 - val_output_1_acc: 0.9965 - val_output_2_acc: 0.9953 - val_output_3_acc: 0.9921\n",
      "Epoch 153/200\n",
      "2999/2999 [==============================] - 1s 480us/step - loss: 0.1707 - output_0_loss: 0.0510 - output_1_loss: 0.0436 - output_2_loss: 0.0361 - output_3_loss: 0.0401 - output_0_acc: 0.9940 - output_1_acc: 0.9963 - output_2_acc: 0.9977 - output_3_acc: 0.9987 - val_loss: 0.2652 - val_output_0_loss: 0.0605 - val_output_1_loss: 0.0974 - val_output_2_loss: 0.0493 - val_output_3_loss: 0.0580 - val_output_0_acc: 0.9946 - val_output_1_acc: 0.9783 - val_output_2_acc: 0.9977 - val_output_3_acc: 0.9947\n",
      "Epoch 154/200\n",
      "2999/2999 [==============================] - 1s 464us/step - loss: 0.1705 - output_0_loss: 0.0452 - output_1_loss: 0.0479 - output_2_loss: 0.0364 - output_3_loss: 0.0411 - output_0_acc: 0.9947 - output_1_acc: 0.9947 - output_2_acc: 0.9980 - output_3_acc: 0.9950 - val_loss: 0.2610 - val_output_0_loss: 0.0614 - val_output_1_loss: 0.0433 - val_output_2_loss: 0.0519 - val_output_3_loss: 0.1044 - val_output_0_acc: 0.9919 - val_output_1_acc: 0.9975 - val_output_2_acc: 0.9955 - val_output_3_acc: 0.9715\n",
      "Epoch 155/200\n",
      "2999/2999 [==============================] - 1s 453us/step - loss: 0.1688 - output_0_loss: 0.0440 - output_1_loss: 0.0457 - output_2_loss: 0.0363 - output_3_loss: 0.0429 - output_0_acc: 0.9957 - output_1_acc: 0.9947 - output_2_acc: 0.9967 - output_3_acc: 0.9957 - val_loss: 0.2664 - val_output_0_loss: 0.0930 - val_output_1_loss: 0.0465 - val_output_2_loss: 0.0644 - val_output_3_loss: 0.0625 - val_output_0_acc: 0.9822 - val_output_1_acc: 0.9975 - val_output_2_acc: 0.9947 - val_output_3_acc: 0.9918\n",
      "Epoch 156/200\n",
      "2999/2999 [==============================] - 1s 474us/step - loss: 0.1674 - output_0_loss: 0.0426 - output_1_loss: 0.0445 - output_2_loss: 0.0364 - output_3_loss: 0.0438 - output_0_acc: 0.9973 - output_1_acc: 0.9950 - output_2_acc: 0.9983 - output_3_acc: 0.9963 - val_loss: 0.2738 - val_output_0_loss: 0.0749 - val_output_1_loss: 0.0578 - val_output_2_loss: 0.0817 - val_output_3_loss: 0.0594 - val_output_0_acc: 0.9851 - val_output_1_acc: 0.9925 - val_output_2_acc: 0.9814 - val_output_3_acc: 0.9932\n",
      "Epoch 157/200\n",
      "2999/2999 [==============================] - 1s 444us/step - loss: 0.1532 - output_0_loss: 0.0389 - output_1_loss: 0.0416 - output_2_loss: 0.0340 - output_3_loss: 0.0388 - output_0_acc: 0.9983 - output_1_acc: 0.9960 - output_2_acc: 0.9983 - output_3_acc: 0.9973 - val_loss: 0.2469 - val_output_0_loss: 0.0730 - val_output_1_loss: 0.0680 - val_output_2_loss: 0.0475 - val_output_3_loss: 0.0584 - val_output_0_acc: 0.9851 - val_output_1_acc: 0.9886 - val_output_2_acc: 0.9967 - val_output_3_acc: 0.9917\n",
      "Epoch 158/200\n",
      "2999/2999 [==============================] - 1s 462us/step - loss: 0.1516 - output_0_loss: 0.0406 - output_1_loss: 0.0403 - output_2_loss: 0.0317 - output_3_loss: 0.0389 - output_0_acc: 0.9977 - output_1_acc: 0.9957 - output_2_acc: 0.9980 - output_3_acc: 0.9977 - val_loss: 0.2744 - val_output_0_loss: 0.0879 - val_output_1_loss: 0.0686 - val_output_2_loss: 0.0563 - val_output_3_loss: 0.0617 - val_output_0_acc: 0.9809 - val_output_1_acc: 0.9899 - val_output_2_acc: 0.9949 - val_output_3_acc: 0.9889\n",
      "Epoch 159/200\n",
      "2999/2999 [==============================] - 1s 450us/step - loss: 0.1525 - output_0_loss: 0.0401 - output_1_loss: 0.0409 - output_2_loss: 0.0342 - output_3_loss: 0.0372 - output_0_acc: 0.9977 - output_1_acc: 0.9973 - output_2_acc: 0.9957 - output_3_acc: 0.9967 - val_loss: 0.2322 - val_output_0_loss: 0.0579 - val_output_1_loss: 0.0669 - val_output_2_loss: 0.0471 - val_output_3_loss: 0.0603 - val_output_0_acc: 0.9938 - val_output_1_acc: 0.9909 - val_output_2_acc: 0.9966 - val_output_3_acc: 0.9932\n",
      "Epoch 160/200\n",
      "2999/2999 [==============================] - 1s 424us/step - loss: 0.1503 - output_0_loss: 0.0399 - output_1_loss: 0.0401 - output_2_loss: 0.0339 - output_3_loss: 0.0364 - output_0_acc: 0.9960 - output_1_acc: 0.9960 - output_2_acc: 0.9963 - output_3_acc: 0.9970 - val_loss: 0.2035 - val_output_0_loss: 0.0507 - val_output_1_loss: 0.0637 - val_output_2_loss: 0.0424 - val_output_3_loss: 0.0467 - val_output_0_acc: 0.9947 - val_output_1_acc: 0.9883 - val_output_2_acc: 0.9954 - val_output_3_acc: 0.9937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200\n",
      "2999/2999 [==============================] - 1s 465us/step - loss: 0.1441 - output_0_loss: 0.0357 - output_1_loss: 0.0388 - output_2_loss: 0.0345 - output_3_loss: 0.0351 - output_0_acc: 0.9980 - output_1_acc: 0.9950 - output_2_acc: 0.9967 - output_3_acc: 0.9973 - val_loss: 0.1944 - val_output_0_loss: 0.0510 - val_output_1_loss: 0.0462 - val_output_2_loss: 0.0295 - val_output_3_loss: 0.0676 - val_output_0_acc: 0.9952 - val_output_1_acc: 0.9957 - val_output_2_acc: 0.9990 - val_output_3_acc: 0.9863\n",
      "Epoch 162/200\n",
      "2999/2999 [==============================] - 1s 449us/step - loss: 0.1407 - output_0_loss: 0.0383 - output_1_loss: 0.0379 - output_2_loss: 0.0288 - output_3_loss: 0.0357 - output_0_acc: 0.9947 - output_1_acc: 0.9960 - output_2_acc: 0.9967 - output_3_acc: 0.9947 - val_loss: 0.1838 - val_output_0_loss: 0.0614 - val_output_1_loss: 0.0485 - val_output_2_loss: 0.0400 - val_output_3_loss: 0.0339 - val_output_0_acc: 0.9920 - val_output_1_acc: 0.9971 - val_output_2_acc: 0.9949 - val_output_3_acc: 0.9977\n",
      "Epoch 163/200\n",
      "2999/2999 [==============================] - 1s 436us/step - loss: 0.1340 - output_0_loss: 0.0356 - output_1_loss: 0.0354 - output_2_loss: 0.0302 - output_3_loss: 0.0328 - output_0_acc: 0.9967 - output_1_acc: 0.9973 - output_2_acc: 0.9980 - output_3_acc: 0.9973 - val_loss: 0.1760 - val_output_0_loss: 0.0474 - val_output_1_loss: 0.0397 - val_output_2_loss: 0.0500 - val_output_3_loss: 0.0389 - val_output_0_acc: 0.9951 - val_output_1_acc: 0.9964 - val_output_2_acc: 0.9903 - val_output_3_acc: 0.9969\n",
      "Epoch 164/200\n",
      "2999/2999 [==============================] - 1s 468us/step - loss: 0.1369 - output_0_loss: 0.0374 - output_1_loss: 0.0364 - output_2_loss: 0.0295 - output_3_loss: 0.0336 - output_0_acc: 0.9953 - output_1_acc: 0.9960 - output_2_acc: 0.9967 - output_3_acc: 0.9977 - val_loss: 0.2343 - val_output_0_loss: 0.0556 - val_output_1_loss: 0.0749 - val_output_2_loss: 0.0570 - val_output_3_loss: 0.0467 - val_output_0_acc: 0.9902 - val_output_1_acc: 0.9836 - val_output_2_acc: 0.9968 - val_output_3_acc: 0.9967\n",
      "Epoch 165/200\n",
      "2999/2999 [==============================] - 1s 469us/step - loss: 0.1265 - output_0_loss: 0.0309 - output_1_loss: 0.0369 - output_2_loss: 0.0271 - output_3_loss: 0.0316 - output_0_acc: 0.9967 - output_1_acc: 0.9960 - output_2_acc: 0.9967 - output_3_acc: 0.9973 - val_loss: 0.2566 - val_output_0_loss: 0.0384 - val_output_1_loss: 0.0806 - val_output_2_loss: 0.0847 - val_output_3_loss: 0.0529 - val_output_0_acc: 0.9963 - val_output_1_acc: 0.9839 - val_output_2_acc: 0.9804 - val_output_3_acc: 0.9926\n",
      "Epoch 166/200\n",
      "2999/2999 [==============================] - 1s 453us/step - loss: 0.1306 - output_0_loss: 0.0350 - output_1_loss: 0.0324 - output_2_loss: 0.0310 - output_3_loss: 0.0321 - output_0_acc: 0.9977 - output_1_acc: 0.9970 - output_2_acc: 0.9947 - output_3_acc: 0.9967 - val_loss: 0.1786 - val_output_0_loss: 0.0436 - val_output_1_loss: 0.0386 - val_output_2_loss: 0.0555 - val_output_3_loss: 0.0408 - val_output_0_acc: 0.9951 - val_output_1_acc: 0.9983 - val_output_2_acc: 0.9881 - val_output_3_acc: 0.9962\n",
      "Epoch 167/200\n",
      "2999/2999 [==============================] - 1s 400us/step - loss: 0.1202 - output_0_loss: 0.0334 - output_1_loss: 0.0335 - output_2_loss: 0.0235 - output_3_loss: 0.0298 - output_0_acc: 0.9963 - output_1_acc: 0.9973 - output_2_acc: 0.9980 - output_3_acc: 0.9977 - val_loss: 0.1676 - val_output_0_loss: 0.0405 - val_output_1_loss: 0.0454 - val_output_2_loss: 0.0329 - val_output_3_loss: 0.0488 - val_output_0_acc: 0.9974 - val_output_1_acc: 0.9959 - val_output_2_acc: 0.9985 - val_output_3_acc: 0.9912\n",
      "Epoch 168/200\n",
      "2999/2999 [==============================] - 1s 438us/step - loss: 0.1186 - output_0_loss: 0.0321 - output_1_loss: 0.0315 - output_2_loss: 0.0264 - output_3_loss: 0.0287 - output_0_acc: 0.9960 - output_1_acc: 0.9973 - output_2_acc: 0.9987 - output_3_acc: 0.9977 - val_loss: 0.2007 - val_output_0_loss: 0.0439 - val_output_1_loss: 0.0804 - val_output_2_loss: 0.0270 - val_output_3_loss: 0.0494 - val_output_0_acc: 0.9953 - val_output_1_acc: 0.9842 - val_output_2_acc: 0.9984 - val_output_3_acc: 0.9959\n",
      "Epoch 169/200\n",
      "2999/2999 [==============================] - 1s 464us/step - loss: 0.1182 - output_0_loss: 0.0299 - output_1_loss: 0.0321 - output_2_loss: 0.0269 - output_3_loss: 0.0294 - output_0_acc: 0.9977 - output_1_acc: 0.9950 - output_2_acc: 0.9983 - output_3_acc: 0.9983 - val_loss: 0.1756 - val_output_0_loss: 0.0433 - val_output_1_loss: 0.0733 - val_output_2_loss: 0.0243 - val_output_3_loss: 0.0347 - val_output_0_acc: 0.9953 - val_output_1_acc: 0.9817 - val_output_2_acc: 0.9986 - val_output_3_acc: 0.9979\n",
      "Epoch 170/200\n",
      "2999/2999 [==============================] - 1s 439us/step - loss: 0.1169 - output_0_loss: 0.0301 - output_1_loss: 0.0326 - output_2_loss: 0.0242 - output_3_loss: 0.0299 - output_0_acc: 0.9973 - output_1_acc: 0.9970 - output_2_acc: 0.9977 - output_3_acc: 0.9977 - val_loss: 0.1237 - val_output_0_loss: 0.0356 - val_output_1_loss: 0.0308 - val_output_2_loss: 0.0321 - val_output_3_loss: 0.0253 - val_output_0_acc: 0.9966 - val_output_1_acc: 0.9984 - val_output_2_acc: 0.9993 - val_output_3_acc: 0.9994\n",
      "Epoch 171/200\n",
      "2999/2999 [==============================] - 1s 410us/step - loss: 0.1107 - output_0_loss: 0.0277 - output_1_loss: 0.0293 - output_2_loss: 0.0271 - output_3_loss: 0.0266 - output_0_acc: 0.9983 - output_1_acc: 0.9967 - output_2_acc: 0.9970 - output_3_acc: 0.9990 - val_loss: 0.1706 - val_output_0_loss: 0.0528 - val_output_1_loss: 0.0380 - val_output_2_loss: 0.0302 - val_output_3_loss: 0.0496 - val_output_0_acc: 0.9930 - val_output_1_acc: 0.9956 - val_output_2_acc: 0.9992 - val_output_3_acc: 0.9942\n",
      "Epoch 172/200\n",
      "2999/2999 [==============================] - 1s 472us/step - loss: 0.1081 - output_0_loss: 0.0300 - output_1_loss: 0.0287 - output_2_loss: 0.0223 - output_3_loss: 0.0271 - output_0_acc: 0.9970 - output_1_acc: 0.9983 - output_2_acc: 0.9993 - output_3_acc: 0.9983 - val_loss: 0.1653 - val_output_0_loss: 0.0370 - val_output_1_loss: 0.0355 - val_output_2_loss: 0.0394 - val_output_3_loss: 0.0534 - val_output_0_acc: 0.9967 - val_output_1_acc: 0.9979 - val_output_2_acc: 0.9976 - val_output_3_acc: 0.9895\n",
      "Epoch 173/200\n",
      "2999/2999 [==============================] - 1s 445us/step - loss: 0.1103 - output_0_loss: 0.0289 - output_1_loss: 0.0271 - output_2_loss: 0.0254 - output_3_loss: 0.0289 - output_0_acc: 0.9963 - output_1_acc: 0.9977 - output_2_acc: 0.9970 - output_3_acc: 0.9970 - val_loss: 0.2583 - val_output_0_loss: 0.0414 - val_output_1_loss: 0.1428 - val_output_2_loss: 0.0409 - val_output_3_loss: 0.0332 - val_output_0_acc: 0.9944 - val_output_1_acc: 0.9363 - val_output_2_acc: 0.9960 - val_output_3_acc: 0.9957\n",
      "Epoch 174/200\n",
      "2999/2999 [==============================] - 1s 419us/step - loss: 0.1051 - output_0_loss: 0.0267 - output_1_loss: 0.0302 - output_2_loss: 0.0222 - output_3_loss: 0.0260 - output_0_acc: 0.9973 - output_1_acc: 0.9963 - output_2_acc: 0.9980 - output_3_acc: 0.9970 - val_loss: 0.1503 - val_output_0_loss: 0.0421 - val_output_1_loss: 0.0341 - val_output_2_loss: 0.0252 - val_output_3_loss: 0.0489 - val_output_0_acc: 0.9945 - val_output_1_acc: 0.9964 - val_output_2_acc: 0.9987 - val_output_3_acc: 0.9954\n",
      "Epoch 175/200\n",
      "2999/2999 [==============================] - 1s 420us/step - loss: 0.0987 - output_0_loss: 0.0254 - output_1_loss: 0.0264 - output_2_loss: 0.0211 - output_3_loss: 0.0258 - output_0_acc: 0.9983 - output_1_acc: 0.9977 - output_2_acc: 0.9983 - output_3_acc: 0.9977 - val_loss: 0.1703 - val_output_0_loss: 0.0375 - val_output_1_loss: 0.0682 - val_output_2_loss: 0.0269 - val_output_3_loss: 0.0378 - val_output_0_acc: 0.9960 - val_output_1_acc: 0.9803 - val_output_2_acc: 0.9986 - val_output_3_acc: 0.9984\n",
      "Epoch 176/200\n",
      "2999/2999 [==============================] - 1s 406us/step - loss: 0.1029 - output_0_loss: 0.0282 - output_1_loss: 0.0280 - output_2_loss: 0.0226 - output_3_loss: 0.0241 - output_0_acc: 0.9973 - output_1_acc: 0.9973 - output_2_acc: 0.9987 - output_3_acc: 0.9973 - val_loss: 0.2034 - val_output_0_loss: 0.0565 - val_output_1_loss: 0.0360 - val_output_2_loss: 0.0704 - val_output_3_loss: 0.0406 - val_output_0_acc: 0.9899 - val_output_1_acc: 0.9958 - val_output_2_acc: 0.9865 - val_output_3_acc: 0.9938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200\n",
      "2999/2999 [==============================] - 1s 437us/step - loss: 0.1004 - output_0_loss: 0.0244 - output_1_loss: 0.0302 - output_2_loss: 0.0203 - output_3_loss: 0.0253 - output_0_acc: 0.9983 - output_1_acc: 0.9973 - output_2_acc: 0.9990 - output_3_acc: 0.9983 - val_loss: 0.2081 - val_output_0_loss: 0.1112 - val_output_1_loss: 0.0356 - val_output_2_loss: 0.0271 - val_output_3_loss: 0.0342 - val_output_0_acc: 0.9690 - val_output_1_acc: 0.9982 - val_output_2_acc: 0.9970 - val_output_3_acc: 0.9953\n",
      "Epoch 178/200\n",
      "2999/2999 [==============================] - 1s 445us/step - loss: 0.0930 - output_0_loss: 0.0255 - output_1_loss: 0.0254 - output_2_loss: 0.0202 - output_3_loss: 0.0219 - output_0_acc: 0.9963 - output_1_acc: 0.9990 - output_2_acc: 0.9997 - output_3_acc: 0.9983 - val_loss: 0.1435 - val_output_0_loss: 0.0433 - val_output_1_loss: 0.0332 - val_output_2_loss: 0.0207 - val_output_3_loss: 0.0463 - val_output_0_acc: 0.9933 - val_output_1_acc: 0.9980 - val_output_2_acc: 0.9984 - val_output_3_acc: 0.9906\n",
      "Epoch 179/200\n",
      "2999/2999 [==============================] - 1s 447us/step - loss: 0.0926 - output_0_loss: 0.0236 - output_1_loss: 0.0241 - output_2_loss: 0.0217 - output_3_loss: 0.0232 - output_0_acc: 0.9977 - output_1_acc: 0.9970 - output_2_acc: 0.9960 - output_3_acc: 0.9967 - val_loss: 0.2275 - val_output_0_loss: 0.0448 - val_output_1_loss: 0.0405 - val_output_2_loss: 0.0943 - val_output_3_loss: 0.0480 - val_output_0_acc: 0.9932 - val_output_1_acc: 0.9953 - val_output_2_acc: 0.9633 - val_output_3_acc: 0.9867\n",
      "Epoch 180/200\n",
      "2999/2999 [==============================] - 1s 413us/step - loss: 0.0956 - output_0_loss: 0.0240 - output_1_loss: 0.0280 - output_2_loss: 0.0195 - output_3_loss: 0.0241 - output_0_acc: 0.9973 - output_1_acc: 0.9960 - output_2_acc: 0.9980 - output_3_acc: 0.9973 - val_loss: 0.2131 - val_output_0_loss: 0.0751 - val_output_1_loss: 0.0406 - val_output_2_loss: 0.0388 - val_output_3_loss: 0.0586 - val_output_0_acc: 0.9800 - val_output_1_acc: 0.9960 - val_output_2_acc: 0.9943 - val_output_3_acc: 0.9871\n",
      "Epoch 181/200\n",
      "2999/2999 [==============================] - 1s 406us/step - loss: 0.0887 - output_0_loss: 0.0218 - output_1_loss: 0.0234 - output_2_loss: 0.0197 - output_3_loss: 0.0238 - output_0_acc: 0.9983 - output_1_acc: 0.9977 - output_2_acc: 0.9983 - output_3_acc: 0.9970 - val_loss: 0.1678 - val_output_0_loss: 0.0561 - val_output_1_loss: 0.0400 - val_output_2_loss: 0.0242 - val_output_3_loss: 0.0475 - val_output_0_acc: 0.9903 - val_output_1_acc: 0.9979 - val_output_2_acc: 0.9963 - val_output_3_acc: 0.9914\n",
      "Epoch 182/200\n",
      "2999/2999 [==============================] - 1s 408us/step - loss: 0.0869 - output_0_loss: 0.0226 - output_1_loss: 0.0241 - output_2_loss: 0.0188 - output_3_loss: 0.0215 - output_0_acc: 0.9970 - output_1_acc: 0.9973 - output_2_acc: 0.9987 - output_3_acc: 0.9977 - val_loss: 0.1069 - val_output_0_loss: 0.0325 - val_output_1_loss: 0.0276 - val_output_2_loss: 0.0239 - val_output_3_loss: 0.0228 - val_output_0_acc: 0.9956 - val_output_1_acc: 0.9982 - val_output_2_acc: 0.9980 - val_output_3_acc: 0.9996\n",
      "Epoch 183/200\n",
      "2999/2999 [==============================] - 1s 437us/step - loss: 0.0864 - output_0_loss: 0.0221 - output_1_loss: 0.0228 - output_2_loss: 0.0193 - output_3_loss: 0.0222 - output_0_acc: 0.9970 - output_1_acc: 0.9987 - output_2_acc: 0.9987 - output_3_acc: 0.9970 - val_loss: 0.1880 - val_output_0_loss: 0.0603 - val_output_1_loss: 0.0278 - val_output_2_loss: 0.0316 - val_output_3_loss: 0.0682 - val_output_0_acc: 0.9865 - val_output_1_acc: 0.9985 - val_output_2_acc: 0.9975 - val_output_3_acc: 0.9739\n",
      "Epoch 184/200\n",
      "2999/2999 [==============================] - 1s 448us/step - loss: 0.0834 - output_0_loss: 0.0204 - output_1_loss: 0.0235 - output_2_loss: 0.0189 - output_3_loss: 0.0206 - output_0_acc: 0.9973 - output_1_acc: 0.9977 - output_2_acc: 0.9980 - output_3_acc: 0.9987 - val_loss: 0.1012 - val_output_0_loss: 0.0334 - val_output_1_loss: 0.0216 - val_output_2_loss: 0.0173 - val_output_3_loss: 0.0288 - val_output_0_acc: 0.9964 - val_output_1_acc: 0.9990 - val_output_2_acc: 0.9994 - val_output_3_acc: 0.9970\n",
      "Epoch 185/200\n",
      "2999/2999 [==============================] - 1s 445us/step - loss: 0.0811 - output_0_loss: 0.0210 - output_1_loss: 0.0224 - output_2_loss: 0.0168 - output_3_loss: 0.0208 - output_0_acc: 0.9983 - output_1_acc: 0.9970 - output_2_acc: 0.9973 - output_3_acc: 0.9980 - val_loss: 0.1144 - val_output_0_loss: 0.0350 - val_output_1_loss: 0.0366 - val_output_2_loss: 0.0177 - val_output_3_loss: 0.0252 - val_output_0_acc: 0.9949 - val_output_1_acc: 0.9977 - val_output_2_acc: 0.9994 - val_output_3_acc: 0.9975\n",
      "Epoch 186/200\n",
      "2999/2999 [==============================] - 1s 447us/step - loss: 0.0806 - output_0_loss: 0.0182 - output_1_loss: 0.0235 - output_2_loss: 0.0176 - output_3_loss: 0.0213 - output_0_acc: 0.9997 - output_1_acc: 0.9967 - output_2_acc: 0.9977 - output_3_acc: 0.9970 - val_loss: 0.1370 - val_output_0_loss: 0.0478 - val_output_1_loss: 0.0316 - val_output_2_loss: 0.0269 - val_output_3_loss: 0.0306 - val_output_0_acc: 0.9907 - val_output_1_acc: 0.9965 - val_output_2_acc: 0.9986 - val_output_3_acc: 0.9970\n",
      "Epoch 187/200\n",
      "2999/2999 [==============================] - 1s 444us/step - loss: 0.0752 - output_0_loss: 0.0177 - output_1_loss: 0.0235 - output_2_loss: 0.0166 - output_3_loss: 0.0175 - output_0_acc: 0.9990 - output_1_acc: 0.9963 - output_2_acc: 0.9990 - output_3_acc: 0.9990 - val_loss: 0.1204 - val_output_0_loss: 0.0383 - val_output_1_loss: 0.0467 - val_output_2_loss: 0.0143 - val_output_3_loss: 0.0211 - val_output_0_acc: 0.9946 - val_output_1_acc: 0.9953 - val_output_2_acc: 0.9994 - val_output_3_acc: 0.9978\n",
      "Epoch 188/200\n",
      "2999/2999 [==============================] - 1s 464us/step - loss: 0.0754 - output_0_loss: 0.0196 - output_1_loss: 0.0211 - output_2_loss: 0.0161 - output_3_loss: 0.0184 - output_0_acc: 0.9983 - output_1_acc: 0.9983 - output_2_acc: 0.9983 - output_3_acc: 0.9987 - val_loss: 0.1657 - val_output_0_loss: 0.0542 - val_output_1_loss: 0.0243 - val_output_2_loss: 0.0344 - val_output_3_loss: 0.0529 - val_output_0_acc: 0.9913 - val_output_1_acc: 0.9983 - val_output_2_acc: 0.9937 - val_output_3_acc: 0.9861\n",
      "Epoch 189/200\n",
      "2999/2999 [==============================] - 1s 449us/step - loss: 0.0772 - output_0_loss: 0.0180 - output_1_loss: 0.0201 - output_2_loss: 0.0189 - output_3_loss: 0.0202 - output_0_acc: 0.9980 - output_1_acc: 0.9987 - output_2_acc: 0.9980 - output_3_acc: 0.9977 - val_loss: 0.1663 - val_output_0_loss: 0.0681 - val_output_1_loss: 0.0595 - val_output_2_loss: 0.0184 - val_output_3_loss: 0.0203 - val_output_0_acc: 0.9799 - val_output_1_acc: 0.9876 - val_output_2_acc: 0.9992 - val_output_3_acc: 0.9991\n",
      "Epoch 190/200\n",
      "2999/2999 [==============================] - 1s 453us/step - loss: 0.0675 - output_0_loss: 0.0183 - output_1_loss: 0.0181 - output_2_loss: 0.0141 - output_3_loss: 0.0171 - output_0_acc: 0.9973 - output_1_acc: 0.9987 - output_2_acc: 0.9990 - output_3_acc: 0.9993 - val_loss: 0.1404 - val_output_0_loss: 0.0429 - val_output_1_loss: 0.0234 - val_output_2_loss: 0.0368 - val_output_3_loss: 0.0373 - val_output_0_acc: 0.9903 - val_output_1_acc: 0.9981 - val_output_2_acc: 0.9957 - val_output_3_acc: 0.9909\n",
      "Epoch 191/200\n",
      "2999/2999 [==============================] - 1s 431us/step - loss: 0.0740 - output_0_loss: 0.0180 - output_1_loss: 0.0206 - output_2_loss: 0.0158 - output_3_loss: 0.0196 - output_0_acc: 0.9980 - output_1_acc: 0.9967 - output_2_acc: 0.9987 - output_3_acc: 0.9983 - val_loss: 0.1624 - val_output_0_loss: 0.0462 - val_output_1_loss: 0.0554 - val_output_2_loss: 0.0397 - val_output_3_loss: 0.0212 - val_output_0_acc: 0.9909 - val_output_1_acc: 0.9816 - val_output_2_acc: 0.9930 - val_output_3_acc: 0.9977\n",
      "Epoch 192/200\n",
      "2999/2999 [==============================] - 1s 427us/step - loss: 0.0650 - output_0_loss: 0.0165 - output_1_loss: 0.0189 - output_2_loss: 0.0144 - output_3_loss: 0.0153 - output_0_acc: 0.9983 - output_1_acc: 0.9977 - output_2_acc: 0.9990 - output_3_acc: 0.9990 - val_loss: 0.1309 - val_output_0_loss: 0.0303 - val_output_1_loss: 0.0618 - val_output_2_loss: 0.0126 - val_output_3_loss: 0.0262 - val_output_0_acc: 0.9959 - val_output_1_acc: 0.9816 - val_output_2_acc: 0.9993 - val_output_3_acc: 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      "2999/2999 [==============================] - 1s 401us/step - loss: 0.0706 - output_0_loss: 0.0179 - output_1_loss: 0.0215 - output_2_loss: 0.0128 - output_3_loss: 0.0184 - output_0_acc: 0.9977 - output_1_acc: 0.9963 - output_2_acc: 0.9997 - output_3_acc: 0.9980 - val_loss: 0.1399 - val_output_0_loss: 0.0220 - val_output_1_loss: 0.0399 - val_output_2_loss: 0.0403 - val_output_3_loss: 0.0378 - val_output_0_acc: 0.9981 - val_output_1_acc: 0.9934 - val_output_2_acc: 0.9961 - val_output_3_acc: 0.9927\n",
      "Epoch 194/200\n",
      "2999/2999 [==============================] - 1s 391us/step - loss: 0.0666 - output_0_loss: 0.0160 - output_1_loss: 0.0169 - output_2_loss: 0.0167 - output_3_loss: 0.0169 - output_0_acc: 0.9993 - output_1_acc: 0.9987 - output_2_acc: 0.9977 - output_3_acc: 0.9980 - val_loss: 0.1388 - val_output_0_loss: 0.0352 - val_output_1_loss: 0.0251 - val_output_2_loss: 0.0241 - val_output_3_loss: 0.0544 - val_output_0_acc: 0.9946 - val_output_1_acc: 0.9984 - val_output_2_acc: 0.9984 - val_output_3_acc: 0.9873\n",
      "Epoch 195/200\n",
      "2999/2999 [==============================] - 1s 424us/step - loss: 0.0666 - output_0_loss: 0.0173 - output_1_loss: 0.0186 - output_2_loss: 0.0145 - output_3_loss: 0.0162 - output_0_acc: 0.9987 - output_1_acc: 0.9980 - output_2_acc: 0.9980 - output_3_acc: 0.9983 - val_loss: 0.1205 - val_output_0_loss: 0.0373 - val_output_1_loss: 0.0287 - val_output_2_loss: 0.0116 - val_output_3_loss: 0.0429 - val_output_0_acc: 0.9936 - val_output_1_acc: 0.9968 - val_output_2_acc: 0.9996 - val_output_3_acc: 0.9900\n",
      "Epoch 196/200\n",
      "2999/2999 [==============================] - 1s 443us/step - loss: 0.0604 - output_0_loss: 0.0175 - output_1_loss: 0.0153 - output_2_loss: 0.0125 - output_3_loss: 0.0151 - output_0_acc: 0.9977 - output_1_acc: 0.9993 - output_2_acc: 0.9990 - output_3_acc: 0.9990 - val_loss: 0.1538 - val_output_0_loss: 0.0349 - val_output_1_loss: 0.0400 - val_output_2_loss: 0.0348 - val_output_3_loss: 0.0441 - val_output_0_acc: 0.9943 - val_output_1_acc: 0.9970 - val_output_2_acc: 0.9956 - val_output_3_acc: 0.9922\n",
      "Epoch 197/200\n",
      "2999/2999 [==============================] - 1s 427us/step - loss: 0.0614 - output_0_loss: 0.0147 - output_1_loss: 0.0167 - output_2_loss: 0.0132 - output_3_loss: 0.0167 - output_0_acc: 0.9990 - output_1_acc: 0.9983 - output_2_acc: 0.9993 - output_3_acc: 0.9980 - val_loss: 0.1059 - val_output_0_loss: 0.0303 - val_output_1_loss: 0.0275 - val_output_2_loss: 0.0211 - val_output_3_loss: 0.0269 - val_output_0_acc: 0.9945 - val_output_1_acc: 0.9970 - val_output_2_acc: 0.9964 - val_output_3_acc: 0.9957\n",
      "Epoch 198/200\n",
      "2999/2999 [==============================] - 1s 408us/step - loss: 0.0634 - output_0_loss: 0.0133 - output_1_loss: 0.0185 - output_2_loss: 0.0166 - output_3_loss: 0.0149 - output_0_acc: 0.9993 - output_1_acc: 0.9960 - output_2_acc: 0.9973 - output_3_acc: 0.9987 - val_loss: 0.0769 - val_output_0_loss: 0.0249 - val_output_1_loss: 0.0194 - val_output_2_loss: 0.0180 - val_output_3_loss: 0.0146 - val_output_0_acc: 0.9969 - val_output_1_acc: 0.9993 - val_output_2_acc: 0.9987 - val_output_3_acc: 0.9990\n",
      "Epoch 199/200\n",
      "2999/2999 [==============================] - 1s 416us/step - loss: 0.0597 - output_0_loss: 0.0141 - output_1_loss: 0.0161 - output_2_loss: 0.0150 - output_3_loss: 0.0146 - output_0_acc: 0.9987 - output_1_acc: 0.9973 - output_2_acc: 0.9970 - output_3_acc: 0.9983 - val_loss: 0.1692 - val_output_0_loss: 0.0335 - val_output_1_loss: 0.0970 - val_output_2_loss: 0.0146 - val_output_3_loss: 0.0241 - val_output_0_acc: 0.9922 - val_output_1_acc: 0.9644 - val_output_2_acc: 0.9986 - val_output_3_acc: 0.9970\n",
      "Epoch 200/200\n",
      "2999/2999 [==============================] - 1s 420us/step - loss: 0.0603 - output_0_loss: 0.0151 - output_1_loss: 0.0179 - output_2_loss: 0.0116 - output_3_loss: 0.0157 - output_0_acc: 0.9987 - output_1_acc: 0.9977 - output_2_acc: 0.9997 - output_3_acc: 0.9977 - val_loss: 0.1454 - val_output_0_loss: 0.0351 - val_output_1_loss: 0.0483 - val_output_2_loss: 0.0228 - val_output_3_loss: 0.0392 - val_output_0_acc: 0.9942 - val_output_1_acc: 0.9864 - val_output_2_acc: 0.9949 - val_output_3_acc: 0.9901\n"
     ]
    }
   ],
   "source": [
    "history = coding_model.fit(x_train, y_train2, validation_split=percentage_split, batch_size=32, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values (of first char only)\n",
    "plt.plot(history.history['output_0_acc'])\n",
    "plt.plot(history.history['val_output_0_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot training & validation loss values (of first char only)\n",
    "plt.plot(history.history['output_0_loss'])\n",
    "plt.plot(history.history['val_output_0_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fdfa', 'viyv', 'sbfn']\n",
      "x_test=\n",
      " [[102 100 102  97]\n",
      " [118 105 121 118]\n",
      " [115  98 102 110]]\n",
      "x_test_mean=\n",
      " [[-0.99908758 -1.26194207 -0.99009764 -1.66466556]\n",
      " [ 1.13374959 -0.59515102  1.5349497   1.13819867]\n",
      " [ 0.73384262 -1.52865849 -0.99009764  0.07044087]]\n",
      "-->\n",
      "prediction\n",
      "['5-3-5-0-', '21-8-25-21-', '18-1-5-13-']\n",
      "check prediction\n",
      "y_test=\n",
      " [[ 5  3  5  0]\n",
      " [21  8 24 21]\n",
      " [18  1  5 13]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "nb_words_to_test = 3\n",
    "\n",
    "x_test = create_inputs(nb_words_to_test, nb_chars, nb_letters)\n",
    "print_readable_inputs(x_test)\n",
    "print(\"x_test=\\n\", x_test)\n",
    "\n",
    "x_test_n  = scaler.transform(x_test)\n",
    "print(\"x_test_mean=\\n\", x_test_n)\n",
    "print('-->')\n",
    "\n",
    "prediction = coding_model.predict(x_test_n)\n",
    "#print(prediction)\n",
    "print('prediction')\n",
    "print_readable_outputs(prediction, nb_words_to_test)\n",
    "\n",
    "print('check prediction')\n",
    "y_test = encrypt(x_test, nb_words_to_test, nb_chars)\n",
    "print(\"y_test=\\n\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
