{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of characters in a word.\n",
    "# for instance abccba has nb_chars = 6\n",
    "nb_chars = 4\n",
    "\n",
    "# number of possible characters used during the encoding.\n",
    "# for instance abcde leads to 01234 has nb_letters = 5\n",
    "nb_letters = 26\n",
    "\n",
    "# number of words samples to be generated \n",
    "nb_words = 30000\n",
    "\n",
    "# percentage of words that will be used for validation\n",
    "percentage_split = 0.90\n",
    "\n",
    "# number of epochs for fitting the model training step\n",
    "nb_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456976"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of combinations\n",
    "nb_letters**nb_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inputs(nb_words, nb_chars, nb_letters):\n",
    "    '''Create a numpy array of nb_words rows with nb_chars columns each element\n",
    "    being a random letter of nb_letters (a, b...)'''\n",
    "    words = np.zeros((nb_words, nb_chars), dtype=int)\n",
    "    \n",
    "    for w in range(nb_words):\n",
    "        optim_tentative = False\n",
    "        if optim_tentative == True and w%10 != 0:\n",
    "            i = random.randint(0, nb_letters-1)\n",
    "            for c in range(nb_chars):\n",
    "                words[w, c] = ord('a') + i\n",
    "        else:\n",
    "            for c in range(nb_chars):\n",
    "                i = random.randint(0, nb_letters-1)\n",
    "                words[w, c] = ord('a') + i\n",
    "                \n",
    "    return words\n",
    "\n",
    "\n",
    "def encrypt(words, nb_words, nb_chars):\n",
    "    '''Encrypt each element of a numpy array of nb_words rows with nb_chars \n",
    "    columns each item with a secret algorithm'''\n",
    "    \n",
    "    encrypted_words = words.copy()\n",
    "    encrypted_words_probs = np.zeros((nb_words, nb_chars, nb_chars))\n",
    "    \n",
    "    #val_max = -1\n",
    "    \n",
    "    for w in range(nb_words):\n",
    "        for c in range(nb_chars): # 0,1,2,3,4\n",
    "            encrypted_words[w,c] = int(words[w,c]) - 49\n",
    "            val = encrypted_words[w,c] - 48\n",
    "            \n",
    "            #if val > val_max:\n",
    "            #    val_max = val\n",
    "            \n",
    "            # add entropy (i.e. mistakes in the encryption)\n",
    "            #epsilon = random.randint(0, 100)\n",
    "            #if epsilon == 5 and val != val_max:\n",
    "            #val +=1\n",
    "            \n",
    "            #print('w:',w,', c:',c,', [wc]:', val)\n",
    "            #encrypted_words_probs[w, c, val ] = 1.0\n",
    "            encrypted_words[w,c] = val\n",
    "    return encrypted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_features = nb_chars\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = layers.Input(shape=(nb_chars,), dtype='float32', name='main_input')\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = layers.Dense(4096, activation='relu', name='hl_1')(inputs)\n",
    "#x = layers.Dense(2048, activation='relu', name='hl_1')(inputs)\n",
    "#x = layers.Dense(64, activation='relu', name='hl_2')(x)\n",
    "\n",
    "outputs = []\n",
    "losses = {}\n",
    "for o in range(nb_chars):\n",
    "    name_i = 'output_'+str(o)\n",
    "    output_i = layers.Dense(nb_letters, activation='softmax', dtype='float32', name=name_i)(x)\n",
    "    outputs.append(output_i)\n",
    "    losses[name_i] = 'categorical_crossentropy'\n",
    "\n",
    "coding_model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "coding_model.compile(optimizer='rmsprop',\n",
    "                     loss=losses,\n",
    "                     metrics=['accuracy'])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hl_1 (Dense)                    (None, 4096)         20480       main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output_0 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_2 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "output_3 (Dense)                (None, 26)           106522      hl_1[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 446,568\n",
      "Trainable params: 446,568\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(coding_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_readable_inputs(x):\n",
    "    words = []\n",
    "    for w in x:\n",
    "        word = ''\n",
    "        for c in w:\n",
    "            word += chr(c)\n",
    "        words.append(word)\n",
    "   \n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_readable_outputs(outputs, nb_words, nb_chars):\n",
    "    \n",
    "    # outputs are listed : first, per char, second by sample, third by letter probability\n",
    "    words = [''] * nb_words\n",
    "    \n",
    "    c_i = 0\n",
    "    for char in outputs:\n",
    "\n",
    "        s_i = 0\n",
    "        for sample in char:\n",
    "\n",
    "            l_i = 0\n",
    "            best_value = -float('inf')\n",
    "            best_letter = -1\n",
    "            for letter_probs in sample:\n",
    "                if letter_probs > best_value:\n",
    "                    best_value = letter_probs\n",
    "                    best_letter = l_i\n",
    "                l_i += 1\n",
    "            words[s_i] += str(best_letter)\n",
    "            if c_i != nb_chars - 1:\n",
    "                words[s_i] += ' '\n",
    "            s_i += 1\n",
    "        c_i += 1\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_sub_set(y, c_ref, nb_chars):\n",
    "    '''Retrieve the probalities of the i-th char'''\n",
    "    nb_samples = len(y)\n",
    "    \n",
    "    yi = np.zeros((nb_samples, nb_letters), dtype=int)\n",
    "    \n",
    "    for s in range(nb_samples):\n",
    "        for c in range(nb_chars):\n",
    "            #print('ysl:',y[s][0][l_i])\n",
    "            if c == c_ref:\n",
    "                yi[s] = y[s, c]\n",
    "                \n",
    "    return yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (as readable inputs)\n",
      "['fefp', 'mykj', 'zkeq', 'mvbr']\n",
      "x (partial):\n",
      " [[102 101 102 112]\n",
      " [109 121 107 106]\n",
      " [122 107 101 113]\n",
      " [109 118  98 114]] out of  30000\n",
      "\n",
      "x_train:\n",
      " [[-0.99720738 -1.13225965 -1.00406459  0.33113328]\n",
      " [-0.06497649  1.5331141  -0.33546674 -0.47110625]\n",
      " [ 1.66630944 -0.33264753 -1.13778416  0.46483987]\n",
      " [-0.06497649  1.13330803 -1.53894287  0.59854645]] out of  30000\n",
      "\n",
      "y (readable):\n",
      " [[ 5  4  5 15]\n",
      " [12 24 10  9]\n",
      " [25 10  4 16]\n",
      " ...\n",
      " [15 11 24 22]\n",
      " [ 9  3  1 11]\n",
      " [23 18  6 25]]\n",
      "\n",
      "y (less readable):\n",
      " [[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0.]]] out of  30000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "x = create_inputs(nb_words, nb_chars, nb_letters)\n",
    "print('x: (as readable inputs)')\n",
    "\n",
    "first_n_samples = 4\n",
    "\n",
    "print_readable_inputs(x[:first_n_samples])\n",
    "print('x (partial):\\n', x[:first_n_samples], 'out of ',len(x))\n",
    "print()\n",
    "\n",
    "# process the x data as useful ANN input data\n",
    "scaler = StandardScaler()\n",
    "x_train  = scaler.fit_transform(x)\n",
    "\n",
    "print('x_train:\\n', x_train[:first_n_samples], 'out of ',len(x_train))\n",
    "print()\n",
    "\n",
    "# create output data for training\n",
    "y = encrypt(x, nb_words, nb_chars)\n",
    "print('y (readable):\\n', y)\n",
    "print()\n",
    "\n",
    "# process the y data as useful ANN output data\n",
    "y_train0 = keras.utils.to_categorical(y, nb_letters)\n",
    "print('y (less readable):\\n', y_train0[:first_n_samples], 'out of ',len(y_train0))\n",
    "print('')\n",
    "\n",
    "# process the y data as useful ANN multiple-outputs data\n",
    "y_train = []\n",
    "for c in range(nb_chars):\n",
    "    yi_train = get_sub_sub_set(y_train0, c, nb_chars)\n",
    "    y_train.append(yi_train)\n",
    "\n",
    "# Not really displayable, henced commented\n",
    "#print('y_train):')\n",
    "#print(y_train[:first_n_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2999 samples, validate on 27001 samples\n",
      "Epoch 1/200\n",
      "2999/2999 [==============================] - 2s 646us/step - loss: 10.6956 - output_0_loss: 2.6789 - output_1_loss: 2.6779 - output_2_loss: 2.6541 - output_3_loss: 2.6848 - output_0_acc: 0.1384 - output_1_acc: 0.1327 - output_2_acc: 0.1444 - output_3_acc: 0.1417 - val_loss: 9.5365 - val_output_0_loss: 2.3642 - val_output_1_loss: 2.4061 - val_output_2_loss: 2.3776 - val_output_3_loss: 2.3886 - val_output_0_acc: 0.1820 - val_output_1_acc: 0.1764 - val_output_2_acc: 0.1627 - val_output_3_acc: 0.1717\n",
      "Epoch 2/200\n",
      "2999/2999 [==============================] - 1s 484us/step - loss: 8.9429 - output_0_loss: 2.2393 - output_1_loss: 2.2400 - output_2_loss: 2.2213 - output_3_loss: 2.2423 - output_0_acc: 0.1971 - output_1_acc: 0.2101 - output_2_acc: 0.2147 - output_3_acc: 0.2074 - val_loss: 8.6315 - val_output_0_loss: 2.1530 - val_output_1_loss: 2.1420 - val_output_2_loss: 2.1463 - val_output_3_loss: 2.1902 - val_output_0_acc: 0.2077 - val_output_1_acc: 0.2085 - val_output_2_acc: 0.2043 - val_output_3_acc: 0.2112\n",
      "Epoch 3/200\n",
      "2999/2999 [==============================] - 1s 460us/step - loss: 8.1844 - output_0_loss: 2.0486 - output_1_loss: 2.0484 - output_2_loss: 2.0390 - output_3_loss: 2.0483 - output_0_acc: 0.2347 - output_1_acc: 0.2357 - output_2_acc: 0.2384 - output_3_acc: 0.2384 - val_loss: 8.1228 - val_output_0_loss: 2.0624 - val_output_1_loss: 2.0136 - val_output_2_loss: 2.0214 - val_output_3_loss: 2.0255 - val_output_0_acc: 0.2167 - val_output_1_acc: 0.2475 - val_output_2_acc: 0.2267 - val_output_3_acc: 0.2301\n",
      "Epoch 4/200\n",
      "2999/2999 [==============================] - 1s 440us/step - loss: 7.6529 - output_0_loss: 1.9082 - output_1_loss: 1.9142 - output_2_loss: 1.9137 - output_3_loss: 1.9168 - output_0_acc: 0.2861 - output_1_acc: 0.2798 - output_2_acc: 0.2804 - output_3_acc: 0.2834 - val_loss: 7.6740 - val_output_0_loss: 1.9154 - val_output_1_loss: 1.8870 - val_output_2_loss: 1.9334 - val_output_3_loss: 1.9382 - val_output_0_acc: 0.2566 - val_output_1_acc: 0.2897 - val_output_2_acc: 0.2760 - val_output_3_acc: 0.2523\n",
      "Epoch 5/200\n",
      "2999/2999 [==============================] - 1s 404us/step - loss: 7.2141 - output_0_loss: 1.7962 - output_1_loss: 1.8076 - output_2_loss: 1.8002 - output_3_loss: 1.8101 - output_0_acc: 0.3128 - output_1_acc: 0.3104 - output_2_acc: 0.3068 - output_3_acc: 0.3034 - val_loss: 7.3788 - val_output_0_loss: 1.8572 - val_output_1_loss: 1.7975 - val_output_2_loss: 1.8537 - val_output_3_loss: 1.8704 - val_output_0_acc: 0.2885 - val_output_1_acc: 0.3170 - val_output_2_acc: 0.2657 - val_output_3_acc: 0.2810\n",
      "Epoch 6/200\n",
      "2999/2999 [==============================] - 1s 446us/step - loss: 6.8577 - output_0_loss: 1.7027 - output_1_loss: 1.7161 - output_2_loss: 1.7137 - output_3_loss: 1.7252 - output_0_acc: 0.3491 - output_1_acc: 0.3408 - output_2_acc: 0.3344 - output_3_acc: 0.3298 - val_loss: 7.0049 - val_output_0_loss: 1.7657 - val_output_1_loss: 1.8133 - val_output_2_loss: 1.7028 - val_output_3_loss: 1.7231 - val_output_0_acc: 0.2916 - val_output_1_acc: 0.3075 - val_output_2_acc: 0.3196 - val_output_3_acc: 0.3292\n",
      "Epoch 7/200\n",
      "2999/2999 [==============================] - 1s 440us/step - loss: 6.5364 - output_0_loss: 1.6381 - output_1_loss: 1.6353 - output_2_loss: 1.6323 - output_3_loss: 1.6306 - output_0_acc: 0.3735 - output_1_acc: 0.3585 - output_2_acc: 0.3645 - output_3_acc: 0.3748 - val_loss: 6.6643 - val_output_0_loss: 1.6653 - val_output_1_loss: 1.6576 - val_output_2_loss: 1.6451 - val_output_3_loss: 1.6963 - val_output_0_acc: 0.3302 - val_output_1_acc: 0.3527 - val_output_2_acc: 0.3362 - val_output_3_acc: 0.3386\n",
      "Epoch 8/200\n",
      "2999/2999 [==============================] - 1s 446us/step - loss: 6.2861 - output_0_loss: 1.5747 - output_1_loss: 1.5763 - output_2_loss: 1.5683 - output_3_loss: 1.5667 - output_0_acc: 0.3878 - output_1_acc: 0.3831 - output_2_acc: 0.3921 - output_3_acc: 0.3925 - val_loss: 6.3826 - val_output_0_loss: 1.5485 - val_output_1_loss: 1.6279 - val_output_2_loss: 1.6021 - val_output_3_loss: 1.6040 - val_output_0_acc: 0.3844 - val_output_1_acc: 0.3437 - val_output_2_acc: 0.3728 - val_output_3_acc: 0.3611\n",
      "Epoch 9/200\n",
      "2999/2999 [==============================] - 1s 430us/step - loss: 6.0355 - output_0_loss: 1.4903 - output_1_loss: 1.5175 - output_2_loss: 1.5099 - output_3_loss: 1.5177 - output_0_acc: 0.4191 - output_1_acc: 0.3988 - output_2_acc: 0.3905 - output_3_acc: 0.4058 - val_loss: 6.1495 - val_output_0_loss: 1.5477 - val_output_1_loss: 1.5280 - val_output_2_loss: 1.5018 - val_output_3_loss: 1.5721 - val_output_0_acc: 0.3782 - val_output_1_acc: 0.3753 - val_output_2_acc: 0.3846 - val_output_3_acc: 0.3900\n",
      "Epoch 10/200\n",
      "2999/2999 [==============================] - 1s 422us/step - loss: 5.8052 - output_0_loss: 1.4473 - output_1_loss: 1.4480 - output_2_loss: 1.4563 - output_3_loss: 1.4536 - output_0_acc: 0.4218 - output_1_acc: 0.4408 - output_2_acc: 0.4158 - output_3_acc: 0.4275 - val_loss: 5.9992 - val_output_0_loss: 1.4807 - val_output_1_loss: 1.5158 - val_output_2_loss: 1.5142 - val_output_3_loss: 1.4885 - val_output_0_acc: 0.4286 - val_output_1_acc: 0.3984 - val_output_2_acc: 0.3725 - val_output_3_acc: 0.4012\n",
      "Epoch 11/200\n",
      "2999/2999 [==============================] - 1s 436us/step - loss: 5.5682 - output_0_loss: 1.3863 - output_1_loss: 1.4012 - output_2_loss: 1.3875 - output_3_loss: 1.3931 - output_0_acc: 0.4615 - output_1_acc: 0.4471 - output_2_acc: 0.4461 - output_3_acc: 0.4552 - val_loss: 5.7278 - val_output_0_loss: 1.3884 - val_output_1_loss: 1.4370 - val_output_2_loss: 1.4395 - val_output_3_loss: 1.4628 - val_output_0_acc: 0.4203 - val_output_1_acc: 0.4207 - val_output_2_acc: 0.3931 - val_output_3_acc: 0.4112\n",
      "Epoch 12/200\n",
      "2999/2999 [==============================] - 1s 450us/step - loss: 5.3785 - output_0_loss: 1.3421 - output_1_loss: 1.3506 - output_2_loss: 1.3446 - output_3_loss: 1.3412 - output_0_acc: 0.4605 - output_1_acc: 0.4685 - output_2_acc: 0.4678 - output_3_acc: 0.4728 - val_loss: 5.7154 - val_output_0_loss: 1.4432 - val_output_1_loss: 1.4992 - val_output_2_loss: 1.3833 - val_output_3_loss: 1.3898 - val_output_0_acc: 0.3986 - val_output_1_acc: 0.3971 - val_output_2_acc: 0.4235 - val_output_3_acc: 0.4401\n",
      "Epoch 13/200\n",
      "2999/2999 [==============================] - 1s 431us/step - loss: 5.2328 - output_0_loss: 1.3026 - output_1_loss: 1.3222 - output_2_loss: 1.3091 - output_3_loss: 1.2989 - output_0_acc: 0.4918 - output_1_acc: 0.4705 - output_2_acc: 0.4682 - output_3_acc: 0.4835 - val_loss: 5.6795 - val_output_0_loss: 1.4154 - val_output_1_loss: 1.4550 - val_output_2_loss: 1.3987 - val_output_3_loss: 1.4104 - val_output_0_acc: 0.4651 - val_output_1_acc: 0.4011 - val_output_2_acc: 0.4158 - val_output_3_acc: 0.4193\n",
      "Epoch 14/200\n",
      "2999/2999 [==============================] - 1s 423us/step - loss: 5.0514 - output_0_loss: 1.2580 - output_1_loss: 1.2767 - output_2_loss: 1.2506 - output_3_loss: 1.2662 - output_0_acc: 0.5038 - output_1_acc: 0.4922 - output_2_acc: 0.4978 - output_3_acc: 0.4928 - val_loss: 5.3774 - val_output_0_loss: 1.3231 - val_output_1_loss: 1.3510 - val_output_2_loss: 1.3005 - val_output_3_loss: 1.4028 - val_output_0_acc: 0.4332 - val_output_1_acc: 0.4259 - val_output_2_acc: 0.4781 - val_output_3_acc: 0.4003\n",
      "Epoch 15/200\n",
      "2999/2999 [==============================] - 1s 418us/step - loss: 4.9115 - output_0_loss: 1.2230 - output_1_loss: 1.2324 - output_2_loss: 1.2239 - output_3_loss: 1.2322 - output_0_acc: 0.5175 - output_1_acc: 0.5188 - output_2_acc: 0.5075 - output_3_acc: 0.5105 - val_loss: 5.2206 - val_output_0_loss: 1.3011 - val_output_1_loss: 1.3353 - val_output_2_loss: 1.3064 - val_output_3_loss: 1.2778 - val_output_0_acc: 0.4521 - val_output_1_acc: 0.4360 - val_output_2_acc: 0.4624 - val_output_3_acc: 0.4908\n",
      "Epoch 16/200\n",
      "2999/2999 [==============================] - 2s 503us/step - loss: 4.7872 - output_0_loss: 1.1926 - output_1_loss: 1.2082 - output_2_loss: 1.1937 - output_3_loss: 1.1927 - output_0_acc: 0.5222 - output_1_acc: 0.5172 - output_2_acc: 0.5242 - output_3_acc: 0.5328 - val_loss: 5.0704 - val_output_0_loss: 1.2669 - val_output_1_loss: 1.3138 - val_output_2_loss: 1.2589 - val_output_3_loss: 1.2308 - val_output_0_acc: 0.4792 - val_output_1_acc: 0.4741 - val_output_2_acc: 0.4919 - val_output_3_acc: 0.5179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "2999/2999 [==============================] - 1s 471us/step - loss: 4.6228 - output_0_loss: 1.1545 - output_1_loss: 1.1720 - output_2_loss: 1.1445 - output_3_loss: 1.1519 - output_0_acc: 0.5442 - output_1_acc: 0.5325 - output_2_acc: 0.5295 - output_3_acc: 0.5398 - val_loss: 4.9831 - val_output_0_loss: 1.2549 - val_output_1_loss: 1.2735 - val_output_2_loss: 1.1845 - val_output_3_loss: 1.2702 - val_output_0_acc: 0.4763 - val_output_1_acc: 0.4912 - val_output_2_acc: 0.4857 - val_output_3_acc: 0.4754\n",
      "Epoch 18/200\n",
      "2999/2999 [==============================] - 1s 438us/step - loss: 4.5114 - output_0_loss: 1.1214 - output_1_loss: 1.1407 - output_2_loss: 1.1201 - output_3_loss: 1.1291 - output_0_acc: 0.5552 - output_1_acc: 0.5425 - output_2_acc: 0.5488 - output_3_acc: 0.5465 - val_loss: 4.7672 - val_output_0_loss: 1.1580 - val_output_1_loss: 1.2317 - val_output_2_loss: 1.1721 - val_output_3_loss: 1.2054 - val_output_0_acc: 0.5339 - val_output_1_acc: 0.5449 - val_output_2_acc: 0.5453 - val_output_3_acc: 0.5102\n",
      "Epoch 19/200\n",
      "2999/2999 [==============================] - 1s 443us/step - loss: 4.3601 - output_0_loss: 1.0777 - output_1_loss: 1.1043 - output_2_loss: 1.0879 - output_3_loss: 1.0902 - output_0_acc: 0.5759 - output_1_acc: 0.5512 - output_2_acc: 0.5705 - output_3_acc: 0.5585 - val_loss: 4.8300 - val_output_0_loss: 1.2493 - val_output_1_loss: 1.3191 - val_output_2_loss: 1.1116 - val_output_3_loss: 1.1500 - val_output_0_acc: 0.4872 - val_output_1_acc: 0.4706 - val_output_2_acc: 0.5232 - val_output_3_acc: 0.5506\n",
      "Epoch 20/200\n",
      "2999/2999 [==============================] - 1s 419us/step - loss: 4.2266 - output_0_loss: 1.0533 - output_1_loss: 1.0733 - output_2_loss: 1.0469 - output_3_loss: 1.0532 - output_0_acc: 0.5859 - output_1_acc: 0.5775 - output_2_acc: 0.5789 - output_3_acc: 0.5842 - val_loss: 4.7017 - val_output_0_loss: 1.2473 - val_output_1_loss: 1.1525 - val_output_2_loss: 1.0937 - val_output_3_loss: 1.2081 - val_output_0_acc: 0.4495 - val_output_1_acc: 0.5603 - val_output_2_acc: 0.5402 - val_output_3_acc: 0.4948\n",
      "Epoch 21/200\n",
      "2999/2999 [==============================] - 1s 418us/step - loss: 4.1571 - output_0_loss: 1.0370 - output_1_loss: 1.0610 - output_2_loss: 1.0228 - output_3_loss: 1.0363 - output_0_acc: 0.5812 - output_1_acc: 0.5755 - output_2_acc: 0.5875 - output_3_acc: 0.5775 - val_loss: 4.4789 - val_output_0_loss: 1.1249 - val_output_1_loss: 1.1747 - val_output_2_loss: 1.0651 - val_output_3_loss: 1.1142 - val_output_0_acc: 0.5249 - val_output_1_acc: 0.4846 - val_output_2_acc: 0.5538 - val_output_3_acc: 0.5187\n",
      "Epoch 22/200\n",
      "2999/2999 [==============================] - 1s 418us/step - loss: 4.0374 - output_0_loss: 1.0061 - output_1_loss: 1.0297 - output_2_loss: 0.9978 - output_3_loss: 1.0039 - output_0_acc: 0.6039 - output_1_acc: 0.5925 - output_2_acc: 0.6035 - output_3_acc: 0.6085 - val_loss: 4.5373 - val_output_0_loss: 1.1483 - val_output_1_loss: 1.1445 - val_output_2_loss: 1.0981 - val_output_3_loss: 1.1464 - val_output_0_acc: 0.5287 - val_output_1_acc: 0.5395 - val_output_2_acc: 0.5202 - val_output_3_acc: 0.5345\n",
      "Epoch 23/200\n",
      "2999/2999 [==============================] - 1s 463us/step - loss: 3.9299 - output_0_loss: 0.9756 - output_1_loss: 1.0024 - output_2_loss: 0.9762 - output_3_loss: 0.9758 - output_0_acc: 0.6162 - output_1_acc: 0.6042 - output_2_acc: 0.6042 - output_3_acc: 0.6175 - val_loss: 4.3343 - val_output_0_loss: 1.0525 - val_output_1_loss: 1.1329 - val_output_2_loss: 1.1076 - val_output_3_loss: 1.0412 - val_output_0_acc: 0.5595 - val_output_1_acc: 0.5682 - val_output_2_acc: 0.5384 - val_output_3_acc: 0.6145\n",
      "Epoch 24/200\n",
      "2999/2999 [==============================] - 1s 453us/step - loss: 3.8556 - output_0_loss: 0.9607 - output_1_loss: 0.9803 - output_2_loss: 0.9538 - output_3_loss: 0.9607 - output_0_acc: 0.6295 - output_1_acc: 0.6055 - output_2_acc: 0.6199 - output_3_acc: 0.6182 - val_loss: 4.2787 - val_output_0_loss: 1.0770 - val_output_1_loss: 1.1029 - val_output_2_loss: 1.0008 - val_output_3_loss: 1.0981 - val_output_0_acc: 0.5442 - val_output_1_acc: 0.5285 - val_output_2_acc: 0.5859 - val_output_3_acc: 0.5214\n",
      "Epoch 25/200\n",
      "2999/2999 [==============================] - 1s 403us/step - loss: 3.7203 - output_0_loss: 0.9250 - output_1_loss: 0.9549 - output_2_loss: 0.9205 - output_3_loss: 0.9199 - output_0_acc: 0.6382 - output_1_acc: 0.6215 - output_2_acc: 0.6375 - output_3_acc: 0.6302 - val_loss: 4.2093 - val_output_0_loss: 0.9778 - val_output_1_loss: 1.0655 - val_output_2_loss: 1.0709 - val_output_3_loss: 1.0951 - val_output_0_acc: 0.6054 - val_output_1_acc: 0.5253 - val_output_2_acc: 0.5378 - val_output_3_acc: 0.5295\n",
      "Epoch 26/200\n",
      "2999/2999 [==============================] - 1s 428us/step - loss: 3.6610 - output_0_loss: 0.9125 - output_1_loss: 0.9246 - output_2_loss: 0.9188 - output_3_loss: 0.9050 - output_0_acc: 0.6439 - output_1_acc: 0.6365 - output_2_acc: 0.6332 - output_3_acc: 0.6402 - val_loss: 4.2692 - val_output_0_loss: 1.0385 - val_output_1_loss: 1.0100 - val_output_2_loss: 1.1133 - val_output_3_loss: 1.1073 - val_output_0_acc: 0.5722 - val_output_1_acc: 0.5949 - val_output_2_acc: 0.4509 - val_output_3_acc: 0.5294\n",
      "Epoch 27/200\n",
      "2999/2999 [==============================] - 1s 439us/step - loss: 3.5641 - output_0_loss: 0.8811 - output_1_loss: 0.9091 - output_2_loss: 0.8841 - output_3_loss: 0.8897 - output_0_acc: 0.6516 - output_1_acc: 0.6495 - output_2_acc: 0.6539 - output_3_acc: 0.6512 - val_loss: 3.9293 - val_output_0_loss: 0.9489 - val_output_1_loss: 1.0379 - val_output_2_loss: 0.9908 - val_output_3_loss: 0.9516 - val_output_0_acc: 0.5699 - val_output_1_acc: 0.5848 - val_output_2_acc: 0.5804 - val_output_3_acc: 0.6306\n",
      "Epoch 28/200\n",
      "2999/2999 [==============================] - 1s 455us/step - loss: 3.4732 - output_0_loss: 0.8603 - output_1_loss: 0.8917 - output_2_loss: 0.8539 - output_3_loss: 0.8674 - output_0_acc: 0.6616 - output_1_acc: 0.6485 - output_2_acc: 0.6689 - output_3_acc: 0.6652 - val_loss: 3.8498 - val_output_0_loss: 0.9495 - val_output_1_loss: 1.0034 - val_output_2_loss: 0.9962 - val_output_3_loss: 0.9007 - val_output_0_acc: 0.6251 - val_output_1_acc: 0.5693 - val_output_2_acc: 0.5480 - val_output_3_acc: 0.6559\n",
      "Epoch 29/200\n",
      "2999/2999 [==============================] - 1s 409us/step - loss: 3.3854 - output_0_loss: 0.8410 - output_1_loss: 0.8738 - output_2_loss: 0.8382 - output_3_loss: 0.8325 - output_0_acc: 0.6719 - output_1_acc: 0.6629 - output_2_acc: 0.6796 - output_3_acc: 0.6776 - val_loss: 3.9558 - val_output_0_loss: 0.9424 - val_output_1_loss: 1.0184 - val_output_2_loss: 1.0145 - val_output_3_loss: 0.9805 - val_output_0_acc: 0.6163 - val_output_1_acc: 0.5814 - val_output_2_acc: 0.5593 - val_output_3_acc: 0.5715\n",
      "Epoch 30/200\n",
      "2999/2999 [==============================] - 1s 441us/step - loss: 3.3090 - output_0_loss: 0.8158 - output_1_loss: 0.8474 - output_2_loss: 0.8229 - output_3_loss: 0.8229 - output_0_acc: 0.6869 - output_1_acc: 0.6732 - output_2_acc: 0.6836 - output_3_acc: 0.6839 - val_loss: 3.7779 - val_output_0_loss: 0.9240 - val_output_1_loss: 1.0249 - val_output_2_loss: 0.8416 - val_output_3_loss: 0.9874 - val_output_0_acc: 0.6302 - val_output_1_acc: 0.5073 - val_output_2_acc: 0.6670 - val_output_3_acc: 0.5955\n",
      "Epoch 31/200\n",
      "2999/2999 [==============================] - 1s 394us/step - loss: 3.2392 - output_0_loss: 0.8069 - output_1_loss: 0.8360 - output_2_loss: 0.7931 - output_3_loss: 0.8032 - output_0_acc: 0.6979 - output_1_acc: 0.6699 - output_2_acc: 0.6929 - output_3_acc: 0.6982 - val_loss: 3.6414 - val_output_0_loss: 0.8385 - val_output_1_loss: 0.9593 - val_output_2_loss: 0.9336 - val_output_3_loss: 0.9101 - val_output_0_acc: 0.6782 - val_output_1_acc: 0.6243 - val_output_2_acc: 0.6104 - val_output_3_acc: 0.6383\n",
      "Epoch 32/200\n",
      "2999/2999 [==============================] - 1s 415us/step - loss: 3.1682 - output_0_loss: 0.7756 - output_1_loss: 0.8102 - output_2_loss: 0.7884 - output_3_loss: 0.7941 - output_0_acc: 0.7109 - output_1_acc: 0.6869 - output_2_acc: 0.6932 - output_3_acc: 0.6992 - val_loss: 3.6202 - val_output_0_loss: 0.8729 - val_output_1_loss: 0.8939 - val_output_2_loss: 0.8874 - val_output_3_loss: 0.9660 - val_output_0_acc: 0.6853 - val_output_1_acc: 0.6348 - val_output_2_acc: 0.6274 - val_output_3_acc: 0.5762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "2999/2999 [==============================] - 1s 404us/step - loss: 3.0928 - output_0_loss: 0.7621 - output_1_loss: 0.8021 - output_2_loss: 0.7603 - output_3_loss: 0.7682 - output_0_acc: 0.7129 - output_1_acc: 0.6816 - output_2_acc: 0.7149 - output_3_acc: 0.7122 - val_loss: 3.5954 - val_output_0_loss: 0.8345 - val_output_1_loss: 0.9041 - val_output_2_loss: 0.8816 - val_output_3_loss: 0.9752 - val_output_0_acc: 0.6645 - val_output_1_acc: 0.6221 - val_output_2_acc: 0.6141 - val_output_3_acc: 0.6201\n",
      "Epoch 34/200\n",
      "2999/2999 [==============================] - 1s 421us/step - loss: 3.0293 - output_0_loss: 0.7505 - output_1_loss: 0.7888 - output_2_loss: 0.7402 - output_3_loss: 0.7499 - output_0_acc: 0.7166 - output_1_acc: 0.6996 - output_2_acc: 0.7249 - output_3_acc: 0.7146 - val_loss: 3.6269 - val_output_0_loss: 0.8596 - val_output_1_loss: 0.9060 - val_output_2_loss: 0.9937 - val_output_3_loss: 0.8675 - val_output_0_acc: 0.6327 - val_output_1_acc: 0.6210 - val_output_2_acc: 0.5903 - val_output_3_acc: 0.6198\n",
      "Epoch 35/200\n",
      "2999/2999 [==============================] - 1s 409us/step - loss: 2.9525 - output_0_loss: 0.7190 - output_1_loss: 0.7653 - output_2_loss: 0.7290 - output_3_loss: 0.7393 - output_0_acc: 0.7326 - output_1_acc: 0.7056 - output_2_acc: 0.7412 - output_3_acc: 0.7249 - val_loss: 3.4099 - val_output_0_loss: 0.8434 - val_output_1_loss: 0.8450 - val_output_2_loss: 0.8589 - val_output_3_loss: 0.8627 - val_output_0_acc: 0.6459 - val_output_1_acc: 0.6345 - val_output_2_acc: 0.6674 - val_output_3_acc: 0.6363\n",
      "Epoch 36/200\n",
      "2999/2999 [==============================] - 1s 458us/step - loss: 2.8605 - output_0_loss: 0.7016 - output_1_loss: 0.7433 - output_2_loss: 0.7076 - output_3_loss: 0.7079 - output_0_acc: 0.7432 - output_1_acc: 0.7162 - output_2_acc: 0.7329 - output_3_acc: 0.7449 - val_loss: 3.2896 - val_output_0_loss: 0.7904 - val_output_1_loss: 0.8234 - val_output_2_loss: 0.8509 - val_output_3_loss: 0.8249 - val_output_0_acc: 0.6830 - val_output_1_acc: 0.6799 - val_output_2_acc: 0.6589 - val_output_3_acc: 0.6580\n",
      "Epoch 37/200\n",
      "2999/2999 [==============================] - 1s 419us/step - loss: 2.8174 - output_0_loss: 0.6895 - output_1_loss: 0.7412 - output_2_loss: 0.6911 - output_3_loss: 0.6956 - output_0_acc: 0.7489 - output_1_acc: 0.7259 - output_2_acc: 0.7472 - output_3_acc: 0.7446 - val_loss: 3.2712 - val_output_0_loss: 0.7890 - val_output_1_loss: 0.8697 - val_output_2_loss: 0.7938 - val_output_3_loss: 0.8187 - val_output_0_acc: 0.7056 - val_output_1_acc: 0.6147 - val_output_2_acc: 0.6659 - val_output_3_acc: 0.6647\n",
      "Epoch 38/200\n",
      "2999/2999 [==============================] - 1s 456us/step - loss: 2.7768 - output_0_loss: 0.6790 - output_1_loss: 0.7270 - output_2_loss: 0.6831 - output_3_loss: 0.6877 - output_0_acc: 0.7563 - output_1_acc: 0.7256 - output_2_acc: 0.7479 - output_3_acc: 0.7486 - val_loss: 3.0498 - val_output_0_loss: 0.7306 - val_output_1_loss: 0.8097 - val_output_2_loss: 0.7285 - val_output_3_loss: 0.7810 - val_output_0_acc: 0.7262 - val_output_1_acc: 0.6913 - val_output_2_acc: 0.7192 - val_output_3_acc: 0.6952\n",
      "Epoch 39/200\n",
      "2999/2999 [==============================] - 1s 437us/step - loss: 2.6949 - output_0_loss: 0.6566 - output_1_loss: 0.7032 - output_2_loss: 0.6698 - output_3_loss: 0.6653 - output_0_acc: 0.7673 - output_1_acc: 0.7336 - output_2_acc: 0.7499 - output_3_acc: 0.7589 - val_loss: 3.0591 - val_output_0_loss: 0.7105 - val_output_1_loss: 0.8369 - val_output_2_loss: 0.7135 - val_output_3_loss: 0.7982 - val_output_0_acc: 0.7428 - val_output_1_acc: 0.6732 - val_output_2_acc: 0.7517 - val_output_3_acc: 0.6746\n",
      "Epoch 40/200\n",
      "2999/2999 [==============================] - 1s 458us/step - loss: 2.6295 - output_0_loss: 0.6376 - output_1_loss: 0.6901 - output_2_loss: 0.6473 - output_3_loss: 0.6545 - output_0_acc: 0.7736 - output_1_acc: 0.7332 - output_2_acc: 0.7686 - output_3_acc: 0.7613 - val_loss: 2.9973 - val_output_0_loss: 0.7682 - val_output_1_loss: 0.7535 - val_output_2_loss: 0.7209 - val_output_3_loss: 0.7547 - val_output_0_acc: 0.6614 - val_output_1_acc: 0.7109 - val_output_2_acc: 0.7187 - val_output_3_acc: 0.6890\n",
      "Epoch 41/200\n",
      "2999/2999 [==============================] - 1s 438us/step - loss: 2.5683 - output_0_loss: 0.6353 - output_1_loss: 0.6708 - output_2_loss: 0.6332 - output_3_loss: 0.6290 - output_0_acc: 0.7773 - output_1_acc: 0.7636 - output_2_acc: 0.7796 - output_3_acc: 0.7833 - val_loss: 3.0991 - val_output_0_loss: 0.7255 - val_output_1_loss: 0.8850 - val_output_2_loss: 0.7548 - val_output_3_loss: 0.7338 - val_output_0_acc: 0.7148 - val_output_1_acc: 0.6351 - val_output_2_acc: 0.7030 - val_output_3_acc: 0.7463\n",
      "Epoch 42/200\n",
      "2999/2999 [==============================] - 1s 478us/step - loss: 2.5328 - output_0_loss: 0.6184 - output_1_loss: 0.6647 - output_2_loss: 0.6222 - output_3_loss: 0.6275 - output_0_acc: 0.7763 - output_1_acc: 0.7533 - output_2_acc: 0.7786 - output_3_acc: 0.7776 - val_loss: 3.0307 - val_output_0_loss: 0.7712 - val_output_1_loss: 0.8514 - val_output_2_loss: 0.6916 - val_output_3_loss: 0.7165 - val_output_0_acc: 0.6875 - val_output_1_acc: 0.6643 - val_output_2_acc: 0.7408 - val_output_3_acc: 0.7287\n",
      "Epoch 43/200\n",
      "2999/2999 [==============================] - 1s 453us/step - loss: 2.4716 - output_0_loss: 0.5972 - output_1_loss: 0.6455 - output_2_loss: 0.6106 - output_3_loss: 0.6182 - output_0_acc: 0.8016 - output_1_acc: 0.7669 - output_2_acc: 0.7873 - output_3_acc: 0.7823 - val_loss: 2.8472 - val_output_0_loss: 0.7343 - val_output_1_loss: 0.7407 - val_output_2_loss: 0.6646 - val_output_3_loss: 0.7077 - val_output_0_acc: 0.7127 - val_output_1_acc: 0.6970 - val_output_2_acc: 0.7139 - val_output_3_acc: 0.7293\n",
      "Epoch 44/200\n",
      "2999/2999 [==============================] - 1s 468us/step - loss: 2.4340 - output_0_loss: 0.5991 - output_1_loss: 0.6472 - output_2_loss: 0.5997 - output_3_loss: 0.5880 - output_0_acc: 0.7913 - output_1_acc: 0.7616 - output_2_acc: 0.7976 - output_3_acc: 0.7966 - val_loss: 2.8849 - val_output_0_loss: 0.7325 - val_output_1_loss: 0.7701 - val_output_2_loss: 0.6582 - val_output_3_loss: 0.7241 - val_output_0_acc: 0.7096 - val_output_1_acc: 0.6654 - val_output_2_acc: 0.7365 - val_output_3_acc: 0.6988\n",
      "Epoch 45/200\n",
      "2999/2999 [==============================] - 1s 453us/step - loss: 2.3584 - output_0_loss: 0.5817 - output_1_loss: 0.6246 - output_2_loss: 0.5786 - output_3_loss: 0.5735 - output_0_acc: 0.7979 - output_1_acc: 0.7936 - output_2_acc: 0.8039 - output_3_acc: 0.8046 - val_loss: 2.9166 - val_output_0_loss: 0.7297 - val_output_1_loss: 0.7594 - val_output_2_loss: 0.6732 - val_output_3_loss: 0.7543 - val_output_0_acc: 0.6849 - val_output_1_acc: 0.6842 - val_output_2_acc: 0.7452 - val_output_3_acc: 0.6915\n",
      "Epoch 46/200\n",
      "2999/2999 [==============================] - 1s 456us/step - loss: 2.3181 - output_0_loss: 0.5657 - output_1_loss: 0.6105 - output_2_loss: 0.5633 - output_3_loss: 0.5786 - output_0_acc: 0.8089 - output_1_acc: 0.7859 - output_2_acc: 0.8109 - output_3_acc: 0.7993 - val_loss: 2.7274 - val_output_0_loss: 0.7140 - val_output_1_loss: 0.7534 - val_output_2_loss: 0.6036 - val_output_3_loss: 0.6564 - val_output_0_acc: 0.7040 - val_output_1_acc: 0.6954 - val_output_2_acc: 0.8112 - val_output_3_acc: 0.7381\n",
      "Epoch 47/200\n",
      "2999/2999 [==============================] - 1s 456us/step - loss: 2.2551 - output_0_loss: 0.5470 - output_1_loss: 0.5978 - output_2_loss: 0.5494 - output_3_loss: 0.5609 - output_0_acc: 0.8186 - output_1_acc: 0.7963 - output_2_acc: 0.8179 - output_3_acc: 0.8203 - val_loss: 2.7749 - val_output_0_loss: 0.6209 - val_output_1_loss: 0.7713 - val_output_2_loss: 0.6930 - val_output_3_loss: 0.6896 - val_output_0_acc: 0.7907 - val_output_1_acc: 0.6625 - val_output_2_acc: 0.7170 - val_output_3_acc: 0.7151\n",
      "Epoch 48/200\n",
      "2999/2999 [==============================] - 1s 451us/step - loss: 2.2333 - output_0_loss: 0.5386 - output_1_loss: 0.5936 - output_2_loss: 0.5393 - output_3_loss: 0.5618 - output_0_acc: 0.8303 - output_1_acc: 0.7889 - output_2_acc: 0.8293 - output_3_acc: 0.8086 - val_loss: 2.6344 - val_output_0_loss: 0.6634 - val_output_1_loss: 0.6869 - val_output_2_loss: 0.6370 - val_output_3_loss: 0.6472 - val_output_0_acc: 0.7387 - val_output_1_acc: 0.7342 - val_output_2_acc: 0.7725 - val_output_3_acc: 0.7480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "2999/2999 [==============================] - 1s 401us/step - loss: 2.1689 - output_0_loss: 0.5320 - output_1_loss: 0.5774 - output_2_loss: 0.5315 - output_3_loss: 0.5281 - output_0_acc: 0.8303 - output_1_acc: 0.7963 - output_2_acc: 0.8263 - output_3_acc: 0.8243 - val_loss: 2.6798 - val_output_0_loss: 0.7116 - val_output_1_loss: 0.7517 - val_output_2_loss: 0.5697 - val_output_3_loss: 0.6468 - val_output_0_acc: 0.7585 - val_output_1_acc: 0.6878 - val_output_2_acc: 0.8092 - val_output_3_acc: 0.7528\n",
      "Epoch 50/200\n",
      "2999/2999 [==============================] - 1s 451us/step - loss: 2.1242 - output_0_loss: 0.5170 - output_1_loss: 0.5659 - output_2_loss: 0.5190 - output_3_loss: 0.5223 - output_0_acc: 0.8393 - output_1_acc: 0.8076 - output_2_acc: 0.8363 - output_3_acc: 0.8306 - val_loss: 2.5153 - val_output_0_loss: 0.5940 - val_output_1_loss: 0.7047 - val_output_2_loss: 0.6215 - val_output_3_loss: 0.5951 - val_output_0_acc: 0.7789 - val_output_1_acc: 0.6870 - val_output_2_acc: 0.7574 - val_output_3_acc: 0.7997\n",
      "Epoch 51/200\n",
      "2999/2999 [==============================] - 1s 408us/step - loss: 2.0708 - output_0_loss: 0.5015 - output_1_loss: 0.5524 - output_2_loss: 0.5004 - output_3_loss: 0.5165 - output_0_acc: 0.8396 - output_1_acc: 0.8113 - output_2_acc: 0.8439 - output_3_acc: 0.8389 - val_loss: 2.5585 - val_output_0_loss: 0.6813 - val_output_1_loss: 0.6455 - val_output_2_loss: 0.6305 - val_output_3_loss: 0.6012 - val_output_0_acc: 0.6994 - val_output_1_acc: 0.7532 - val_output_2_acc: 0.7629 - val_output_3_acc: 0.7892\n",
      "Epoch 52/200\n",
      "2999/2999 [==============================] - 1s 456us/step - loss: 2.0388 - output_0_loss: 0.4975 - output_1_loss: 0.5384 - output_2_loss: 0.4967 - output_3_loss: 0.5062 - output_0_acc: 0.8416 - output_1_acc: 0.8189 - output_2_acc: 0.8416 - output_3_acc: 0.8346 - val_loss: 2.4362 - val_output_0_loss: 0.6285 - val_output_1_loss: 0.6095 - val_output_2_loss: 0.6326 - val_output_3_loss: 0.5656 - val_output_0_acc: 0.7392 - val_output_1_acc: 0.7998 - val_output_2_acc: 0.7296 - val_output_3_acc: 0.8158\n",
      "Epoch 53/200\n",
      "2999/2999 [==============================] - 1s 462us/step - loss: 1.9991 - output_0_loss: 0.4771 - output_1_loss: 0.5369 - output_2_loss: 0.4927 - output_3_loss: 0.4924 - output_0_acc: 0.8616 - output_1_acc: 0.8139 - output_2_acc: 0.8479 - output_3_acc: 0.8409 - val_loss: 2.4520 - val_output_0_loss: 0.6185 - val_output_1_loss: 0.7279 - val_output_2_loss: 0.5692 - val_output_3_loss: 0.5364 - val_output_0_acc: 0.7557 - val_output_1_acc: 0.6823 - val_output_2_acc: 0.7988 - val_output_3_acc: 0.8363\n",
      "Epoch 54/200\n",
      "2999/2999 [==============================] - 1s 471us/step - loss: 1.9400 - output_0_loss: 0.4744 - output_1_loss: 0.5117 - output_2_loss: 0.4668 - output_3_loss: 0.4871 - output_0_acc: 0.8546 - output_1_acc: 0.8309 - output_2_acc: 0.8586 - output_3_acc: 0.8416 - val_loss: 2.4954 - val_output_0_loss: 0.5812 - val_output_1_loss: 0.7691 - val_output_2_loss: 0.5656 - val_output_3_loss: 0.5795 - val_output_0_acc: 0.7745 - val_output_1_acc: 0.7128 - val_output_2_acc: 0.8309 - val_output_3_acc: 0.7602\n",
      "Epoch 55/200\n",
      "2999/2999 [==============================] - 1s 418us/step - loss: 1.9154 - output_0_loss: 0.4619 - output_1_loss: 0.5162 - output_2_loss: 0.4649 - output_3_loss: 0.4723 - output_0_acc: 0.8723 - output_1_acc: 0.8303 - output_2_acc: 0.8560 - output_3_acc: 0.8513 - val_loss: 2.3703 - val_output_0_loss: 0.5532 - val_output_1_loss: 0.6485 - val_output_2_loss: 0.5846 - val_output_3_loss: 0.5840 - val_output_0_acc: 0.7917 - val_output_1_acc: 0.7351 - val_output_2_acc: 0.7566 - val_output_3_acc: 0.7707\n",
      "Epoch 56/200\n",
      "2999/2999 [==============================] - 1s 441us/step - loss: 1.8589 - output_0_loss: 0.4557 - output_1_loss: 0.4953 - output_2_loss: 0.4464 - output_3_loss: 0.4616 - output_0_acc: 0.8636 - output_1_acc: 0.8366 - output_2_acc: 0.8746 - output_3_acc: 0.8663 - val_loss: 2.3435 - val_output_0_loss: 0.6478 - val_output_1_loss: 0.5705 - val_output_2_loss: 0.5150 - val_output_3_loss: 0.6102 - val_output_0_acc: 0.7237 - val_output_1_acc: 0.8047 - val_output_2_acc: 0.8346 - val_output_3_acc: 0.7454\n",
      "Epoch 57/200\n",
      "2999/2999 [==============================] - 1s 412us/step - loss: 1.8114 - output_0_loss: 0.4355 - output_1_loss: 0.4885 - output_2_loss: 0.4383 - output_3_loss: 0.4491 - output_0_acc: 0.8773 - output_1_acc: 0.8413 - output_2_acc: 0.8700 - output_3_acc: 0.8683 - val_loss: 2.3268 - val_output_0_loss: 0.5762 - val_output_1_loss: 0.6898 - val_output_2_loss: 0.5308 - val_output_3_loss: 0.5299 - val_output_0_acc: 0.7833 - val_output_1_acc: 0.7283 - val_output_2_acc: 0.8101 - val_output_3_acc: 0.8227\n",
      "Epoch 58/200\n",
      "2999/2999 [==============================] - 1s 425us/step - loss: 1.7897 - output_0_loss: 0.4276 - output_1_loss: 0.4831 - output_2_loss: 0.4410 - output_3_loss: 0.4380 - output_0_acc: 0.8760 - output_1_acc: 0.8436 - output_2_acc: 0.8676 - output_3_acc: 0.8710 - val_loss: 2.2092 - val_output_0_loss: 0.5233 - val_output_1_loss: 0.6209 - val_output_2_loss: 0.4868 - val_output_3_loss: 0.5782 - val_output_0_acc: 0.8249 - val_output_1_acc: 0.7865 - val_output_2_acc: 0.8422 - val_output_3_acc: 0.7852\n",
      "Epoch 59/200\n",
      "2999/2999 [==============================] - 1s 405us/step - loss: 1.7436 - output_0_loss: 0.4185 - output_1_loss: 0.4702 - output_2_loss: 0.4198 - output_3_loss: 0.4352 - output_0_acc: 0.8746 - output_1_acc: 0.8523 - output_2_acc: 0.8776 - output_3_acc: 0.8750 - val_loss: 2.2370 - val_output_0_loss: 0.6567 - val_output_1_loss: 0.5681 - val_output_2_loss: 0.4489 - val_output_3_loss: 0.5633 - val_output_0_acc: 0.7057 - val_output_1_acc: 0.7923 - val_output_2_acc: 0.8767 - val_output_3_acc: 0.7884\n",
      "Epoch 60/200\n",
      "2999/2999 [==============================] - 1s 441us/step - loss: 1.6999 - output_0_loss: 0.4135 - output_1_loss: 0.4600 - output_2_loss: 0.4062 - output_3_loss: 0.4202 - output_0_acc: 0.8763 - output_1_acc: 0.8623 - output_2_acc: 0.8936 - output_3_acc: 0.8793 - val_loss: 2.0561 - val_output_0_loss: 0.4509 - val_output_1_loss: 0.5677 - val_output_2_loss: 0.5162 - val_output_3_loss: 0.5212 - val_output_0_acc: 0.8806 - val_output_1_acc: 0.7775 - val_output_2_acc: 0.7982 - val_output_3_acc: 0.8187\n",
      "Epoch 61/200\n",
      "2999/2999 [==============================] - 1s 444us/step - loss: 1.6827 - output_0_loss: 0.4027 - output_1_loss: 0.4571 - output_2_loss: 0.4052 - output_3_loss: 0.4177 - output_0_acc: 0.8863 - output_1_acc: 0.8613 - output_2_acc: 0.8866 - output_3_acc: 0.8826 - val_loss: 2.0722 - val_output_0_loss: 0.4993 - val_output_1_loss: 0.5146 - val_output_2_loss: 0.5270 - val_output_3_loss: 0.5313 - val_output_0_acc: 0.8209 - val_output_1_acc: 0.8293 - val_output_2_acc: 0.7818 - val_output_3_acc: 0.7971\n",
      "Epoch 62/200\n",
      "2999/2999 [==============================] - 1s 435us/step - loss: 1.6450 - output_0_loss: 0.3936 - output_1_loss: 0.4528 - output_2_loss: 0.3908 - output_3_loss: 0.4078 - output_0_acc: 0.8906 - output_1_acc: 0.8626 - output_2_acc: 0.8970 - output_3_acc: 0.8876 - val_loss: 2.0229 - val_output_0_loss: 0.4392 - val_output_1_loss: 0.5368 - val_output_2_loss: 0.5388 - val_output_3_loss: 0.5080 - val_output_0_acc: 0.8811 - val_output_1_acc: 0.8137 - val_output_2_acc: 0.7955 - val_output_3_acc: 0.8145\n",
      "Epoch 63/200\n",
      "2999/2999 [==============================] - 1s 474us/step - loss: 1.5979 - output_0_loss: 0.3829 - output_1_loss: 0.4450 - output_2_loss: 0.3792 - output_3_loss: 0.3908 - output_0_acc: 0.9043 - output_1_acc: 0.8693 - output_2_acc: 0.8970 - output_3_acc: 0.8890 - val_loss: 2.1327 - val_output_0_loss: 0.4357 - val_output_1_loss: 0.5655 - val_output_2_loss: 0.6008 - val_output_3_loss: 0.5306 - val_output_0_acc: 0.8692 - val_output_1_acc: 0.7783 - val_output_2_acc: 0.7592 - val_output_3_acc: 0.7817\n",
      "Epoch 64/200\n",
      "2999/2999 [==============================] - 1s 435us/step - loss: 1.5678 - output_0_loss: 0.3778 - output_1_loss: 0.4280 - output_2_loss: 0.3726 - output_3_loss: 0.3894 - output_0_acc: 0.8976 - output_1_acc: 0.8726 - output_2_acc: 0.9126 - output_3_acc: 0.8880 - val_loss: 1.9010 - val_output_0_loss: 0.4260 - val_output_1_loss: 0.5198 - val_output_2_loss: 0.4898 - val_output_3_loss: 0.4654 - val_output_0_acc: 0.8846 - val_output_1_acc: 0.8133 - val_output_2_acc: 0.8007 - val_output_3_acc: 0.8599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200\n",
      "2999/2999 [==============================] - 1s 475us/step - loss: 1.5218 - output_0_loss: 0.3661 - output_1_loss: 0.4199 - output_2_loss: 0.3619 - output_3_loss: 0.3738 - output_0_acc: 0.9040 - output_1_acc: 0.8760 - output_2_acc: 0.9050 - output_3_acc: 0.8966 - val_loss: 2.0313 - val_output_0_loss: 0.4631 - val_output_1_loss: 0.6291 - val_output_2_loss: 0.4615 - val_output_3_loss: 0.4777 - val_output_0_acc: 0.8496 - val_output_1_acc: 0.7232 - val_output_2_acc: 0.8436 - val_output_3_acc: 0.8348\n",
      "Epoch 66/200\n",
      "2999/2999 [==============================] - 1s 480us/step - loss: 1.4935 - output_0_loss: 0.3588 - output_1_loss: 0.4104 - output_2_loss: 0.3577 - output_3_loss: 0.3666 - output_0_acc: 0.9120 - output_1_acc: 0.8853 - output_2_acc: 0.9073 - output_3_acc: 0.9016 - val_loss: 1.8045 - val_output_0_loss: 0.4548 - val_output_1_loss: 0.5171 - val_output_2_loss: 0.3888 - val_output_3_loss: 0.4439 - val_output_0_acc: 0.8489 - val_output_1_acc: 0.8107 - val_output_2_acc: 0.9079 - val_output_3_acc: 0.8590\n",
      "Epoch 67/200\n",
      "2999/2999 [==============================] - 1s 466us/step - loss: 1.4609 - output_0_loss: 0.3473 - output_1_loss: 0.4037 - output_2_loss: 0.3521 - output_3_loss: 0.3578 - output_0_acc: 0.9140 - output_1_acc: 0.8840 - output_2_acc: 0.9076 - output_3_acc: 0.9076 - val_loss: 1.8367 - val_output_0_loss: 0.4287 - val_output_1_loss: 0.5096 - val_output_2_loss: 0.4468 - val_output_3_loss: 0.4515 - val_output_0_acc: 0.8575 - val_output_1_acc: 0.8315 - val_output_2_acc: 0.8367 - val_output_3_acc: 0.8538\n",
      "Epoch 68/200\n",
      "2999/2999 [==============================] - 1s 481us/step - loss: 1.4224 - output_0_loss: 0.3403 - output_1_loss: 0.3898 - output_2_loss: 0.3379 - output_3_loss: 0.3544 - output_0_acc: 0.9100 - output_1_acc: 0.8953 - output_2_acc: 0.9213 - output_3_acc: 0.9116 - val_loss: 1.7709 - val_output_0_loss: 0.4663 - val_output_1_loss: 0.4433 - val_output_2_loss: 0.4167 - val_output_3_loss: 0.4447 - val_output_0_acc: 0.8422 - val_output_1_acc: 0.8880 - val_output_2_acc: 0.8767 - val_output_3_acc: 0.8553\n",
      "Epoch 69/200\n",
      "2999/2999 [==============================] - 1s 455us/step - loss: 1.3920 - output_0_loss: 0.3360 - output_1_loss: 0.3879 - output_2_loss: 0.3296 - output_3_loss: 0.3386 - output_0_acc: 0.9123 - output_1_acc: 0.8946 - output_2_acc: 0.9290 - output_3_acc: 0.9190 - val_loss: 1.7850 - val_output_0_loss: 0.3480 - val_output_1_loss: 0.5511 - val_output_2_loss: 0.4469 - val_output_3_loss: 0.4390 - val_output_0_acc: 0.9309 - val_output_1_acc: 0.7756 - val_output_2_acc: 0.8322 - val_output_3_acc: 0.8540\n",
      "Epoch 70/200\n",
      "2999/2999 [==============================] - 1s 402us/step - loss: 1.3780 - output_0_loss: 0.3322 - output_1_loss: 0.3774 - output_2_loss: 0.3282 - output_3_loss: 0.3402 - output_0_acc: 0.9190 - output_1_acc: 0.8980 - output_2_acc: 0.9183 - output_3_acc: 0.9103 - val_loss: 1.7361 - val_output_0_loss: 0.3612 - val_output_1_loss: 0.5457 - val_output_2_loss: 0.3998 - val_output_3_loss: 0.4294 - val_output_0_acc: 0.9150 - val_output_1_acc: 0.7972 - val_output_2_acc: 0.8859 - val_output_3_acc: 0.8564\n",
      "Epoch 71/200\n",
      "2999/2999 [==============================] - 1s 429us/step - loss: 1.3396 - output_0_loss: 0.3159 - output_1_loss: 0.3736 - output_2_loss: 0.3248 - output_3_loss: 0.3254 - output_0_acc: 0.9306 - output_1_acc: 0.8933 - output_2_acc: 0.9246 - output_3_acc: 0.9226 - val_loss: 1.8664 - val_output_0_loss: 0.4160 - val_output_1_loss: 0.4220 - val_output_2_loss: 0.4681 - val_output_3_loss: 0.5603 - val_output_0_acc: 0.8711 - val_output_1_acc: 0.8837 - val_output_2_acc: 0.8077 - val_output_3_acc: 0.7876\n",
      "Epoch 72/200\n",
      "2999/2999 [==============================] - 1s 430us/step - loss: 1.3030 - output_0_loss: 0.3106 - output_1_loss: 0.3666 - output_2_loss: 0.3099 - output_3_loss: 0.3159 - output_0_acc: 0.9280 - output_1_acc: 0.9053 - output_2_acc: 0.9303 - output_3_acc: 0.9233 - val_loss: 1.6226 - val_output_0_loss: 0.3922 - val_output_1_loss: 0.4657 - val_output_2_loss: 0.3451 - val_output_3_loss: 0.4197 - val_output_0_acc: 0.8854 - val_output_1_acc: 0.8228 - val_output_2_acc: 0.9264 - val_output_3_acc: 0.8655\n",
      "Epoch 73/200\n",
      "2999/2999 [==============================] - 1s 441us/step - loss: 1.2805 - output_0_loss: 0.3080 - output_1_loss: 0.3501 - output_2_loss: 0.3052 - output_3_loss: 0.3172 - output_0_acc: 0.9266 - output_1_acc: 0.9070 - output_2_acc: 0.9270 - output_3_acc: 0.9240 - val_loss: 1.6822 - val_output_0_loss: 0.4238 - val_output_1_loss: 0.4967 - val_output_2_loss: 0.3859 - val_output_3_loss: 0.3757 - val_output_0_acc: 0.8543 - val_output_1_acc: 0.8077 - val_output_2_acc: 0.8854 - val_output_3_acc: 0.8896\n",
      "Epoch 74/200\n",
      "2999/2999 [==============================] - 1s 418us/step - loss: 1.2447 - output_0_loss: 0.2963 - output_1_loss: 0.3475 - output_2_loss: 0.2942 - output_3_loss: 0.3066 - output_0_acc: 0.9306 - output_1_acc: 0.9090 - output_2_acc: 0.9340 - output_3_acc: 0.9276 - val_loss: 1.6533 - val_output_0_loss: 0.3864 - val_output_1_loss: 0.4248 - val_output_2_loss: 0.3836 - val_output_3_loss: 0.4584 - val_output_0_acc: 0.8889 - val_output_1_acc: 0.8698 - val_output_2_acc: 0.8943 - val_output_3_acc: 0.8398\n",
      "Epoch 75/200\n",
      "2999/2999 [==============================] - 1s 423us/step - loss: 1.2132 - output_0_loss: 0.2938 - output_1_loss: 0.3392 - output_2_loss: 0.2848 - output_3_loss: 0.2953 - output_0_acc: 0.9346 - output_1_acc: 0.9086 - output_2_acc: 0.9420 - output_3_acc: 0.9320 - val_loss: 1.5743 - val_output_0_loss: 0.4074 - val_output_1_loss: 0.4274 - val_output_2_loss: 0.3680 - val_output_3_loss: 0.3715 - val_output_0_acc: 0.8679 - val_output_1_acc: 0.8478 - val_output_2_acc: 0.8855 - val_output_3_acc: 0.8972\n",
      "Epoch 76/200\n",
      "2999/2999 [==============================] - 1s 397us/step - loss: 1.1859 - output_0_loss: 0.2774 - output_1_loss: 0.3331 - output_2_loss: 0.2826 - output_3_loss: 0.2927 - output_0_acc: 0.9413 - output_1_acc: 0.9136 - output_2_acc: 0.9416 - output_3_acc: 0.9296 - val_loss: 1.5760 - val_output_0_loss: 0.3662 - val_output_1_loss: 0.4434 - val_output_2_loss: 0.3533 - val_output_3_loss: 0.4131 - val_output_0_acc: 0.8875 - val_output_1_acc: 0.8449 - val_output_2_acc: 0.8908 - val_output_3_acc: 0.8476\n",
      "Epoch 77/200\n",
      "2999/2999 [==============================] - 1s 407us/step - loss: 1.1629 - output_0_loss: 0.2801 - output_1_loss: 0.3299 - output_2_loss: 0.2748 - output_3_loss: 0.2781 - output_0_acc: 0.9396 - output_1_acc: 0.9136 - output_2_acc: 0.9373 - output_3_acc: 0.9383 - val_loss: 1.4919 - val_output_0_loss: 0.3385 - val_output_1_loss: 0.4515 - val_output_2_loss: 0.3000 - val_output_3_loss: 0.4020 - val_output_0_acc: 0.9207 - val_output_1_acc: 0.8404 - val_output_2_acc: 0.9516 - val_output_3_acc: 0.8798\n",
      "Epoch 78/200\n",
      "2999/2999 [==============================] - 1s 430us/step - loss: 1.1433 - output_0_loss: 0.2679 - output_1_loss: 0.3253 - output_2_loss: 0.2643 - output_3_loss: 0.2858 - output_0_acc: 0.9483 - output_1_acc: 0.9160 - output_2_acc: 0.9470 - output_3_acc: 0.9373 - val_loss: 1.5959 - val_output_0_loss: 0.4162 - val_output_1_loss: 0.4109 - val_output_2_loss: 0.3388 - val_output_3_loss: 0.4300 - val_output_0_acc: 0.8462 - val_output_1_acc: 0.8547 - val_output_2_acc: 0.9047 - val_output_3_acc: 0.8479\n",
      "Epoch 79/200\n",
      "2999/2999 [==============================] - 1s 420us/step - loss: 1.1143 - output_0_loss: 0.2607 - output_1_loss: 0.3162 - output_2_loss: 0.2627 - output_3_loss: 0.2746 - output_0_acc: 0.9436 - output_1_acc: 0.9243 - output_2_acc: 0.9513 - output_3_acc: 0.9403 - val_loss: 1.4697 - val_output_0_loss: 0.3431 - val_output_1_loss: 0.4128 - val_output_2_loss: 0.3410 - val_output_3_loss: 0.3728 - val_output_0_acc: 0.8908 - val_output_1_acc: 0.8727 - val_output_2_acc: 0.9092 - val_output_3_acc: 0.8926\n",
      "Epoch 80/200\n",
      "2999/2999 [==============================] - 1s 412us/step - loss: 1.0843 - output_0_loss: 0.2638 - output_1_loss: 0.3027 - output_2_loss: 0.2488 - output_3_loss: 0.2689 - output_0_acc: 0.9420 - output_1_acc: 0.9266 - output_2_acc: 0.9500 - output_3_acc: 0.9393 - val_loss: 1.3711 - val_output_0_loss: 0.3388 - val_output_1_loss: 0.3607 - val_output_2_loss: 0.3024 - val_output_3_loss: 0.3693 - val_output_0_acc: 0.9024 - val_output_1_acc: 0.9156 - val_output_2_acc: 0.9399 - val_output_3_acc: 0.8788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "2999/2999 [==============================] - 1s 425us/step - loss: 1.0606 - output_0_loss: 0.2479 - output_1_loss: 0.3091 - output_2_loss: 0.2484 - output_3_loss: 0.2552 - output_0_acc: 0.9527 - output_1_acc: 0.9326 - output_2_acc: 0.9543 - output_3_acc: 0.9483 - val_loss: 1.5230 - val_output_0_loss: 0.3593 - val_output_1_loss: 0.5170 - val_output_2_loss: 0.2981 - val_output_3_loss: 0.3486 - val_output_0_acc: 0.8838 - val_output_1_acc: 0.7622 - val_output_2_acc: 0.9269 - val_output_3_acc: 0.9054\n",
      "Epoch 82/200\n",
      "2999/2999 [==============================] - 1s 437us/step - loss: 1.0300 - output_0_loss: 0.2437 - output_1_loss: 0.2903 - output_2_loss: 0.2379 - output_3_loss: 0.2582 - output_0_acc: 0.9486 - output_1_acc: 0.9333 - output_2_acc: 0.9577 - output_3_acc: 0.9443 - val_loss: 1.4274 - val_output_0_loss: 0.3097 - val_output_1_loss: 0.3841 - val_output_2_loss: 0.3425 - val_output_3_loss: 0.3910 - val_output_0_acc: 0.9206 - val_output_1_acc: 0.8782 - val_output_2_acc: 0.9024 - val_output_3_acc: 0.8517\n",
      "Epoch 83/200\n",
      "2999/2999 [==============================] - 1s 436us/step - loss: 1.0114 - output_0_loss: 0.2435 - output_1_loss: 0.2877 - output_2_loss: 0.2305 - output_3_loss: 0.2497 - output_0_acc: 0.9490 - output_1_acc: 0.9310 - output_2_acc: 0.9580 - output_3_acc: 0.9483 - val_loss: 1.3371 - val_output_0_loss: 0.3010 - val_output_1_loss: 0.4186 - val_output_2_loss: 0.2833 - val_output_3_loss: 0.3342 - val_output_0_acc: 0.9319 - val_output_1_acc: 0.8664 - val_output_2_acc: 0.9419 - val_output_3_acc: 0.9093\n",
      "Epoch 84/200\n",
      "2999/2999 [==============================] - 1s 429us/step - loss: 0.9763 - output_0_loss: 0.2251 - output_1_loss: 0.2825 - output_2_loss: 0.2284 - output_3_loss: 0.2403 - output_0_acc: 0.9583 - output_1_acc: 0.9360 - output_2_acc: 0.9537 - output_3_acc: 0.9466 - val_loss: 1.3454 - val_output_0_loss: 0.3222 - val_output_1_loss: 0.4051 - val_output_2_loss: 0.3147 - val_output_3_loss: 0.3034 - val_output_0_acc: 0.9110 - val_output_1_acc: 0.8767 - val_output_2_acc: 0.9042 - val_output_3_acc: 0.9228\n",
      "Epoch 85/200\n",
      "2999/2999 [==============================] - 1s 431us/step - loss: 0.9567 - output_0_loss: 0.2242 - output_1_loss: 0.2740 - output_2_loss: 0.2177 - output_3_loss: 0.2407 - output_0_acc: 0.9607 - output_1_acc: 0.9376 - output_2_acc: 0.9667 - output_3_acc: 0.9507 - val_loss: 1.2868 - val_output_0_loss: 0.2797 - val_output_1_loss: 0.3905 - val_output_2_loss: 0.2972 - val_output_3_loss: 0.3194 - val_output_0_acc: 0.9281 - val_output_1_acc: 0.8781 - val_output_2_acc: 0.9178 - val_output_3_acc: 0.9074\n",
      "Epoch 86/200\n",
      "2999/2999 [==============================] - 1s 450us/step - loss: 0.9359 - output_0_loss: 0.2158 - output_1_loss: 0.2722 - output_2_loss: 0.2179 - output_3_loss: 0.2300 - output_0_acc: 0.9630 - output_1_acc: 0.9340 - output_2_acc: 0.9633 - output_3_acc: 0.9540 - val_loss: 1.3589 - val_output_0_loss: 0.3306 - val_output_1_loss: 0.3692 - val_output_2_loss: 0.3369 - val_output_3_loss: 0.3222 - val_output_0_acc: 0.8959 - val_output_1_acc: 0.8883 - val_output_2_acc: 0.8968 - val_output_3_acc: 0.8999\n",
      "Epoch 87/200\n",
      "2999/2999 [==============================] - 1s 446us/step - loss: 0.9146 - output_0_loss: 0.2132 - output_1_loss: 0.2637 - output_2_loss: 0.2112 - output_3_loss: 0.2266 - output_0_acc: 0.9607 - output_1_acc: 0.9423 - output_2_acc: 0.9630 - output_3_acc: 0.9557 - val_loss: 1.3135 - val_output_0_loss: 0.3011 - val_output_1_loss: 0.4734 - val_output_2_loss: 0.2439 - val_output_3_loss: 0.2950 - val_output_0_acc: 0.9019 - val_output_1_acc: 0.8149 - val_output_2_acc: 0.9576 - val_output_3_acc: 0.9302\n",
      "Epoch 88/200\n",
      "2999/2999 [==============================] - 1s 422us/step - loss: 0.9090 - output_0_loss: 0.2127 - output_1_loss: 0.2671 - output_2_loss: 0.2093 - output_3_loss: 0.2199 - output_0_acc: 0.9570 - output_1_acc: 0.9403 - output_2_acc: 0.9607 - output_3_acc: 0.9570 - val_loss: 1.1877 - val_output_0_loss: 0.3123 - val_output_1_loss: 0.3277 - val_output_2_loss: 0.2444 - val_output_3_loss: 0.3033 - val_output_0_acc: 0.9047 - val_output_1_acc: 0.9179 - val_output_2_acc: 0.9476 - val_output_3_acc: 0.9114\n",
      "Epoch 89/200\n",
      "2999/2999 [==============================] - 1s 431us/step - loss: 0.8681 - output_0_loss: 0.2000 - output_1_loss: 0.2511 - output_2_loss: 0.2019 - output_3_loss: 0.2151 - output_0_acc: 0.9667 - output_1_acc: 0.9523 - output_2_acc: 0.9690 - output_3_acc: 0.9600 - val_loss: 1.1510 - val_output_0_loss: 0.2964 - val_output_1_loss: 0.3536 - val_output_2_loss: 0.2223 - val_output_3_loss: 0.2787 - val_output_0_acc: 0.9218 - val_output_1_acc: 0.8857 - val_output_2_acc: 0.9701 - val_output_3_acc: 0.9147\n",
      "Epoch 90/200\n",
      "2999/2999 [==============================] - 1s 444us/step - loss: 0.8567 - output_0_loss: 0.2019 - output_1_loss: 0.2507 - output_2_loss: 0.1943 - output_3_loss: 0.2098 - output_0_acc: 0.9660 - output_1_acc: 0.9420 - output_2_acc: 0.9720 - output_3_acc: 0.9657 - val_loss: 1.2279 - val_output_0_loss: 0.2916 - val_output_1_loss: 0.3017 - val_output_2_loss: 0.3935 - val_output_3_loss: 0.2410 - val_output_0_acc: 0.9167 - val_output_1_acc: 0.9302 - val_output_2_acc: 0.8425 - val_output_3_acc: 0.9637\n",
      "Epoch 91/200\n",
      "2999/2999 [==============================] - 1s 402us/step - loss: 0.8235 - output_0_loss: 0.1891 - output_1_loss: 0.2398 - output_2_loss: 0.1931 - output_3_loss: 0.2015 - output_0_acc: 0.9680 - output_1_acc: 0.9533 - output_2_acc: 0.9723 - output_3_acc: 0.9630 - val_loss: 1.1604 - val_output_0_loss: 0.2468 - val_output_1_loss: 0.3162 - val_output_2_loss: 0.2229 - val_output_3_loss: 0.3746 - val_output_0_acc: 0.9493 - val_output_1_acc: 0.9196 - val_output_2_acc: 0.9591 - val_output_3_acc: 0.8637\n",
      "Epoch 92/200\n",
      "2999/2999 [==============================] - 1s 397us/step - loss: 0.8068 - output_0_loss: 0.1877 - output_1_loss: 0.2350 - output_2_loss: 0.1820 - output_3_loss: 0.2021 - output_0_acc: 0.9677 - output_1_acc: 0.9537 - output_2_acc: 0.9757 - output_3_acc: 0.9647 - val_loss: 1.1982 - val_output_0_loss: 0.2285 - val_output_1_loss: 0.3164 - val_output_2_loss: 0.3179 - val_output_3_loss: 0.3355 - val_output_0_acc: 0.9524 - val_output_1_acc: 0.9117 - val_output_2_acc: 0.9115 - val_output_3_acc: 0.8877\n",
      "Epoch 93/200\n",
      "2999/2999 [==============================] - 1s 407us/step - loss: 0.7980 - output_0_loss: 0.1871 - output_1_loss: 0.2383 - output_2_loss: 0.1769 - output_3_loss: 0.1957 - output_0_acc: 0.9703 - output_1_acc: 0.9540 - output_2_acc: 0.9760 - output_3_acc: 0.9613 - val_loss: 1.1747 - val_output_0_loss: 0.2710 - val_output_1_loss: 0.3040 - val_output_2_loss: 0.2789 - val_output_3_loss: 0.3208 - val_output_0_acc: 0.9327 - val_output_1_acc: 0.9141 - val_output_2_acc: 0.9231 - val_output_3_acc: 0.8966\n",
      "Epoch 94/200\n",
      "2999/2999 [==============================] - 1s 434us/step - loss: 0.7746 - output_0_loss: 0.1820 - output_1_loss: 0.2259 - output_2_loss: 0.1761 - output_3_loss: 0.1906 - output_0_acc: 0.9720 - output_1_acc: 0.9587 - output_2_acc: 0.9720 - output_3_acc: 0.9700 - val_loss: 1.0523 - val_output_0_loss: 0.2173 - val_output_1_loss: 0.3512 - val_output_2_loss: 0.1989 - val_output_3_loss: 0.2849 - val_output_0_acc: 0.9629 - val_output_1_acc: 0.8737 - val_output_2_acc: 0.9707 - val_output_3_acc: 0.9250\n",
      "Epoch 95/200\n",
      "2999/2999 [==============================] - 1s 444us/step - loss: 0.7566 - output_0_loss: 0.1761 - output_1_loss: 0.2212 - output_2_loss: 0.1725 - output_3_loss: 0.1868 - output_0_acc: 0.9677 - output_1_acc: 0.9617 - output_2_acc: 0.9747 - output_3_acc: 0.9680 - val_loss: 1.0889 - val_output_0_loss: 0.2475 - val_output_1_loss: 0.3266 - val_output_2_loss: 0.2568 - val_output_3_loss: 0.2580 - val_output_0_acc: 0.9443 - val_output_1_acc: 0.8937 - val_output_2_acc: 0.9117 - val_output_3_acc: 0.9318\n",
      "Epoch 96/200\n",
      "2999/2999 [==============================] - 1s 451us/step - loss: 0.7336 - output_0_loss: 0.1744 - output_1_loss: 0.2169 - output_2_loss: 0.1655 - output_3_loss: 0.1769 - output_0_acc: 0.9713 - output_1_acc: 0.9603 - output_2_acc: 0.9740 - output_3_acc: 0.9720 - val_loss: 1.1044 - val_output_0_loss: 0.3024 - val_output_1_loss: 0.3311 - val_output_2_loss: 0.2288 - val_output_3_loss: 0.2421 - val_output_0_acc: 0.8858 - val_output_1_acc: 0.8962 - val_output_2_acc: 0.9442 - val_output_3_acc: 0.9372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "2999/2999 [==============================] - 1s 446us/step - loss: 0.7171 - output_0_loss: 0.1664 - output_1_loss: 0.2117 - output_2_loss: 0.1642 - output_3_loss: 0.1748 - output_0_acc: 0.9713 - output_1_acc: 0.9580 - output_2_acc: 0.9717 - output_3_acc: 0.9737 - val_loss: 1.1522 - val_output_0_loss: 0.3530 - val_output_1_loss: 0.3228 - val_output_2_loss: 0.2332 - val_output_3_loss: 0.2431 - val_output_0_acc: 0.8588 - val_output_1_acc: 0.9124 - val_output_2_acc: 0.9409 - val_output_3_acc: 0.9301\n",
      "Epoch 98/200\n",
      "2999/2999 [==============================] - 1s 456us/step - loss: 0.6989 - output_0_loss: 0.1656 - output_1_loss: 0.2064 - output_2_loss: 0.1591 - output_3_loss: 0.1679 - output_0_acc: 0.9760 - output_1_acc: 0.9627 - output_2_acc: 0.9793 - output_3_acc: 0.9730 - val_loss: 1.0532 - val_output_0_loss: 0.3012 - val_output_1_loss: 0.3108 - val_output_2_loss: 0.2264 - val_output_3_loss: 0.2148 - val_output_0_acc: 0.9068 - val_output_1_acc: 0.9158 - val_output_2_acc: 0.9606 - val_output_3_acc: 0.9591\n",
      "Epoch 99/200\n",
      "2999/2999 [==============================] - 1s 462us/step - loss: 0.6891 - output_0_loss: 0.1606 - output_1_loss: 0.2015 - output_2_loss: 0.1559 - output_3_loss: 0.1712 - output_0_acc: 0.9773 - output_1_acc: 0.9647 - output_2_acc: 0.9760 - output_3_acc: 0.9710 - val_loss: 0.9275 - val_output_0_loss: 0.2045 - val_output_1_loss: 0.2860 - val_output_2_loss: 0.2099 - val_output_3_loss: 0.2271 - val_output_0_acc: 0.9638 - val_output_1_acc: 0.9228 - val_output_2_acc: 0.9557 - val_output_3_acc: 0.9400\n",
      "Epoch 100/200\n",
      "2999/2999 [==============================] - 1s 470us/step - loss: 0.6587 - output_0_loss: 0.1492 - output_1_loss: 0.1963 - output_2_loss: 0.1503 - output_3_loss: 0.1629 - output_0_acc: 0.9770 - output_1_acc: 0.9663 - output_2_acc: 0.9810 - output_3_acc: 0.9733 - val_loss: 0.9358 - val_output_0_loss: 0.2935 - val_output_1_loss: 0.2314 - val_output_2_loss: 0.1798 - val_output_3_loss: 0.2311 - val_output_0_acc: 0.8962 - val_output_1_acc: 0.9619 - val_output_2_acc: 0.9657 - val_output_3_acc: 0.9378\n",
      "Epoch 101/200\n",
      "2999/2999 [==============================] - 1s 447us/step - loss: 0.6507 - output_0_loss: 0.1510 - output_1_loss: 0.1952 - output_2_loss: 0.1464 - output_3_loss: 0.1581 - output_0_acc: 0.9790 - output_1_acc: 0.9647 - output_2_acc: 0.9797 - output_3_acc: 0.9747 - val_loss: 0.8747 - val_output_0_loss: 0.2003 - val_output_1_loss: 0.2754 - val_output_2_loss: 0.1936 - val_output_3_loss: 0.2055 - val_output_0_acc: 0.9570 - val_output_1_acc: 0.9238 - val_output_2_acc: 0.9670 - val_output_3_acc: 0.9590\n",
      "Epoch 102/200\n",
      "2999/2999 [==============================] - 1s 424us/step - loss: 0.6294 - output_0_loss: 0.1454 - output_1_loss: 0.1871 - output_2_loss: 0.1452 - output_3_loss: 0.1517 - output_0_acc: 0.9840 - output_1_acc: 0.9680 - output_2_acc: 0.9810 - output_3_acc: 0.9757 - val_loss: 0.9071 - val_output_0_loss: 0.2424 - val_output_1_loss: 0.2857 - val_output_2_loss: 0.1532 - val_output_3_loss: 0.2258 - val_output_0_acc: 0.9419 - val_output_1_acc: 0.8992 - val_output_2_acc: 0.9844 - val_output_3_acc: 0.9447\n",
      "Epoch 103/200\n",
      "2999/2999 [==============================] - 1s 399us/step - loss: 0.6199 - output_0_loss: 0.1474 - output_1_loss: 0.1855 - output_2_loss: 0.1371 - output_3_loss: 0.1499 - output_0_acc: 0.9803 - output_1_acc: 0.9713 - output_2_acc: 0.9833 - output_3_acc: 0.9790 - val_loss: 0.8668 - val_output_0_loss: 0.1852 - val_output_1_loss: 0.2499 - val_output_2_loss: 0.1595 - val_output_3_loss: 0.2723 - val_output_0_acc: 0.9706 - val_output_1_acc: 0.9450 - val_output_2_acc: 0.9795 - val_output_3_acc: 0.9054\n",
      "Epoch 104/200\n",
      "2999/2999 [==============================] - 1s 436us/step - loss: 0.5978 - output_0_loss: 0.1391 - output_1_loss: 0.1784 - output_2_loss: 0.1324 - output_3_loss: 0.1479 - output_0_acc: 0.9803 - output_1_acc: 0.9713 - output_2_acc: 0.9867 - output_3_acc: 0.9760 - val_loss: 0.9157 - val_output_0_loss: 0.1988 - val_output_1_loss: 0.2782 - val_output_2_loss: 0.1952 - val_output_3_loss: 0.2435 - val_output_0_acc: 0.9685 - val_output_1_acc: 0.9159 - val_output_2_acc: 0.9704 - val_output_3_acc: 0.9338\n",
      "Epoch 105/200\n",
      "2999/2999 [==============================] - 1s 426us/step - loss: 0.5891 - output_0_loss: 0.1347 - output_1_loss: 0.1768 - output_2_loss: 0.1325 - output_3_loss: 0.1452 - output_0_acc: 0.9823 - output_1_acc: 0.9727 - output_2_acc: 0.9827 - output_3_acc: 0.9793 - val_loss: 0.9896 - val_output_0_loss: 0.2227 - val_output_1_loss: 0.3303 - val_output_2_loss: 0.2218 - val_output_3_loss: 0.2147 - val_output_0_acc: 0.9446 - val_output_1_acc: 0.8744 - val_output_2_acc: 0.9368 - val_output_3_acc: 0.9468\n",
      "Epoch 106/200\n",
      "2999/2999 [==============================] - 1s 430us/step - loss: 0.5762 - output_0_loss: 0.1301 - output_1_loss: 0.1760 - output_2_loss: 0.1274 - output_3_loss: 0.1427 - output_0_acc: 0.9827 - output_1_acc: 0.9710 - output_2_acc: 0.9853 - output_3_acc: 0.9773 - val_loss: 0.7532 - val_output_0_loss: 0.1746 - val_output_1_loss: 0.2235 - val_output_2_loss: 0.1508 - val_output_3_loss: 0.2043 - val_output_0_acc: 0.9682 - val_output_1_acc: 0.9560 - val_output_2_acc: 0.9831 - val_output_3_acc: 0.9514\n",
      "Epoch 107/200\n",
      "2999/2999 [==============================] - 1s 392us/step - loss: 0.5515 - output_0_loss: 0.1248 - output_1_loss: 0.1651 - output_2_loss: 0.1241 - output_3_loss: 0.1375 - output_0_acc: 0.9863 - output_1_acc: 0.9760 - output_2_acc: 0.9820 - output_3_acc: 0.9823 - val_loss: 0.9580 - val_output_0_loss: 0.1872 - val_output_1_loss: 0.2554 - val_output_2_loss: 0.2095 - val_output_3_loss: 0.3059 - val_output_0_acc: 0.9577 - val_output_1_acc: 0.9270 - val_output_2_acc: 0.9513 - val_output_3_acc: 0.8959\n",
      "Epoch 108/200\n",
      "2999/2999 [==============================] - 1s 419us/step - loss: 0.5418 - output_0_loss: 0.1198 - output_1_loss: 0.1680 - output_2_loss: 0.1211 - output_3_loss: 0.1329 - output_0_acc: 0.9863 - output_1_acc: 0.9723 - output_2_acc: 0.9847 - output_3_acc: 0.9817 - val_loss: 0.7465 - val_output_0_loss: 0.1551 - val_output_1_loss: 0.2443 - val_output_2_loss: 0.1553 - val_output_3_loss: 0.1918 - val_output_0_acc: 0.9791 - val_output_1_acc: 0.9372 - val_output_2_acc: 0.9676 - val_output_3_acc: 0.9490\n",
      "Epoch 109/200\n",
      "2999/2999 [==============================] - 1s 453us/step - loss: 0.5317 - output_0_loss: 0.1237 - output_1_loss: 0.1626 - output_2_loss: 0.1172 - output_3_loss: 0.1283 - output_0_acc: 0.9857 - output_1_acc: 0.9717 - output_2_acc: 0.9867 - output_3_acc: 0.9833 - val_loss: 0.8681 - val_output_0_loss: 0.1887 - val_output_1_loss: 0.2446 - val_output_2_loss: 0.1995 - val_output_3_loss: 0.2353 - val_output_0_acc: 0.9526 - val_output_1_acc: 0.9265 - val_output_2_acc: 0.9536 - val_output_3_acc: 0.9286\n",
      "Epoch 110/200\n",
      "2999/2999 [==============================] - 1s 411us/step - loss: 0.5140 - output_0_loss: 0.1166 - output_1_loss: 0.1551 - output_2_loss: 0.1171 - output_3_loss: 0.1252 - output_0_acc: 0.9873 - output_1_acc: 0.9760 - output_2_acc: 0.9857 - output_3_acc: 0.9817 - val_loss: 0.8248 - val_output_0_loss: 0.1562 - val_output_1_loss: 0.2553 - val_output_2_loss: 0.1867 - val_output_3_loss: 0.2266 - val_output_0_acc: 0.9794 - val_output_1_acc: 0.9189 - val_output_2_acc: 0.9641 - val_output_3_acc: 0.9426\n",
      "Epoch 111/200\n",
      "2999/2999 [==============================] - 1s 420us/step - loss: 0.5080 - output_0_loss: 0.1209 - output_1_loss: 0.1545 - output_2_loss: 0.1111 - output_3_loss: 0.1215 - output_0_acc: 0.9860 - output_1_acc: 0.9807 - output_2_acc: 0.9883 - output_3_acc: 0.9830 - val_loss: 0.7770 - val_output_0_loss: 0.1779 - val_output_1_loss: 0.2716 - val_output_2_loss: 0.1558 - val_output_3_loss: 0.1717 - val_output_0_acc: 0.9626 - val_output_1_acc: 0.9006 - val_output_2_acc: 0.9701 - val_output_3_acc: 0.9630\n",
      "Epoch 112/200\n",
      "2999/2999 [==============================] - 1s 437us/step - loss: 0.4893 - output_0_loss: 0.1099 - output_1_loss: 0.1483 - output_2_loss: 0.1090 - output_3_loss: 0.1220 - output_0_acc: 0.9870 - output_1_acc: 0.9790 - output_2_acc: 0.9877 - output_3_acc: 0.9823 - val_loss: 0.7504 - val_output_0_loss: 0.1766 - val_output_1_loss: 0.2312 - val_output_2_loss: 0.1261 - val_output_3_loss: 0.2164 - val_output_0_acc: 0.9569 - val_output_1_acc: 0.9457 - val_output_2_acc: 0.9879 - val_output_3_acc: 0.9261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/200\n",
      "2999/2999 [==============================] - 1s 446us/step - loss: 0.4779 - output_0_loss: 0.1114 - output_1_loss: 0.1475 - output_2_loss: 0.1037 - output_3_loss: 0.1153 - output_0_acc: 0.9880 - output_1_acc: 0.9790 - output_2_acc: 0.9910 - output_3_acc: 0.9857 - val_loss: 0.8577 - val_output_0_loss: 0.1690 - val_output_1_loss: 0.1918 - val_output_2_loss: 0.3261 - val_output_3_loss: 0.1709 - val_output_0_acc: 0.9573 - val_output_1_acc: 0.9673 - val_output_2_acc: 0.8884 - val_output_3_acc: 0.9587\n",
      "Epoch 114/200\n",
      "2999/2999 [==============================] - 1s 432us/step - loss: 0.4747 - output_0_loss: 0.1062 - output_1_loss: 0.1455 - output_2_loss: 0.1064 - output_3_loss: 0.1165 - output_0_acc: 0.9863 - output_1_acc: 0.9800 - output_2_acc: 0.9850 - output_3_acc: 0.9827 - val_loss: 0.7369 - val_output_0_loss: 0.1663 - val_output_1_loss: 0.1871 - val_output_2_loss: 0.1666 - val_output_3_loss: 0.2169 - val_output_0_acc: 0.9585 - val_output_1_acc: 0.9614 - val_output_2_acc: 0.9613 - val_output_3_acc: 0.9371\n",
      "Epoch 115/200\n",
      "2999/2999 [==============================] - 1s 419us/step - loss: 0.4607 - output_0_loss: 0.1075 - output_1_loss: 0.1400 - output_2_loss: 0.1013 - output_3_loss: 0.1118 - output_0_acc: 0.9887 - output_1_acc: 0.9817 - output_2_acc: 0.9887 - output_3_acc: 0.9860 - val_loss: 0.6991 - val_output_0_loss: 0.1866 - val_output_1_loss: 0.2363 - val_output_2_loss: 0.1241 - val_output_3_loss: 0.1522 - val_output_0_acc: 0.9567 - val_output_1_acc: 0.9264 - val_output_2_acc: 0.9880 - val_output_3_acc: 0.9702\n",
      "Epoch 116/200\n",
      "2999/2999 [==============================] - 1s 415us/step - loss: 0.4451 - output_0_loss: 0.1001 - output_1_loss: 0.1363 - output_2_loss: 0.1003 - output_3_loss: 0.1085 - output_0_acc: 0.9893 - output_1_acc: 0.9823 - output_2_acc: 0.9913 - output_3_acc: 0.9847 - val_loss: 0.7148 - val_output_0_loss: 0.1651 - val_output_1_loss: 0.2442 - val_output_2_loss: 0.1557 - val_output_3_loss: 0.1497 - val_output_0_acc: 0.9630 - val_output_1_acc: 0.9240 - val_output_2_acc: 0.9669 - val_output_3_acc: 0.9711\n",
      "Epoch 117/200\n",
      "2999/2999 [==============================] - 1s 480us/step - loss: 0.4400 - output_0_loss: 0.1018 - output_1_loss: 0.1376 - output_2_loss: 0.0951 - output_3_loss: 0.1055 - output_0_acc: 0.9880 - output_1_acc: 0.9823 - output_2_acc: 0.9920 - output_3_acc: 0.9857 - val_loss: 0.5606 - val_output_0_loss: 0.1077 - val_output_1_loss: 0.1543 - val_output_2_loss: 0.1466 - val_output_3_loss: 0.1519 - val_output_0_acc: 0.9882 - val_output_1_acc: 0.9757 - val_output_2_acc: 0.9632 - val_output_3_acc: 0.9644\n",
      "Epoch 118/200\n",
      "2999/2999 [==============================] - 1s 418us/step - loss: 0.4196 - output_0_loss: 0.0941 - output_1_loss: 0.1298 - output_2_loss: 0.0923 - output_3_loss: 0.1036 - output_0_acc: 0.9913 - output_1_acc: 0.9817 - output_2_acc: 0.9910 - output_3_acc: 0.9887 - val_loss: 0.6174 - val_output_0_loss: 0.1848 - val_output_1_loss: 0.2227 - val_output_2_loss: 0.0972 - val_output_3_loss: 0.1127 - val_output_0_acc: 0.9480 - val_output_1_acc: 0.9270 - val_output_2_acc: 0.9944 - val_output_3_acc: 0.9889\n",
      "Epoch 119/200\n",
      "2999/2999 [==============================] - 1s 415us/step - loss: 0.4158 - output_0_loss: 0.0941 - output_1_loss: 0.1277 - output_2_loss: 0.0945 - output_3_loss: 0.0994 - output_0_acc: 0.9900 - output_1_acc: 0.9837 - output_2_acc: 0.9897 - output_3_acc: 0.9883 - val_loss: 0.6690 - val_output_0_loss: 0.1854 - val_output_1_loss: 0.1903 - val_output_2_loss: 0.1116 - val_output_3_loss: 0.1817 - val_output_0_acc: 0.9339 - val_output_1_acc: 0.9563 - val_output_2_acc: 0.9789 - val_output_3_acc: 0.9420\n",
      "Epoch 120/200\n",
      "2999/2999 [==============================] - 1s 433us/step - loss: 0.4033 - output_0_loss: 0.0917 - output_1_loss: 0.1241 - output_2_loss: 0.0881 - output_3_loss: 0.0994 - output_0_acc: 0.9903 - output_1_acc: 0.9880 - output_2_acc: 0.9897 - output_3_acc: 0.9880 - val_loss: 0.6194 - val_output_0_loss: 0.1324 - val_output_1_loss: 0.1935 - val_output_2_loss: 0.1226 - val_output_3_loss: 0.1708 - val_output_0_acc: 0.9812 - val_output_1_acc: 0.9523 - val_output_2_acc: 0.9731 - val_output_3_acc: 0.9627\n",
      "Epoch 121/200\n",
      "2999/2999 [==============================] - 1s 410us/step - loss: 0.3967 - output_0_loss: 0.0935 - output_1_loss: 0.1203 - output_2_loss: 0.0862 - output_3_loss: 0.0967 - output_0_acc: 0.9893 - output_1_acc: 0.9870 - output_2_acc: 0.9900 - output_3_acc: 0.9893 - val_loss: 0.5254 - val_output_0_loss: 0.1027 - val_output_1_loss: 0.1728 - val_output_2_loss: 0.1071 - val_output_3_loss: 0.1427 - val_output_0_acc: 0.9861 - val_output_1_acc: 0.9691 - val_output_2_acc: 0.9920 - val_output_3_acc: 0.9737\n",
      "Epoch 122/200\n",
      "2999/2999 [==============================] - 1s 436us/step - loss: 0.3812 - output_0_loss: 0.0865 - output_1_loss: 0.1213 - output_2_loss: 0.0817 - output_3_loss: 0.0918 - output_0_acc: 0.9927 - output_1_acc: 0.9827 - output_2_acc: 0.9930 - output_3_acc: 0.9903 - val_loss: 0.7271 - val_output_0_loss: 0.1981 - val_output_1_loss: 0.1814 - val_output_2_loss: 0.1833 - val_output_3_loss: 0.1643 - val_output_0_acc: 0.9314 - val_output_1_acc: 0.9649 - val_output_2_acc: 0.9600 - val_output_3_acc: 0.9659\n",
      "Epoch 123/200\n",
      "2999/2999 [==============================] - 1s 452us/step - loss: 0.3701 - output_0_loss: 0.0840 - output_1_loss: 0.1146 - output_2_loss: 0.0797 - output_3_loss: 0.0918 - output_0_acc: 0.9897 - output_1_acc: 0.9853 - output_2_acc: 0.9923 - output_3_acc: 0.9870 - val_loss: 0.6039 - val_output_0_loss: 0.1623 - val_output_1_loss: 0.2019 - val_output_2_loss: 0.1247 - val_output_3_loss: 0.1149 - val_output_0_acc: 0.9611 - val_output_1_acc: 0.9497 - val_output_2_acc: 0.9723 - val_output_3_acc: 0.9824\n",
      "Epoch 124/200\n",
      "2999/2999 [==============================] - 1s 420us/step - loss: 0.3670 - output_0_loss: 0.0839 - output_1_loss: 0.1134 - output_2_loss: 0.0798 - output_3_loss: 0.0899 - output_0_acc: 0.9917 - output_1_acc: 0.9897 - output_2_acc: 0.9920 - output_3_acc: 0.9883 - val_loss: 0.5310 - val_output_0_loss: 0.1396 - val_output_1_loss: 0.1513 - val_output_2_loss: 0.1131 - val_output_3_loss: 0.1271 - val_output_0_acc: 0.9750 - val_output_1_acc: 0.9726 - val_output_2_acc: 0.9818 - val_output_3_acc: 0.9752\n",
      "Epoch 125/200\n",
      "2999/2999 [==============================] - 1s 451us/step - loss: 0.3530 - output_0_loss: 0.0820 - output_1_loss: 0.1114 - output_2_loss: 0.0759 - output_3_loss: 0.0836 - output_0_acc: 0.9910 - output_1_acc: 0.9857 - output_2_acc: 0.9940 - output_3_acc: 0.9920 - val_loss: 0.5873 - val_output_0_loss: 0.1484 - val_output_1_loss: 0.1873 - val_output_2_loss: 0.1365 - val_output_3_loss: 0.1149 - val_output_0_acc: 0.9717 - val_output_1_acc: 0.9509 - val_output_2_acc: 0.9672 - val_output_3_acc: 0.9848\n",
      "Epoch 126/200\n",
      "2999/2999 [==============================] - 1s 440us/step - loss: 0.3440 - output_0_loss: 0.0822 - output_1_loss: 0.1045 - output_2_loss: 0.0730 - output_3_loss: 0.0843 - output_0_acc: 0.9903 - output_1_acc: 0.9890 - output_2_acc: 0.9933 - output_3_acc: 0.9907 - val_loss: 0.5314 - val_output_0_loss: 0.1013 - val_output_1_loss: 0.1781 - val_output_2_loss: 0.1150 - val_output_3_loss: 0.1370 - val_output_0_acc: 0.9927 - val_output_1_acc: 0.9645 - val_output_2_acc: 0.9804 - val_output_3_acc: 0.9772\n",
      "Epoch 127/200\n",
      "2999/2999 [==============================] - 1s 454us/step - loss: 0.3382 - output_0_loss: 0.0801 - output_1_loss: 0.1036 - output_2_loss: 0.0722 - output_3_loss: 0.0822 - output_0_acc: 0.9910 - output_1_acc: 0.9887 - output_2_acc: 0.9930 - output_3_acc: 0.9930 - val_loss: 0.5489 - val_output_0_loss: 0.1307 - val_output_1_loss: 0.2197 - val_output_2_loss: 0.0957 - val_output_3_loss: 0.1028 - val_output_0_acc: 0.9767 - val_output_1_acc: 0.9072 - val_output_2_acc: 0.9847 - val_output_3_acc: 0.9856\n",
      "Epoch 128/200\n",
      "2999/2999 [==============================] - 1s 431us/step - loss: 0.3311 - output_0_loss: 0.0752 - output_1_loss: 0.1020 - output_2_loss: 0.0726 - output_3_loss: 0.0814 - output_0_acc: 0.9950 - output_1_acc: 0.9887 - output_2_acc: 0.9933 - output_3_acc: 0.9890 - val_loss: 0.4851 - val_output_0_loss: 0.1199 - val_output_1_loss: 0.1456 - val_output_2_loss: 0.1091 - val_output_3_loss: 0.1104 - val_output_0_acc: 0.9887 - val_output_1_acc: 0.9711 - val_output_2_acc: 0.9855 - val_output_3_acc: 0.9781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/200\n",
      "2999/2999 [==============================] - 1s 421us/step - loss: 0.3238 - output_0_loss: 0.0725 - output_1_loss: 0.1046 - output_2_loss: 0.0696 - output_3_loss: 0.0771 - output_0_acc: 0.9943 - output_1_acc: 0.9850 - output_2_acc: 0.9927 - output_3_acc: 0.9933 - val_loss: 0.5332 - val_output_0_loss: 0.1163 - val_output_1_loss: 0.2108 - val_output_2_loss: 0.0920 - val_output_3_loss: 0.1141 - val_output_0_acc: 0.9826 - val_output_1_acc: 0.9247 - val_output_2_acc: 0.9927 - val_output_3_acc: 0.9816\n",
      "Epoch 130/200\n",
      "2999/2999 [==============================] - 1s 419us/step - loss: 0.3126 - output_0_loss: 0.0708 - output_1_loss: 0.0976 - output_2_loss: 0.0690 - output_3_loss: 0.0752 - output_0_acc: 0.9930 - output_1_acc: 0.9893 - output_2_acc: 0.9937 - output_3_acc: 0.9913 - val_loss: 0.5109 - val_output_0_loss: 0.1341 - val_output_1_loss: 0.1246 - val_output_2_loss: 0.0905 - val_output_3_loss: 0.1616 - val_output_0_acc: 0.9672 - val_output_1_acc: 0.9831 - val_output_2_acc: 0.9819 - val_output_3_acc: 0.9503\n",
      "Epoch 131/200\n",
      "2999/2999 [==============================] - 1s 383us/step - loss: 0.3077 - output_0_loss: 0.0687 - output_1_loss: 0.0967 - output_2_loss: 0.0682 - output_3_loss: 0.0742 - output_0_acc: 0.9940 - output_1_acc: 0.9877 - output_2_acc: 0.9953 - output_3_acc: 0.9933 - val_loss: 0.4880 - val_output_0_loss: 0.1250 - val_output_1_loss: 0.1075 - val_output_2_loss: 0.1236 - val_output_3_loss: 0.1319 - val_output_0_acc: 0.9709 - val_output_1_acc: 0.9904 - val_output_2_acc: 0.9701 - val_output_3_acc: 0.9730\n",
      "Epoch 132/200\n",
      "2999/2999 [==============================] - 1s 423us/step - loss: 0.2907 - output_0_loss: 0.0658 - output_1_loss: 0.0885 - output_2_loss: 0.0633 - output_3_loss: 0.0732 - output_0_acc: 0.9940 - output_1_acc: 0.9937 - output_2_acc: 0.9940 - output_3_acc: 0.9930 - val_loss: 0.4282 - val_output_0_loss: 0.1088 - val_output_1_loss: 0.1258 - val_output_2_loss: 0.1011 - val_output_3_loss: 0.0925 - val_output_0_acc: 0.9862 - val_output_1_acc: 0.9793 - val_output_2_acc: 0.9850 - val_output_3_acc: 0.9921\n",
      "Epoch 133/200\n",
      "2999/2999 [==============================] - 1s 409us/step - loss: 0.2959 - output_0_loss: 0.0684 - output_1_loss: 0.0955 - output_2_loss: 0.0627 - output_3_loss: 0.0693 - output_0_acc: 0.9930 - output_1_acc: 0.9900 - output_2_acc: 0.9940 - output_3_acc: 0.9937 - val_loss: 0.5077 - val_output_0_loss: 0.1497 - val_output_1_loss: 0.1129 - val_output_2_loss: 0.0776 - val_output_3_loss: 0.1676 - val_output_0_acc: 0.9528 - val_output_1_acc: 0.9850 - val_output_2_acc: 0.9954 - val_output_3_acc: 0.9504\n",
      "Epoch 134/200\n",
      "2999/2999 [==============================] - 1s 437us/step - loss: 0.2851 - output_0_loss: 0.0630 - output_1_loss: 0.0903 - output_2_loss: 0.0605 - output_3_loss: 0.0712 - output_0_acc: 0.9940 - output_1_acc: 0.9920 - output_2_acc: 0.9947 - output_3_acc: 0.9927 - val_loss: 0.4408 - val_output_0_loss: 0.0990 - val_output_1_loss: 0.1465 - val_output_2_loss: 0.0910 - val_output_3_loss: 0.1042 - val_output_0_acc: 0.9861 - val_output_1_acc: 0.9696 - val_output_2_acc: 0.9904 - val_output_3_acc: 0.9847\n",
      "Epoch 135/200\n",
      "2999/2999 [==============================] - 1s 459us/step - loss: 0.2741 - output_0_loss: 0.0637 - output_1_loss: 0.0841 - output_2_loss: 0.0585 - output_3_loss: 0.0677 - output_0_acc: 0.9943 - output_1_acc: 0.9920 - output_2_acc: 0.9940 - output_3_acc: 0.9937 - val_loss: 0.3609 - val_output_0_loss: 0.0672 - val_output_1_loss: 0.1289 - val_output_2_loss: 0.0771 - val_output_3_loss: 0.0877 - val_output_0_acc: 0.9947 - val_output_1_acc: 0.9774 - val_output_2_acc: 0.9944 - val_output_3_acc: 0.9888\n",
      "Epoch 136/200\n",
      "2999/2999 [==============================] - 1s 454us/step - loss: 0.2673 - output_0_loss: 0.0640 - output_1_loss: 0.0821 - output_2_loss: 0.0572 - output_3_loss: 0.0639 - output_0_acc: 0.9933 - output_1_acc: 0.9933 - output_2_acc: 0.9947 - output_3_acc: 0.9940 - val_loss: 0.4214 - val_output_0_loss: 0.0758 - val_output_1_loss: 0.1375 - val_output_2_loss: 0.1286 - val_output_3_loss: 0.0795 - val_output_0_acc: 0.9949 - val_output_1_acc: 0.9766 - val_output_2_acc: 0.9660 - val_output_3_acc: 0.9900\n",
      "Epoch 137/200\n",
      "2999/2999 [==============================] - 1s 426us/step - loss: 0.2607 - output_0_loss: 0.0593 - output_1_loss: 0.0837 - output_2_loss: 0.0545 - output_3_loss: 0.0631 - output_0_acc: 0.9957 - output_1_acc: 0.9907 - output_2_acc: 0.9963 - output_3_acc: 0.9953 - val_loss: 0.3833 - val_output_0_loss: 0.0799 - val_output_1_loss: 0.0915 - val_output_2_loss: 0.0786 - val_output_3_loss: 0.1333 - val_output_0_acc: 0.9927 - val_output_1_acc: 0.9934 - val_output_2_acc: 0.9891 - val_output_3_acc: 0.9706\n",
      "Epoch 138/200\n",
      "2999/2999 [==============================] - 1s 452us/step - loss: 0.2552 - output_0_loss: 0.0615 - output_1_loss: 0.0790 - output_2_loss: 0.0528 - output_3_loss: 0.0620 - output_0_acc: 0.9953 - output_1_acc: 0.9907 - output_2_acc: 0.9960 - output_3_acc: 0.9923 - val_loss: 0.3985 - val_output_0_loss: 0.0577 - val_output_1_loss: 0.1612 - val_output_2_loss: 0.0741 - val_output_3_loss: 0.1055 - val_output_0_acc: 0.9969 - val_output_1_acc: 0.9570 - val_output_2_acc: 0.9929 - val_output_3_acc: 0.9784\n",
      "Epoch 139/200\n",
      "2999/2999 [==============================] - 1s 444us/step - loss: 0.2539 - output_0_loss: 0.0590 - output_1_loss: 0.0794 - output_2_loss: 0.0549 - output_3_loss: 0.0605 - output_0_acc: 0.9953 - output_1_acc: 0.9910 - output_2_acc: 0.9940 - output_3_acc: 0.9953 - val_loss: 0.4082 - val_output_0_loss: 0.0806 - val_output_1_loss: 0.1005 - val_output_2_loss: 0.1271 - val_output_3_loss: 0.1001 - val_output_0_acc: 0.9876 - val_output_1_acc: 0.9899 - val_output_2_acc: 0.9561 - val_output_3_acc: 0.9864\n",
      "Epoch 140/200\n",
      "2999/2999 [==============================] - 1s 404us/step - loss: 0.2389 - output_0_loss: 0.0571 - output_1_loss: 0.0741 - output_2_loss: 0.0524 - output_3_loss: 0.0554 - output_0_acc: 0.9947 - output_1_acc: 0.9943 - output_2_acc: 0.9960 - output_3_acc: 0.9950 - val_loss: 0.4298 - val_output_0_loss: 0.0932 - val_output_1_loss: 0.1175 - val_output_2_loss: 0.0688 - val_output_3_loss: 0.1502 - val_output_0_acc: 0.9845 - val_output_1_acc: 0.9795 - val_output_2_acc: 0.9942 - val_output_3_acc: 0.9519\n",
      "Epoch 141/200\n",
      "2999/2999 [==============================] - 1s 421us/step - loss: 0.2361 - output_0_loss: 0.0547 - output_1_loss: 0.0726 - output_2_loss: 0.0496 - output_3_loss: 0.0592 - output_0_acc: 0.9947 - output_1_acc: 0.9943 - output_2_acc: 0.9967 - output_3_acc: 0.9930 - val_loss: 0.4164 - val_output_0_loss: 0.0728 - val_output_1_loss: 0.1430 - val_output_2_loss: 0.1146 - val_output_3_loss: 0.0860 - val_output_0_acc: 0.9868 - val_output_1_acc: 0.9604 - val_output_2_acc: 0.9831 - val_output_3_acc: 0.9880\n",
      "Epoch 142/200\n",
      "2999/2999 [==============================] - 1s 403us/step - loss: 0.2379 - output_0_loss: 0.0563 - output_1_loss: 0.0742 - output_2_loss: 0.0498 - output_3_loss: 0.0577 - output_0_acc: 0.9943 - output_1_acc: 0.9907 - output_2_acc: 0.9963 - output_3_acc: 0.9930 - val_loss: 0.3859 - val_output_0_loss: 0.1001 - val_output_1_loss: 0.1364 - val_output_2_loss: 0.0763 - val_output_3_loss: 0.0731 - val_output_0_acc: 0.9828 - val_output_1_acc: 0.9624 - val_output_2_acc: 0.9939 - val_output_3_acc: 0.9938\n",
      "Epoch 143/200\n",
      "2999/2999 [==============================] - 1s 414us/step - loss: 0.2262 - output_0_loss: 0.0505 - output_1_loss: 0.0700 - output_2_loss: 0.0509 - output_3_loss: 0.0547 - output_0_acc: 0.9960 - output_1_acc: 0.9920 - output_2_acc: 0.9957 - output_3_acc: 0.9930 - val_loss: 0.4009 - val_output_0_loss: 0.0845 - val_output_1_loss: 0.1235 - val_output_2_loss: 0.1034 - val_output_3_loss: 0.0896 - val_output_0_acc: 0.9866 - val_output_1_acc: 0.9797 - val_output_2_acc: 0.9760 - val_output_3_acc: 0.9884\n",
      "Epoch 144/200\n",
      "2999/2999 [==============================] - 1s 452us/step - loss: 0.2165 - output_0_loss: 0.0512 - output_1_loss: 0.0701 - output_2_loss: 0.0446 - output_3_loss: 0.0507 - output_0_acc: 0.9947 - output_1_acc: 0.9933 - output_2_acc: 0.9970 - output_3_acc: 0.9960 - val_loss: 0.4197 - val_output_0_loss: 0.0738 - val_output_1_loss: 0.1057 - val_output_2_loss: 0.0695 - val_output_3_loss: 0.1707 - val_output_0_acc: 0.9944 - val_output_1_acc: 0.9885 - val_output_2_acc: 0.9898 - val_output_3_acc: 0.9599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "2999/2999 [==============================] - 1s 460us/step - loss: 0.2090 - output_0_loss: 0.0470 - output_1_loss: 0.0682 - output_2_loss: 0.0432 - output_3_loss: 0.0506 - output_0_acc: 0.9970 - output_1_acc: 0.9940 - output_2_acc: 0.9973 - output_3_acc: 0.9970 - val_loss: 0.3183 - val_output_0_loss: 0.0922 - val_output_1_loss: 0.0918 - val_output_2_loss: 0.0596 - val_output_3_loss: 0.0747 - val_output_0_acc: 0.9774 - val_output_1_acc: 0.9911 - val_output_2_acc: 0.9909 - val_output_3_acc: 0.9897\n",
      "Epoch 146/200\n",
      "2999/2999 [==============================] - 1s 455us/step - loss: 0.2130 - output_0_loss: 0.0472 - output_1_loss: 0.0668 - output_2_loss: 0.0459 - output_3_loss: 0.0530 - output_0_acc: 0.9977 - output_1_acc: 0.9930 - output_2_acc: 0.9960 - output_3_acc: 0.9920 - val_loss: 0.3730 - val_output_0_loss: 0.1304 - val_output_1_loss: 0.1103 - val_output_2_loss: 0.0734 - val_output_3_loss: 0.0589 - val_output_0_acc: 0.9608 - val_output_1_acc: 0.9789 - val_output_2_acc: 0.9909 - val_output_3_acc: 0.9927\n",
      "Epoch 147/200\n",
      "2999/2999 [==============================] - 1s 453us/step - loss: 0.2007 - output_0_loss: 0.0454 - output_1_loss: 0.0612 - output_2_loss: 0.0435 - output_3_loss: 0.0506 - output_0_acc: 0.9967 - output_1_acc: 0.9963 - output_2_acc: 0.9967 - output_3_acc: 0.9943 - val_loss: 0.2815 - val_output_0_loss: 0.0630 - val_output_1_loss: 0.1079 - val_output_2_loss: 0.0502 - val_output_3_loss: 0.0604 - val_output_0_acc: 0.9927 - val_output_1_acc: 0.9770 - val_output_2_acc: 0.9976 - val_output_3_acc: 0.9934\n",
      "Epoch 148/200\n",
      "2999/2999 [==============================] - 1s 452us/step - loss: 0.1982 - output_0_loss: 0.0444 - output_1_loss: 0.0614 - output_2_loss: 0.0448 - output_3_loss: 0.0475 - output_0_acc: 0.9980 - output_1_acc: 0.9937 - output_2_acc: 0.9940 - output_3_acc: 0.9960 - val_loss: 0.3205 - val_output_0_loss: 0.0895 - val_output_1_loss: 0.0951 - val_output_2_loss: 0.0606 - val_output_3_loss: 0.0754 - val_output_0_acc: 0.9824 - val_output_1_acc: 0.9877 - val_output_2_acc: 0.9945 - val_output_3_acc: 0.9887\n",
      "Epoch 149/200\n",
      "2999/2999 [==============================] - 1s 460us/step - loss: 0.1974 - output_0_loss: 0.0440 - output_1_loss: 0.0626 - output_2_loss: 0.0404 - output_3_loss: 0.0504 - output_0_acc: 0.9950 - output_1_acc: 0.9940 - output_2_acc: 0.9967 - output_3_acc: 0.9940 - val_loss: 0.3531 - val_output_0_loss: 0.0446 - val_output_1_loss: 0.1501 - val_output_2_loss: 0.0744 - val_output_3_loss: 0.0840 - val_output_0_acc: 0.9973 - val_output_1_acc: 0.9589 - val_output_2_acc: 0.9923 - val_output_3_acc: 0.9813\n",
      "Epoch 150/200\n",
      "2999/2999 [==============================] - 1s 404us/step - loss: 0.1842 - output_0_loss: 0.0423 - output_1_loss: 0.0558 - output_2_loss: 0.0401 - output_3_loss: 0.0460 - output_0_acc: 0.9960 - output_1_acc: 0.9953 - output_2_acc: 0.9973 - output_3_acc: 0.9973 - val_loss: 0.2671 - val_output_0_loss: 0.0461 - val_output_1_loss: 0.0897 - val_output_2_loss: 0.0791 - val_output_3_loss: 0.0522 - val_output_0_acc: 0.9971 - val_output_1_acc: 0.9877 - val_output_2_acc: 0.9863 - val_output_3_acc: 0.9955\n",
      "Epoch 151/200\n",
      "2999/2999 [==============================] - 1s 440us/step - loss: 0.1874 - output_0_loss: 0.0420 - output_1_loss: 0.0586 - output_2_loss: 0.0441 - output_3_loss: 0.0426 - output_0_acc: 0.9963 - output_1_acc: 0.9950 - output_2_acc: 0.9953 - output_3_acc: 0.9983 - val_loss: 0.3805 - val_output_0_loss: 0.0873 - val_output_1_loss: 0.1225 - val_output_2_loss: 0.0792 - val_output_3_loss: 0.0916 - val_output_0_acc: 0.9866 - val_output_1_acc: 0.9683 - val_output_2_acc: 0.9855 - val_output_3_acc: 0.9801\n",
      "Epoch 152/200\n",
      "2999/2999 [==============================] - 1s 456us/step - loss: 0.1780 - output_0_loss: 0.0396 - output_1_loss: 0.0547 - output_2_loss: 0.0372 - output_3_loss: 0.0465 - output_0_acc: 0.9973 - output_1_acc: 0.9947 - output_2_acc: 0.9967 - output_3_acc: 0.9957 - val_loss: 0.2935 - val_output_0_loss: 0.0738 - val_output_1_loss: 0.0804 - val_output_2_loss: 0.0530 - val_output_3_loss: 0.0863 - val_output_0_acc: 0.9904 - val_output_1_acc: 0.9902 - val_output_2_acc: 0.9960 - val_output_3_acc: 0.9809\n",
      "Epoch 153/200\n",
      "2999/2999 [==============================] - 1s 432us/step - loss: 0.1768 - output_0_loss: 0.0376 - output_1_loss: 0.0556 - output_2_loss: 0.0371 - output_3_loss: 0.0466 - output_0_acc: 0.9970 - output_1_acc: 0.9940 - output_2_acc: 0.9967 - output_3_acc: 0.9947 - val_loss: 0.2843 - val_output_0_loss: 0.0664 - val_output_1_loss: 0.0664 - val_output_2_loss: 0.0705 - val_output_3_loss: 0.0810 - val_output_0_acc: 0.9904 - val_output_1_acc: 0.9947 - val_output_2_acc: 0.9873 - val_output_3_acc: 0.9825\n",
      "Epoch 154/200\n",
      "2999/2999 [==============================] - 1s 426us/step - loss: 0.1688 - output_0_loss: 0.0393 - output_1_loss: 0.0538 - output_2_loss: 0.0357 - output_3_loss: 0.0400 - output_0_acc: 0.9973 - output_1_acc: 0.9957 - output_2_acc: 0.9970 - output_3_acc: 0.9970 - val_loss: 0.2991 - val_output_0_loss: 0.0544 - val_output_1_loss: 0.1319 - val_output_2_loss: 0.0492 - val_output_3_loss: 0.0636 - val_output_0_acc: 0.9924 - val_output_1_acc: 0.9713 - val_output_2_acc: 0.9954 - val_output_3_acc: 0.9924\n",
      "Epoch 155/200\n",
      "2999/2999 [==============================] - 1s 432us/step - loss: 0.1688 - output_0_loss: 0.0386 - output_1_loss: 0.0521 - output_2_loss: 0.0352 - output_3_loss: 0.0429 - output_0_acc: 0.9963 - output_1_acc: 0.9960 - output_2_acc: 0.9977 - output_3_acc: 0.9947 - val_loss: 0.2368 - val_output_0_loss: 0.0696 - val_output_1_loss: 0.0751 - val_output_2_loss: 0.0449 - val_output_3_loss: 0.0473 - val_output_0_acc: 0.9930 - val_output_1_acc: 0.9922 - val_output_2_acc: 0.9951 - val_output_3_acc: 0.9957\n",
      "Epoch 156/200\n",
      "2999/2999 [==============================] - 1s 451us/step - loss: 0.1594 - output_0_loss: 0.0355 - output_1_loss: 0.0491 - output_2_loss: 0.0344 - output_3_loss: 0.0404 - output_0_acc: 0.9970 - output_1_acc: 0.9973 - output_2_acc: 0.9973 - output_3_acc: 0.9970 - val_loss: 0.2666 - val_output_0_loss: 0.0474 - val_output_1_loss: 0.1092 - val_output_2_loss: 0.0395 - val_output_3_loss: 0.0704 - val_output_0_acc: 0.9970 - val_output_1_acc: 0.9750 - val_output_2_acc: 0.9973 - val_output_3_acc: 0.9899\n",
      "Epoch 157/200\n",
      "2999/2999 [==============================] - 1s 451us/step - loss: 0.1566 - output_0_loss: 0.0366 - output_1_loss: 0.0487 - output_2_loss: 0.0354 - output_3_loss: 0.0358 - output_0_acc: 0.9963 - output_1_acc: 0.9947 - output_2_acc: 0.9963 - output_3_acc: 0.9980 - val_loss: 0.3668 - val_output_0_loss: 0.1462 - val_output_1_loss: 0.0828 - val_output_2_loss: 0.0520 - val_output_3_loss: 0.0857 - val_output_0_acc: 0.9562 - val_output_1_acc: 0.9894 - val_output_2_acc: 0.9967 - val_output_3_acc: 0.9825\n",
      "Epoch 158/200\n",
      "2999/2999 [==============================] - 1s 454us/step - loss: 0.1623 - output_0_loss: 0.0370 - output_1_loss: 0.0498 - output_2_loss: 0.0362 - output_3_loss: 0.0393 - output_0_acc: 0.9957 - output_1_acc: 0.9953 - output_2_acc: 0.9960 - output_3_acc: 0.9953 - val_loss: 0.2193 - val_output_0_loss: 0.0675 - val_output_1_loss: 0.0618 - val_output_2_loss: 0.0491 - val_output_3_loss: 0.0409 - val_output_0_acc: 0.9927 - val_output_1_acc: 0.9948 - val_output_2_acc: 0.9965 - val_output_3_acc: 0.9983\n",
      "Epoch 159/200\n",
      "2999/2999 [==============================] - 1s 440us/step - loss: 0.1497 - output_0_loss: 0.0361 - output_1_loss: 0.0447 - output_2_loss: 0.0333 - output_3_loss: 0.0356 - output_0_acc: 0.9967 - output_1_acc: 0.9973 - output_2_acc: 0.9970 - output_3_acc: 0.9973 - val_loss: 0.2475 - val_output_0_loss: 0.0622 - val_output_1_loss: 0.0659 - val_output_2_loss: 0.0407 - val_output_3_loss: 0.0788 - val_output_0_acc: 0.9923 - val_output_1_acc: 0.9957 - val_output_2_acc: 0.9957 - val_output_3_acc: 0.9825\n",
      "Epoch 160/200\n",
      "2999/2999 [==============================] - 1s 452us/step - loss: 0.1497 - output_0_loss: 0.0322 - output_1_loss: 0.0463 - output_2_loss: 0.0325 - output_3_loss: 0.0388 - output_0_acc: 0.9980 - output_1_acc: 0.9963 - output_2_acc: 0.9960 - output_3_acc: 0.9950 - val_loss: 0.2095 - val_output_0_loss: 0.0516 - val_output_1_loss: 0.0629 - val_output_2_loss: 0.0425 - val_output_3_loss: 0.0525 - val_output_0_acc: 0.9924 - val_output_1_acc: 0.9946 - val_output_2_acc: 0.9929 - val_output_3_acc: 0.9934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200\n",
      "2999/2999 [==============================] - 1s 437us/step - loss: 0.1410 - output_0_loss: 0.0345 - output_1_loss: 0.0419 - output_2_loss: 0.0299 - output_3_loss: 0.0347 - output_0_acc: 0.9980 - output_1_acc: 0.9983 - output_2_acc: 0.9967 - output_3_acc: 0.9977 - val_loss: 0.2486 - val_output_0_loss: 0.0439 - val_output_1_loss: 0.0717 - val_output_2_loss: 0.0682 - val_output_3_loss: 0.0648 - val_output_0_acc: 0.9954 - val_output_1_acc: 0.9917 - val_output_2_acc: 0.9886 - val_output_3_acc: 0.9839\n",
      "Epoch 162/200\n",
      "2999/2999 [==============================] - 1s 431us/step - loss: 0.1424 - output_0_loss: 0.0324 - output_1_loss: 0.0468 - output_2_loss: 0.0303 - output_3_loss: 0.0330 - output_0_acc: 0.9977 - output_1_acc: 0.9957 - output_2_acc: 0.9983 - output_3_acc: 0.9970 - val_loss: 0.2635 - val_output_0_loss: 0.0626 - val_output_1_loss: 0.0695 - val_output_2_loss: 0.0360 - val_output_3_loss: 0.0954 - val_output_0_acc: 0.9897 - val_output_1_acc: 0.9907 - val_output_2_acc: 0.9970 - val_output_3_acc: 0.9776\n",
      "Epoch 163/200\n",
      "2999/2999 [==============================] - 1s 441us/step - loss: 0.1427 - output_0_loss: 0.0337 - output_1_loss: 0.0417 - output_2_loss: 0.0335 - output_3_loss: 0.0338 - output_0_acc: 0.9963 - output_1_acc: 0.9953 - output_2_acc: 0.9967 - output_3_acc: 0.9963 - val_loss: 0.2563 - val_output_0_loss: 0.0310 - val_output_1_loss: 0.1020 - val_output_2_loss: 0.0367 - val_output_3_loss: 0.0865 - val_output_0_acc: 0.9991 - val_output_1_acc: 0.9727 - val_output_2_acc: 0.9976 - val_output_3_acc: 0.9823\n",
      "Epoch 164/200\n",
      "2999/2999 [==============================] - 1s 445us/step - loss: 0.1296 - output_0_loss: 0.0304 - output_1_loss: 0.0419 - output_2_loss: 0.0282 - output_3_loss: 0.0290 - output_0_acc: 0.9980 - output_1_acc: 0.9960 - output_2_acc: 0.9980 - output_3_acc: 0.9983 - val_loss: 0.3308 - val_output_0_loss: 0.0335 - val_output_1_loss: 0.0660 - val_output_2_loss: 0.0994 - val_output_3_loss: 0.1319 - val_output_0_acc: 0.9981 - val_output_1_acc: 0.9914 - val_output_2_acc: 0.9675 - val_output_3_acc: 0.9544\n",
      "Epoch 165/200\n",
      "2999/2999 [==============================] - 1s 445us/step - loss: 0.1338 - output_0_loss: 0.0287 - output_1_loss: 0.0419 - output_2_loss: 0.0262 - output_3_loss: 0.0370 - output_0_acc: 0.9983 - output_1_acc: 0.9967 - output_2_acc: 0.9983 - output_3_acc: 0.9937 - val_loss: 0.1669 - val_output_0_loss: 0.0327 - val_output_1_loss: 0.0598 - val_output_2_loss: 0.0381 - val_output_3_loss: 0.0363 - val_output_0_acc: 0.9977 - val_output_1_acc: 0.9928 - val_output_2_acc: 0.9971 - val_output_3_acc: 0.9982\n",
      "Epoch 166/200\n",
      "2999/2999 [==============================] - 1s 450us/step - loss: 0.1278 - output_0_loss: 0.0290 - output_1_loss: 0.0384 - output_2_loss: 0.0282 - output_3_loss: 0.0323 - output_0_acc: 0.9977 - output_1_acc: 0.9977 - output_2_acc: 0.9977 - output_3_acc: 0.9970 - val_loss: 0.2590 - val_output_0_loss: 0.0840 - val_output_1_loss: 0.0857 - val_output_2_loss: 0.0363 - val_output_3_loss: 0.0530 - val_output_0_acc: 0.9740 - val_output_1_acc: 0.9793 - val_output_2_acc: 0.9957 - val_output_3_acc: 0.9944\n",
      "Epoch 167/200\n",
      "2999/2999 [==============================] - 1s 454us/step - loss: 0.1286 - output_0_loss: 0.0296 - output_1_loss: 0.0381 - output_2_loss: 0.0278 - output_3_loss: 0.0331 - output_0_acc: 0.9983 - output_1_acc: 0.9950 - output_2_acc: 0.9980 - output_3_acc: 0.9973 - val_loss: 0.2217 - val_output_0_loss: 0.0284 - val_output_1_loss: 0.1055 - val_output_2_loss: 0.0378 - val_output_3_loss: 0.0500 - val_output_0_acc: 0.9994 - val_output_1_acc: 0.9748 - val_output_2_acc: 0.9958 - val_output_3_acc: 0.9916\n",
      "Epoch 168/200\n",
      "2999/2999 [==============================] - 1s 430us/step - loss: 0.1210 - output_0_loss: 0.0307 - output_1_loss: 0.0353 - output_2_loss: 0.0276 - output_3_loss: 0.0275 - output_0_acc: 0.9973 - output_1_acc: 0.9967 - output_2_acc: 0.9987 - output_3_acc: 0.9990 - val_loss: 0.1597 - val_output_0_loss: 0.0291 - val_output_1_loss: 0.0516 - val_output_2_loss: 0.0282 - val_output_3_loss: 0.0508 - val_output_0_acc: 0.9980 - val_output_1_acc: 0.9943 - val_output_2_acc: 0.9985 - val_output_3_acc: 0.9950\n",
      "Epoch 169/200\n",
      "2999/2999 [==============================] - 1s 415us/step - loss: 0.1214 - output_0_loss: 0.0270 - output_1_loss: 0.0371 - output_2_loss: 0.0275 - output_3_loss: 0.0298 - output_0_acc: 0.9983 - output_1_acc: 0.9970 - output_2_acc: 0.9967 - output_3_acc: 0.9970 - val_loss: 0.3024 - val_output_0_loss: 0.0881 - val_output_1_loss: 0.0971 - val_output_2_loss: 0.0668 - val_output_3_loss: 0.0503 - val_output_0_acc: 0.9733 - val_output_1_acc: 0.9620 - val_output_2_acc: 0.9872 - val_output_3_acc: 0.9927\n",
      "Epoch 170/200\n",
      "2999/2999 [==============================] - 1s 392us/step - loss: 0.1147 - output_0_loss: 0.0256 - output_1_loss: 0.0351 - output_2_loss: 0.0255 - output_3_loss: 0.0285 - output_0_acc: 0.9980 - output_1_acc: 0.9980 - output_2_acc: 0.9977 - output_3_acc: 0.9977 - val_loss: 0.2461 - val_output_0_loss: 0.0674 - val_output_1_loss: 0.0747 - val_output_2_loss: 0.0403 - val_output_3_loss: 0.0637 - val_output_0_acc: 0.9862 - val_output_1_acc: 0.9903 - val_output_2_acc: 0.9942 - val_output_3_acc: 0.9836\n",
      "Epoch 171/200\n",
      "2999/2999 [==============================] - 1s 411us/step - loss: 0.1133 - output_0_loss: 0.0266 - output_1_loss: 0.0373 - output_2_loss: 0.0231 - output_3_loss: 0.0263 - output_0_acc: 0.9983 - output_1_acc: 0.9963 - output_2_acc: 0.9980 - output_3_acc: 0.9977 - val_loss: 0.2125 - val_output_0_loss: 0.0311 - val_output_1_loss: 0.0862 - val_output_2_loss: 0.0510 - val_output_3_loss: 0.0442 - val_output_0_acc: 0.9987 - val_output_1_acc: 0.9811 - val_output_2_acc: 0.9919 - val_output_3_acc: 0.9948\n",
      "Epoch 172/200\n",
      "2999/2999 [==============================] - 1s 415us/step - loss: 0.1162 - output_0_loss: 0.0264 - output_1_loss: 0.0349 - output_2_loss: 0.0260 - output_3_loss: 0.0288 - output_0_acc: 0.9970 - output_1_acc: 0.9980 - output_2_acc: 0.9973 - output_3_acc: 0.9973 - val_loss: 0.1793 - val_output_0_loss: 0.0324 - val_output_1_loss: 0.0600 - val_output_2_loss: 0.0308 - val_output_3_loss: 0.0562 - val_output_0_acc: 0.9983 - val_output_1_acc: 0.9914 - val_output_2_acc: 0.9973 - val_output_3_acc: 0.9886\n",
      "Epoch 173/200\n",
      "2999/2999 [==============================] - 1s 419us/step - loss: 0.1107 - output_0_loss: 0.0229 - output_1_loss: 0.0357 - output_2_loss: 0.0237 - output_3_loss: 0.0284 - output_0_acc: 0.9993 - output_1_acc: 0.9957 - output_2_acc: 0.9980 - output_3_acc: 0.9967 - val_loss: 0.1948 - val_output_0_loss: 0.0415 - val_output_1_loss: 0.0730 - val_output_2_loss: 0.0298 - val_output_3_loss: 0.0505 - val_output_0_acc: 0.9963 - val_output_1_acc: 0.9803 - val_output_2_acc: 0.9978 - val_output_3_acc: 0.9912\n",
      "Epoch 174/200\n",
      "2999/2999 [==============================] - 1s 428us/step - loss: 0.1033 - output_0_loss: 0.0241 - output_1_loss: 0.0310 - output_2_loss: 0.0220 - output_3_loss: 0.0262 - output_0_acc: 0.9983 - output_1_acc: 0.9973 - output_2_acc: 0.9983 - output_3_acc: 0.9973 - val_loss: 0.2196 - val_output_0_loss: 0.0392 - val_output_1_loss: 0.0717 - val_output_2_loss: 0.0335 - val_output_3_loss: 0.0752 - val_output_0_acc: 0.9957 - val_output_1_acc: 0.9829 - val_output_2_acc: 0.9974 - val_output_3_acc: 0.9786\n",
      "Epoch 175/200\n",
      "2999/2999 [==============================] - 1s 439us/step - loss: 0.1022 - output_0_loss: 0.0237 - output_1_loss: 0.0309 - output_2_loss: 0.0213 - output_3_loss: 0.0263 - output_0_acc: 0.9987 - output_1_acc: 0.9983 - output_2_acc: 0.9987 - output_3_acc: 0.9977 - val_loss: 0.1923 - val_output_0_loss: 0.0224 - val_output_1_loss: 0.0540 - val_output_2_loss: 0.0383 - val_output_3_loss: 0.0775 - val_output_0_acc: 0.9990 - val_output_1_acc: 0.9934 - val_output_2_acc: 0.9975 - val_output_3_acc: 0.9857\n",
      "Epoch 176/200\n",
      "2999/2999 [==============================] - 1s 443us/step - loss: 0.1007 - output_0_loss: 0.0226 - output_1_loss: 0.0302 - output_2_loss: 0.0226 - output_3_loss: 0.0253 - output_0_acc: 0.9973 - output_1_acc: 0.9977 - output_2_acc: 0.9987 - output_3_acc: 0.9973 - val_loss: 0.1689 - val_output_0_loss: 0.0258 - val_output_1_loss: 0.0545 - val_output_2_loss: 0.0400 - val_output_3_loss: 0.0487 - val_output_0_acc: 0.9983 - val_output_1_acc: 0.9897 - val_output_2_acc: 0.9953 - val_output_3_acc: 0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200\n",
      "2999/2999 [==============================] - 1s 448us/step - loss: 0.1039 - output_0_loss: 0.0249 - output_1_loss: 0.0337 - output_2_loss: 0.0229 - output_3_loss: 0.0224 - output_0_acc: 0.9970 - output_1_acc: 0.9967 - output_2_acc: 0.9973 - output_3_acc: 0.9987 - val_loss: 0.1689 - val_output_0_loss: 0.0338 - val_output_1_loss: 0.0529 - val_output_2_loss: 0.0476 - val_output_3_loss: 0.0345 - val_output_0_acc: 0.9987 - val_output_1_acc: 0.9942 - val_output_2_acc: 0.9933 - val_output_3_acc: 0.9964\n",
      "Epoch 178/200\n",
      "2999/2999 [==============================] - 1s 433us/step - loss: 0.0998 - output_0_loss: 0.0230 - output_1_loss: 0.0291 - output_2_loss: 0.0224 - output_3_loss: 0.0253 - output_0_acc: 0.9977 - output_1_acc: 0.9977 - output_2_acc: 0.9983 - output_3_acc: 0.9967 - val_loss: 0.1477 - val_output_0_loss: 0.0285 - val_output_1_loss: 0.0446 - val_output_2_loss: 0.0416 - val_output_3_loss: 0.0330 - val_output_0_acc: 0.9980 - val_output_1_acc: 0.9916 - val_output_2_acc: 0.9969 - val_output_3_acc: 0.9977\n",
      "Epoch 179/200\n",
      "2999/2999 [==============================] - 1s 436us/step - loss: 0.0977 - output_0_loss: 0.0241 - output_1_loss: 0.0323 - output_2_loss: 0.0194 - output_3_loss: 0.0218 - output_0_acc: 0.9980 - output_1_acc: 0.9960 - output_2_acc: 0.9983 - output_3_acc: 0.9987 - val_loss: 0.1385 - val_output_0_loss: 0.0274 - val_output_1_loss: 0.0316 - val_output_2_loss: 0.0378 - val_output_3_loss: 0.0416 - val_output_0_acc: 0.9993 - val_output_1_acc: 0.9977 - val_output_2_acc: 0.9923 - val_output_3_acc: 0.9954\n",
      "Epoch 180/200\n",
      "2999/2999 [==============================] - 1s 408us/step - loss: 0.0877 - output_0_loss: 0.0203 - output_1_loss: 0.0257 - output_2_loss: 0.0192 - output_3_loss: 0.0226 - output_0_acc: 0.9990 - output_1_acc: 0.9980 - output_2_acc: 0.9990 - output_3_acc: 0.9980 - val_loss: 0.1331 - val_output_0_loss: 0.0281 - val_output_1_loss: 0.0339 - val_output_2_loss: 0.0301 - val_output_3_loss: 0.0410 - val_output_0_acc: 0.9987 - val_output_1_acc: 0.9987 - val_output_2_acc: 0.9970 - val_output_3_acc: 0.9935\n",
      "Epoch 181/200\n",
      "2999/2999 [==============================] - 1s 416us/step - loss: 0.0916 - output_0_loss: 0.0208 - output_1_loss: 0.0288 - output_2_loss: 0.0210 - output_3_loss: 0.0211 - output_0_acc: 0.9987 - output_1_acc: 0.9963 - output_2_acc: 0.9987 - output_3_acc: 0.9980 - val_loss: 0.2028 - val_output_0_loss: 0.0228 - val_output_1_loss: 0.1252 - val_output_2_loss: 0.0258 - val_output_3_loss: 0.0290 - val_output_0_acc: 0.9989 - val_output_1_acc: 0.9542 - val_output_2_acc: 0.9980 - val_output_3_acc: 0.9966\n",
      "Epoch 182/200\n",
      "2999/2999 [==============================] - 1s 417us/step - loss: 0.0885 - output_0_loss: 0.0200 - output_1_loss: 0.0281 - output_2_loss: 0.0194 - output_3_loss: 0.0210 - output_0_acc: 0.9980 - output_1_acc: 0.9973 - output_2_acc: 0.9990 - output_3_acc: 0.9967 - val_loss: 0.1747 - val_output_0_loss: 0.0515 - val_output_1_loss: 0.0359 - val_output_2_loss: 0.0327 - val_output_3_loss: 0.0546 - val_output_0_acc: 0.9920 - val_output_1_acc: 0.9990 - val_output_2_acc: 0.9964 - val_output_3_acc: 0.9883\n",
      "Epoch 183/200\n",
      "2999/2999 [==============================] - 1s 402us/step - loss: 0.0967 - output_0_loss: 0.0216 - output_1_loss: 0.0272 - output_2_loss: 0.0236 - output_3_loss: 0.0243 - output_0_acc: 0.9973 - output_1_acc: 0.9983 - output_2_acc: 0.9940 - output_3_acc: 0.9967 - val_loss: 0.1361 - val_output_0_loss: 0.0310 - val_output_1_loss: 0.0525 - val_output_2_loss: 0.0241 - val_output_3_loss: 0.0285 - val_output_0_acc: 0.9965 - val_output_1_acc: 0.9904 - val_output_2_acc: 0.9985 - val_output_3_acc: 0.9986\n",
      "Epoch 184/200\n",
      "2999/2999 [==============================] - 1s 427us/step - loss: 0.0826 - output_0_loss: 0.0213 - output_1_loss: 0.0252 - output_2_loss: 0.0167 - output_3_loss: 0.0194 - output_0_acc: 0.9980 - output_1_acc: 0.9983 - output_2_acc: 0.9983 - output_3_acc: 0.9990 - val_loss: 0.1192 - val_output_0_loss: 0.0221 - val_output_1_loss: 0.0422 - val_output_2_loss: 0.0221 - val_output_3_loss: 0.0328 - val_output_0_acc: 0.9991 - val_output_1_acc: 0.9941 - val_output_2_acc: 0.9987 - val_output_3_acc: 0.9950\n",
      "Epoch 185/200\n",
      "2999/2999 [==============================] - 1s 449us/step - loss: 0.0789 - output_0_loss: 0.0166 - output_1_loss: 0.0239 - output_2_loss: 0.0171 - output_3_loss: 0.0213 - output_0_acc: 0.9990 - output_1_acc: 0.9990 - output_2_acc: 0.9987 - output_3_acc: 0.9960 - val_loss: 0.1421 - val_output_0_loss: 0.0324 - val_output_1_loss: 0.0445 - val_output_2_loss: 0.0161 - val_output_3_loss: 0.0491 - val_output_0_acc: 0.9965 - val_output_1_acc: 0.9937 - val_output_2_acc: 0.9986 - val_output_3_acc: 0.9807\n",
      "Epoch 186/200\n",
      "2999/2999 [==============================] - 1s 455us/step - loss: 0.0789 - output_0_loss: 0.0169 - output_1_loss: 0.0219 - output_2_loss: 0.0183 - output_3_loss: 0.0218 - output_0_acc: 0.9993 - output_1_acc: 0.9987 - output_2_acc: 0.9973 - output_3_acc: 0.9973 - val_loss: 0.1620 - val_output_0_loss: 0.0574 - val_output_1_loss: 0.0467 - val_output_2_loss: 0.0330 - val_output_3_loss: 0.0249 - val_output_0_acc: 0.9859 - val_output_1_acc: 0.9927 - val_output_2_acc: 0.9957 - val_output_3_acc: 0.9973\n",
      "Epoch 187/200\n",
      "2999/2999 [==============================] - 1s 449us/step - loss: 0.0819 - output_0_loss: 0.0174 - output_1_loss: 0.0235 - output_2_loss: 0.0197 - output_3_loss: 0.0213 - output_0_acc: 0.9983 - output_1_acc: 0.9977 - output_2_acc: 0.9977 - output_3_acc: 0.9973 - val_loss: 0.1338 - val_output_0_loss: 0.0480 - val_output_1_loss: 0.0380 - val_output_2_loss: 0.0182 - val_output_3_loss: 0.0295 - val_output_0_acc: 0.9939 - val_output_1_acc: 0.9952 - val_output_2_acc: 0.9989 - val_output_3_acc: 0.9956\n",
      "Epoch 188/200\n",
      "2999/2999 [==============================] - 1s 437us/step - loss: 0.0744 - output_0_loss: 0.0161 - output_1_loss: 0.0231 - output_2_loss: 0.0172 - output_3_loss: 0.0181 - output_0_acc: 0.9990 - output_1_acc: 0.9977 - output_2_acc: 0.9980 - output_3_acc: 0.9983 - val_loss: 0.1524 - val_output_0_loss: 0.0249 - val_output_1_loss: 0.0498 - val_output_2_loss: 0.0457 - val_output_3_loss: 0.0320 - val_output_0_acc: 0.9985 - val_output_1_acc: 0.9936 - val_output_2_acc: 0.9882 - val_output_3_acc: 0.9953\n",
      "Epoch 189/200\n",
      "2999/2999 [==============================] - 1s 407us/step - loss: 0.0729 - output_0_loss: 0.0170 - output_1_loss: 0.0211 - output_2_loss: 0.0163 - output_3_loss: 0.0185 - output_0_acc: 0.9987 - output_1_acc: 0.9983 - output_2_acc: 0.9980 - output_3_acc: 0.9987 - val_loss: 0.1563 - val_output_0_loss: 0.0200 - val_output_1_loss: 0.0369 - val_output_2_loss: 0.0723 - val_output_3_loss: 0.0270 - val_output_0_acc: 0.9995 - val_output_1_acc: 0.9972 - val_output_2_acc: 0.9722 - val_output_3_acc: 0.9959\n",
      "Epoch 190/200\n",
      "2999/2999 [==============================] - 1s 445us/step - loss: 0.0728 - output_0_loss: 0.0166 - output_1_loss: 0.0213 - output_2_loss: 0.0165 - output_3_loss: 0.0184 - output_0_acc: 0.9993 - output_1_acc: 0.9987 - output_2_acc: 0.9983 - output_3_acc: 0.9987 - val_loss: 0.1324 - val_output_0_loss: 0.0491 - val_output_1_loss: 0.0416 - val_output_2_loss: 0.0235 - val_output_3_loss: 0.0182 - val_output_0_acc: 0.9880 - val_output_1_acc: 0.9933 - val_output_2_acc: 0.9964 - val_output_3_acc: 0.9995\n",
      "Epoch 191/200\n",
      "2999/2999 [==============================] - 1s 428us/step - loss: 0.0729 - output_0_loss: 0.0177 - output_1_loss: 0.0220 - output_2_loss: 0.0149 - output_3_loss: 0.0184 - output_0_acc: 0.9977 - output_1_acc: 0.9980 - output_2_acc: 0.9997 - output_3_acc: 0.9980 - val_loss: 0.1122 - val_output_0_loss: 0.0181 - val_output_1_loss: 0.0335 - val_output_2_loss: 0.0345 - val_output_3_loss: 0.0261 - val_output_0_acc: 0.9990 - val_output_1_acc: 0.9967 - val_output_2_acc: 0.9951 - val_output_3_acc: 0.9977\n",
      "Epoch 192/200\n",
      "2999/2999 [==============================] - 1s 416us/step - loss: 0.0702 - output_0_loss: 0.0187 - output_1_loss: 0.0209 - output_2_loss: 0.0145 - output_3_loss: 0.0160 - output_0_acc: 0.9977 - output_1_acc: 0.9973 - output_2_acc: 0.9990 - output_3_acc: 0.9990 - val_loss: 0.1300 - val_output_0_loss: 0.0432 - val_output_1_loss: 0.0315 - val_output_2_loss: 0.0347 - val_output_3_loss: 0.0206 - val_output_0_acc: 0.9911 - val_output_1_acc: 0.9970 - val_output_2_acc: 0.9933 - val_output_3_acc: 0.9979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      "2999/2999 [==============================] - 1s 413us/step - loss: 0.0715 - output_0_loss: 0.0145 - output_1_loss: 0.0210 - output_2_loss: 0.0169 - output_3_loss: 0.0191 - output_0_acc: 0.9997 - output_1_acc: 0.9987 - output_2_acc: 0.9980 - output_3_acc: 0.9977 - val_loss: 0.1369 - val_output_0_loss: 0.0218 - val_output_1_loss: 0.0344 - val_output_2_loss: 0.0420 - val_output_3_loss: 0.0387 - val_output_0_acc: 0.9974 - val_output_1_acc: 0.9945 - val_output_2_acc: 0.9941 - val_output_3_acc: 0.9921\n",
      "Epoch 194/200\n",
      "2999/2999 [==============================] - 1s 423us/step - loss: 0.0703 - output_0_loss: 0.0150 - output_1_loss: 0.0226 - output_2_loss: 0.0160 - output_3_loss: 0.0168 - output_0_acc: 0.9990 - output_1_acc: 0.9977 - output_2_acc: 0.9983 - output_3_acc: 0.9977 - val_loss: 0.0845 - val_output_0_loss: 0.0194 - val_output_1_loss: 0.0225 - val_output_2_loss: 0.0206 - val_output_3_loss: 0.0221 - val_output_0_acc: 0.9993 - val_output_1_acc: 0.9981 - val_output_2_acc: 0.9975 - val_output_3_acc: 0.9979\n",
      "Epoch 195/200\n",
      "2999/2999 [==============================] - 1s 421us/step - loss: 0.0654 - output_0_loss: 0.0137 - output_1_loss: 0.0191 - output_2_loss: 0.0157 - output_3_loss: 0.0168 - output_0_acc: 0.9987 - output_1_acc: 0.9990 - output_2_acc: 0.9987 - output_3_acc: 0.9977 - val_loss: 0.1558 - val_output_0_loss: 0.0262 - val_output_1_loss: 0.0256 - val_output_2_loss: 0.0492 - val_output_3_loss: 0.0547 - val_output_0_acc: 0.9971 - val_output_1_acc: 0.9988 - val_output_2_acc: 0.9874 - val_output_3_acc: 0.9856\n",
      "Epoch 196/200\n",
      "2999/2999 [==============================] - 1s 438us/step - loss: 0.0664 - output_0_loss: 0.0156 - output_1_loss: 0.0190 - output_2_loss: 0.0144 - output_3_loss: 0.0174 - output_0_acc: 0.9983 - output_1_acc: 0.9980 - output_2_acc: 0.9983 - output_3_acc: 0.9973 - val_loss: 0.0901 - val_output_0_loss: 0.0194 - val_output_1_loss: 0.0264 - val_output_2_loss: 0.0206 - val_output_3_loss: 0.0237 - val_output_0_acc: 0.9991 - val_output_1_acc: 0.9978 - val_output_2_acc: 0.9989 - val_output_3_acc: 0.9972\n",
      "Epoch 197/200\n",
      "2999/2999 [==============================] - 1s 435us/step - loss: 0.0592 - output_0_loss: 0.0137 - output_1_loss: 0.0181 - output_2_loss: 0.0132 - output_3_loss: 0.0142 - output_0_acc: 0.9997 - output_1_acc: 0.9990 - output_2_acc: 0.9997 - output_3_acc: 0.9983 - val_loss: 0.1036 - val_output_0_loss: 0.0203 - val_output_1_loss: 0.0328 - val_output_2_loss: 0.0154 - val_output_3_loss: 0.0351 - val_output_0_acc: 0.9990 - val_output_1_acc: 0.9963 - val_output_2_acc: 0.9986 - val_output_3_acc: 0.9916\n",
      "Epoch 198/200\n",
      "2999/2999 [==============================] - 1s 446us/step - loss: 0.0615 - output_0_loss: 0.0150 - output_1_loss: 0.0193 - output_2_loss: 0.0133 - output_3_loss: 0.0139 - output_0_acc: 0.9983 - output_1_acc: 0.9980 - output_2_acc: 0.9990 - output_3_acc: 0.9983 - val_loss: 0.1285 - val_output_0_loss: 0.0170 - val_output_1_loss: 0.0622 - val_output_2_loss: 0.0259 - val_output_3_loss: 0.0235 - val_output_0_acc: 0.9988 - val_output_1_acc: 0.9823 - val_output_2_acc: 0.9959 - val_output_3_acc: 0.9957\n",
      "Epoch 199/200\n",
      "2999/2999 [==============================] - 1s 420us/step - loss: 0.0583 - output_0_loss: 0.0121 - output_1_loss: 0.0173 - output_2_loss: 0.0138 - output_3_loss: 0.0151 - output_0_acc: 0.9997 - output_1_acc: 0.9987 - output_2_acc: 0.9993 - output_3_acc: 0.9980 - val_loss: 0.0806 - val_output_0_loss: 0.0169 - val_output_1_loss: 0.0265 - val_output_2_loss: 0.0170 - val_output_3_loss: 0.0202 - val_output_0_acc: 0.9986 - val_output_1_acc: 0.9969 - val_output_2_acc: 0.9986 - val_output_3_acc: 0.9983\n",
      "Epoch 200/200\n",
      "2999/2999 [==============================] - 1s 435us/step - loss: 0.0615 - output_0_loss: 0.0167 - output_1_loss: 0.0175 - output_2_loss: 0.0130 - output_3_loss: 0.0143 - output_0_acc: 0.9977 - output_1_acc: 0.9983 - output_2_acc: 0.9987 - output_3_acc: 0.9983 - val_loss: 0.0840 - val_output_0_loss: 0.0220 - val_output_1_loss: 0.0238 - val_output_2_loss: 0.0155 - val_output_3_loss: 0.0227 - val_output_0_acc: 0.9993 - val_output_1_acc: 0.9987 - val_output_2_acc: 0.9983 - val_output_3_acc: 0.9984\n"
     ]
    }
   ],
   "source": [
    "history = coding_model.fit(x_train, y_train, validation_split=percentage_split, batch_size=32, epochs=nb_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values (of first char only)\n",
    "plt.plot(history.history['output_0_acc'])\n",
    "plt.plot(history.history['val_output_0_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot training & validation loss values (of first char only)\n",
    "plt.plot(history.history['output_0_loss'])\n",
    "plt.plot(history.history['val_output_0_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iwoo', 'ozqb', 'glte']\n",
      "x_test=\n",
      " [[105 119 111 111]\n",
      " [111 122 113  98]\n",
      " [103 108 116 101]]\n",
      "x_test_scaled=\n",
      " [[-0.59767986  1.26657672  0.19941154  0.19742669]\n",
      " [ 0.20137519  1.66638279  0.46685068 -1.54075895]\n",
      " [-0.86403154 -0.19937884  0.86800938 -1.13963919]]\n",
      "-->\n",
      "prediction\n",
      "['8 22 14 14', '14 25 16 1', '6 11 19 4']\n",
      "check prediction\n",
      "y_test=\n",
      " [[ 8 22 14 14]\n",
      " [14 25 16  1]\n",
      " [ 6 11 19  4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "nb_words_to_test = 3\n",
    "\n",
    "x_test = create_inputs(nb_words_to_test, nb_chars, nb_letters)\n",
    "print_readable_inputs(x_test)\n",
    "print(\"x_test=\\n\", x_test)\n",
    "\n",
    "x_test_scaled  = scaler.transform(x_test)\n",
    "print(\"x_test_scaled=\\n\", x_test_scaled)\n",
    "print('-->')\n",
    "\n",
    "prediction = coding_model.predict(x_test_scaled)\n",
    "#print(prediction)\n",
    "print('prediction')\n",
    "print_readable_outputs(prediction, nb_words_to_test, nb_chars)\n",
    "\n",
    "print('check prediction')\n",
    "y_test = encrypt(x_test, nb_words_to_test, nb_chars)\n",
    "print(\"y_test=\\n\", y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
