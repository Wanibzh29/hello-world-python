{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.__version__=1.3.0\n",
      "keras.__version__=1.2.2\n"
     ]
    }
   ],
   "source": [
    "print('tf.__version__='+tf.__version__)\n",
    "print('keras.__version__='+keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_y(x):\n",
    "    x0 = x[0]\n",
    "    x1 = x[1]\n",
    "    x2 = x[2]\n",
    "    x3 = x[3]\n",
    "    y = 10 + 5*x0 + 200*x1*x1 + 3000*x2*x2*x2 + 3*x3*x3*x3*x3\n",
    "    return y\n",
    "    \n",
    "def create_x_y(nb_samples):\n",
    "    x0 = np.array([0.0, 1.0, 2.0, 3.0])\n",
    "    y0 = calculate_y(x0)\n",
    "    X = x0\n",
    "    Y = y0\n",
    "\n",
    "    for i in range(nb_samples-1):\n",
    "\n",
    "        x = np.array([0.0, 1.0, 2.0, 3.0])\n",
    "        x[0] = x[0] + random.uniform(0, 1) - 0.5\n",
    "        x[1] = x[1] + random.uniform(0, 1) - 0.5\n",
    "        x[2] = x[2] + random.uniform(0, 1) - 0.5\n",
    "        x[3] = x[3] + random.uniform(0, 1) - 0.5\n",
    "        X = np.vstack([X, x])\n",
    "    \n",
    "        y = calculate_y(x)\n",
    "        Y = np.vstack([Y, y])\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 4)\n",
      "(8000, 1)\n",
      "(2000, 4)\n",
      "4\n",
      "(2000, 1)\n"
     ]
    }
   ],
   "source": [
    "nb_samples = 10000\n",
    "\n",
    "train_data, train_targets = create_x_y(int(nb_samples*.8))\n",
    "print(train_data.shape)\n",
    "print(train_targets.shape)\n",
    "\n",
    "test_data, test_targets = create_x_y(int(nb_samples*.2))\n",
    "print(test_data.shape)\n",
    "print(test_data.shape[1])\n",
    "print(test_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "8000/8000 [==============================] - 0s - loss: 779577972.8000 - mean_absolute_error: 25847.1815     \n",
      "Epoch 2/150\n",
      "8000/8000 [==============================] - 0s - loss: 679803463.2000 - mean_absolute_error: 23853.9530     \n",
      "Epoch 3/150\n",
      "8000/8000 [==============================] - 0s - loss: 428791981.8000 - mean_absolute_error: 17848.4400     \n",
      "Epoch 4/150\n",
      "8000/8000 [==============================] - 0s - loss: 152188682.4100 - mean_absolute_error: 9698.3150     \n",
      "Epoch 5/150\n",
      "8000/8000 [==============================] - 0s - loss: 91253087.3700 - mean_absolute_error: 8234.0138     \n",
      "Epoch 6/150\n",
      "8000/8000 [==============================] - 0s - loss: 88870081.8700 - mean_absolute_error: 8141.4833     \n",
      "Epoch 7/150\n",
      "8000/8000 [==============================] - 0s - loss: 86565524.4500 - mean_absolute_error: 8034.9970     \n",
      "Epoch 8/150\n",
      "8000/8000 [==============================] - 0s - loss: 84114554.5800 - mean_absolute_error: 7929.7359     \n",
      "Epoch 9/150\n",
      "8000/8000 [==============================] - 0s - loss: 81711716.6000 - mean_absolute_error: 7820.1072     \n",
      "Epoch 10/150\n",
      "8000/8000 [==============================] - 0s - loss: 79216382.4400 - mean_absolute_error: 7704.1637     \n",
      "Epoch 11/150\n",
      "8000/8000 [==============================] - 0s - loss: 76710233.9300 - mean_absolute_error: 7586.5671     \n",
      "Epoch 12/150\n",
      "8000/8000 [==============================] - 0s - loss: 73997774.3300 - mean_absolute_error: 7452.5164     \n",
      "Epoch 13/150\n",
      "8000/8000 [==============================] - 0s - loss: 71144168.5600 - mean_absolute_error: 7314.0147     \n",
      "Epoch 14/150\n",
      "8000/8000 [==============================] - 0s - loss: 68144569.8400 - mean_absolute_error: 7163.8485     \n",
      "Epoch 15/150\n",
      "8000/8000 [==============================] - 0s - loss: 65019269.1750 - mean_absolute_error: 7001.2617     \n",
      "Epoch 16/150\n",
      "8000/8000 [==============================] - 0s - loss: 61634942.8750 - mean_absolute_error: 6819.3381     \n",
      "Epoch 17/150\n",
      "8000/8000 [==============================] - 0s - loss: 57937252.4650 - mean_absolute_error: 6614.6977     \n",
      "Epoch 18/150\n",
      "8000/8000 [==============================] - 0s - loss: 54069680.6800 - mean_absolute_error: 6391.6430     \n",
      "Epoch 19/150\n",
      "8000/8000 [==============================] - 0s - loss: 49703290.9550 - mean_absolute_error: 6134.4933     \n",
      "Epoch 20/150\n",
      "8000/8000 [==============================] - 0s - loss: 44773722.1750 - mean_absolute_error: 5822.3720     \n",
      "Epoch 21/150\n",
      "8000/8000 [==============================] - 0s - loss: 39594282.0650 - mean_absolute_error: 5466.0506     \n",
      "Epoch 22/150\n",
      "8000/8000 [==============================] - 0s - loss: 33895188.9450 - mean_absolute_error: 5044.3358     \n",
      "Epoch 23/150\n",
      "8000/8000 [==============================] - 0s - loss: 28052718.0350 - mean_absolute_error: 4563.6958     \n",
      "Epoch 24/150\n",
      "8000/8000 [==============================] - 0s - loss: 22433877.7100 - mean_absolute_error: 4028.6750     \n",
      "Epoch 25/150\n",
      "8000/8000 [==============================] - 0s - loss: 17710930.8113 - mean_absolute_error: 3499.7989     \n",
      "Epoch 26/150\n",
      "8000/8000 [==============================] - 0s - loss: 14441883.3063 - mean_absolute_error: 3100.7035     \n",
      "Epoch 27/150\n",
      "8000/8000 [==============================] - 0s - loss: 12538656.9269 - mean_absolute_error: 2863.6290     \n",
      "Epoch 28/150\n",
      "8000/8000 [==============================] - 0s - loss: 11447332.0600 - mean_absolute_error: 2733.1134     \n",
      "Epoch 29/150\n",
      "8000/8000 [==============================] - 0s - loss: 10708577.9725 - mean_absolute_error: 2651.7218     \n",
      "Epoch 30/150\n",
      "8000/8000 [==============================] - 0s - loss: 10123890.1400 - mean_absolute_error: 2582.4602     \n",
      "Epoch 31/150\n",
      "8000/8000 [==============================] - 0s - loss: 9675520.9919 - mean_absolute_error: 2532.0519     \n",
      "Epoch 32/150\n",
      "8000/8000 [==============================] - 0s - loss: 9268961.0031 - mean_absolute_error: 2480.7640     \n",
      "Epoch 33/150\n",
      "8000/8000 [==============================] - 0s - loss: 8911986.2356 - mean_absolute_error: 2436.6811     \n",
      "Epoch 34/150\n",
      "8000/8000 [==============================] - 0s - loss: 8540154.0813 - mean_absolute_error: 2386.7859     \n",
      "Epoch 35/150\n",
      "8000/8000 [==============================] - 0s - loss: 8213794.6850 - mean_absolute_error: 2341.7602     \n",
      "Epoch 36/150\n",
      "8000/8000 [==============================] - 0s - loss: 7868435.6975 - mean_absolute_error: 2293.7428     \n",
      "Epoch 37/150\n",
      "8000/8000 [==============================] - 0s - loss: 7557206.7725 - mean_absolute_error: 2249.0662     \n",
      "Epoch 38/150\n",
      "8000/8000 [==============================] - 0s - loss: 7221643.1312 - mean_absolute_error: 2198.2056     \n",
      "Epoch 39/150\n",
      "8000/8000 [==============================] - 0s - loss: 6880564.3681 - mean_absolute_error: 2147.0038     \n",
      "Epoch 40/150\n",
      "8000/8000 [==============================] - 0s - loss: 6578084.5094 - mean_absolute_error: 2098.4079     \n",
      "Epoch 41/150\n",
      "8000/8000 [==============================] - 0s - loss: 6264695.0047 - mean_absolute_error: 2046.1425     \n",
      "Epoch 42/150\n",
      "8000/8000 [==============================] - 0s - loss: 5958413.2425 - mean_absolute_error: 1995.6087     \n",
      "Epoch 43/150\n",
      "8000/8000 [==============================] - 0s - loss: 5589327.2619 - mean_absolute_error: 1926.2064     \n",
      "Epoch 44/150\n",
      "8000/8000 [==============================] - 0s - loss: 5281671.3731 - mean_absolute_error: 1869.8321     \n",
      "Epoch 45/150\n",
      "8000/8000 [==============================] - 0s - loss: 4989360.1206 - mean_absolute_error: 1818.2878     \n",
      "Epoch 46/150\n",
      "8000/8000 [==============================] - 0s - loss: 4718268.0769 - mean_absolute_error: 1766.8057     \n",
      "Epoch 47/150\n",
      "8000/8000 [==============================] - 0s - loss: 4448879.5231 - mean_absolute_error: 1713.8392     \n",
      "Epoch 48/150\n",
      "8000/8000 [==============================] - 0s - loss: 4190373.9634 - mean_absolute_error: 1662.5600     \n",
      "Epoch 49/150\n",
      "8000/8000 [==============================] - 0s - loss: 3929814.3659 - mean_absolute_error: 1607.3607     \n",
      "Epoch 50/150\n",
      "8000/8000 [==============================] - 0s - loss: 3698487.4683 - mean_absolute_error: 1558.5396     \n",
      "Epoch 51/150\n",
      "8000/8000 [==============================] - 0s - loss: 3485374.8737 - mean_absolute_error: 1510.9438     \n",
      "Epoch 52/150\n",
      "8000/8000 [==============================] - 0s - loss: 3265034.1328 - mean_absolute_error: 1460.5108     \n",
      "Epoch 53/150\n",
      "8000/8000 [==============================] - 0s - loss: 3057273.8344 - mean_absolute_error: 1413.1981     \n",
      "Epoch 54/150\n",
      "8000/8000 [==============================] - 0s - loss: 2870197.8642 - mean_absolute_error: 1369.5171     \n",
      "Epoch 55/150\n",
      "8000/8000 [==============================] - 0s - loss: 2638002.6847 - mean_absolute_error: 1310.9602     \n",
      "Epoch 56/150\n",
      "8000/8000 [==============================] - 0s - loss: 2387515.4803 - mean_absolute_error: 1241.7493     \n",
      "Epoch 57/150\n",
      "8000/8000 [==============================] - 0s - loss: 2216383.9612 - mean_absolute_error: 1198.4374     \n",
      "Epoch 58/150\n",
      "8000/8000 [==============================] - 0s - loss: 2063541.2636 - mean_absolute_error: 1158.9274     \n",
      "Epoch 59/150\n",
      "8000/8000 [==============================] - 0s - loss: 1910530.7002 - mean_absolute_error: 1116.2978     \n",
      "Epoch 60/150\n",
      "8000/8000 [==============================] - 0s - loss: 1778339.6683 - mean_absolute_error: 1081.1839     \n",
      "Epoch 61/150\n",
      "8000/8000 [==============================] - 0s - loss: 1660281.0194 - mean_absolute_error: 1047.2420     \n",
      "Epoch 62/150\n",
      "8000/8000 [==============================] - 0s - loss: 1554725.7833 - mean_absolute_error: 1016.8213     \n",
      "Epoch 63/150\n",
      "8000/8000 [==============================] - 0s - loss: 1463629.7637 - mean_absolute_error: 991.3097     \n",
      "Epoch 64/150\n",
      "8000/8000 [==============================] - 0s - loss: 1377911.6870 - mean_absolute_error: 965.0083     \n",
      "Epoch 65/150\n",
      "8000/8000 [==============================] - 0s - loss: 1302142.3255 - mean_absolute_error: 940.7084     \n",
      "Epoch 66/150\n",
      "8000/8000 [==============================] - 0s - loss: 1236182.8816 - mean_absolute_error: 920.9789     \n",
      "Epoch 67/150\n",
      "8000/8000 [==============================] - 0s - loss: 1172629.9825 - mean_absolute_error: 898.8813     \n",
      "Epoch 68/150\n",
      "8000/8000 [==============================] - 0s - loss: 1117863.0157 - mean_absolute_error: 878.1326     \n",
      "Epoch 69/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s - loss: 1069359.3855 - mean_absolute_error: 860.7580     \n",
      "Epoch 70/150\n",
      "8000/8000 [==============================] - 0s - loss: 1023743.7405 - mean_absolute_error: 843.8421     \n",
      "Epoch 71/150\n",
      "8000/8000 [==============================] - 0s - loss: 982014.2732 - mean_absolute_error: 826.0464     \n",
      "Epoch 72/150\n",
      "8000/8000 [==============================] - 0s - loss: 938692.8213 - mean_absolute_error: 808.3484     \n",
      "Epoch 73/150\n",
      "8000/8000 [==============================] - 0s - loss: 904689.7464 - mean_absolute_error: 793.4531     \n",
      "Epoch 74/150\n",
      "8000/8000 [==============================] - 0s - loss: 868684.0303 - mean_absolute_error: 776.5674     \n",
      "Epoch 75/150\n",
      "8000/8000 [==============================] - 0s - loss: 838202.9518 - mean_absolute_error: 762.3003     \n",
      "Epoch 76/150\n",
      "8000/8000 [==============================] - 0s - loss: 806494.2434 - mean_absolute_error: 745.9733     \n",
      "Epoch 77/150\n",
      "8000/8000 [==============================] - 0s - loss: 772006.7042 - mean_absolute_error: 728.3899     \n",
      "Epoch 78/150\n",
      "8000/8000 [==============================] - 0s - loss: 705354.3993 - mean_absolute_error: 692.0614     \n",
      "Epoch 79/150\n",
      "8000/8000 [==============================] - 0s - loss: 631463.9348 - mean_absolute_error: 646.7754     \n",
      "Epoch 80/150\n",
      "8000/8000 [==============================] - 0s - loss: 599470.9735 - mean_absolute_error: 628.5184     \n",
      "Epoch 81/150\n",
      "8000/8000 [==============================] - 0s - loss: 575254.9641 - mean_absolute_error: 613.2482     \n",
      "Epoch 82/150\n",
      "8000/8000 [==============================] - 0s - loss: 549479.1008 - mean_absolute_error: 596.9897     \n",
      "Epoch 83/150\n",
      "8000/8000 [==============================] - 0s - loss: 523369.6061 - mean_absolute_error: 580.2936     \n",
      "Epoch 84/150\n",
      "8000/8000 [==============================] - 0s - loss: 500676.0610 - mean_absolute_error: 563.4183     \n",
      "Epoch 85/150\n",
      "8000/8000 [==============================] - 0s - loss: 478017.0538 - mean_absolute_error: 548.2289     \n",
      "Epoch 86/150\n",
      "8000/8000 [==============================] - 0s - loss: 458045.9318 - mean_absolute_error: 535.1326     \n",
      "Epoch 87/150\n",
      "8000/8000 [==============================] - 0s - loss: 438608.8010 - mean_absolute_error: 521.4612     \n",
      "Epoch 88/150\n",
      "8000/8000 [==============================] - 0s - loss: 420301.7234 - mean_absolute_error: 508.4899     \n",
      "Epoch 89/150\n",
      "8000/8000 [==============================] - 0s - loss: 406508.9071 - mean_absolute_error: 499.3701     \n",
      "Epoch 90/150\n",
      "8000/8000 [==============================] - 0s - loss: 390094.1516 - mean_absolute_error: 489.3036     \n",
      "Epoch 91/150\n",
      "8000/8000 [==============================] - 0s - loss: 376610.3606 - mean_absolute_error: 479.8206     \n",
      "Epoch 92/150\n",
      "8000/8000 [==============================] - 0s - loss: 364254.2940 - mean_absolute_error: 472.5221     \n",
      "Epoch 93/150\n",
      "8000/8000 [==============================] - 0s - loss: 349887.1411 - mean_absolute_error: 463.3575     \n",
      "Epoch 94/150\n",
      "8000/8000 [==============================] - 0s - loss: 336891.9854 - mean_absolute_error: 451.5050     \n",
      "Epoch 95/150\n",
      "8000/8000 [==============================] - 0s - loss: 324493.8665 - mean_absolute_error: 441.2150     \n",
      "Epoch 96/150\n",
      "8000/8000 [==============================] - 0s - loss: 310183.6018 - mean_absolute_error: 429.7507     \n",
      "Epoch 97/150\n",
      "8000/8000 [==============================] - 0s - loss: 298775.0713 - mean_absolute_error: 421.1816     \n",
      "Epoch 98/150\n",
      "8000/8000 [==============================] - 0s - loss: 287309.5434 - mean_absolute_error: 413.0108     \n",
      "Epoch 99/150\n",
      "8000/8000 [==============================] - 0s - loss: 275452.2502 - mean_absolute_error: 403.3266     \n",
      "Epoch 100/150\n",
      "8000/8000 [==============================] - 0s - loss: 266468.5088 - mean_absolute_error: 395.7161     \n",
      "Epoch 101/150\n",
      "8000/8000 [==============================] - 0s - loss: 255429.1622 - mean_absolute_error: 386.2615     \n",
      "Epoch 102/150\n",
      "8000/8000 [==============================] - 0s - loss: 245098.0479 - mean_absolute_error: 378.9198     \n",
      "Epoch 103/150\n",
      "8000/8000 [==============================] - 0s - loss: 236587.9379 - mean_absolute_error: 371.6921     \n",
      "Epoch 104/150\n",
      "8000/8000 [==============================] - 0s - loss: 226515.0420 - mean_absolute_error: 362.1265     \n",
      "Epoch 105/150\n",
      "8000/8000 [==============================] - 0s - loss: 218207.6506 - mean_absolute_error: 355.5415     \n",
      "Epoch 106/150\n",
      "8000/8000 [==============================] - 0s - loss: 208896.9184 - mean_absolute_error: 348.0611     \n",
      "Epoch 107/150\n",
      "8000/8000 [==============================] - 0s - loss: 201479.0603 - mean_absolute_error: 342.2653     \n",
      "Epoch 108/150\n",
      "8000/8000 [==============================] - 0s - loss: 192971.6959 - mean_absolute_error: 334.1756     \n",
      "Epoch 109/150\n",
      "8000/8000 [==============================] - 0s - loss: 185817.9721 - mean_absolute_error: 327.2052     \n",
      "Epoch 110/150\n",
      "8000/8000 [==============================] - 0s - loss: 177874.7880 - mean_absolute_error: 319.7666     \n",
      "Epoch 111/150\n",
      "8000/8000 [==============================] - 0s - loss: 169508.5515 - mean_absolute_error: 311.3130     \n",
      "Epoch 112/150\n",
      "8000/8000 [==============================] - 0s - loss: 162722.4175 - mean_absolute_error: 305.3483     \n",
      "Epoch 113/150\n",
      "8000/8000 [==============================] - 0s - loss: 155996.8493 - mean_absolute_error: 297.9458     \n",
      "Epoch 114/150\n",
      "8000/8000 [==============================] - 0s - loss: 148583.6818 - mean_absolute_error: 290.7134     \n",
      "Epoch 115/150\n",
      "8000/8000 [==============================] - 0s - loss: 142862.1850 - mean_absolute_error: 284.7763     \n",
      "Epoch 116/150\n",
      "8000/8000 [==============================] - 0s - loss: 136019.6014 - mean_absolute_error: 278.3778     \n",
      "Epoch 117/150\n",
      "8000/8000 [==============================] - 0s - loss: 130125.7127 - mean_absolute_error: 271.5159     \n",
      "Epoch 118/150\n",
      "8000/8000 [==============================] - 0s - loss: 123585.3310 - mean_absolute_error: 263.8779     \n",
      "Epoch 119/150\n",
      "8000/8000 [==============================] - 0s - loss: 117902.0609 - mean_absolute_error: 257.8900     \n",
      "Epoch 120/150\n",
      "8000/8000 [==============================] - 0s - loss: 112536.2227 - mean_absolute_error: 250.9400     \n",
      "Epoch 121/150\n",
      "8000/8000 [==============================] - 0s - loss: 106791.9266 - mean_absolute_error: 245.2923     \n",
      "Epoch 122/150\n",
      "8000/8000 [==============================] - 0s - loss: 101279.6836 - mean_absolute_error: 237.5424     \n",
      "Epoch 123/150\n",
      "8000/8000 [==============================] - 0s - loss: 96654.4147 - mean_absolute_error: 232.9214     \n",
      "Epoch 124/150\n",
      "8000/8000 [==============================] - 0s - loss: 92590.3213 - mean_absolute_error: 227.6658     \n",
      "Epoch 125/150\n",
      "8000/8000 [==============================] - 0s - loss: 87097.9235 - mean_absolute_error: 220.8734     \n",
      "Epoch 126/150\n",
      "8000/8000 [==============================] - 0s - loss: 82297.7378 - mean_absolute_error: 214.0702     \n",
      "Epoch 127/150\n",
      "8000/8000 [==============================] - 0s - loss: 77938.7680 - mean_absolute_error: 208.4048     \n",
      "Epoch 128/150\n",
      "8000/8000 [==============================] - 0s - loss: 74368.4380 - mean_absolute_error: 203.3548     \n",
      "Epoch 129/150\n",
      "8000/8000 [==============================] - 0s - loss: 70677.9006 - mean_absolute_error: 197.4367     \n",
      "Epoch 130/150\n",
      "8000/8000 [==============================] - 0s - loss: 66986.7439 - mean_absolute_error: 192.7717     \n",
      "Epoch 131/150\n",
      "8000/8000 [==============================] - 0s - loss: 63233.0450 - mean_absolute_error: 187.4521     \n",
      "Epoch 132/150\n",
      "8000/8000 [==============================] - 0s - loss: 60244.9033 - mean_absolute_error: 182.8214     \n",
      "Epoch 133/150\n",
      "8000/8000 [==============================] - 0s - loss: 57550.0555 - mean_absolute_error: 178.3027     \n",
      "Epoch 134/150\n",
      "8000/8000 [==============================] - 0s - loss: 53772.1997 - mean_absolute_error: 171.9719     \n",
      "Epoch 135/150\n",
      "8000/8000 [==============================] - 0s - loss: 51258.4819 - mean_absolute_error: 168.4233     \n",
      "Epoch 136/150\n",
      "8000/8000 [==============================] - 0s - loss: 48716.2052 - mean_absolute_error: 163.6974     \n",
      "Epoch 137/150\n",
      "8000/8000 [==============================] - 0s - loss: 46527.3376 - mean_absolute_error: 160.2772     \n",
      "Epoch 138/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s - loss: 43810.1073 - mean_absolute_error: 155.5740     \n",
      "Epoch 139/150\n",
      "8000/8000 [==============================] - 0s - loss: 42030.6162 - mean_absolute_error: 152.7364     \n",
      "Epoch 140/150\n",
      "8000/8000 [==============================] - 0s - loss: 40044.4972 - mean_absolute_error: 149.4600     \n",
      "Epoch 141/150\n",
      "8000/8000 [==============================] - 0s - loss: 37969.0165 - mean_absolute_error: 145.1027     \n",
      "Epoch 142/150\n",
      "8000/8000 [==============================] - 0s - loss: 36177.7404 - mean_absolute_error: 142.2909     \n",
      "Epoch 143/150\n",
      "8000/8000 [==============================] - 0s - loss: 34443.1049 - mean_absolute_error: 138.9111     \n",
      "Epoch 144/150\n",
      "8000/8000 [==============================] - 0s - loss: 33069.6938 - mean_absolute_error: 136.8885     \n",
      "Epoch 145/150\n",
      "8000/8000 [==============================] - 0s - loss: 31832.3986 - mean_absolute_error: 134.4374     \n",
      "Epoch 146/150\n",
      "8000/8000 [==============================] - 0s - loss: 30337.0436 - mean_absolute_error: 131.9039     \n",
      "Epoch 147/150\n",
      "8000/8000 [==============================] - 0s - loss: 29317.3542 - mean_absolute_error: 129.4324     \n",
      "Epoch 148/150\n",
      "8000/8000 [==============================] - 0s - loss: 28046.6475 - mean_absolute_error: 127.5042     \n",
      "Epoch 149/150\n",
      "8000/8000 [==============================] - 0s - loss: 27537.8013 - mean_absolute_error: 126.7068     \n",
      "Epoch 150/150\n",
      "8000/8000 [==============================] - 0s - loss: 26495.3733 - mean_absolute_error: 124.5644     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5d0c7a33c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_dim=4, input_shape=(train_data.shape[1],)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['mae'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_data, train_targets, nb_epoch=150, batch_size=20,  verbose=1)\n",
    "\n",
    "# calculate predictions\n",
    "#predictions = model.predict(X)\n",
    "\n",
    "# round predictions\n",
    "#rounded = [round(x[0]) for x in predictions]\n",
    "#print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0.0, 1.0, 2.0, 3.0])\n",
    "y0 = calculate_y(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          1.          2.          3.        ]\n",
      " [-0.35222132  1.17974134  1.63493743  3.06029932]]\n",
      "[[24453.        ]\n",
      " [13660.39412834]]\n"
     ]
    }
   ],
   "source": [
    "test_data, test_targets = create_x_y(2)\n",
    "print(test_data)\n",
    "print(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24458.848]\n",
      " [13794.267]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
